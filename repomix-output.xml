This file is a merged representation of the entire codebase, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.cargo/config.toml
.gitignore
app.rc
assets/app-icon-small-light.png
assets/app-icon-small.png
assets/app.ico
assets/GoogleSansFlex-VariableFont_GRAD,ROND,opsz,slnt,wdth,wght.ttf
assets/tray_icon-light.png
assets/tray_icon.png
build.ps1
build.rs
Cargo.toml
docs/images/demo-video.gif
docs/images/screenshot.png
docs/WEBVIEW2_INITIALIZATION.md
installer.nsi
promptdj-midi/.gitignore
promptdj-midi/components/OnboardingPopup.ts
promptdj-midi/components/PlayPauseButton.ts
promptdj-midi/components/PlayPauseMorphWrapper.tsx
promptdj-midi/components/PromptController.ts
promptdj-midi/components/PromptDjMidi.ts
promptdj-midi/components/react/LoadingIndicator.css
promptdj-midi/components/react/LoadingIndicator.jsx
promptdj-midi/components/react/LoadingIndicator/cubic.js
promptdj-midi/components/react/LoadingIndicator/featureMapper.js
promptdj-midi/components/react/LoadingIndicator/floatMapping.js
promptdj-midi/components/react/LoadingIndicator/measuredPolygon.js
promptdj-midi/components/react/LoadingIndicator/morph-fixed.js
promptdj-midi/components/react/LoadingIndicator/roundedPolygon.js
promptdj-midi/components/react/LoadingIndicator/utils.js
promptdj-midi/components/react/material-switch.css
promptdj-midi/components/react/PlayPauseMorphType4.jsx
promptdj-midi/components/ToastMessage.ts
promptdj-midi/components/WeightKnob.ts
promptdj-midi/index.css
promptdj-midi/index.html
promptdj-midi/index.tsx
promptdj-midi/metadata.json
promptdj-midi/package.json
promptdj-midi/README.md
promptdj-midi/styles/material-tokens.css
promptdj-midi/tsconfig.json
promptdj-midi/types.ts
promptdj-midi/utils/audio.ts
promptdj-midi/utils/AudioAnalyser.ts
promptdj-midi/utils/AudioProcessing.ts
promptdj-midi/utils/LiveMusicHelper.ts
promptdj-midi/utils/Locales.ts
promptdj-midi/utils/MidiDispatcher.ts
promptdj-midi/utils/throttle.ts
promptdj-midi/vite.config.ts
README.md
screen-record/.gitignore
screen-record/components.json
screen-record/index.html
screen-record/package.json
screen-record/postcss.config.js
screen-record/public/pointer.svg
screen-record/public/screenshot.png
screen-record/public/tauri.svg
screen-record/public/vite.svg
screen-record/README.md
screen-record/src/App.css
screen-record/src/App.tsx
screen-record/src/assets/logo.svg
screen-record/src/assets/react.svg
screen-record/src/components/Timeline.tsx
screen-record/src/components/ui/button.tsx
screen-record/src/hooks/useUndoRedo.ts
screen-record/src/lib/autoZoom.ts
screen-record/src/lib/projectManager.ts
screen-record/src/lib/thumbnailGenerator.ts
screen-record/src/lib/utils.ts
screen-record/src/lib/videoController.ts
screen-record/src/lib/videoExporter.ts
screen-record/src/lib/videoRenderer.ts
screen-record/src/main.tsx
screen-record/src/types/video.ts
screen-record/src/vite-env.d.ts
screen-record/tailwind.config.js
screen-record/tsconfig.json
screen-record/tsconfig.node.json
screen-record/vite.config.ts
scripts/setup-egui-snarl.ps1
src/api/audio.rs
src/api/client.rs
src/api/gemini_live/manager.rs
src/api/gemini_live/mod.rs
src/api/gemini_live/types.rs
src/api/gemini_live/websocket.rs
src/api/gemini_live/worker.rs
src/api/mod.rs
src/api/ollama.rs
src/api/realtime_audio/capture.rs
src/api/realtime_audio/mod.rs
src/api/realtime_audio/model_loader.rs
src/api/realtime_audio/parakeet.rs
src/api/realtime_audio/state.rs
src/api/realtime_audio/transcription.rs
src/api/realtime_audio/translation.rs
src/api/realtime_audio/utils.rs
src/api/realtime_audio/websocket.rs
src/api/text.rs
src/api/tts/edge_voices.rs
src/api/tts/instance.rs
src/api/tts/manager.rs
src/api/tts/mod.rs
src/api/tts/player.rs
src/api/tts/types.rs
src/api/tts/utils.rs
src/api/tts/websocket.rs
src/api/tts/worker.rs
src/api/tts/wsola.rs
src/api/types.rs
src/api/vision.rs
src/assets.rs
src/config/config.rs
src/config/io.rs
src/config/mod.rs
src/config/preset/block.rs
src/config/preset/defaults/audio.rs
src/config/preset/defaults/image.rs
src/config/preset/defaults/master.rs
src/config/preset/defaults/mod.rs
src/config/preset/defaults/text.rs
src/config/preset/mod.rs
src/config/preset/preset.rs
src/config/types/enums.rs
src/config/types/hotkey.rs
src/config/types/mod.rs
src/config/types/tts.rs
src/debug_log.rs
src/embed_dlls/DirectML.dll
src/embed_dlls/msvcp140_1.dll
src/embed_dlls/msvcp140.dll
src/embed_dlls/onnxruntime.dll
src/embed_dlls/vcruntime140_1.dll
src/embed_dlls/vcruntime140.dll
src/gui/app.rs
src/gui/app/init.rs
src/gui/app/input_handler.rs
src/gui/app/logic.rs
src/gui/app/rendering.rs
src/gui/app/types.rs
src/gui/app/utils.rs
src/gui/icons.rs
src/gui/key_mapping.rs
src/gui/locale.rs
src/gui/mod.rs
src/gui/settings_ui/download_manager/detection.rs
src/gui/settings_ui/download_manager/mod.rs
src/gui/settings_ui/download_manager/persistence.rs
src/gui/settings_ui/download_manager/run.rs
src/gui/settings_ui/download_manager/types.rs
src/gui/settings_ui/download_manager/ui.rs
src/gui/settings_ui/download_manager/utils.rs
src/gui/settings_ui/footer.rs
src/gui/settings_ui/global/downloaded_tools.rs
src/gui/settings_ui/global/mod.rs
src/gui/settings_ui/global/tts_settings.rs
src/gui/settings_ui/global/update_section.rs
src/gui/settings_ui/global/usage_stats.rs
src/gui/settings_ui/help_assistant.rs
src/gui/settings_ui/history.rs
src/gui/settings_ui/mod.rs
src/gui/settings_ui/node_graph/body.rs
src/gui/settings_ui/node_graph/conversion.rs
src/gui/settings_ui/node_graph/mod.rs
src/gui/settings_ui/node_graph/node.rs
src/gui/settings_ui/node_graph/utils.rs
src/gui/settings_ui/node_graph/viewer.rs
src/gui/settings_ui/preset.rs
src/gui/settings_ui/sidebar.rs
src/gui/splash.rs
src/gui/utils.rs
src/history.rs
src/icon_gen.rs
src/main.rs
src/model_config.rs
src/overlay/auto_copy_badge.rs
src/overlay/broom_assets.rs
src/overlay/continuous_mode.rs
src/overlay/favorite_bubble/html.rs
src/overlay/favorite_bubble/mod.rs
src/overlay/favorite_bubble/panel.rs
src/overlay/favorite_bubble/render.rs
src/overlay/favorite_bubble/state.rs
src/overlay/favorite_bubble/utils.rs
src/overlay/favorite_bubble/window.rs
src/overlay/html_components/css_main.rs
src/overlay/html_components/css_modals.rs
src/overlay/html_components/font_manager.rs
src/overlay/html_components/grid_js.rs
src/overlay/html_components/icons.rs
src/overlay/html_components/js_logic.rs
src/overlay/html_components/js_main.rs
src/overlay/html_components/mod.rs
src/overlay/input_history.rs
src/overlay/mod.rs
src/overlay/paint_utils.rs
src/overlay/preset_wheel/html.rs
src/overlay/preset_wheel/mod.rs
src/overlay/preset_wheel/window.rs
src/overlay/process/chain.rs
src/overlay/process/mod.rs
src/overlay/process/pipeline.rs
src/overlay/process/types.rs
src/overlay/process/window.rs
src/overlay/prompt_dj/mod.rs
src/overlay/realtime_egui.rs
src/overlay/realtime_html.rs
src/overlay/realtime_webview.rs
src/overlay/realtime_webview/app_selection.rs
src/overlay/realtime_webview/manager.rs
src/overlay/realtime_webview/state.rs
src/overlay/realtime_webview/webview.rs
src/overlay/realtime_webview/wndproc.rs
src/overlay/recording.rs
src/overlay/result/button_canvas.rs
src/overlay/result/event_handler/click_actions.rs
src/overlay/result/event_handler/misc.rs
src/overlay/result/event_handler/mod.rs
src/overlay/result/event_handler/mouse_input.rs
src/overlay/result/event_handler/timer_tasks.rs
src/overlay/result/layout.rs
src/overlay/result/logic.rs
src/overlay/result/markdown_view.rs
src/overlay/result/mod.rs
src/overlay/result/paint.rs
src/overlay/result/state.rs
src/overlay/result/window.rs
src/overlay/screen_record/audio_engine.rs
src/overlay/screen_record/engine.rs
src/overlay/screen_record/keyviz_config.json
src/overlay/screen_record/keyviz.rs
src/overlay/screen_record/mod.rs
src/overlay/screen_record/native_export.rs
src/overlay/selection.rs
src/overlay/text_input.rs
src/overlay/text_selection_webview/html.rs
src/overlay/text_selection_webview/mod.rs
src/overlay/text_selection.rs
src/overlay/tray_popup.rs
src/overlay/utils.rs
src/registry_integration.rs
src/unpack_dlls.rs
src/updater.rs
src/win_types.rs
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="app.rc">
id ICON "assets/app.ico"

1 VERSIONINFO
FILEVERSION 3,5,1,0
PRODUCTVERSION 3,5,1,0
BEGIN
  BLOCK "StringFileInfo"
  BEGIN
    BLOCK "040904E4"
    BEGIN
      VALUE "CompanyName", "nganlinh4 - Open Source Developer"
      VALUE "FileDescription", "Screen Goated Toolbox - AI-powered screen capture and productivity tool. Open source on GitHub."
      VALUE "FileVersion", "3.5.1.0"
      VALUE "InternalName", "screen-goated-toolbox"
      VALUE "LegalCopyright", "Copyright (c) 2024-2025 nganlinh4. MIT License. https://github.com/nganlinh4/screen-goated-toolbox"
      VALUE "OriginalFilename", "ScreenGoatedToolbox.exe"
      VALUE "ProductName", "Screen Goated Toolbox (SGT)"
      VALUE "ProductVersion", "3.5.1.0"
    END
  END
  BLOCK "VarFileInfo"
  BEGIN
    VALUE "Translation", 0x409, 1252
  END
END
</file>

<file path="docs/WEBVIEW2_INITIALIZATION.md">
# WebView2 Initialization on Windows - Critical Notes

## The Problem

WebView2 (`wry` crate) creation can hang indefinitely on Windows when:
1. Called from deeply nested spawned threads
2. Called without proper warmup of the WebView2 infrastructure

## Root Cause

WebView2 requires the first `WebViewBuilder::build_as_child()` call to happen in a specific context:
- Thread spawned **directly from the main thread** 
- With a proper message loop running
- Window styles matching: `WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED` (NO `WS_EX_NOACTIVATE`)
- Base style: `WS_POPUP` (NO `WS_CLIPCHILDREN`)

When the first WebView is created from a thread that was spawned several levels deep in the call stack (e.g., hotkey handler → capture thread → process thread → result window thread), the WebView2 controller initialization hangs at `CreateCoreWebView2Controller`.

## The Solution: Warmup Pattern

Follow the same pattern as `text_input.rs`:

1. **Call warmup at app startup** (in `main.rs`):
```rust
overlay::result::markdown_view::warmup();
```

2. **Warmup spawns a dedicated thread** from the main thread context:
```rust
pub fn warmup() {
    std::thread::spawn(|| {
        warmup_internal();
    });
}
```

3. **Create a hidden window with WebView** in that thread:
```rust
fn warmup_internal() {
    // Create hidden window
    let hwnd = CreateWindowExW(
        WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED,
        class_name,
        w!("MarkdownWarmup"),
        WS_POPUP,
        0, 0, 100, 100,
        None, None, instance, None
    );
    
    // Make transparent
    SetLayeredWindowAttributes(hwnd, COLORREF(0), 0, LWA_ALPHA);
    
    // Create WebView - this "warms up" the WebView2 infrastructure
    let result = WebViewBuilder::new()
        .with_bounds(...)
        .with_html("<html><body>Warmup</body></html>")
        .with_transparent(false)
        .build_as_child(&wrapper);
    
    // Run message loop forever to keep thread alive
    while GetMessageW(&mut msg, None, 0, 0).into() {
        TranslateMessage(&msg);
        DispatchMessageW(&msg);
    }
}
```

4. **After warmup succeeds**, all subsequent WebView2 creations work - even from deeply nested threads!

## Why This Works

The first WebView2 creation initializes the shared WebView2 runtime infrastructure. Once initialized from a "good" thread context (spawned directly from main), all other threads can successfully create WebViews.

## Window Style Requirements for WebView2

| Style | Required for WebView2 |
|-------|----------------------|
| `WS_EX_NOACTIVATE` | ❌ AVOID - blocks initialization |
| `WS_CLIPCHILDREN` | ❌ AVOID - can interfere |
| `WS_EX_LAYERED` | ✅ OK |
| `WS_EX_TOOLWINDOW` | ✅ OK |
| `WS_EX_TOPMOST` | ✅ OK |
| `WS_POPUP` | ✅ Use as base style |

## Debug Tips

If WebView creation hangs:
1. Check if `[WARMUP] WebView created successfully!` appears at startup
2. If not, the warmup itself is failing
3. Add `eprintln!` at each step to find where it hangs
4. The typical hang point is Step 6 (`build_as_child()`)

## Related Files

- `src/overlay/result/markdown_view.rs` - Contains `warmup()` function
- `src/overlay/text_input.rs` - Reference implementation that works
- `src/main.rs` - Where warmup is called

---
*This issue was debugged in December 2024. The fix involved extensive investigation of thread spawning hierarchies, window styles, and COM initialization.*
</file>

<file path="installer.nsi">
; Screen Goated Toolbox Installer
!include "MUI2.nsh"
!include "x64.nsh"

; Basic Settings
Name "Screen Goated Toolbox"
OutFile "target\release\screen-goated-toolbox-installer.exe"
InstallDir "$PROGRAMFILES\ScreenGoatedToolbox"
RequestExecutionLevel admin
Icon ".\assets\app.ico"

; MUI Settings
!insertmacro MUI_PAGE_WELCOME
!insertmacro MUI_PAGE_DIRECTORY
!insertmacro MUI_PAGE_INSTFILES
!insertmacro MUI_PAGE_FINISH

!insertmacro MUI_LANGUAGE "English"

; Installer Sections
Section "Install Application"
  SetOutPath "$INSTDIR"
  
  ; Copy main executable
  File "target\release\screen-goated-toolbox.exe"
  
  ; Copy Visual C++ Runtime and install it
  File "vc_redist.x64.exe"
  DetailPrint "Installing Visual C++ Runtime..."
  ExecWait "$INSTDIR\vc_redist.x64.exe /quiet /norestart" $0
  Delete "$INSTDIR\vc_redist.x64.exe"
  
  ; Create Start Menu shortcut
  CreateDirectory "$SMPROGRAMS\Screen Goated Toolbox"
  CreateShortcut "$SMPROGRAMS\Screen Goated Toolbox\Screen Goated Toolbox.lnk" "$INSTDIR\screen-goated-toolbox.exe"
  CreateShortcut "$SMPROGRAMS\Screen Goated Toolbox\Uninstall.lnk" "$INSTDIR\uninstall.exe"
  
  ; Create Desktop shortcut (optional, uncomment if desired)
  ; CreateShortcut "$DESKTOP\Screen Goated Toolbox.lnk" "$INSTDIR\screen-goated-toolbox.exe"
  
  ; Write uninstaller
  WriteUninstaller "$INSTDIR\uninstall.exe"
  
  ; Write registry entry for Add/Remove Programs
  WriteRegStr HKLM "Software\Microsoft\Windows\CurrentVersion\Uninstall\ScreenGoatedToolbox" "DisplayName" "Screen Goated Toolbox"
  WriteRegStr HKLM "Software\Microsoft\Windows\CurrentVersion\Uninstall\ScreenGoatedToolbox" "UninstallString" "$INSTDIR\uninstall.exe"
  WriteRegStr HKLM "Software\Microsoft\Windows\CurrentVersion\Uninstall\ScreenGoatedToolbox" "InstallLocation" "$INSTDIR"
  WriteRegStr HKLM "Software\Microsoft\Windows\CurrentVersion\Uninstall\ScreenGoatedToolbox" "DisplayVersion" "1.6"
SectionEnd

; Uninstaller Section
Section "Uninstall"
  Delete "$INSTDIR\screen-goated-toolbox.exe"
  Delete "$INSTDIR\uninstall.exe"
  RMDir "$INSTDIR"
  
  Delete "$SMPROGRAMS\Screen Goated Toolbox\Screen Goated Toolbox.lnk"
  Delete "$SMPROGRAMS\Screen Goated Toolbox\Uninstall.lnk"
  RMDir "$SMPROGRAMS\Screen Goated Toolbox"
  
  Delete "$DESKTOP\Screen Goated Toolbox.lnk"
  
  DeleteRegKey HKLM "Software\Microsoft\Windows\CurrentVersion\Uninstall\ScreenGoatedToolbox"
SectionEnd
</file>

<file path="promptdj-midi/.gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
</file>

<file path="promptdj-midi/components/OnboardingPopup.ts">
import { css, html, LitElement } from 'lit';
import { customElement, state, property } from 'lit/decorators.js';
import { LOCALES, Lang } from '../utils/Locales';

@customElement('onboarding-popup')
export class OnboardingPopup extends LitElement {
    static override styles = css`
    :host {
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
    }
    .overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0, 0, 0, 0.6);
      backdrop-filter: blur(8px);
      z-index: 2000;
      display: flex;
      align-items: center;
      justify-content: center;
      animation: fadeIn 0.4s cubic-bezier(0.2, 0.0, 0, 1.0);
    }
    .popup {
      background: linear-gradient(145deg, rgba(30, 30, 30, 0.95), rgba(15, 15, 15, 0.98));
      border: 1px solid rgba(255, 255, 255, 0.15);
      border-radius: 20px;
      padding: 32px 40px;
      max-width: 480px;
      width: 90%;
      box-shadow: 0 20px 50px rgba(0, 0, 0, 0.6);
      display: flex;
      flex-direction: column;
      gap: 20px;
      transform: translateY(0);
      animation: slideUp 0.4s cubic-bezier(0.2, 0.0, 0, 1.0);
      color: #fff;
    }
    .title {
      font-size: 20px;
      font-weight: 600;
      margin: 0;
      color: #fff;
      display: flex;
      align-items: center;
      gap: 10px;
    }
    /* Simple info icon using CSS/Unicode or SVG. SVG is better. */
    .icon {
        color: #bb86fc;
        width: 24px;
        height: 24px;
    }
    .message {
      font-size: 16px;
      line-height: 1.6;
      opacity: 0.9;
      color: #e0e0e0;
      margin: 0;
    }
    .btn {
      align-self: flex-end;
      background: linear-gradient(135deg, #6200ea, #7c4dff);
      color: #fff;
      border: none;
      padding: 10px 24px;
      border-radius: 8px;
      font-size: 15px;
      font-weight: 600;
      cursor: pointer;
      transition: all 0.2s ease;
      font-family: inherit;
      box-shadow: 0 4px 12px rgba(98, 0, 234, 0.3);
    }
    .btn:hover {
      filter: brightness(1.1);
      transform: translateY(-1px);
      box-shadow: 0 6px 16px rgba(98, 0, 234, 0.4);
    }
    .btn:active {
      transform: translateY(0);
    }
    @keyframes fadeIn {
      from { opacity: 0; }
      to { opacity: 1; }
    }
    @keyframes slideUp {
      from { transform: translateY(20px); opacity: 0; }
      to { transform: translateY(0); opacity: 1; }
    }
  `;

    @property({ type: String }) lang: string = 'en';
    @state() private isVisible = false;

    connectedCallback() {
        super.connectedCallback();
        const seen = localStorage.getItem('pdj_onboarding_seen');
        if (!seen) {
            this.isVisible = true;
        }
    }

    private dismiss() {
        localStorage.setItem('pdj_onboarding_seen', 'true');
        this.isVisible = false;
    }

    render() {
        if (!this.isVisible) return html``;
        const t = LOCALES[this.lang as Lang];

        return html`
      <div class="overlay" @click=${this.dismiss}>
        <div class="popup" @click=${(e: Event) => e.stopPropagation()}>
          <h2 class="title">
            <svg class="icon" viewBox="0 0 24 24" fill="currentColor"><path d="M12 2C6.48 2 2 6.48 2 12s4.48 10 10 10 10-4.48 10-10S17.52 2 12 2zm1 15h-2v-6h2v6zm0-8h-2V7h2v2z"/></svg>
            ${t.onboarding_title}
          </h2>
          <p class="message">
            ${t.onboarding_msg}
          </p>
          <button class="btn" @click=${this.dismiss}>${t.onboarding_btn}</button>
        </div>
      </div>
    `;
    }
}
</file>

<file path="promptdj-midi/components/PlayPauseButton.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import { svg, css, html, LitElement } from 'lit';
import { customElement, property } from 'lit/decorators.js';
import type { PlaybackState } from '../types';

@customElement('play-pause-button')
export class PlayPauseButton extends LitElement {

  @property({ type: String }) playbackState: PlaybackState = 'stopped';

  static override styles = css`
    :host {
      position: relative;
      display: flex;
      align-items: center;
      justify-content: center;
      pointer-events: none;
    }
    :host(:hover) svg {
      transform: scale(1.2);
    }
    svg {
      width: 100%;
      height: 100%;
      transition: transform 0.5s cubic-bezier(0.25, 1.56, 0.32, 0.99);
    }
    .hitbox {
      pointer-events: all;
      position: absolute;
      width: 65%;
      aspect-ratio: 1;
      top: 9%;
      border-radius: 50%;
      cursor: pointer;
    }
    .loader {
      stroke: #ffffff;
      stroke-width: 3;
      stroke-linecap: round;
      animation: spin linear 1s infinite;
      transform-origin: center;
      transform-box: fill-box;
    }
    @keyframes spin {
      from { transform: rotate(0deg); }
      to { transform: rotate(359deg); }
    }
  `;

  private renderSvg() {
    return html` <svg
      width="140"
      height="140"
      viewBox="0 -10 140 150"
      fill="none"
      xmlns="http://www.w3.org/2000/svg">
      <rect
        x="22"
        y="6"
        width="96"
        height="96"
        rx="48"
        fill="black"
        fill-opacity="0.05" />
      <rect
        x="23.5"
        y="7.5"
        width="93"
        height="93"
        rx="46.5"
        stroke="black"
        stroke-opacity="0.3"
        stroke-width="3" />
      <g filter="url(#filter0_ddi_1048_7373)">
        <rect
          x="25"
          y="9"
          width="90"
          height="90"
          rx="45"
          fill="white"
          fill-opacity="0.05"
          shape-rendering="crispEdges" />
      </g>
      ${this.renderIcon()}
      <defs>
        <filter
          id="filter0_ddi_1048_7373"
          x="0"
          y="0"
          width="140"
          height="140"
          filterUnits="userSpaceOnUse"
          color-interpolation-filters="sRGB">
          <feFlood flood-opacity="0" result="BackgroundImageFix" />
          <feColorMatrix
            in="SourceAlpha"
            type="matrix"
            values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"
            result="hardAlpha" />
          <feOffset dy="2" />
          <feGaussianBlur stdDeviation="4" />
          <feComposite in2="hardAlpha" operator="out" />
          <feColorMatrix
            type="matrix"
            values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0" />
          <feBlend
            mode="normal"
            in2="BackgroundImageFix"
            result="effect1_dropShadow_1048_7373" />
          <feColorMatrix
            in="SourceAlpha"
            type="matrix"
            values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"
            result="hardAlpha" />
          <feOffset dy="16" />
          <feGaussianBlur stdDeviation="12.5" />
          <feComposite in2="hardAlpha" operator="out" />
          <feColorMatrix
            type="matrix"
            values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.25 0" />
          <feBlend
            mode="normal"
            in2="effect1_dropShadow_1048_7373"
            result="effect2_dropShadow_1048_7373" />
          <feBlend
            mode="normal"
            in="SourceGraphic"
            in2="effect2_dropShadow_1048_7373"
            result="shape" />
          <feColorMatrix
            in="SourceAlpha"
            type="matrix"
            values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 127 0"
            result="hardAlpha" />
          <feOffset dy="3" />
          <feGaussianBlur stdDeviation="1.5" />
          <feComposite in2="hardAlpha" operator="arithmetic" k2="-1" k3="1" />
          <feColorMatrix
            type="matrix"
            values="0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0.05 0" />
          <feBlend
            mode="normal"
            in2="shape"
            result="effect3_innerShadow_1048_7373" />
        </filter>
      </defs>
    </svg>`;
  }

  private renderPause() {
    return svg`<text x="70" y="54" fill="#FEFEFE" font-size="24" class="material-symbols-rounded">pause</text>`;
  }

  private renderPlay() {
    return svg`<text x="70" y="54" fill="#FEFEFE" font-size="24" class="material-symbols-rounded">play_arrow</text>`;
  }

  private renderLoading() {
    return svg`<text x="70" y="54" fill="#FEFEFE" font-size="24" class="material-symbols-rounded loader">sync</text>`;
  }

  private renderIcon() {
    if (this.playbackState === 'playing') {
      return this.renderPause();
    } else if (this.playbackState === 'loading') {
      return this.renderLoading();
    } else {
      return this.renderPlay();
    }
  }

  override render() {
    return html`${this.renderSvg()}<div class="hitbox"></div>`;
  }
}

declare global {
  interface HTMLElementTagNameMap {
    'play-pause-button': PlayPauseButton
  }
}
</file>

<file path="promptdj-midi/components/PlayPauseMorphWrapper.tsx">
import { createRoot, Root } from 'react-dom/client';
import PlayPauseMorphType4 from './react/PlayPauseMorphType4.jsx';
import LoadingIndicator from './react/LoadingIndicator.jsx';

class PlayPauseMorphElement extends HTMLElement {
  private _root: Root | null = null;
  private _container: HTMLDivElement | null = null;
  private _playing = false;
  private _loading = false;
  private _size = 140;
  private _color = '#ffffff';

  static get observedAttributes() {
    return ['playing', 'loading', 'size', 'color'];
  }

  connectedCallback() {
    if (!this._container) {
      this._container = document.createElement('div');
      this._container.style.display = 'inline-block';
      this.appendChild(this._container);
    }
    if (!this._root) {
      this._root = createRoot(this._container!);
    }
    // Initialize attributes
    this._playing = this.hasAttribute('playing')
      ? this.getAttribute('playing') !== 'false'
      : false;
    this._loading = this.hasAttribute('loading')
      ? this.getAttribute('loading') !== 'false'
      : false;
    if (this.hasAttribute('size')) {
      const n = Number(this.getAttribute('size'));
      if (!Number.isNaN(n) && n > 0) this._size = n;
    }
    if (this.hasAttribute('color')) {
      const c = String(this.getAttribute('color'));
      if (c) this._color = c;
    }
    this.renderReact();
  }

  attributeChangedCallback(name: string, _oldVal: string | null, newVal: string | null) {
    switch (name) {
      case 'playing':
        this._playing = newVal !== 'false' && newVal !== null;
        break;
      case 'loading':
        this._loading = newVal !== 'false' && newVal !== null;
        break;
      case 'size': {
        const n = Number(newVal);
        if (!Number.isNaN(n) && n > 0) this._size = n;
        break;
      }
      case 'color':
        if (newVal) this._color = newVal;
        break;
    }
    this.renderReact();
  }

  disconnectedCallback() {
    try { this._root?.unmount(); } catch { }
    this._root = null;
    this._container = null;
  }

  private onToggle = () => {
    // Delegate to host; loading state is controlled by the Lit host via attribute binding
    this.dispatchEvent(new CustomEvent('play-pause', { bubbles: true, composed: true }));
  };

  private renderReact() {
    if (!this._root) return;
    const size = this._size;
    const spinnerSize = Math.max(24, Math.floor(size * 0.8));
    // Detect theme from iframe document element
    let isLight = true;
    try { isLight = (document.documentElement.getAttribute('data-theme') || 'light') !== 'dark'; } catch { }
    this._root.render(
      <div
        style={{
          position: 'relative',
          width: size,
          height: size,
          // Add shadow only in light theme for better depth
          filter: isLight ? 'drop-shadow(0 6px 20px rgba(0,0,0,0.25)) drop-shadow(0 2px 8px rgba(0,0,0,0.18))' : undefined,
        }}
      >
        <PlayPauseMorphType4
          playing={this._playing}
          onToggle={this.onToggle}
          size={size}
          color={this._color}
          title="Play/Pause"
          className={undefined}
          style={undefined}
          config={undefined}
        />
        {this._loading && (
          <div style={{ position: 'absolute', inset: 0, display: 'flex', alignItems: 'center', justifyContent: 'center', zIndex: 9999, pointerEvents: 'none' }}>
            <LoadingIndicator
              size={spinnerSize}
              showContainer={false}
              theme={'dark'}
              className={''}
              style={undefined}
            />
          </div>
        )}
      </div>
    );
  }
}

customElements.define('play-pause-morph', PlayPauseMorphElement);
</file>

<file path="promptdj-midi/components/PromptController.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import { css, html, LitElement } from 'lit';
import { customElement, property, query, state } from 'lit/decorators.js';
import { classMap } from 'lit/directives/class-map.js';

import './WeightKnob';
import type { WeightKnob } from './WeightKnob';

import type { MidiDispatcher } from '../utils/MidiDispatcher';
import type { Prompt, ControlChange } from '../types';
import { LOCALES, Lang } from '../utils/Locales';

/** A single prompt input associated with a MIDI CC. */
@customElement('prompt-controller')
export class PromptController extends LitElement {
  static override styles = css`
    @keyframes pulse-orange {
      0%,
      100% {
        box-shadow: 0 0 0.8vmin orange;
        transform: translateX(-50%) scale(1);
      }
      50% {
        box-shadow: 0 0 1.5vmin orange, 0 0 0.1vmin orange inset;
        transform: translateX(-50%) scale(1.05);
      }
    }

    .prompt {
      width: 100%;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      /* Establish a positioning context for the MIDI label */
      position: relative;
    }
    weight-knob {
      width: 70%;
      flex-shrink: 0;
      order: 2;
      cursor: ns-resize;
    }
    
    #midi {
      position: absolute;
      top: 1vmin;
      left: 50%;
      transform: translateX(-50%);
      z-index: 10;
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
      text-align: center;
      font-size: 1.5vmin;
      border-radius: 1.5vmin;
      padding: 2px 5px;
      color: #fff;
      background: #222;
      cursor: pointer;
      visibility: hidden;
      user-select: none;
      box-shadow: 0 0 0 0.1vmin #fff4;
      transition: transform 0.2s ease, box-shadow 0.2s ease;
    }
    
    #midi:hover {
      transform: translateX(-50%) scale(1.1);
      box-shadow: 0 0 0.5vmin #fff;
    }
    
    .learn-mode #midi {
      color: orange;
      animation: pulse-orange 1.5s infinite;
    }
    
    .show-cc #midi {
      visibility: visible;
    }

    .text-wrapper {
      position: relative;
      width: 17vmin;
      height: 6vmin;
      margin-top: -7.5vmin;
      display: flex;
      align-items: center;
      justify-content: center;
      
      /* 
       * ==================================================================
       * THE FIX: This is the key change.
       * By setting pointer-events to 'none', this wrapper becomes 
       * transparent to mouse clicks, allowing them to pass through to the
       * weight-knob underneath it. The interactive children below will
       * re-enable pointer-events for themselves.
       * ==================================================================
       */
      pointer-events: none;
      order: 3;
    }

    #text-svg {
      width: 100%;
      height: 100%;
      overflow: visible;
      user-select: none;
      pointer-events: none; /* The SVG container itself is not interactive */
    }

    /* Default = dark-friendly (white text with black glow) */
    #text-svg text {
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
      font-stretch: 70%;
      font-weight: 500;
      font-size: 2.3vmin;
      fill: #fff;
      text-anchor: middle;
      -webkit-font-smoothing: antialiased;
      text-shadow: 0 0 0.5vmin #000, 0 0 0.5vmin #000;
      /* FIX: Re-enable pointer events for the text so it can be clicked */
      pointer-events: auto; 
      cursor: text;
      transition: transform 0.25s cubic-bezier(0.175, 0.885, 0.32, 1.275),
        text-shadow 0.2s ease-out, fill 0.2s ease-out;
      transform-origin: 50% 50%;
    }

    /* Light theme: black text with white shadows */
    :host-context([data-theme="light"]) #text-svg text {
      fill: #000;
      text-shadow: 0 0 0.6vmin #fff, 0 0 1.2vmin rgba(255,255,255,0.85);
    }

    .edit-icon {
      position: absolute;
      right: -4vmin; /* Adjusted for text label */
      top: 1.5vmin;
      color: #fff;
      text-shadow: 0 0 0.3vmin #000;
      opacity: 0;
      transform: translateX(5px);
      transition: all 0.2s ease-out;
      pointer-events: none;
      font-size: 1.8vmin;
      font-weight: 500;
    }

    .is-hovering #text-svg text {
      transform: scale(1.2) translateY(-4px);
      text-shadow: 0 0 1.5vmin #fff, 0 0 0.5vmin #000;
    }

    .is-hovering .edit-icon {
      opacity: 1;
      transform: translateX(0);
    }

    #text {
      font-weight: 500;
      font-size: 2.2vmin;
      text-shadow: 0 0 0.8vmin #000, 0 0 0.2vmin #000;
      max-width: 17vmin;
      min-width: 2vmin;
      padding: 0.1em 0.3em;
      border-radius: 0.25vmin;
      text-align: center;
      white-space: pre;
      overflow: hidden;
      border: none;
      outline: none;
      -webkit-font-smoothing: antialiased;
      background: #000;
      color: #fff;
      position: absolute;
      visibility: hidden;
      z-index: 2;
      /* FIX: Re-enable pointer events for the input field so it can be focused */
      pointer-events: auto;
      cursor: text;

      &:not(:focus) {
        text-overflow: ellipsis;
      }
    }

    /* Keep arc text visible during editing so it looks curved */
    .is-editing .edit-icon {
      visibility: hidden;
    }
    .is-editing #text-svg {
      opacity: 0;
    }
    .is-editing #text {
      visibility: visible;
      opacity: 1; /* show input for cursor */
      border: 1px solid #fff;
      border-radius: 1vmin;
      background: rgba(0, 0, 0, 0.7);
      /* Stabilize caret behavior in production builds */
      text-align: left;
      direction: ltr;
      unicode-bidi: plaintext;
    }

    /* Make the arched text visually distinct during editing. */
    .is-editing #text-svg text {
      /* Retain the scale from the hover state to prevent a visual "jump". */
      transform: scale(1.2) translateY(-4px);
      /* Invert colors to make the editing mode highly visible. */
      fill: #000;
      text-shadow: 0 0 0.6vmin #fff, 0 0 1.2vmin rgba(255, 255, 255, 0.85);
    }

    /* Invert editing mode colors for the light theme too. */
    :host-context([data-theme='light']) .is-editing #text-svg text {
      fill: #fff;
      text-shadow: 0 0 0.5vmin #000, 0 0 0.5vmin #000;
    }

    :host([filtered]) {
      weight-knob {
        opacity: 0.5;
      }
      .text-wrapper {
        background: #da2000;
        border-radius: 0.25vmin;
        z-index: 1;
      }
      #text {
        background: transparent;
      }
    }

    @media only screen and (max-width: 600px) {
      #text,
      #text-svg text {
        font-size: 3.8vmin;
      }
      weight-knob {
        width: 60%;
      }
    .material-symbols-rounded {
      font-family: 'Material Symbols Rounded';
      font-weight: normal;
      font-style: normal;
      display: inline-block;
      line-height: 1;
      text-transform: none;
      letter-spacing: normal;
      word-wrap: normal;
      white-space: nowrap;
      direction: ltr;
      -webkit-font-smoothing: antialiased;
      font-variation-settings: 'FILL' 1, 'wght' 400, 'grad' 0, 'opsz' 24;
    }
  `;

  @property({ type: String }) promptId = '';
  @property({ type: String }) text = '';
  @property({ type: Number }) weight = 0;
  @property({ type: String }) color = '';
  @property({ type: String }) lang = 'en';
  @property({ type: Boolean, reflect: true }) filtered = false;

  @property({ type: Number }) cc = 0;
  @property({ type: Number }) channel = 0; // Not currently used

  @property({ type: Boolean }) learnMode = false;
  @property({ type: Boolean }) showCC = false;

  @query('weight-knob') private weightInput!: WeightKnob;
  @query('#text') private textInput!: HTMLSpanElement;

  @property({ type: Object })
  midiDispatcher: MidiDispatcher | null = null;

  @property({ type: Number }) audioLevel = 0;

  @state() private isEditing = false;
  @state() private isHovering = false;

  private lastValidText!: string;

  override connectedCallback() {
    super.connectedCallback();
    this.midiDispatcher?.addEventListener('cc-message', (e: Event) => {
      const customEvent = e as CustomEvent<ControlChange>;
      const { channel, cc, value } = customEvent.detail;
      if (this.learnMode) {
        this.cc = cc;
        this.channel = channel;
        this.learnMode = false;
        this.dispatchPromptChange();
      } else if (cc === this.cc) {
        this.weight = (value / 127) * 2;
        this.dispatchPromptChange();
      }
    });
  }

  override firstUpdated() {
    this.textInput.setAttribute('contenteditable', 'plaintext-only');
    this.textInput.setAttribute('dir', 'ltr'); // Ensure LTR direction to avoid RTL heuristics
    this.textInput.textContent = this.text;
    this.lastValidText = this.text;

    const textEl = this.shadowRoot?.querySelector('#text-svg text');
    if (textEl) {
      textEl.addEventListener('mouseover', () => {
        this.isHovering = true;
      });
      textEl.addEventListener('mouseout', () => {
        this.isHovering = false;
      });
      textEl.addEventListener('click', () => this.startEditing());
    }
  }

  override update(changedProperties: Map<string, unknown>) {
    if (changedProperties.has('showCC') && !this.showCC) {
      this.learnMode = false;
    }
    // Avoid resetting the contenteditable while the user is typing, which can move the caret
    if (changedProperties.has('text') && this.textInput && !this.isEditing) {
      this.textInput.textContent = this.text;
    }
    super.update(changedProperties);
  }

  private dispatchPromptChange() {
    this.dispatchEvent(
      new CustomEvent<Prompt>('prompt-changed', {
        detail: {
          promptId: this.promptId,
          text: this.text,
          weight: this.weight,
          cc: this.cc,
          color: this.color,
        },
      })
    );
  }

  private onKeyDown(e: KeyboardEvent) {
    if (e.key === 'Enter') {
      e.preventDefault();
      this.textInput.blur();
    }
    if (e.key === 'Escape') {
      e.preventDefault();
      this.resetText();
      this.textInput.blur();
    }
  }

  private onInlineInput() {
    // Live-update arc text while typing (span is invisible, arc shows)
    const newText = this.textInput.textContent ?? '';
    this.text = newText;
    // Do not commit lastValidText until stopEditing; but propagate for live behavior
    this.dispatchPromptChange();
  }

  private resetText() {
    this.text = this.lastValidText;
    this.textInput.textContent = this.lastValidText;
  }

  private async stopEditing() {
    this.isEditing = false;
    const newText = this.textInput.textContent?.trim();
    if (!newText) {
      this.resetText();
    } else {
      this.text = newText;
      this.lastValidText = newText;
    }
    this.dispatchPromptChange();
    this.textInput.scrollLeft = 0;
  }

  private onFocus() {
    const selection = window.getSelection();
    if (!selection) return;
    const range = document.createRange();
    range.selectNodeContents(this.textInput);
    range.collapse(false); // place caret at end
    selection.removeAllRanges();
    selection.addRange(range);
  }

  private startEditing() {
    if (this.isEditing) return;
    this.isEditing = true;
    this.text = '';
    this.textInput.textContent = '';
    this.updateComplete.then(() => {
      this.textInput.focus();
      this.onFocus();
    });
  }

  private updateWeight() {
    this.weight = this.weightInput.value;
    this.dispatchPromptChange();
  }

  private toggleLearnMode() {
    this.learnMode = !this.learnMode;
  }

  override render() {
    const promptClasses = classMap({
      prompt: true,
      'learn-mode': this.learnMode,
      'show-cc': this.showCC,
    });

    const textWrapperClasses = classMap({
      'text-wrapper': true,
      'is-editing': this.isEditing,
      'is-hovering': this.isHovering && !this.isEditing,
    });


    return html`<div class=${promptClasses}>
      <weight-knob
        id="weight"
        value=${this.weight}
        color=${this.filtered ? '#888' : this.color}
        audioLevel=${this.filtered ? 0 : this.audioLevel}
        @input=${this.updateWeight}
      ></weight-knob>

      <div class=${textWrapperClasses}>
        <svg id="text-svg" viewBox="-10 0 120 25">
          <path
            id="text-arc-path"
            d="M -10,20 A 60,45 0 0,0 110,20"
            fill="none"
            stroke="none"
          ></path>
          <text>
            <textPath href="#text-arc-path" startOffset="50%">
              ${this.text}
            </textPath>
          </text>
        </svg>

        <span class="edit-icon" title=${LOCALES[this.lang as Lang].edit_tooltip}>
          ${LOCALES[this.lang as Lang].edit_btn}
        </span>

        <span
          id="text"
          spellcheck="false"
          @input=${this.onInlineInput}
          @focus=${this.onFocus}
          @keydown=${this.onKeyDown}
          @blur=${this.stopEditing}
        ></span>
      </div>

      <div id="midi" @click=${this.toggleLearnMode}>
        ${this.learnMode ? (this.lang === 'ko' ? '학습' : this.lang === 'vi' ? 'Học' : 'Learn') : `CC:${this.cc}`}
      </div>
    </div>`;
  }
}

declare global {
  interface HTMLElementTagNameMap {
    'prompt-controller': PromptController;
  }
}
</file>

<file path="promptdj-midi/components/PromptDjMidi.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import { css, html, LitElement } from 'lit';
import { customElement, property, state, query } from 'lit/decorators.js';
import { styleMap } from 'lit/directives/style-map.js';

import { throttle } from '../utils/throttle';

import './PromptController';
import './PlayPauseMorphWrapper';
import './OnboardingPopup';
import type { PlaybackState, Prompt } from '../types';
import { MidiDispatcher } from '../utils/MidiDispatcher';
import { LOCALES, Lang } from '../utils/Locales';

/** The grid of prompt inputs. */
@customElement('prompt-dj-midi')
export class PromptDjMidi extends LitElement {
  static override styles = css`
    :host {
      height: 100%;
      display: flex;
      flex-direction: column;
      justify-content: center;
      align-items: center;
      box-sizing: border-box;
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
    }
    button {
      font-family: inherit;
    }
    #background {
      will-change: background-image;
      position: absolute;
      height: 100%;
      width: 100%;
      z-index: -1;
      background: var(--md-surface);
    }
    /* Main layout: grid on the left, controls on the right */
    #content {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 8vmin;
      position: relative;
    }

    /* Grid wrapper includes just the grid now */
    #gridWrap {
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 2.5vmin;
      height: 80vmin;
    }

    /* #addColumn removed */

    .add-slot {
      width: 17vmin;
      height: 11vmin;
      display: inline-flex;
      align-items: center;
      justify-content: center;
      background: transparent;
      border: none;
      cursor: pointer;
    }
    .add-slot .add-icon {
      width: 9vmin;
      height: 9vmin;
      color: #fff;
      filter: drop-shadow(0 12px 22px rgba(0,0,0,0.25)) drop-shadow(0 4px 10px rgba(0,0,0,0.18));
      transition: transform var(--md-duration-short3) var(--md-easing-emphasized);
    }
    :host([data-theme="light"]) .add-slot .add-icon { color: #fff; }
    .add-slot:hover .add-icon { transform: scale(1.05); }

    #grid {
      width: 120vmin;
      height: 80vmin;
      display: grid;
      grid-template-columns: repeat(6, 1fr);
      gap: 2.5vmin;
    }
    .pc-wrap {
      position: relative;
      overflow: visible;
    }
    .pc-clear {
      position: absolute;
      top: -1.2vmin;
      right: -1.2vmin;
      width: 4.2vmin;
      height: 4.2vmin;
      border-radius: 9999px;
      border: 1px solid var(--md-outline-variant);
      background: var(--md-surface);
      color: var(--md-on-surface);
      display: inline-flex;
      align-items: center;
      justify-content: center;
      padding: 0;
      line-height: 0;
      box-sizing: border-box;
      cursor: pointer;
      box-shadow: var(--md-elevation-level1);
      opacity: 0;
      z-index: 20;
      pointer-events: auto;
      transition: opacity var(--md-duration-short3) var(--md-easing-standard),
                  transform var(--md-duration-short3) var(--md-easing-standard),
                  box-shadow var(--md-duration-short3) var(--md-easing-standard),
                  background-color var(--md-duration-short3) var(--md-easing-standard),
                  border-color var(--md-duration-short3) var(--md-easing-standard);
      transform: scale(0.9);
    }
    .pc-clear svg { width: 100%; height: 100%; display: block; }
    .pc-wrap:hover .pc-clear { opacity: 1; transform: scale(1); }
    .pc-clear:hover {
      background: var(--md-surface-variant);
      border-color: var(--md-outline);
      box-shadow: var(--md-elevation-level2);
      transform: scale(1.06);
    }
    .pc-clear:active {
      transform: scale(0.96);
      box-shadow: var(--md-elevation-level1);
    }
    .pc-clear:focus-visible {
      outline: none;
      box-shadow: 0 0 0 0.22vmin rgba(0,0,0,0.3), var(--md-elevation-level2);
    }

    /* Modal Styling */
    .modal-overlay {
      position: fixed;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      background: rgba(0, 0, 0, 0.6);
      backdrop-filter: blur(5px);
      z-index: 1000;
      display: flex;
      align-items: center;
      justify-content: center;
      animation: fadeIn 0.3s ease;
    }
    .modal-content {
      background: var(--md-surface, #222);
      padding: 3vmin;
      border-radius: 2vmin;
      box-shadow: 0 10px 30px rgba(0,0,0,0.5);
      border: 1px solid rgba(255,255,255,0.1);
      display: flex;
      flex-direction: column;
      gap: 2vmin;
      min-width: 40vmin;
      max-width: 90%;
      transform: translateY(0);
      animation: slideIn 0.3s ease;
    }
    @keyframes fadeIn { from { opacity: 0; } to { opacity: 1; } }
    @keyframes slideIn { from { transform: translateY(20px); opacity: 0; } to { transform: translateY(0); opacity: 1; } }

    .modal-header {
      display: flex;
      justify-content: space-between;
      align-items: center;
      font-size: 2.2vmin;
      font-weight: bold;
      color: var(--md-on-surface, #fff);
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
    }
    .close-modal {
      background: transparent;
      border: none;
      color: rgba(255,255,255,0.6);
      cursor: pointer;
      font-size: 3vmin;
      line-height: 1;
      padding: 0;
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
    }
    .close-modal:hover { color: #fff; }

    .audio-player {
      width: 100%;
      height: 6vmin;
      border-radius: 999px;
      margin-top: 1vmin;
    }
    
    .download-btn {
      background: var(--md-primary, #6200ea);
      color: var(--md-on-primary, #fff);
      border: none;
      padding: 1.5vmin 3vmin;
      border-radius: 4vmin;
      font-size: 2vmin;
      cursor: pointer;
      display: flex;
      align-items: center;
      justify-content: center;
      gap: 1vmin;
      font-weight: 500;
      font-family: inherit;
      transition: background 0.2s;
    }
    .download-btn:hover {
      filter: brightness(1.2);
    }

    #sideControls {
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      height: 80vmin;
    }
    play-pause-morph {
      width: 23vmin;
      height: 23vmin;
      display: inline-block;
    }


  
    .mini-controls {
      display: flex;
      gap: 1.5vmin;
      margin-top: 4vmin;
    }
    .mini-btn {
      width: 7vmin;
      height: 7vmin;
      background: transparent;
      border: none;
      color: white;
      display: flex;
      align-items: center;
      justify-content: center;
      cursor: pointer;
      transition: all 0.2s ease;
    }
    .mini-btn:hover { transform: scale(1.15); }
    .mini-btn.active { color: #ff3c3c; filter: drop-shadow(0 0 1vmin #ff3c3c); }
    .mini-btn.toggled { color: var(--md-primary); filter: drop-shadow(0 0 1vmin var(--md-primary)); }
    .material-symbols-rounded {
      font-family: 'Material Symbols Rounded';
      font-weight: normal;
      font-style: normal;
      display: inline-block;
      line-height: 1;
      text-transform: none;
      letter-spacing: normal;
      word-wrap: normal;
      white-space: nowrap;
      direction: ltr;
      -webkit-font-smoothing: antialiased;
      font-variation-settings: 'FILL' 1, 'wght' 400, 'grad' 0, 'opsz' 24;
      font-size: 4vmin;
      filter: drop-shadow(0 2px 4px rgba(0,0,0,0.5));
    }
    :host([data-theme="light"]) .material-symbols-rounded {
      filter: drop-shadow(0 1px 2px rgba(0,0,0,0.3));
    }
    .mini-btn .material-symbols-rounded { font-size: 3.5vmin; }
    .pc-clear .material-symbols-rounded { font-size: 2.8vmin; }
    .add-slot .material-symbols-rounded { font-size: 10vmin; }

    .rec-timer-container {
      min-height: 5vmin;
      display: flex;
      flex-direction: column;
      align-items: center;
      justify-content: center;
      font-variant-numeric: tabular-nums;
      margin-top: 1vmin;
      pointer-events: none;
    }
    .rec-timer-elapsed {
      font-size: 1.15em;
      font-weight: 700;
      color: var(--accent-color, #ff4444);
      line-height: 1;
      font-stretch: 125%;
      font-variation-settings: 'wdth' 125;
    }
    .rec-timer-audio {
      font-size: 0.75em; 
      opacity: 0.7;
      margin-top: 2px;
    }

    .volume-container {
      display: flex;
      align-items: center;
      justify-content: center;
      width: 100%;
      margin-bottom: 4vmin;
      box-sizing: border-box;
      gap: 1vmin;
      opacity: 0;
      transition: opacity 0.3s ease;
    }
    #sideControls:hover .volume-container {
      opacity: 1;
    }
    .volume-icon {
      color: #fff;
      font-size: 3vmin;
    }
    .volume-slider {
      flex: 1;
      -webkit-appearance: none;
      height: 0.6vmin;
      border-radius: 1vmin;
      /* Background handled via inline style for active/inactive range opacity */
      outline: none;
      cursor: pointer;
      box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2);
    }
    .volume-slider::-webkit-slider-thumb {
      -webkit-appearance: none;
      width: 2vmin;
      height: 2vmin;
      border-radius: 50%;
      background: #ffffff;
      cursor: pointer;
      transition: transform 0.1s;
      box-shadow: 0 1px 4px rgba(0, 0, 0, 0.3);
    }
    .volume-slider::-webkit-slider-thumb:hover { transform: scale(1.2); }
  `;

  private prompts: Map<string, Prompt>;
  private midiDispatcher: MidiDispatcher;

  @property({ type: Boolean }) private showMidi = false;
  @property({ type: String }) public playbackState: PlaybackState = 'stopped';
  @property({ type: String }) public lang: string = 'en';
  @property({ type: Boolean }) public apiKeySet = false;
  @property({ type: Number }) public audioLevel = 0;
  private lastUserAction: 'play' | 'pause' | null = null;

  @state() private isRecording = false;
  @state() private recordElapsed = 0;
  @state() private recordAudioElapsed = 0;
  private recordInterval: number | null = null;

  // Recording playback state
  @state() private recordingUrl: string | null = null;

  @state() private midiInputIds: string[] = [];
  @state() private activeMidiInputId: string | null = null;
  @state() private optimisticLoading: boolean = false;
  @state() private optimisticPlaying: boolean | null = null; // null = follow real state
  @state() private downloaded = false;
  private clickCooldownUntil: number = 0; // epoch ms; during this window, ignore extra toggles

  // Background drift control
  @state() private driftStrength: number = 0; // 0 = at base, 1 = full drift
  private driftTarget: number = 0;
  private driftRaf: number | null = null;
  private lastDriftTick = 0;

  // Left add-column activation state (4 slots)
  @state() private addSlotsActive: boolean[] = [false, false, false, false];
  // Track which base grid slots are removed (to render add buttons in-grid)
  @state() private removedSlots: Set<string> = new Set();

  @state() private volume: number = 1.0;

  @property({ type: Object })
  private filteredPrompts = new Set<string>();

  private basePrompts: Map<string, Prompt>;
  private baseOrder: string[] = [];
  private readonly STORAGE_KEY = 'pdj_midi_state_v1';

  constructor(
    initialPrompts: Map<string, Prompt>,
  ) {
    super();
    // Deep-copy base prompts
    this.basePrompts = new Map<string, Prompt>();
    for (const [k, p] of initialPrompts.entries()) {
      this.basePrompts.set(k, { ...p });
      this.baseOrder.push(k);
    }
    // Start with defaults, BUT leave the last 2 (Custom) as empty slots
    // There are 24 slots total. We want 22 active, 2 empty.
    this.prompts = new Map();
    let count = 0;
    for (const [k, p] of this.basePrompts.entries()) {
      if (count < 22) {
        this.prompts.set(k, { ...p });
      }
      count++;
    }
    this.midiDispatcher = new MidiDispatcher();

    // Load saved state and MERGE it
    try {
      const raw = localStorage.getItem(this.STORAGE_KEY);
      if (raw) {
        const parsed = JSON.parse(raw);
        const savedPrompts: any[] = Array.isArray(parsed?.prompts) ? parsed.prompts : [];

        savedPrompts.forEach((p) => {
          if (p && typeof p.promptId === 'string') {
            // Only update if it corresponds to a valid base prompt or a known extra
            // (For now, we trust the defaults structure more for the base grid)
            if (this.prompts.has(p.promptId)) {
              const existing = this.prompts.get(p.promptId)!;
              // Restore USER state (text, weight, color) but keep structure valid
              this.prompts.set(p.promptId, {
                ...existing,
                text: typeof p.text === 'string' ? p.text : existing.text,
                weight: typeof p.weight === 'number' ? p.weight : existing.weight,
                color: p.color || existing.color,
                cc: typeof p.cc === 'number' ? p.cc : existing.cc
              });
            } else if (p.promptId.startsWith('extra-')) {
              // Restore extra slots
              this.prompts.set(p.promptId, {
                promptId: p.promptId,
                text: p.text || '',
                weight: p.weight || 0,
                cc: p.cc || 0,
                color: p.color || '#ffffff'
              });
            }
          }
        });

        if (Array.isArray(parsed?.addSlotsActive) && parsed.addSlotsActive.length === 4) {
          this.addSlotsActive = parsed.addSlotsActive.map((b: any) => !!b);
        }
        const rs = parsed?.removedSlots;
        if (Array.isArray(rs)) {
          // Only respect removal of keys that actually exist in our base order
          const validRemovals = rs.filter((x: any) => typeof x === 'string' && this.basePrompts.has(x));
          this.removedSlots = new Set<string>(validRemovals);
        }
      }
    } catch { }
  }

  public showRecording(blob: Blob) {
    if (this.recordingUrl) {
      URL.revokeObjectURL(this.recordingUrl);
    }
    this.recordingUrl = URL.createObjectURL(blob);
    this.requestUpdate();
  }

  private closeModal() {
    if (this.recordingUrl) {
      URL.revokeObjectURL(this.recordingUrl);
      this.recordingUrl = null;
    }
  }

  private downloadRecording() {
    if (!this.recordingUrl) return;
    const a = document.createElement('a');
    a.href = this.recordingUrl;
    a.download = `PromptDJ_${new Date().toISOString().replace(/:/g, '-')}.wav`;
    a.click();
    this.downloaded = true;
    setTimeout(() => { this.downloaded = false; }, 3000);
  }

  private renderModal() {
    const labels = LOCALES[this.lang as Lang];
    if (!this.recordingUrl) return html``;
    return html`
      <div class="modal-overlay" @click=${this.closeModal}>
        <div class="modal-content" @click=${(e: Event) => e.stopPropagation()}>
          <div class="modal-header">
            <div style="flex: 1; display: flex; flex-direction: column; gap: 2px;">
              <span style="display: block;">${this.downloaded ? labels.saved : labels.recording_ready}</span>
              <div style="font-size: 0.85em; opacity: 0.8;">${this.downloaded ? '' : labels.silence_removed}</div>
            </div>
            <button class="close-modal" @click=${this.closeModal}>&times;</button>
          </div>
          <audio class="audio-player" src=${this.recordingUrl} controls></audio>
          <button class="download-btn" @click=${this.downloadRecording}>
            <span class="material-symbols-rounded">${this.downloaded ? 'check_circle' : 'download'}</span>
            ${this.downloaded ? labels.downloaded_msg : labels.download_btn}
          </button>
        </div>
      </div>
    `;
  }

  private saveState() {
    try {
      const arr = [...this.prompts.values()].map(p => ({
        promptId: p.promptId,
        text: p.text,
        weight: p.weight,
        cc: p.cc,
        color: p.color,
      }));
      const payload = {
        prompts: arr,
        addSlotsActive: this.addSlotsActive,
        removedSlots: [...this.removedSlots],
      };
      localStorage.setItem(this.STORAGE_KEY, JSON.stringify(payload));
    } catch { }
  }

  private handlePromptChanged(e: CustomEvent<Prompt>) {
    const { promptId, text, weight, cc } = e.detail;
    const prompt = this.prompts.get(promptId);

    if (!prompt) {
      console.error('prompt not found', promptId);
      return;
    }

    prompt.text = text;
    prompt.weight = weight;
    prompt.cc = cc;

    const newPrompts = new Map(this.prompts);
    newPrompts.set(promptId, prompt);

    this.prompts = newPrompts;
    this.requestUpdate();
    this.saveState();

    this.dispatchEvent(
      new CustomEvent('prompts-changed', { detail: this.prompts }),
    );
  }

  /** Generates radial gradients for each prompt based on weight and color, with gentle drift while playing. */
  private readonly makeBackground = throttle(
    () => {
      const clamp01 = (v: number) => Math.min(Math.max(v, 0), 1);

      const MAX_WEIGHT = 0.5;
      const MAX_ALPHA = 0.6;

      const t = performance.now() * 0.0006; // time base for gentle drift

      const bg: string[] = [];

      [...this.prompts.values()].forEach((p, i) => {
        // Stable alpha and size based on weight (no level-based pulsing)
        const alphaPct = clamp01(p.weight / MAX_WEIGHT) * MAX_ALPHA;
        const alpha = Math.round(alphaPct * 0xff)
          .toString(16)
          .padStart(2, '0');

        const stop = p.weight / 2;

        // Base grid position
        const gx = (i % 6) / 5;
        const gy = Math.floor(i / 6) / 3;

        // Gentle, eased drift per prompt scaled by driftStrength
        const phase = i * 1.37; // unique-ish per index
        const driftAmp = 4 * (this.driftStrength || 0); // percent units
        const driftX = Math.sin(t + phase) * driftAmp;
        const driftY = Math.cos(t * 0.9 + phase) * driftAmp;
        const xPct = gx * 100 + driftX;
        const yPct = gy * 100 + driftY;

        const s = `radial-gradient(circle at ${xPct}% ${yPct}%, ${p.color}${alpha} 0px, ${p.color}00 ${Math.max(0, Math.min(100, stop * 100))}%)`;

        bg.push(s);
      });

      return bg.join(', ');
    },
    30, // don't re-render more than once every XXms
  );

  public async setShowMidi(show: boolean) {
    this.showMidi = show;
    if (!this.showMidi) return;
    try {
      const inputIds = await this.midiDispatcher.getMidiAccess();
      this.midiInputIds = inputIds;
      this.activeMidiInputId = this.midiDispatcher.activeMidiInputId;
      // Notify listeners (iframe bridge) that inputs are available/updated
      this.dispatchEvent(new CustomEvent('midi-inputs-changed', { detail: { inputs: this.midiInputIds, activeId: this.activeMidiInputId } }));
    } catch (e) {
      this.showMidi = false;
      this.dispatchEvent(new CustomEvent('error', { detail: (e as any).message }));
    }
  }

  // Public API used by parent (main app) via postMessage bridge
  public getShowMidi(): boolean { return this.showMidi; }
  public async refreshMidiInputs(): Promise<void> {
    try {
      const inputIds = await this.midiDispatcher.getMidiAccess();
      this.midiInputIds = inputIds;
      this.activeMidiInputId = this.midiDispatcher.activeMidiInputId;
      this.dispatchEvent(new CustomEvent('midi-inputs-changed', { detail: { inputs: this.midiInputIds, activeId: this.activeMidiInputId } }));
    } catch (e) {
      this.dispatchEvent(new CustomEvent('error', { detail: (e as any).message }));
    }
  }
  public getMidiInputs(): string[] { return this.midiInputIds; }
  public getActiveMidiInputId(): string | null { return this.activeMidiInputId; }
  public setActiveMidiInputId(id: string) {
    if (!id) return;
    this.activeMidiInputId = id;
    this.midiDispatcher.activeMidiInputId = id;
    this.dispatchEvent(new CustomEvent('midi-inputs-changed', { detail: { inputs: this.midiInputIds, activeId: this.activeMidiInputId } }));
    this.requestUpdate();
  }

  // Localized placeholder text
  private trPlaceholder(): string {
    return LOCALES[this.lang as Lang].prompt_placeholder;
  }

  private playPause(e: Event) {
    // Prevent the bubbling play-pause event from also reaching outer listeners
    e.stopPropagation();

    // Debounce rapid clicks to avoid double toggles
    const now = Date.now();
    if (now < this.clickCooldownUntil) return;
    this.clickCooldownUntil = now + 500;

    const morphEl = this.renderRoot?.querySelector('play-pause-morph') as HTMLElement | null;

    // If currently playing or loading: this click means STOP
    if (this.playbackState === 'playing' || this.playbackState === 'loading') {
      this.lastUserAction = 'pause';
      this.optimisticPlaying = false; // pause -> play morph immediately
      this.optimisticLoading = false; // ensure spinner is off
      morphEl?.removeAttribute('loading');
      morphEl?.setAttribute('playing', 'false');
      this.dispatchEvent(new CustomEvent('pause', { bubbles: true })); // explicit pause/stop
      return;
    }

    // If paused/stopped: this click means PLAY
    if (!this.apiKeySet) {
      this.dispatchEvent(new CustomEvent('error', { detail: 'Please set your Gemini API key in the main app first.' }));
      return;
    }
    this.lastUserAction = 'play';
    this.optimisticLoading = true; // show spinner immediately
    this.optimisticPlaying = null; // follow real state for icon
    morphEl?.setAttribute('loading', '');
    this.dispatchEvent(new CustomEvent('play', { bubbles: true }));
  }

  public addFilteredPrompt(prompt: string) {
    this.filteredPrompts = new Set([...this.filteredPrompts, prompt]);
  }

  public setPromptLabels(labels: string[]) {
    const updated = new Map<string, Prompt>();
    let i = 0;
    for (const [key, p] of this.prompts.entries()) {
      const newText = labels[i] ?? p.text;
      updated.set(key, { ...p, text: newText });
      i++;
    }
    this.prompts = updated;
    this.requestUpdate();
    this.dispatchEvent(new CustomEvent('prompts-changed', { detail: this.prompts }));
  }

  public getPrompts(): Map<string, Prompt> {
    return new Map(this.prompts);
  }

  private addExtraSlot(idx: number) {
    const promptId = `extra-${idx}`;
    if (this.prompts.has(promptId)) return;
    const color = ['#9900ff', '#2af6de', '#ff25f6', '#ffdd28'][idx % 4];
    const p: Prompt = { promptId, text: this.trPlaceholder(), weight: 0, cc: 100 + idx, color };
    const updated = new Map(this.prompts);
    updated.set(promptId, p);
    this.prompts = updated;
    const slots = [...this.addSlotsActive];
    slots[idx] = true;
    this.addSlotsActive = slots;
    this.requestUpdate();
    this.saveState();
    this.dispatchEvent(new CustomEvent('prompts-changed', { detail: this.prompts }));
  }

  private addBaseSlot(idx: number) {
    const id = this.baseOrder[idx];
    if (!id || this.prompts.has(id)) return;
    const base = this.basePrompts.get(id);
    if (!base) return;
    const updated = new Map(this.prompts);
    // Always use placeholder text when adding (user deleted the original intentionally)
    const text = this.trPlaceholder();
    updated.set(id, { ...base, text });
    this.prompts = updated;
    const rem = new Set(this.removedSlots);
    rem.delete(id);
    this.removedSlots = rem;
    this.requestUpdate();
    this.saveState();
    this.dispatchEvent(new CustomEvent('prompts-changed', { detail: this.prompts }));
  }

  private clearPrompt(promptId: string) {
    if (!this.prompts.has(promptId)) return;
    if (promptId.startsWith('extra-')) {
      // Remove extra prompt and deactivate slot
      const idx = Number(promptId.split('-')[1] || 0);
      const updated = new Map(this.prompts);
      updated.delete(promptId);
      this.prompts = updated;
      const slots = [...this.addSlotsActive];
      if (!Number.isNaN(idx)) slots[idx] = false;
      this.addSlotsActive = slots;
      this.requestUpdate();
      this.saveState();
      this.dispatchEvent(new CustomEvent('prompts-changed', { detail: this.prompts }));
      return;
    }
    // Remove built-in prompt and mark slot as removed to render add button in-grid
    const updated = new Map(this.prompts);
    updated.delete(promptId);
    this.prompts = updated;
    const rem = new Set(this.removedSlots);
    rem.add(promptId);
    this.removedSlots = rem;
    this.requestUpdate();
    this.saveState();
    this.dispatchEvent(new CustomEvent('prompts-changed', { detail: this.prompts }));
  }

  public resetAll() {
    // Reset to original base prompts
    // BUT maintain the "22 active, 2 empty" rule
    const newPrompts = new Map<string, Prompt>();
    let count = 0;
    for (const [k, p] of this.basePrompts.entries()) {
      if (count < 22) {
        newPrompts.set(k, { ...p });
      }
      count++;
    }
    this.prompts = newPrompts;
    this.addSlotsActive = [false, false, false, false];
    this.removedSlots = new Set();
    this.requestUpdate();
    this.saveState();
    this.dispatchEvent(new CustomEvent('prompts-changed', { detail: this.prompts }));
  }

  private formatDuration(sec: number) {
    if (!sec) return "0:00";
    const m = Math.floor(sec / 60);
    const s = Math.floor(sec % 60);
    return `${m}:${s.toString().padStart(2, '0')}`;
  }

  private toggleRecording() {
    if (this.recordInterval) {
      clearInterval(this.recordInterval);
      this.recordInterval = null;
    }

    this.isRecording = !this.isRecording;
    if (this.isRecording) {
      this.recordElapsed = 0;
      this.recordAudioElapsed = 0;
      const startTime = Date.now();
      let lastTick = startTime;

      this.recordInterval = window.setInterval(() => {
        const now = Date.now();
        const dt = (now - lastTick) / 1000;
        lastTick = now;

        this.recordElapsed = (now - startTime) / 1000;
        // Sensitivity threshold bumped to 0.02
        if (this.audioLevel > 0.02) {
          this.recordAudioElapsed += dt;
        }
        this.requestUpdate();
      }, 100);

      this.dispatchEvent(new CustomEvent('start-recording'));
    } else {
      this.dispatchEvent(new CustomEvent('stop-recording'));
    }
  }

  private toggleMidiPanel() {
    // Reset MIDI state when toggling on to allow retry after denial
    if (!this.showMidi) {
      this.midiDispatcher.reset();
    }
    this.setShowMidi(!this.showMidi);
  }

  private handleVolumeChange(e: Event) {
    const val = parseFloat((e.target as HTMLInputElement).value);
    this.volume = val;

    // 1. IPC to native
    if ((window as any).ipc) {
      (window as any).ipc.postMessage('set_volume:' + val);
    }

    // 2. Global variable for hooks
    (window as any)._currentVolume = val;

    // 3. Audio tags
    document.querySelectorAll('audio, video').forEach((el) => {
      (el as HTMLMediaElement).volume = val;
    });

    // 4. Captured AudioContext Gains (from mod.rs hook)
    const gains = (window as any)._activeMasterGains;
    if (Array.isArray(gains)) {
      gains.forEach((g: any) => {
        try {
          if (g && g.gain) {
            // smooth transition
            g.gain.setTargetAtTime(val, g.context.currentTime, 0.1);
          }
        } catch {
          if (g && g.gain) g.gain.value = val;
        }
      });
    }
  }


  protected updated(changedProps: Map<string, any>) {
    if (changedProps.has('playbackState')) {
      const state = this.playbackState;

      // Set drift target based on state and ensure the animation loop is running
      this.driftTarget = (state === 'playing' || state === 'loading') ? 1 : 0;
      this.ensureDriftLoop();

      if (this.lastUserAction === 'play') {
        if (state === 'playing') {
          this.optimisticLoading = false;
          this.optimisticPlaying = null;
          this.lastUserAction = null;
        } else if (state === 'loading') {
          this.optimisticLoading = true;
        } else if (state === 'paused' || state === 'stopped') {
          this.optimisticLoading = true;
        }
      } else if (this.lastUserAction === 'pause') {
        this.optimisticLoading = false;
        this.optimisticPlaying = false;
        if (state === 'paused' || state === 'stopped') {
          this.lastUserAction = null;
        }
      } else {
        this.optimisticLoading = (state === 'loading');
        this.optimisticPlaying = null;
      }
    }
  }

  private ensureDriftLoop() {
    if (this.driftRaf != null) return;
    this.lastDriftTick = performance.now();
    const tick = () => {
      const now = performance.now();
      const dt = Math.max(0, now - this.lastDriftTick) / 1000; // seconds
      this.lastDriftTick = now;

      // Approach driftTarget smoothly (exponential smoothing)
      const speed = 3.0; // higher = faster return/engage
      const diff = this.driftTarget - this.driftStrength;
      const step = 1 - Math.exp(-speed * dt);
      this.driftStrength = this.driftStrength + diff * step;

      // Force a re-render so gradients animate (uses performance.now in makeBackground)
      this.requestUpdate();

      // If we're returning to base and very close, stop the loop; otherwise keep running
      if (this.driftTarget === 0 && Math.abs(this.driftStrength) < 0.001) {
        this.driftStrength = 0;
        this.driftRaf = null;
        return;
      }
      this.driftRaf = requestAnimationFrame(tick);
    };
    this.driftRaf = requestAnimationFrame(tick);
  }

  override render() {
    const bg = styleMap({
      backgroundImage: this.makeBackground(),
    });
    const playingProp = this.optimisticPlaying !== null
      ? this.optimisticPlaying
      : (this.playbackState === 'playing');
    const loadingProp = this.optimisticLoading || this.playbackState === 'loading';

    return html`<div id="background" style=${bg}></div>
      <onboarding-popup lang=${this.lang}></onboarding-popup>
      ${this.renderModal()}
      <div id="content">
        <div id="gridWrap">
          <div id="grid">${this.renderPrompts()}</div>
        </div>
        <div id="sideControls">
          <!-- Volume at the top -->
          <div class="volume-container" title="Master Volume">
            <span class="material-symbols-rounded volume-icon">
              ${this.volume <= 0.001 ? 'volume_off' : this.volume < 0.5 ? 'volume_down' : 'volume_up'}
            </span>
            <input type="range" class="volume-slider" min="0" max="1" step="0.01"
              style=${styleMap({
      background: `linear-gradient(to right, #ffffff 0%, #ffffff ${this.volume * 100}%, rgba(255,255,255,0.3) ${this.volume * 100}%, rgba(255,255,255,0.3) 100%)`
    })}
              .value=${this.volume.toString()}
              @input=${this.handleVolumeChange}>
          </div>

          <play-pause-morph
            ?playing=${playingProp}
            ?loading=${loadingProp}
            @play-pause=${this.playPause}
          ></play-pause-morph>

          <div class="mini-controls">
             <!-- MIDI Toggle -->
             <button class="mini-btn ${this.showMidi ? 'toggled' : ''}" @click=${this.toggleMidiPanel} title=${LOCALES[this.lang as Lang].midi_tooltip}>
               <span class="material-symbols-rounded">piano</span>
             </button>

             <!-- Record Toggle -->
             <button class="mini-btn ${this.isRecording ? 'active' : ''}" @click=${this.toggleRecording} title="${this.isRecording ? LOCALES[this.lang as Lang].stop_tooltip : LOCALES[this.lang as Lang].record_tooltip}">
               <span class="material-symbols-rounded">${this.isRecording ? 'stop' : 'radio_button_checked'}</span>
             </button>

             <!-- Reset -->
             <button class="mini-btn" @click=${() => this.resetAll()} title=${LOCALES[this.lang as Lang].reset_tooltip}>
               <span class="material-symbols-rounded">restart_alt</span>
             </button>
          </div>

          <div class="rec-timer-container">
            ${this.isRecording ? html`
               <div class="rec-timer-elapsed">${this.formatDuration(this.recordElapsed)}</div>
               <div class="rec-timer-audio">Audio: ${this.formatDuration(this.recordAudioElapsed)}</div>
            ` : html``}
          </div>
        </div>
      </div>`;
  }

  private renderPromptWithClear(promptId: string) {
    const p = this.prompts.get(promptId);
    if (!p) return html``;
    return html`<div class="pc-wrap">
      <button class="pc-clear" title=${LOCALES[this.lang as Lang].clear_tooltip} @click=${() => this.clearPrompt(promptId)}>
        <span class="material-symbols-rounded">close</span>
      </button>
      <prompt-controller
        promptId=${p.promptId}
        ?filtered=${this.filteredPrompts.has(p.text)}
        cc=${p.cc}
        text=${p.text}
        weight=${p.weight}
        color=${p.color}
        lang=${this.lang}
        .midiDispatcher=${this.midiDispatcher}
        .showCC=${this.showMidi}
        audioLevel=${this.audioLevel}
        @prompt-changed=${this.handlePromptChanged}
      ></prompt-controller>
    </div>`;
  }

  private renderPrompts() {
    const nodes: any[] = [];
    // Render in base grid order, allowing removed slots to show an add button
    this.baseOrder.forEach((id, idx) => {
      const p = this.prompts.get(id);
      if (!p || this.removedSlots.has(id)) {
        nodes.push(html`<button class="add-slot" @click=${() => this.addBaseSlot(idx)} title=${LOCALES[this.lang as Lang].add_tooltip}>
          <span class="material-symbols-rounded add-icon">add</span>
        </button>`);
      } else {
        nodes.push(this.renderPromptWithClear(id));
      }
    });
    return nodes;
  }
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator.css">
/* Material Design 3 Expressive Loading Indicator */
.loading-indicator {
  display: flex;
  justify-content: center;
  align-items: center;
  position: relative;
  background: none;
  border: none;
  padding: 0;
  margin: 0;
  overflow: hidden; /* Ensure canvas doesn't overflow */
}

.loading-indicator-canvas {
  display: block;
  /* Canvas styling is handled in JS like original figma-showcase */
}

/* Animation performance optimizations */
.loading-indicator-canvas {
  will-change: transform;
  backface-visibility: hidden;
  -webkit-backface-visibility: hidden;
  transform-style: preserve-3d;
  -webkit-transform-style: preserve-3d;
}

/* Accessibility */
.loading-indicator {
  role: progressbar;
  aria-label: "Loading";
  aria-live: polite;
}

/* Responsive behavior */
@media (prefers-reduced-motion: reduce) {
  .loading-indicator-canvas {
    animation-duration: 2s !important;
  }
}

/* High contrast mode support */
@media (prefers-contrast: high) {
  .loading-indicator {
    filter: contrast(1.5);
  }
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator.jsx">
import React, { useEffect, useRef, useState, useCallback } from 'react';
import './LoadingIndicator.css';

/**
 * Material Design 3 Expressive Loading Indicator
 * A sophisticated loading animation with REAL morphing shapes from Figma design
 * 
 * @param {Object} props
 * @param {string} props.theme - 'light' or 'dark' (default: 'dark')
 * @param {boolean} props.showContainer - Whether to show the background container (default: true)
 * @param {number} props.size - Size in pixels (default: 48)
 * @param {string} props.className - Additional CSS classes
 * @param {Object} props.style - Additional inline styles
 * @param {string} [props.color] - Optional override for the shape color (fills). If provided, supersedes theme-based color.
 * @param {string} [props.containerColor] - Optional override for the container color when showContainer is true.
 */
const LoadingIndicator = ({
  theme = 'dark',
  showContainer = true,
  size = 48,
  className = '',
  style = {},
  color,
  containerColor
}) => {
  const canvasRef = useRef(null);
  const animationRef = useRef(null);
  const [isLoaded, setIsLoaded] = useState(false);

  // Colors from Figma design - all 4 variants
  const COLORS = {
    // Container colors
    containerDark: '#2E4578',
    containerLight: '#ADC3FE',

    // Shape colors
    shapeDarkWithContainer: '#D9E2FF',
    shapeDarkNoContainer: '#485E92', // Dark color for dark theme
    shapeLightWithContainer: '#324574',
    shapeLightNoContainer: '#B0C6FF' // Light color for light theme
  };

  // Animation state
  const animationState = useRef({
    currentStep: 1,
    morphShapes: [],
    currentMorph: null,
    morphProgress: 0,
    rotationAngle: 0,
    pulseValue: 1,
    animationTime: 0,
    discreteSpinSpeed: 0,
    isAnimating: false,
    currentShapeIndex: 0,
    nextShapeIndex: 1,
    shapeOrder: []
  });

  // Get the appropriate shape color based on theme and container (with override)
  const getShapeColor = useCallback(() => {
    if (color) return color;
    const isDarkMode = theme === 'dark';
    if (isDarkMode) {
      return showContainer ? COLORS.shapeDarkWithContainer : COLORS.shapeDarkNoContainer;
    } else {
      return showContainer ? COLORS.shapeLightWithContainer : COLORS.shapeLightNoContainer;
    }
  }, [theme, showContainer, COLORS, color]);



  const drawMaterial3Container = useCallback((ctx) => {
    if (!showContainer) return;

    // Use dynamic canvas size based on component size with larger scaling to prevent clipping
    const scaleFactor = size <= 24 ? 3.0 : size <= 48 ? 2.5 : 2.2;
    const canvasSize = Math.round(size * scaleFactor);
    const centerX = canvasSize / 2;
    const centerY = canvasSize / 2;
    const radius = Math.min(canvasSize, canvasSize) * 0.45; // Larger radius to better match SVG shapes

    ctx.save();
    ctx.translate(centerX, centerY);

    ctx.beginPath();
    ctx.arc(0, 0, radius, 0, 2 * Math.PI);

    // Use container override if provided, otherwise based on theme
    const contColor = containerColor || (theme === 'dark' ? COLORS.containerDark : COLORS.containerLight);
    ctx.fillStyle = contColor;
    ctx.fill();

    ctx.restore();
  }, [showContainer, theme, COLORS, size]);



  const applyMaterial3ExpressiveEffects = useCallback((ctx) => {
    const state = animationState.current;
    
    // Update animation time
    state.animationTime += 0.05;

    // Material 3 Expressive spinning with bounce
    if (state.currentMorph && state.morphProgress < 1.0) {
      const morphPhase = state.morphProgress;

      if (morphPhase < 0.8) {
        state.discreteSpinSpeed = 6.0;
      } else {
        const bouncePhase = (morphPhase - 0.8) / 0.2;
        const speedFactor = 1 - bouncePhase;
        const bounce = Math.sin(bouncePhase * Math.PI * 2.5);
        const overshootIntensity = -1.2;
        
        state.discreteSpinSpeed = 6.0 * speedFactor + overshootIntensity * bounce * speedFactor;
      }
    } else {
      state.discreteSpinSpeed = 0.05; 
    }

    state.rotationAngle += state.discreteSpinSpeed;
    ctx.rotate((state.rotationAngle * Math.PI) / 180);

    // DYNAMIC baseScale based on component size for better appearance in buttons
    const baseScale = size <= 24 ? 1.5 : 2.5;

    // Scaling effect
    let syncedScale;
    if (state.currentMorph && state.morphProgress < 1.0) {
      const morphPhase = state.morphProgress;
      let scaleVariation;

      if (morphPhase < 0.8) {
        scaleVariation = 0.015 + Math.sin(state.animationTime * 4) * 0.005;
      } else {
        const bouncePhase = (morphPhase - 0.8) / 0.2;
        scaleVariation = 0.015 + Math.sin(bouncePhase * Math.PI) * 0.025;
      }
      syncedScale = baseScale + scaleVariation;
    } else {
      syncedScale = baseScale + Math.sin(state.animationTime * 1.2) * 0.05;
    }
    ctx.scale(syncedScale, syncedScale);

    // Pulse effect
    if (state.currentMorph && state.morphProgress < 1.0) {
      state.pulseValue = 0.8 + state.morphProgress * 0.2;
    } else {
      state.pulseValue = 0.7 + Math.sin(state.animationTime * 3) * 0.2;
    }
  }, [size]); // Add size to dependency array

  const drawPolygonWithEffects = useCallback((polygon, ctx) => {
    const color = getShapeColor();
    drawPolygon(polygon, color, ctx);
  }, [getShapeColor]);

  const drawCubicsWithEffects = useCallback((cubics, ctx) => {
    const color = getShapeColor();
    drawCubics(cubics, color, ctx);
  }, [getShapeColor]);

  const drawCurrentShape = useCallback((ctx) => {
    const state = animationState.current;

    // Use dynamic canvas size based on component size with larger scaling to prevent clipping
    const scaleFactor = size <= 24 ? 3.0 : size <= 48 ? 2.5 : 2.2;
    const canvasSize = Math.round(size * scaleFactor);
    ctx.clearRect(0, 0, canvasSize, canvasSize);

    // Only draw container if showContainer is true
    if (showContainer) {
      drawMaterial3Container(ctx);
    }

    ctx.save();
    ctx.translate(canvasSize / 2, canvasSize / 2);
    applyMaterial3ExpressiveEffects(ctx);

    // Use random shape order if available, otherwise fall back to sequential
    const shapeIndex = state.shapeOrder.length > 0
      ? state.shapeOrder[state.currentShapeIndex]
      : state.currentStep - 1;
    const shape = state.morphShapes[shapeIndex];
    if (shape) {
      drawPolygonWithEffects(shape, ctx);
    }

    ctx.restore();
  }, [drawMaterial3Container, applyMaterial3ExpressiveEffects, drawPolygonWithEffects, size, showContainer]);

  const drawMorphedShape = useCallback((ctx) => {
    const state = animationState.current;

    // Use dynamic canvas size based on component size with larger scaling to prevent clipping
    const scaleFactor = size <= 24 ? 3.0 : size <= 48 ? 2.5 : 2.2;
    const canvasSize = Math.round(size * scaleFactor);
    ctx.clearRect(0, 0, canvasSize, canvasSize);

    // Only draw container if showContainer is true
    if (showContainer) {
      drawMaterial3Container(ctx);
    }

    ctx.save();
    ctx.translate(canvasSize / 2, canvasSize / 2);
    applyMaterial3ExpressiveEffects(ctx);

    if (state.currentMorph) {
      try {
        const morphedCubics = state.currentMorph.asCubics(state.morphProgress);
        drawCubicsWithEffects(morphedCubics, ctx);
      } catch (error) {
        // Fallback to current shape if morphing fails
        const shape = state.morphShapes[state.currentStep - 1];
        if (shape) {
          drawPolygonWithEffects(shape, ctx);
        }
      }
    }

    ctx.restore();
  }, [drawMaterial3Container, applyMaterial3ExpressiveEffects, drawCubicsWithEffects, drawPolygonWithEffects, size, showContainer]);

  const drawPolygon = useCallback((polygon, color, ctx) => {
    if (polygon && polygon.cubics) {
      drawCubics(polygon.cubics, color, ctx);
    }
  }, []);

  const drawCubics = useCallback((cubics, color, ctx) => {
    if (!cubics || cubics.length === 0) return;

    ctx.fillStyle = color;
    ctx.beginPath();

    const firstCubic = cubics[0];
    ctx.moveTo(firstCubic.anchor0X, firstCubic.anchor0Y);

    for (const cubic of cubics) {
      ctx.bezierCurveTo(
        cubic.control0X, cubic.control0Y,
        cubic.control1X, cubic.control1Y,
        cubic.anchor1X, cubic.anchor1Y
      );
    }

    ctx.closePath();
    ctx.fill();
  }, []);

  // Generate random shape order
  const generateRandomShapeOrder = useCallback((shapeCount) => {
    const indices = Array.from({ length: shapeCount }, (_, i) => i);
    // Fisher-Yates shuffle algorithm
    for (let i = indices.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [indices[i], indices[j]] = [indices[j], indices[i]];
    }
    return indices;
  }, []);

  const startAnimation = useCallback((ctx, Morph) => {
    const state = animationState.current;
    if (state.isAnimating) return;

    state.isAnimating = true;

    // Initialize random shape order if not already set
    if (state.shapeOrder.length === 0) {
      state.shapeOrder = generateRandomShapeOrder(state.morphShapes.length);
      state.currentShapeIndex = 0;
      state.nextShapeIndex = 1;
    }

    const animate = () => {
      if (!state.isAnimating) return;

      // Handle morphing
      if (!state.currentMorph && state.morphShapes.length > 0) {
        const currentIndex = state.shapeOrder[state.currentShapeIndex];
        const nextIndex = state.shapeOrder[state.nextShapeIndex];
        const startShape = state.morphShapes[currentIndex];
        const endShape = state.morphShapes[nextIndex];
        state.currentMorph = new Morph(startShape, endShape);
      }

      if (state.currentMorph) {
        // Update morph progress with Material 3 timing
        let morphIncrement;
        if (state.morphProgress < 0.8) {
          morphIncrement = 0.03;
        } else {
          const easeOutFactor = 1 - (state.morphProgress - 0.8) / 0.2;
          morphIncrement = 0.03 * easeOutFactor;
          morphIncrement = Math.max(morphIncrement, 0.001);
        }
        state.morphProgress += morphIncrement;

        if (state.morphProgress >= 1.0) {
          // Move to next shape pair in random order
          state.morphProgress = 0;
          state.currentShapeIndex = state.nextShapeIndex;
          state.nextShapeIndex = (state.nextShapeIndex + 1) % state.shapeOrder.length;

          // If we've completed a full cycle, generate new random order
          if (state.nextShapeIndex === 0) {
            state.shapeOrder = generateRandomShapeOrder(state.morphShapes.length);
            state.currentShapeIndex = 0;
            state.nextShapeIndex = 1;
          }

          // Create new morph for the next transition
          const currentIndex = state.shapeOrder[state.currentShapeIndex];
          const nextIndex = state.shapeOrder[state.nextShapeIndex];
          const startShape = state.morphShapes[currentIndex];
          const endShape = state.morphShapes[nextIndex];
          state.currentMorph = new Morph(startShape, endShape);
        }

        drawMorphedShape(ctx);
      } else {
        drawCurrentShape(ctx);
      }

      animationRef.current = requestAnimationFrame(animate);
    };

    animate();
  }, [drawMorphedShape, drawCurrentShape, generateRandomShapeOrder]);

  const initializeAnimation = useCallback(async (ctx) => {
    try {
      // Load the REAL modules dynamically
      const [, , { RoundedPolygon }, { Morph }] = await Promise.all([
        import('./LoadingIndicator/utils.js'),
        import('./LoadingIndicator/cubic.js'),
        import('./LoadingIndicator/roundedPolygon.js'),
        import('./LoadingIndicator/morph-fixed.js')
      ]);

      // Create refined collection of 38 diverse shapes!
      const shapes = [];
      for (let i = 0; i < 38; i++) {
        shapes.push(createFallbackShape(i, RoundedPolygon));
      }
      animationState.current.morphShapes = shapes;
      setIsLoaded(true);
      startAnimation(ctx, Morph);
    } catch (error) {
      console.error('❌ Failed to load REAL animation modules:', error);
      setIsLoaded(false);
    }
  }, [startAnimation, size]);







  // Refined collection of creative shapes - WITH PROPER ROUNDING!
  const createFallbackShape = (index, RoundedPolygon) => {
    switch (index) {
      case 0: return new RoundedPolygon(new Float32Array([0, -20, 17, 10, -17, 10]), 6); // Triangle
      case 1: return new RoundedPolygon(new Float32Array([-15, -15, 15, -15, 15, 15, -15, 15]), 8); // Square
      case 2: return new RoundedPolygon(new Float32Array([0, -17, 16, -5, 10, 14, -10, 14, -16, -5]), 5); // Pentagon
      case 3: return createStarPolygon(15, 5, RoundedPolygon); // 5-pointed Star
      case 4: return new RoundedPolygon(new Float32Array([20, 0, 10, 17, -10, 17, -20, 0, -10, -17, 10, -17]), 4); // Hexagon
      case 5: return createCirclePolygon(15, 8, RoundedPolygon); // Octagon
      case 6: return createStarPolygon(18, 6, RoundedPolygon); // 6-pointed Star
      case 7: return createDiamondShape(18, RoundedPolygon); // Diamond
      case 8: return createCrossShape(16, RoundedPolygon); // Cross/Plus
      case 9: return createArrowShape(18, RoundedPolygon); // Arrow
      case 10: return createStarPolygon(14, 4, RoundedPolygon); // 4-pointed Star
      case 11: return createOvalShape(18, 12, RoundedPolygon); // Oval (improved)
      case 12: return createTearDropShape(16, RoundedPolygon); // Teardrop (improved)
      case 13: return createMoonShape(16, RoundedPolygon); // Crescent Moon
      case 14: return createFlowerShape(15, RoundedPolygon); // Flower
      case 15: return createHouseShape(16, RoundedPolygon); // House
      case 16: return createSpadeShape(16, RoundedPolygon); // Spade (improved)
      case 17: return createInfinityShape(18, RoundedPolygon); // Infinity (improved)
      case 18: return createGearShape(16, RoundedPolygon); // Gear/Cog
      case 19: return createSunShape(17, RoundedPolygon); // Sun
      case 20: return createBoltShape(18, RoundedPolygon); // Bolt/Screw
      case 21: return createWaveShape(20, RoundedPolygon); // Wave
      case 22: return createRingShape(16, RoundedPolygon); // Ring/Donut (fixed)
      case 23: return createPillShape(18, RoundedPolygon); // Pill/Capsule
      case 24: return createBoneShape(18, RoundedPolygon); // Bone
      case 25: return createMountainShape(14, RoundedPolygon); // Mountain
      case 26: return createFishShape(18, RoundedPolygon); // Fish
      case 27: return createTreeShape(17, RoundedPolygon); // Tree
      case 28: return createCactusShape(15, RoundedPolygon); // Cactus
      case 29: return createCupShape(15, RoundedPolygon); // Cup (wider bottom)
      case 30: return createBottleShape(14, RoundedPolygon); // Bottle
      case 31: return createBookShape(16, RoundedPolygon); // Book
      case 32: return createPhoneShape(14, RoundedPolygon); // Phone
      case 33: return createCameraShape(16, RoundedPolygon); // Camera
      case 34: return createPuzzlePieceShape(16, RoundedPolygon); // Puzzle Piece (simplified)
      case 35: return createAnchorShape(16, RoundedPolygon); // Anchor
      case 36: return createCrownShape(17, RoundedPolygon); // Crown
      case 37: return createStarPolygon(12, 8, RoundedPolygon); // 8-pointed Star
      default: return createCirclePolygon(15, 8, RoundedPolygon);
    }
  };

  const createCirclePolygon = (radius, sides, RoundedPolygon) => {
    const vertices = new Float32Array(sides * 2);
    for (let i = 0; i < sides; i++) {
      const angle = (i / sides) * 2 * Math.PI;
      vertices[i * 2] = Math.cos(angle) * radius;
      vertices[i * 2 + 1] = Math.sin(angle) * radius;
    }
    return new RoundedPolygon(vertices, 3); // 3px rounding for smooth circle
  };

  const createStarPolygon = (radius, points, RoundedPolygon) => {
    const vertices = new Float32Array(points * 4);
    const innerRadius = radius * 0.4;
    let vertexIndex = 0;

    for (let i = 0; i < points; i++) {
      const outerAngle = (i / points) * 2 * Math.PI - Math.PI / 2;
      vertices[vertexIndex++] = Math.cos(outerAngle) * radius;
      vertices[vertexIndex++] = Math.sin(outerAngle) * radius;

      const innerAngle = ((i + 0.5) / points) * 2 * Math.PI - Math.PI / 2;
      vertices[vertexIndex++] = Math.cos(innerAngle) * innerRadius;
      vertices[vertexIndex++] = Math.sin(innerAngle) * innerRadius;
    }
    return new RoundedPolygon(vertices, 2); // 2px rounding for smooth star points
  };

  const createDiamondShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([0, -size, size, 0, 0, size, -size, 0]);
    return new RoundedPolygon(vertices, 4);
  };

  const createCrossShape = (size, RoundedPolygon) => {
    const thickness = size * 0.3;
    const vertices = new Float32Array([
      -thickness, -size, thickness, -size, thickness, -thickness,
      size, -thickness, size, thickness, thickness, thickness,
      thickness, size, -thickness, size, -thickness, thickness,
      -size, thickness, -size, -thickness, -thickness, -thickness
    ]);
    return new RoundedPolygon(vertices, 3);
  };

  const createArrowShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      0, -size, size * 0.5, -size * 0.3, size * 0.2, -size * 0.3,
      size * 0.2, size, -size * 0.2, size, -size * 0.2, -size * 0.3,
      -size * 0.5, -size * 0.3
    ]);
    return new RoundedPolygon(vertices, 3);
  };

  const createOvalShape = (width, height, RoundedPolygon) => {
    const sides = 24; // More sides for smoother oval
    const vertices = new Float32Array(sides * 2);
    for (let i = 0; i < sides; i++) {
      const angle = (i / sides) * 2 * Math.PI;
      vertices[i * 2] = Math.cos(angle) * width;
      vertices[i * 2 + 1] = Math.sin(angle) * height;
    }
    return new RoundedPolygon(vertices, 1); // Less rounding for smoother curves
  };

  const createTearDropShape = (size, RoundedPolygon) => {
    // Realistic teardrop shape with smooth curves
    const vertices = new Float32Array([
      0, -size, // Sharp point at top
      size * 0.5, -size * 0.6, // Right side curve
      size * 0.8, -size * 0.1, // Right bulge
      size * 0.9, size * 0.3, // Right bottom
      size * 0.6, size * 0.7, // Right bottom curve
      size * 0.2, size * 0.9, // Bottom right
      0, size, // Bottom center
      -size * 0.2, size * 0.9, // Bottom left
      -size * 0.6, size * 0.7, // Left bottom curve
      -size * 0.9, size * 0.3, // Left bottom
      -size * 0.8, -size * 0.1, // Left bulge
      -size * 0.5, -size * 0.6 // Left side curve
    ]);
    return new RoundedPolygon(vertices, 6); // Higher rounding for smooth teardrop
  };

  const createMoonShape = (size, RoundedPolygon) => {
    // Crescent moon approximation
    const vertices = new Float32Array([
      size * 0.5, -size * 0.8, size * 0.8, -size * 0.3, size * 0.6, 0,
      size * 0.8, size * 0.3, size * 0.5, size * 0.8, 0, size * 0.5,
      -size * 0.3, size * 0.2, -size * 0.5, 0, -size * 0.3, -size * 0.2,
      0, -size * 0.5
    ]);
    return new RoundedPolygon(vertices, 5);
  };

  const createFlowerShape = (size, RoundedPolygon) => {
    // 8-petal flower
    const petals = 8;
    const vertices = new Float32Array(petals * 4);
    let vertexIndex = 0;

    for (let i = 0; i < petals; i++) {
      const angle = (i / petals) * 2 * Math.PI;
      const petalTipX = Math.cos(angle) * size;
      const petalTipY = Math.sin(angle) * size;
      const petalBaseX = Math.cos(angle) * size * 0.3;
      const petalBaseY = Math.sin(angle) * size * 0.3;

      vertices[vertexIndex++] = petalTipX;
      vertices[vertexIndex++] = petalTipY;
      vertices[vertexIndex++] = petalBaseX;
      vertices[vertexIndex++] = petalBaseY;
    }
    return new RoundedPolygon(vertices, 6);
  };

  const createHouseShape = (size, RoundedPolygon) => {
    // Simple house silhouette
    const vertices = new Float32Array([
      0, -size, size * 0.7, -size * 0.3, size * 0.7, size * 0.2,
      size * 0.7, size * 0.8, -size * 0.7, size * 0.8, -size * 0.7, size * 0.2,
      -size * 0.7, -size * 0.3
    ]);
    return new RoundedPolygon(vertices, 5);
  };

  const createSpadeShape = (size, RoundedPolygon) => {
    // Smooth spade card suit
    const vertices = new Float32Array([
      0, -size, // Top point
      size * 0.4, -size * 0.6, // Right top curve
      size * 0.7, -size * 0.2, // Right side
      size * 0.8, size * 0.1, // Right bulge
      size * 0.6, size * 0.4, // Right bottom curve
      size * 0.3, size * 0.5, // Right stem connection
      size * 0.25, size * 0.7, // Right stem
      size * 0.15, size * 0.9, // Right stem bottom
      0, size, // Bottom center
      -size * 0.15, size * 0.9, // Left stem bottom
      -size * 0.25, size * 0.7, // Left stem
      -size * 0.3, size * 0.5, // Left stem connection
      -size * 0.6, size * 0.4, // Left bottom curve
      -size * 0.8, size * 0.1, // Left bulge
      -size * 0.7, -size * 0.2, // Left side
      -size * 0.4, -size * 0.6 // Left top curve
    ]);
    return new RoundedPolygon(vertices, 5); // Higher rounding for smooth curves
  };



  const createInfinityShape = (size, RoundedPolygon) => {
    // Smooth infinity symbol (figure-8) with more natural curves
    const vertices = new Float32Array([
      -size * 0.9, 0, // Left outer point
      -size * 0.7, -size * 0.3, // Left top curve
      -size * 0.4, -size * 0.4, // Left top inner
      -size * 0.1, -size * 0.3, // Center top left
      0, 0, // Center crossing
      size * 0.1, -size * 0.3, // Center top right
      size * 0.4, -size * 0.4, // Right top inner
      size * 0.7, -size * 0.3, // Right top curve
      size * 0.9, 0, // Right outer point
      size * 0.7, size * 0.3, // Right bottom curve
      size * 0.4, size * 0.4, // Right bottom inner
      size * 0.1, size * 0.3, // Center bottom right
      0, 0, // Center crossing (duplicate for smooth path)
      -size * 0.1, size * 0.3, // Center bottom left
      -size * 0.4, size * 0.4, // Left bottom inner
      -size * 0.7, size * 0.3 // Left bottom curve
    ]);
    return new RoundedPolygon(vertices, 8); // High rounding for smooth infinity curves
  };

  const createGearShape = (size, RoundedPolygon) => {
    // Gear with 8 teeth
    const teeth = 8;
    const innerRadius = size * 0.6;
    const outerRadius = size;
    const vertices = new Float32Array(teeth * 4);
    let vertexIndex = 0;

    for (let i = 0; i < teeth; i++) {
      const baseAngle = (i / teeth) * 2 * Math.PI;
      const toothAngle = ((i + 0.5) / teeth) * 2 * Math.PI;

      // Inner point
      vertices[vertexIndex++] = Math.cos(baseAngle) * innerRadius;
      vertices[vertexIndex++] = Math.sin(baseAngle) * innerRadius;

      // Outer tooth point
      vertices[vertexIndex++] = Math.cos(toothAngle) * outerRadius;
      vertices[vertexIndex++] = Math.sin(toothAngle) * outerRadius;
    }
    return new RoundedPolygon(vertices, 2);
  };

  const createSunShape = (size, RoundedPolygon) => {
    const rays = 12;
    const innerRadius = size * 0.5;
    const outerRadius = size;
    const vertices = new Float32Array(rays * 4);
    let vertexIndex = 0;

    for (let i = 0; i < rays; i++) {
      const baseAngle = (i / rays) * 2 * Math.PI;
      const rayAngle = ((i + 0.5) / rays) * 2 * Math.PI;

      vertices[vertexIndex++] = Math.cos(baseAngle) * innerRadius;
      vertices[vertexIndex++] = Math.sin(baseAngle) * innerRadius;

      vertices[vertexIndex++] = Math.cos(rayAngle) * outerRadius;
      vertices[vertexIndex++] = Math.sin(rayAngle) * outerRadius;
    }
    return new RoundedPolygon(vertices, 4);
  };



  const createBoltShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      0, -size, // Top
      size * 0.3, -size * 0.7, // Top right
      size * 0.2, -size * 0.3, // Upper body
      size * 0.4, -size * 0.1, // Thread start
      size * 0.2, size * 0.1, // Thread
      size * 0.4, size * 0.3, // Thread
      size * 0.2, size * 0.5, // Thread
      size * 0.4, size * 0.7, // Thread end
      size * 0.2, size, // Bottom right
      -size * 0.2, size, // Bottom left
      -size * 0.4, size * 0.7, // Thread end
      -size * 0.2, size * 0.5, // Thread
      -size * 0.4, size * 0.3, // Thread
      -size * 0.2, size * 0.1, // Thread
      -size * 0.4, -size * 0.1, // Thread start
      -size * 0.2, -size * 0.3, // Upper body
      -size * 0.3, -size * 0.7 // Top left
    ]);
    return new RoundedPolygon(vertices, 2);
  };

  const createLeafShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      0, -size, // Tip
      size * 0.3, -size * 0.7, // Right upper
      size * 0.6, -size * 0.3, // Right side
      size * 0.8, size * 0.1, // Right bulge
      size * 0.6, size * 0.5, // Right lower
      size * 0.2, size * 0.8, // Right bottom
      0, size, // Bottom point
      -size * 0.2, size * 0.8, // Left bottom
      -size * 0.6, size * 0.5, // Left lower
      -size * 0.8, size * 0.1, // Left bulge
      -size * 0.6, -size * 0.3, // Left side
      -size * 0.3, -size * 0.7 // Left upper
    ]);
    return new RoundedPolygon(vertices, 5);
  };

  const createEyeShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.9, 0, // Left corner
      -size * 0.6, -size * 0.4, // Left top
      -size * 0.2, -size * 0.6, // Upper left
      size * 0.2, -size * 0.6, // Upper right
      size * 0.6, -size * 0.4, // Right top
      size * 0.9, 0, // Right corner
      size * 0.6, size * 0.4, // Right bottom
      size * 0.2, size * 0.6, // Lower right
      -size * 0.2, size * 0.6, // Lower left
      -size * 0.6, size * 0.4 // Left bottom
    ]);
    return new RoundedPolygon(vertices, 6);
  };

  const createWaveShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size, 0, // Start
      -size * 0.7, -size * 0.5, // First peak
      -size * 0.3, -size * 0.3, // First valley
      0, -size * 0.6, // Middle peak
      size * 0.3, -size * 0.3, // Second valley
      size * 0.7, -size * 0.5, // Second peak
      size, 0, // End
      size * 0.7, size * 0.5, // Return peak
      size * 0.3, size * 0.3, // Return valley
      0, size * 0.6, // Return middle
      -size * 0.3, size * 0.3, // Return valley
      -size * 0.7, size * 0.5 // Return peak
    ]);
    return new RoundedPolygon(vertices, 7);
  };

  const createRingShape = (size, RoundedPolygon) => {
    const outerSides = 20;
    const innerSides = 16;
    const outerRadius = size;
    const innerRadius = size * 0.4;
    const vertices = new Float32Array((outerSides + innerSides) * 2);
    let vertexIndex = 0;

    // Outer ring - smooth circle
    for (let i = 0; i < outerSides; i++) {
      const angle = (i / outerSides) * 2 * Math.PI;
      vertices[vertexIndex++] = Math.cos(angle) * outerRadius;
      vertices[vertexIndex++] = Math.sin(angle) * outerRadius;
    }

    // Inner ring - smooth circle (reverse direction for proper hole)
    for (let i = innerSides - 1; i >= 0; i--) {
      const angle = (i / innerSides) * 2 * Math.PI;
      vertices[vertexIndex++] = Math.cos(angle) * innerRadius;
      vertices[vertexIndex++] = Math.sin(angle) * innerRadius;
    }

    return new RoundedPolygon(vertices, 2);
  };

  const createCrescentShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      size * 0.6, -size * 0.8, // Top outer
      size * 0.9, -size * 0.3, // Right outer
      size * 0.8, 0, // Right middle
      size * 0.9, size * 0.3, // Right outer bottom
      size * 0.6, size * 0.8, // Bottom outer
      size * 0.2, size * 0.6, // Inner bottom
      0, size * 0.3, // Inner right
      -size * 0.2, 0, // Inner middle
      0, -size * 0.3, // Inner left
      size * 0.2, -size * 0.6 // Inner top
    ]);
    return new RoundedPolygon(vertices, 6);
  };

  const createPillShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.5, -size, // Top left
      size * 0.5, -size, // Top right
      size, -size * 0.5, // Right top curve
      size, size * 0.5, // Right bottom curve
      size * 0.5, size, // Bottom right
      -size * 0.5, size, // Bottom left
      -size, size * 0.5, // Left bottom curve
      -size, -size * 0.5 // Left top curve
    ]);
    return new RoundedPolygon(vertices, 8);
  };

  const createBoneShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.8, -size * 0.3, // Left top
      -size * 0.6, -size * 0.6, // Left top bulge
      -size * 0.3, -size * 0.4, // Left neck
      -size * 0.1, -size * 0.2, // Center left
      size * 0.1, -size * 0.2, // Center right
      size * 0.3, -size * 0.4, // Right neck
      size * 0.6, -size * 0.6, // Right top bulge
      size * 0.8, -size * 0.3, // Right top
      size * 0.8, size * 0.3, // Right bottom
      size * 0.6, size * 0.6, // Right bottom bulge
      size * 0.3, size * 0.4, // Right neck
      size * 0.1, size * 0.2, // Center right
      -size * 0.1, size * 0.2, // Center left
      -size * 0.3, size * 0.4, // Left neck
      -size * 0.6, size * 0.6, // Left bottom bulge
      -size * 0.8, size * 0.3 // Left bottom
    ]);
    return new RoundedPolygon(vertices, 4);
  };

  const createKeyShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.8, -size * 0.2, // Handle left
      -size * 0.8, size * 0.2, // Handle left bottom
      -size * 0.2, size * 0.2, // Handle right bottom
      -size * 0.2, size * 0.1, // Shaft start
      size * 0.6, size * 0.1, // Shaft end
      size * 0.8, size * 0.3, // Tooth 1
      size * 0.9, size * 0.1, // Tooth 1 end
      size * 0.9, -size * 0.1, // Tooth 2 start
      size * 0.8, -size * 0.3, // Tooth 2
      size * 0.6, -size * 0.1, // Shaft end top
      -size * 0.2, -size * 0.1, // Shaft start top
      -size * 0.2, -size * 0.2 // Handle right top
    ]);
    return new RoundedPolygon(vertices, 3);
  };

  const createLockShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.6, -size * 0.2, // Body left
      -size * 0.6, size * 0.8, // Body left bottom
      size * 0.6, size * 0.8, // Body right bottom
      size * 0.6, -size * 0.2, // Body right
      size * 0.4, -size * 0.2, // Shackle right bottom
      size * 0.4, -size * 0.6, // Shackle right
      size * 0.2, -size * 0.8, // Shackle right top
      -size * 0.2, -size * 0.8, // Shackle left top
      -size * 0.4, -size * 0.6, // Shackle left
      -size * 0.4, -size * 0.2 // Shackle left bottom
    ]);
    return new RoundedPolygon(vertices, 4);
  };



  const createMountainShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size, size, // Left base
      -size * 0.6, size * 0.2, // Left slope
      -size * 0.3, -size * 0.8, // Left peak
      0, -size * 0.4, // Center valley
      size * 0.3, -size, // Right peak
      size * 0.6, size * 0.2, // Right slope
      size, size // Right base
    ]);
    return new RoundedPolygon(vertices, 3);
  };

  const createFishShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size, 0, // Tail center
      -size * 0.7, -size * 0.3, // Tail top
      -size * 0.4, -size * 0.2, // Body start top
      size * 0.2, -size * 0.4, // Body top
      size * 0.8, -size * 0.2, // Head top
      size, 0, // Nose
      size * 0.8, size * 0.2, // Head bottom
      size * 0.2, size * 0.4, // Body bottom
      -size * 0.4, size * 0.2, // Body start bottom
      -size * 0.7, size * 0.3 // Tail bottom
    ]);
    return new RoundedPolygon(vertices, 4);
  };

  const createBirdShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.8, size * 0.2, // Tail
      -size * 0.4, 0, // Body back
      -size * 0.2, -size * 0.3, // Body top
      size * 0.2, -size * 0.4, // Neck
      size * 0.6, -size * 0.2, // Head back
      size * 0.9, -size * 0.1, // Beak top
      size, 0, // Beak tip
      size * 0.9, size * 0.1, // Beak bottom
      size * 0.6, size * 0.2, // Head bottom
      size * 0.2, size * 0.4, // Neck bottom
      -size * 0.2, size * 0.5, // Body bottom
      -size * 0.6, size * 0.4 // Wing
    ]);
    return new RoundedPolygon(vertices, 4);
  };

  const createTreeShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.1, size, // Trunk left bottom
      -size * 0.1, size * 0.3, // Trunk left top
      -size * 0.6, size * 0.2, // Leaves left
      -size * 0.7, -size * 0.2, // Leaves left top
      -size * 0.3, -size * 0.8, // Leaves top left
      0, -size, // Leaves top center
      size * 0.3, -size * 0.8, // Leaves top right
      size * 0.7, -size * 0.2, // Leaves right top
      size * 0.6, size * 0.2, // Leaves right
      size * 0.1, size * 0.3, // Trunk right top
      size * 0.1, size // Trunk right bottom
    ]);
    return new RoundedPolygon(vertices, 5);
  };

  // Create remaining shapes (simplified versions for performance)
  const createCactusShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.2, size, -size * 0.2, -size * 0.2, -size * 0.6, -size * 0.4,
      -size * 0.6, -size * 0.8, -size * 0.4, -size * 0.8, -size * 0.4, -size * 0.4,
      -size * 0.1, -size * 0.4, -size * 0.1, -size, size * 0.1, -size,
      size * 0.1, -size * 0.4, size * 0.4, -size * 0.4, size * 0.4, -size * 0.8,
      size * 0.6, -size * 0.8, size * 0.6, -size * 0.4, size * 0.2, -size * 0.2,
      size * 0.2, size
    ]);
    return new RoundedPolygon(vertices, 4);
  };



  const createCupShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.4, -size, // Top left (narrower)
      size * 0.4, -size, // Top right (narrower)
      size * 0.8, size * 0.8, // Bottom right (much wider)
      -size * 0.8, size * 0.8 // Bottom left (much wider)
    ]);
    return new RoundedPolygon(vertices, 6);
  };

  const createBottleShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.2, -size, size * 0.2, -size, size * 0.2, -size * 0.7,
      size * 0.4, -size * 0.7, size * 0.4, size * 0.8, -size * 0.4, size * 0.8,
      -size * 0.4, -size * 0.7, -size * 0.2, -size * 0.7
    ]);
    return new RoundedPolygon(vertices, 4);
  };

  const createBookShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.8, -size * 0.6, size * 0.8, -size * 0.6, size * 0.8, size * 0.6,
      -size * 0.8, size * 0.6
    ]);
    return new RoundedPolygon(vertices, 3);
  };

  const createPhoneShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.4, -size, size * 0.4, -size, size * 0.4, size,
      -size * 0.4, size
    ]);
    return new RoundedPolygon(vertices, 8);
  };



  const createCameraShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.8, -size * 0.2, size * 0.8, -size * 0.2, size * 0.8, size * 0.6,
      -size * 0.8, size * 0.6
    ]);
    return new RoundedPolygon(vertices, 3);
  };



  const createPuzzlePieceShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      // Main square outline with one corner cut out
      -size * 0.8, -size * 0.8, // Top left
      size * 0.8, -size * 0.8, // Top right
      size * 0.8, 0, // Right middle
      0, 0, // Center (cut corner start)
      0, size * 0.8, // Bottom middle
      -size * 0.8, size * 0.8, // Bottom left
      -size * 0.8, -size * 0.8 // Back to start
    ]);
    return new RoundedPolygon(vertices, 4);
  };



  const createRocketShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      0, -size, size * 0.3, -size * 0.6, size * 0.3, size * 0.4,
      size * 0.6, size * 0.8, -size * 0.6, size * 0.8, -size * 0.3, size * 0.4,
      -size * 0.3, -size * 0.6
    ]);
    return new RoundedPolygon(vertices, 4);
  };

  const createAnchorShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      0, -size, size * 0.2, -size * 0.6, size * 0.2, 0,
      size * 0.6, size * 0.4, size * 0.8, size * 0.8, size * 0.4, size * 0.6,
      size * 0.2, size * 0.2, -size * 0.2, size * 0.2, -size * 0.4, size * 0.6,
      -size * 0.8, size * 0.8, -size * 0.6, size * 0.4, -size * 0.2, 0,
      -size * 0.2, -size * 0.6
    ]);
    return new RoundedPolygon(vertices, 3);
  };

  const createCrownShape = (size, RoundedPolygon) => {
    const vertices = new Float32Array([
      -size * 0.8, size * 0.2, -size * 0.6, -size * 0.4, -size * 0.3, size * 0.2,
      0, -size * 0.8, size * 0.3, size * 0.2, size * 0.6, -size * 0.4,
      size * 0.8, size * 0.2, size * 0.8, size * 0.6, -size * 0.8, size * 0.6
    ]);
    return new RoundedPolygon(vertices, 4);
  };

  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas) return;

    const ctx = canvas.getContext('2d');
    const dpr = window.devicePixelRatio || 1;

    // Set canvas internal size based on the display size for proper scaling
    // Use larger scaling for small sizes to prevent clipping
    const scaleFactor = size <= 24 ? 3.0 : size <= 48 ? 2.5 : 2.2;
    const canvasSize = Math.round(size * scaleFactor);
    canvas.width = canvasSize * dpr;
    canvas.height = canvasSize * dpr;
    // Scale for device pixel ratio and fit to display size
    ctx.scale(dpr, dpr);

    // Initialize the REAL animation
    initializeAnimation(ctx);

    return () => {
      const state = animationState.current;
      state.isAnimating = false;
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, [size, initializeAnimation]);

  // Re-render when theme or container changes
  useEffect(() => {
    if (isLoaded && canvasRef.current) {
      // Trigger a redraw with current state
      const ctx = canvasRef.current.getContext('2d');
      const state = animationState.current;
      if (state.currentMorph) {
        drawMorphedShape(ctx);
      } else {
        drawCurrentShape(ctx);
      }
    }
  }, [theme, showContainer, isLoaded, drawMorphedShape, drawCurrentShape]);

  // Cleanup on unmount
  useEffect(() => {
    return () => {
      const state = animationState.current;
      state.isAnimating = false;
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, []);

  return (
    <div
      className={`loading-indicator ${className}`}
      style={{
        width: `${size}px`,
        height: `${size}px`,
        ...style
      }}
    >
      <canvas
        ref={canvasRef}
        className="loading-indicator-canvas"
        style={{
          width: `${size}px`,  // Display at intended size
          height: `${size}px`,
          borderRadius: '12px'
        }}
      />
    </div>
  );
};

export default LoadingIndicator;
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/cubic.js">
/*
 * Copyright 2022 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import {
    Point,
    convex,
    DistanceEpsilon,
    interpolate,
    directionVector,
    distance as math_distance // aliasing to avoid conflict with a potential method
} from "./utils.js"; // Assumed utility file

/**
 * @typedef {object} TransformResult
 * @property {number} first - The transformed x-coordinate.
 * @property {number} second - The transformed y-coordinate.
 */

/**
 * Interface for a function that can transform (rotate/scale/translate/etc.) points.
 * @callback PointTransformer
 * @param {number} x - The x-coordinate of the point to transform.
 * @param {number} y - The y-coordinate of the point to transform.
 * @returns {TransformResult} The transformed point.
 */

/**
 * @typedef {object} MutablePoint
 * @property {number} x
 * @property {number} y
 */


/**
 * This class holds the anchor and control point data for a single cubic Bézier curve, with anchor
 * points at either end and control points determining the slope of the curve
 * between the anchor points.
 */
export class Cubic {
    /** @internal */
    points;

    /**
     * @param {Float32Array|number[]|number} [points=new Float32Array(8)] - Array of 8 points or first coordinate
     * @param {number} [anchor0Y] - If first param is number, this is anchor0Y
     * @param {number} [control0X] - control0X coordinate
     * @param {number} [control0Y] - control0Y coordinate
     * @param {number} [control1X] - control1X coordinate
     * @param {number} [control1Y] - control1Y coordinate
     * @param {number} [anchor1X] - anchor1X coordinate
     * @param {number} [anchor1Y] - anchor1Y coordinate
     */
    constructor(points = new Float32Array(8), anchor0Y, control0X, control0Y, control1X, control1Y, anchor1X, anchor1Y) {
        // Handle overloaded constructor: either array or 8 individual coordinates
        if (typeof points === 'number' && arguments.length === 8) {
            // Called with 8 individual coordinates
            this.points = new Float32Array([
                points, anchor0Y, control0X, control0Y,
                control1X, control1Y, anchor1X, anchor1Y
            ]);
        } else {
            // Called with array
            if (points.length !== 8) {
                throw new Error("Points array size should be 8");
            }
            this.points = points instanceof Float32Array ? points : new Float32Array(points);
        }
    }

    /** The first anchor point x coordinate */
    get anchor0X() { return this.points[0]; }
    /** The first anchor point y coordinate */
    get anchor0Y() { return this.points[1]; }
    /** The first control point x coordinate */
    get control0X() { return this.points[2]; }
    /** The first control point y coordinate */
    get control0Y() { return this.points[3]; }
    /** The second control point x coordinate */
    get control1X() { return this.points[4]; }
    /** The second control point y coordinate */
    get control1Y() { return this.points[5]; }
    /** The second anchor point x coordinate */
    get anchor1X() { return this.points[6]; }
    /** The second anchor point y coordinate */
    get anchor1Y() { return this.points[7]; }

    /**
     * Returns a point on the curve for parameter t, representing the proportional distance along
     * the curve between its starting point at anchor0 and ending point at anchor1.
     *
     * @param {number} t The distance along the curve between the anchor points, where 0 is at
     *   anchor0 and 1 is at anchor1.
     * @returns {Point}
     * @internal
     */
    pointOnCurve(t) {
        const u = 1 - t;
        const u2 = u * u;
        const u3 = u2 * u;
        const t2 = t * t;
        const t3 = t2 * t;

        return new Point(
            this.anchor0X * u3 +
            this.control0X * (3 * t * u2) +
            this.control1X * (3 * t2 * u) +
            this.anchor1X * t3,
            this.anchor0Y * u3 +
            this.control0Y * (3 * t * u2) +
            this.control1Y * (3 * t2 * u) +
            this.anchor1Y * t3,
        );
    }

    /** @internal */
    zeroLength() {
        return Math.abs(this.anchor0X - this.anchor1X) < DistanceEpsilon &&
               Math.abs(this.anchor0Y - this.anchor1Y) < DistanceEpsilon;
    }

    /** @internal */
    convexTo(next) {
        const prevVertex = new Point(this.anchor0X, this.anchor0Y);
        const currVertex = new Point(this.anchor1X, this.anchor1Y);
        const nextVertex = new Point(next.anchor1X, next.anchor1Y);
        return convex(prevVertex, currVertex, nextVertex);
    }

    /** @private */
    zeroIsh(value) {
        return Math.abs(value) < DistanceEpsilon;
    }

    /**
     * This function returns the true bounds of this curve, filling `bounds` with the axis-aligned
     * bounding box values for left, top, right, and bottom, in that order.
     * @param {Float32Array} [bounds=new Float32Array(4)]
     * @param {boolean} [approximate=false]
     * @internal
     */
    calculateBounds(bounds = new Float32Array(4), approximate = false) {
        if (this.zeroLength()) {
            bounds[0] = this.anchor0X;
            bounds[1] = this.anchor0Y;
            bounds[2] = this.anchor0X;
            bounds[3] = this.anchor0Y;
            return;
        }

        let minX = Math.min(this.anchor0X, this.anchor1X);
        let minY = Math.min(this.anchor0Y, this.anchor1Y);
        let maxX = Math.max(this.anchor0X, this.anchor1X);
        let maxY = Math.max(this.anchor0Y, this.anchor1Y);

        if (approximate) {
            bounds[0] = Math.min(minX, this.control0X, this.control1X);
            bounds[1] = Math.min(minY, this.control0Y, this.control1Y);
            bounds[2] = Math.max(maxX, this.control0X, this.control1X);
            bounds[3] = Math.max(maxY, this.control0Y, this.control1Y);
            return;
        }

        // Find derivative roots for X
        const xa = -this.anchor0X + 3 * this.control0X - 3 * this.control1X + this.anchor1X;
        const xb = 2 * this.anchor0X - 4 * this.control0X + 2 * this.control1X;
        const xc = -this.anchor0X + this.control0X;

        if (this.zeroIsh(xa)) {
            if (xb !== 0) {
                const t = -xc / xb;
                if (t >= 0 && t <= 1) {
                    const x = this.pointOnCurve(t).x;
                    minX = Math.min(minX, x);
                    maxX = Math.max(maxX, x);
                }
            }
        } else {
            const xs = xb * xb - 4 * xa * xc;
            if (xs >= 0) {
                const sqrtXs = Math.sqrt(xs);
                const t1 = (-xb + sqrtXs) / (2 * xa);
                if (t1 >= 0 && t1 <= 1) {
                    const x = this.pointOnCurve(t1).x;
                    minX = Math.min(minX, x);
                    maxX = Math.max(maxX, x);
                }
                const t2 = (-xb - sqrtXs) / (2 * xa);
                if (t2 >= 0 && t2 <= 1) {
                    const x = this.pointOnCurve(t2).x;
                    minX = Math.min(minX, x);
                    maxX = Math.max(maxX, x);
                }
            }
        }

        // Find derivative roots for Y
        const ya = -this.anchor0Y + 3 * this.control0Y - 3 * this.control1Y + this.anchor1Y;
        const yb = 2 * this.anchor0Y - 4 * this.control0Y + 2 * this.control1Y;
        const yc = -this.anchor0Y + this.control0Y;

        if (this.zeroIsh(ya)) {
            if (yb !== 0) {
                const t = -yc / yb;
                if (t >= 0 && t <= 1) {
                    const y = this.pointOnCurve(t).y;
                    minY = Math.min(minY, y);
                    maxY = Math.max(maxY, y);
                }
            }
        } else {
            const ys = yb * yb - 4 * ya * yc;
            if (ys >= 0) {
                const sqrtYs = Math.sqrt(ys);
                const t1 = (-yb + sqrtYs) / (2 * ya);
                if (t1 >= 0 && t1 <= 1) {
                    const y = this.pointOnCurve(t1).y;
                    minY = Math.min(minY, y);
                    maxY = Math.max(maxY, y);
                }
                const t2 = (-yb - sqrtYs) / (2 * ya);
                if (t2 >= 0 && t2 <= 1) {
                    const y = this.pointOnCurve(t2).y;
                    minY = Math.min(minY, y);
                    maxY = Math.max(maxY, y);
                }
            }
        }
        bounds[0] = minX;
        bounds[1] = minY;
        bounds[2] = maxX;
        bounds[3] = maxY;
    }

    /**
     * Returns two Cubics, created by splitting this curve at the given distance of `t` between the
     * original starting and ending anchor points.
     * @param {number} t
     * @returns {[Cubic, Cubic]}
     */
    split(t) {
        const u = 1 - t;
        const p = this.pointOnCurve(t);
        const c1 = createCubic(
            this.anchor0X, this.anchor0Y,
            this.anchor0X * u + this.control0X * t, this.anchor0Y * u + this.control0Y * t,
            this.anchor0X * u * u + this.control0X * 2 * u * t + this.control1X * t * t,
            this.anchor0Y * u * u + this.control0Y * 2 * u * t + this.control1Y * t * t,
            p.x, p.y
        );
        const c2 = createCubic(
            p.x, p.y,
            this.control0X * u * u + this.control1X * 2 * u * t + this.anchor1X * t * t,
            this.control0Y * u * u + this.control1Y * 2 * u * t + this.anchor1Y * t * t,
            this.control1X * u + this.anchor1X * t, this.control1Y * u + this.anchor1Y * t,
            this.anchor1X, this.anchor1Y
        );
        return [c1, c2];
    }

    /** Utility function to reverse the control/anchor points for this curve. */
    reverse() {
        return createCubic(
            this.anchor1X, this.anchor1Y, this.control1X, this.control1Y,
            this.control0X, this.control0Y, this.anchor0X, this.anchor0Y
        );
    }

    /** Adds two Cubic objects together, returning a new Cubic. */
    plus(o) { return new Cubic(this.points.map((p, i) => p + o.points[i])); }
    /** Multiplies a Cubic by a scalar value, returning a new Cubic. */
    times(x) { return new Cubic(this.points.map(p => p * x)); }
    /** Divides a Cubic by a scalar value, returning a new Cubic. */
    div(x) { return this.times(1 / x); }

    toString() {
        return `anchor0: (${this.anchor0X}, ${this.anchor0Y}) control0: (${this.control0X}, ${this.control0Y}), ` +
               `control1: (${this.control1X}, ${this.control1Y}), anchor1: (${this.anchor1X}, ${this.anchor1Y})`;
    }

    equals(other) {
        if (this === other) return true;
        if (!(other instanceof Cubic)) return false;
        for (let i = 0; i < this.points.length; i++) {
            if (this.points[i] !== other.points[i]) return false;
        }
        return true;
    }

    /**
     * Transforms the points in this `Cubic` with the given `PointTransformer` and returns a new `Cubic`.
     * @param {PointTransformer} f The `PointTransformer` used to transform this `Cubic`.
     * @returns {Cubic}
     */
    transformed(f) {
        const newCubic = new MutableCubic();
        newCubic.points.set(this.points);
        newCubic.transform(f);
        return new Cubic(newCubic.points);
    }

    /**
     * Generates a bezier curve that is a straight line between the given anchor points.
     * @param {number} x0
     * @param {number} y0
     * @param {number} x1
     * @param {number} y1
     * @returns {Cubic}
     */
    static straightLine(x0, y0, x1, y1) {
        return createCubic(
            x0, y0,
            interpolate(x0, x1, 1 / 3), interpolate(y0, y1, 1 / 3),
            interpolate(x0, x1, 2 / 3), interpolate(y0, y1, 2 / 3),
            x1, y1
        );
    }

    /**
     * Generates a bezier curve that approximates a circular arc.
     * @param {number} centerX
     * @param {number} centerY
     * @param {number} x0
     * @param {number} y0
     * @param {number} x1
     * @param {number} y1
     * @returns {Cubic}
     */
    static circularArc(centerX, centerY, x0, y0, x1, y1) {
        const p0d = directionVector(x0 - centerX, y0 - centerY);
        const p1d = directionVector(x1 - centerX, y1 - centerY);
        const rotatedP0 = p0d.rotate90();
        const rotatedP1 = p1d.rotate90();
        const clockwise = rotatedP0.dotProduct(x1 - centerX, y1 - centerY) >= 0;
        const cosa = p0d.dotProduct(p1d);
        if (cosa > 0.999) return Cubic.straightLine(x0, y0, x1, y1);

        const k = math_distance(x0 - centerX, y0 - centerY) * 4 / 3 *
                  (Math.sqrt(2 * (1 - cosa)) - Math.sqrt(1 - cosa * cosa)) / (1 - cosa) *
                  (clockwise ? 1 : -1);

        return createCubic(
            x0, y0,
            x0 + rotatedP0.x * k, y0 + rotatedP0.y * k,
            x1 - rotatedP1.x * k, y1 - rotatedP1.y * k,
            x1, y1
        );
    }

    /**
     * Generates an empty Cubic defined at (x0, y0).
     * @param {number} x0
     * @param {number} y0
     * @returns {Cubic}
     * @internal
     */
    static empty(x0, y0) {
        return createCubic(x0, y0, x0, y0, x0, y0, x0, y0);
    }
}

/**
 * Creates a Cubic that holds the anchor and control point data for a single Bézier curve.
 * The returned instance is immutable.
 *
 * @param {number} anchor0X
 * @param {number} anchor0Y
 * @param {number} control0X
 * @param {number} control0Y
 * @param {number} control1X
 * @param {number} control1Y
 * @param {number} anchor1X
 * @param {number} anchor1Y
 * @returns {Cubic}
 */
export function createCubic(
    anchor0X, anchor0Y, control0X, control0Y,
    control1X, control1Y, anchor1X, anchor1Y
) {
    return new Cubic(new Float32Array([
        anchor0X, anchor0Y, control0X, control0Y,
        control1X, control1Y, anchor1X, anchor1Y
    ]));
}

/**
 * This is a Mutable version of `Cubic`, used mostly for performance-critical paths to avoid
 * creating new `Cubic` instances.
 *
 * This is used in Morph.forEachCubic, reusing a `MutableCubic` instance to avoid creating new `Cubic`s.
 */
export class MutableCubic extends Cubic {
    /** @private */
    transformOnePoint(f, ix) {
        const result = f.transform(this.points[ix], this.points[ix + 1]);
        this.points[ix] = result.first;
        this.points[ix + 1] = result.second;
    }

    /**
     * @param {PointTransformer} f
     */
    transform(f) {
        this.transformOnePoint(f, 0);
        this.transformOnePoint(f, 2);
        this.transformOnePoint(f, 4);
        this.transformOnePoint(f, 6);
    }

    /**
     * @param {Cubic} c1
     * @param {Cubic} c2
     * @param {number} progress
     */
    interpolate(c1, c2, progress) {
        for (let i = 0; i < 8; i++) {
            this.points[i] = interpolate(c1.points[i], c2.points[i], progress);
        }
    }
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/featureMapper.js">
/*
 * Copyright 2023 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { Feature } from './roundedPolygon.js';
import { Point, DistanceEpsilon, debugLog } from './utils.js';
import { DoubleMapper } from './floatMapping.js';

const LOG_TAG = "FeatureMapping";
const DEBUG = true;

/**
 * A feature with its progress along the polygon's outline.
 * @internal
 */
export class ProgressableFeature {
    /**
     * @param {number} progress - The progress value [0..1].
     * @param {Feature} feature - The feature itself.
     */
    constructor(progress, feature) {
        this.progress = progress;
        this.feature = feature;
    }
}

/**
 * A list of all features in a polygon along with their progress.
 * @typedef {ProgressableFeature[]} MeasuredFeatures
 */

/**
 * A vertex in the distance graph, connecting a feature from each polygon.
 * @private
 */
class DistanceVertex {
    /**
     * @param {number} distance
     * @param {ProgressableFeature} f1
     * @param {ProgressableFeature} f2
     */
    constructor(distance, f1, f2) {
        this.distance = distance;
        this.f1 = f1;
        this.f2 = f2;
    }
}

/**
 * Creates a mapping between the "features" (rounded corners) of two shapes.
 * @param {MeasuredFeatures} features1
 * @param {MeasuredFeatures} features2
 * @returns {DoubleMapper}
 * @internal
 */
export function featureMapper(features1, features2) {
    // We only use corners for this mapping.
    const filteredFeatures1 = [];
    for (const f of features1) {
        if (f.feature.isCorner) {
            filteredFeatures1.push(f);
        }
    }

    const filteredFeatures2 = [];
    for (const f of features2) {
        if (f.feature.isCorner) {
            filteredFeatures2.push(f);
        }
    }

    const featureProgressMapping = doMapping(filteredFeatures1, filteredFeatures2);

    if (DEBUG) {
        debugLog(LOG_TAG, featureProgressMapping.map(p => `${p.first} -> ${p.second}`).join(', '));
    }

    // DoubleMapper constructor expects individual mapping objects as arguments, not an array
    const dm = new DoubleMapper(...featureProgressMapping);

    if (DEBUG) {
        const N = 10;
        const toFixed = (n) => n.toFixed(3);
        const mapValues = Array.from({ length: N + 1 }, (_, i) => toFixed(dm.map(i / N))).join(', ');
        const mapBackValues = Array.from({ length: N + 1 }, (_, i) => toFixed(dm.mapBack(i / N))).join(', ');
        debugLog(LOG_TAG, `Map: ${mapValues}\nMb : ${mapBackValues}`);
    }
    return dm;
}

/**
 * Returns a mapping of the features between features1 and features2.
 * The return is a list of pairs where the first element is the progress of a feature
 * in features1 and the second is the progress of the mapped feature in features2.
 * @param {ProgressableFeature[]} features1
 * @param {ProgressableFeature[]} features2
 * @returns {{first: number, second: number}[]}
 * @private
 */
function doMapping(features1, features2) {
    if (DEBUG) {
        debugLog(LOG_TAG, `Shape1 progresses: ${features1.map(f => f.progress).join(', ')}`);
        debugLog(LOG_TAG, `Shape2 progresses: ${features2.map(f => f.progress).join(', ')}`);
    }

    const distanceVertexList = [];
    for (const f1 of features1) {
        for (const f2 of features2) {
            const d = featureDistSquared(f1.feature, f2.feature);
            if (d !== Number.MAX_VALUE) {
                distanceVertexList.push(new DistanceVertex(d, f1, f2));
            }
        }
    }
    distanceVertexList.sort((a, b) => a.distance - b.distance);

    // Special cases.
    if (distanceVertexList.length === 0) return IdentityMapping;
    if (distanceVertexList.length === 1) {
        const { f1, f2 } = distanceVertexList[0];
        const p1 = f1.progress;
        const p2 = f2.progress;
        return [
            { first: p1, second: p2 },
            { first: (p1 + 0.5) % 1, second: (p2 + 0.5) % 1 }
        ];
    }

    const helper = new MappingHelper();
    distanceVertexList.forEach(vertex => helper.addMapping(vertex.f1, vertex.f2));
    return helper.mapping;
}

const IdentityMapping = [{ first: 0, second: 0 }, { first: 0.5, second: 0.5 }];

/** Helper for `binarySearchBy` */
function binarySearchBy(sortedArray, key, selector) {
    let low = 0;
    let high = sortedArray.length - 1;
    while (low <= high) {
        const mid = Math.floor((low + high) / 2);
        const midVal = selector(sortedArray[mid]);
        if (midVal < key) low = mid + 1;
        else if (midVal > key) high = mid - 1;
        else return mid;
    }
    return -(low + 1);
}

/** Helper for `MappingHelper` */
function progressDistance(p1, p2) {
    const d = Math.abs(p1 - p2);
    return Math.min(d, 1 - d);
}

/** Helper for `MappingHelper` */
function progressInRange(p, start, end) {
    return start <= end ? p >= start && p <= end : p >= start || p <= end;
}

/** @private */
class MappingHelper {
    constructor() {
        this.mapping = []; // {first: number, second: number}[]
        this.usedF1 = new Set(); // Set<ProgressableFeature>
        this.usedF2 = new Set(); // Set<ProgressableFeature>
    }

    addMapping(f1, f2) {
        if (this.usedF1.has(f1) || this.usedF2.has(f2)) return;

        const index = binarySearchBy(this.mapping, f1.progress, item => item.first);
        if (index >= 0) {
            // This should not happen if all features have unique progress values.
            return;
        }

        const insertionIndex = -index - 1;
        const n = this.mapping.length;

        if (n >= 1) {
            const before = this.mapping[(insertionIndex + n - 1) % n];
            const after = this.mapping[insertionIndex % n];

            if (
                progressDistance(f1.progress, before.first) < DistanceEpsilon ||
                progressDistance(f1.progress, after.first) < DistanceEpsilon ||
                progressDistance(f2.progress, before.second) < DistanceEpsilon ||
                progressDistance(f2.progress, after.second) < DistanceEpsilon
            ) {
                return;
            }

            if (n > 1 && !progressInRange(f2.progress, before.second, after.second)) {
                return;
            }
        }

        this.mapping.splice(insertionIndex, 0, { first: f1.progress, second: f2.progress });
        this.usedF1.add(f1);
        this.usedF2.add(f2);
    }
}

/**
 * Returns squared distance between two Features on two different shapes.
 * @internal
 */
function featureDistSquared(f1, f2) {
    if (f1.isCorner && f2.isCorner && f1.convex !== f2.convex) {
        if (DEBUG) debugLog(LOG_TAG, "*** Feature distance ∞ for convex-vs-concave corners");
        return Number.MAX_VALUE;
    }
    const p1 = featureRepresentativePoint(f1);
    const p2 = featureRepresentativePoint(f2);
    const dx = p1.x - p2.x;
    const dy = p1.y - p2.y;
    return dx * dx + dy * dy;
}

/**
 * Gets a representative point for a feature, used for distance calculations.
 * @internal
 */
function featureRepresentativePoint(feature) {
    const firstCubic = feature.cubics[0];
    const lastCubic = feature.cubics[feature.cubics.length - 1];
    const x = (firstCubic.anchor0X + lastCubic.anchor1X) / 2;
    const y = (firstCubic.anchor0Y + lastCubic.anchor1Y) / 2;
    return new Point(x, y);
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/floatMapping.js">
/*
 * Copyright 2023 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { positiveModulo, DistanceEpsilon } from './utils.js';

/**
 * Checks if the given progress is in the given progress range. Since progress is in the [0..1)
 * interval and wraps, there is a special case when `progressTo` < `progressFrom`. For example,
 * if the progress range is 0.7 to 0.2, both 0.8 and 0.1 are inside, and 0.5 is outside.
 * @internal
 * @param {number} progress The progress value to check.
 * @param {number} progressFrom The start of the range.
 * @param {number} progressTo The end of the range.
 * @returns {boolean} True if the progress is within the range.
 */
export function progressInRange(progress, progressFrom, progressTo) {
    if (progressTo >= progressFrom) {
        return progress >= progressFrom && progress <= progressTo;
    } else {
        // The range wraps around (e.g., 0.8 to 0.2)
        return progress >= progressFrom || progress <= progressTo;
    }
}

/**
 * Maps from one set of progress values to another. This is used by DoubleMapper to retrieve the
 * value on one shape that maps to the appropriate value on the other.
 * @internal
 * @param {number[]} xValues The source progress values.
 * @param {number[]} yValues The target progress values.
 * @param {number} x The source value to map.
 * @returns {number} The mapped value in the target space.
 */
export function linearMap(xValues, yValues, x) {
    // Safety check for NaN or invalid arrays
    if (isNaN(x) || !xValues || !yValues || xValues.length === 0 || yValues.length === 0) {
        console.error(`❌ linearMap: Invalid input - x=${x}, xValues=${xValues}, yValues=${yValues}`);
        return 0; // Return safe default
    }

    // Check for NaN values in arrays
    if (xValues.some(isNaN) || yValues.some(isNaN)) {
        console.error(`❌ linearMap: NaN values in arrays - xValues=${xValues}, yValues=${yValues}`);
        return 0; // Return safe default
    }

    if (x < 0 || x > 1) {
        if (x < -DistanceEpsilon || x > 1 + DistanceEpsilon) {
            throw new Error(`Invalid progress: ${x}`);
        }
        x = Math.max(0, Math.min(1, x));
    }

    let segmentStartIndex = -1;
    for (let i = 0; i < xValues.length; i++) {
        if (progressInRange(x, xValues[i], xValues[(i + 1) % xValues.length])) {
            segmentStartIndex = i;
            break;
        }
    }

    // This should always be found if the input is correct, but as a fallback for floating
    // point issues, find the closest start index.
    if (segmentStartIndex === -1) {
        let minDist = Infinity;
        for (let i = 0; i < xValues.length; i++) {
            const dist = progressDistance(x, xValues[i]);
            if (dist < minDist) {
                minDist = dist;
                segmentStartIndex = i;
            }
        }
    }

    const segmentEndIndex = (segmentStartIndex + 1) % xValues.length;
    const segmentSizeX = positiveModulo(xValues[segmentEndIndex] - xValues[segmentStartIndex], 1);
    const segmentSizeY = positiveModulo(yValues[segmentEndIndex] - yValues[segmentStartIndex], 1);

    const positionInSegment = (segmentSizeX < 0.001) ?
        0.5 :
        positiveModulo(x - xValues[segmentStartIndex], 1) / segmentSizeX;

    return positiveModulo(yValues[segmentStartIndex] + segmentSizeY * positionInSegment, 1);
}

/**
 * DoubleMapper creates mappings from values in the [0..1) source space to values in the
 * [0..1) target space, and back. This mapping is created given a finite list of representative
 * mappings, and this is extended to the whole interval by linear interpolation, and wrapping
 * around.
 * @internal
 */
export class DoubleMapper {
    #sourceValues;
    #targetValues;

    /**
     * @param  {...{first: number, second: number}} mappings - A variable number of mapping pairs.
     */
    constructor(...mappings) {
        this.#sourceValues = new Array(mappings.length);
        this.#targetValues = new Array(mappings.length);

        for (let i = 0; i < mappings.length; i++) {
            this.#sourceValues[i] = mappings[i].first;
            this.#targetValues[i] = mappings[i].second;
        }

        validateProgress(this.#sourceValues);
        validateProgress(this.#targetValues);
    }

    /** Maps a value from the source space to the target space. */
    map(x) {
        return linearMap(this.#sourceValues, this.#targetValues, x);
    }

    /** Maps a value from the target space back to the source space. */
    mapBack(x) {
        return linearMap(this.#targetValues, this.#sourceValues, x);
    }

    /** An identity mapper that maps any value to itself. */
    static Identity = new DoubleMapper({
        first: 0,
        second: 0
    }, {
        first: 0.5,
        second: 0.5
    }, );
}

/**
 * Verifies that a list of progress values is valid: all in [0, 1), monotonically
 * increasing with at most one wrap-around, and no two points are too close.
 * @internal
 * @param {number[]} p - The list of progress values.
 */
export function validateProgress(p) {
    if (p.length === 0) return;
    let prev = p[p.length - 1];
    let wraps = 0;
    for (let i = 0; i < p.length; i++) {
        const curr = p[i];
        if (curr < 0 || curr >= 1) {
            throw new Error(`FloatMapping - Progress outside of range: ${p.join(', ')}`);
        }
        // Using <= to be safe with float comparisons
        if (progressDistance(curr, prev) <= DistanceEpsilon) {
            throw new Error(`FloatMapping - Progress repeats a value: ${p.join(', ')}`);
        }
        if (curr < prev) {
            wraps++;
            if (wraps > 1) {
                throw new Error(`FloatMapping - Progress wraps more than once: ${p.join(', ')}`);
            }
        }
        prev = curr;
    }
}

/**
 * Calculates the shortest distance between two progress values on a circle of circumference 1.
 * For example, the distance between 0.9 and 0.1 is 0.2, not 0.8.
 * @internal
 * @param {number} p1
 * @param {number} p2
 * @returns {number}
 */
export function progressDistance(p1, p2) {
    const d = Math.abs(p1 - p2);
    return Math.min(d, 1 - d);
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/measuredPolygon.js">
/*
 * Copyright 2023 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { Cubic } from "./cubic.js";
import { RoundedPolygon, Feature } from "./roundedPolygon.js";
import { ProgressableFeature } from "./featureMapper.js";
import {
    Point,
    DistanceEpsilon,
    positiveModulo,
    debugLog
} from "./utils.js";

const LOG_TAG = "PolygonMeasure";
const DEBUG = false;

/**
 * A MeasuredCubic holds information about the cubic itself, and the outline progress values
 * (start and end) for the cubic. This information is used to match cubics between shapes that
 * lie at similar outline progress positions along their respective shapes (after matching
 * features and shifting).
 *
 * Outline progress is a value in [0..1] that represents the distance traveled along the
 * overall outline path of the shape.
 * @internal
 */
export class MeasuredCubic {
    /** @type {Cubic} */
    cubic;
    /** @type {number} */
    startOutlineProgress;
    /** @type {number} */
    endOutlineProgress;
    /** @type {Measurer} */
    #measurer;
    /** @type {number} */
    measuredSize;

    /**
     * @param {Cubic} cubic
     * @param {number} startOutlineProgress A value between 0.0 and 1.0.
     * @param {number} endOutlineProgress A value between 0.0 and 1.0.
     * @param {Measurer} measurer
     */
    constructor(cubic, startOutlineProgress, endOutlineProgress, measurer) {
        if (endOutlineProgress < startOutlineProgress) {
            // Allow for a small epsilon for floating point errors
            if (endOutlineProgress < startOutlineProgress - DistanceEpsilon) {
                throw new Error(
                   `endOutlineProgress (${endOutlineProgress}) is expected to be equal or ` +
                   `greater than startOutlineProgress (${startOutlineProgress})`
                );
            }
            endOutlineProgress = startOutlineProgress;
        }
        this.cubic = cubic;
        this.startOutlineProgress = startOutlineProgress;
        this.endOutlineProgress = endOutlineProgress;
        this.#measurer = measurer;
        this.measuredSize = this.#measurer.measureCubic(cubic);
    }

    /**
     * @param {number} [startOutlineProgress]
     * @param {number} [endOutlineProgress]
     */
    updateProgressRange(
        startOutlineProgress = this.startOutlineProgress,
        endOutlineProgress = this.endOutlineProgress
    ) {
        if (endOutlineProgress < startOutlineProgress) {
            throw new Error("endOutlineProgress is expected to be equal or greater than startOutlineProgress");
        }
        this.startOutlineProgress = startOutlineProgress;
        this.endOutlineProgress = endOutlineProgress;
    }

    /**
     * Cut this MeasuredCubic into two MeasuredCubics at the given outline progress value.
     * @param {number} cutOutlineProgress
     * @returns {[MeasuredCubic, MeasuredCubic]}
     */
    cutAtProgress(cutOutlineProgress) {
        // Floating point errors can cause cutOutlineProgress to land just slightly
        // outside of the start/end progress for this cubic, so we limit it.
        const boundedCutOutlineProgress = Math.max(
            this.startOutlineProgress,
            Math.min(cutOutlineProgress, this.endOutlineProgress)
        );

        const outlineProgressSize = this.endOutlineProgress - this.startOutlineProgress;
        const progressFromStart = boundedCutOutlineProgress - this.startOutlineProgress;

        // Note that in earlier parts of the computation, we have empty MeasuredCubics (cubics
        // with progressSize == 0), but those cubics are filtered out before this method is called.
        const relativeProgress = outlineProgressSize === 0 ? 0 : progressFromStart / outlineProgressSize;
        const t = this.#measurer.findCubicCutPoint(this.cubic, relativeProgress * this.measuredSize);
        if (t < 0 || t > 1) {
             // Allow for a small epsilon for floating point errors
            if (t < -DistanceEpsilon || t > 1 + DistanceEpsilon) {
                throw new Error(`Cubic cut point ${t} is expected to be between 0 and 1`);
            }
        }

        if (DEBUG) {
            debugLog(LOG_TAG,
                `cutAtProgress: progress = ${boundedCutOutlineProgress} / ` +
                `this = [${this.startOutlineProgress} .. ${this.endOutlineProgress}] / ` +
                `ps = ${progressFromStart} / rp = ${relativeProgress} / t = ${t}`
            );
        }

        const [c1, c2] = this.cubic.split(t);
        return [
            new MeasuredCubic(c1, this.startOutlineProgress, boundedCutOutlineProgress, this.#measurer),
            new MeasuredCubic(c2, boundedCutOutlineProgress, this.endOutlineProgress, this.#measurer)
        ];
    }

    toString() {
        return `MeasuredCubic(outlineProgress=[${this.startOutlineProgress} .. ${this.endOutlineProgress}], ` +
               `size=${this.measuredSize}, cubic=${this.cubic})`;
    }
}


/** @internal */
export class MeasuredPolygon {
    /** @type {Measurer} */
    #measurer;
    /** @type {MeasuredCubic[]} */
    #cubics;
    /** @type {ProgressableFeature[]} */
    features;

    /**
     * @param {Measurer} measurer
     * @param {ProgressableFeature[]} features
     * @param {Cubic[]} cubics
     * @param {number[]} outlineProgress
     * @private
     */
    constructor(measurer, features, cubics, outlineProgress) {
        if (outlineProgress.length !== cubics.length + 1) {
            throw new Error("Outline progress size is expected to be the cubics size + 1");
        }
        if (outlineProgress[0] !== 0) {
            throw new Error("First outline progress value is expected to be zero");
        }
        if (Math.abs(outlineProgress[outlineProgress.length - 1] - 1.0) > DistanceEpsilon) {
             throw new Error("Last outline progress value is expected to be one");
        }

        this.#measurer = measurer;
        this.features = features;

        if (DEBUG) {
            debugLog(LOG_TAG, `CTOR: cubics = ${cubics.join(", ")}\nCTOR: op = ${outlineProgress.join(", ")}`);
        }

        const measuredCubics = [];
        let startOutlineProgress = 0;
        for (let index = 0; index < cubics.length; index++) {
            // Filter out "empty" cubics
            if ((outlineProgress[index + 1] - outlineProgress[index]) > DistanceEpsilon) {
                measuredCubics.push(
                    new MeasuredCubic(
                        cubics[index],
                        startOutlineProgress,
                        outlineProgress[index + 1],
                        this.#measurer
                    )
                );
                // The next measured cubic will start exactly where this one ends.
                startOutlineProgress = outlineProgress[index + 1];
            }
        }
        // We could have removed empty cubics at the end. Ensure the last measured cubic ends at 1.0
        if (measuredCubics.length > 0) {
            measuredCubics[measuredCubics.length - 1].updateProgressRange(undefined, 1.0);
        }
        this.#cubics = measuredCubics;
    }

    /**
     * Finds the point in the input list of measured cubics that pass the given outline progress,
     * and generates a new MeasuredPolygon (equivalent to this), that starts at that point.
     * @param {number} cuttingPoint
     * @returns {MeasuredPolygon}
     */
    cutAndShift(cuttingPoint) {
        if (cuttingPoint < 0 || cuttingPoint > 1) {
            throw new Error("Cutting point is expected to be between 0 and 1");
        }
        if (cuttingPoint < DistanceEpsilon) return this;

        const targetIndex = this.#cubics.findIndex(it =>
            cuttingPoint >= it.startOutlineProgress && cuttingPoint <= it.endOutlineProgress
        );
        if (targetIndex === -1) {
            // This can happen due to floating point inaccuracies, assume it's at the end.
            if (Math.abs(cuttingPoint - 1.0) < DistanceEpsilon) {
                return this;
            }
            throw new Error(`Cutting point ${cuttingPoint} not found in any cubic range.`);
        }

        const target = this.#cubics[targetIndex];
        if (DEBUG) {
            this.#cubics.forEach((cubic, index) => debugLog(LOG_TAG, `cut&Shift | cubic #${index} : ${cubic} `));
            debugLog(LOG_TAG, `cut&Shift, cuttingPoint = ${cuttingPoint}, target = (${targetIndex}) ${target}`);
        }

        const [b1, b2] = target.cutAtProgress(cuttingPoint);
        if (DEBUG) debugLog(LOG_TAG, `Split | ${target} -> ${b1} & ${b2}`);

        const retCubics = [b2.cubic];
        for (let i = 1; i < this.#cubics.length; i++) {
            retCubics.push(this.#cubics[(i + targetIndex) % this.#cubics.length].cubic);
        }
        retCubics.push(b1.cubic);

        const retOutlineProgress = [0];
        for (let index = 1; index < retCubics.length; index++) {
            const cubicIndex = (targetIndex + index - 1) % this.#cubics.length;
            retOutlineProgress.push(
                positiveModulo(this.#cubics[cubicIndex].endOutlineProgress - cuttingPoint, 1.0)
            );
        }
        retOutlineProgress.push(1.0);

        const newFeatures = this.features.map(f =>
            new ProgressableFeature(
                positiveModulo(f.progress - cuttingPoint, 1.0),
                f.feature
            )
        );

        return new MeasuredPolygon(this.#measurer, newFeatures, retCubics, retOutlineProgress);
    }

    get size() { return this.#cubics.length; }

    get(index) { return this.#cubics[index]; }

    [Symbol.iterator]() { return this.#cubics[Symbol.iterator](); }

    /**
     * @param {Measurer} measurer
     * @param {RoundedPolygon} polygon
     * @returns {MeasuredPolygon}
     */
    static measurePolygon(measurer, polygon) {
        const cubics = [];
        const featureToCubic = [];

        for (const feature of polygon.features) {
            for (let cubicIndex = 0; cubicIndex < feature.cubics.length; cubicIndex++) {
                if (feature.isCorner && cubicIndex === Math.floor(feature.cubics.length / 2)) {
                    featureToCubic.push({ feature, index: cubics.length });
                }
                cubics.push(feature.cubics[cubicIndex]);
            }
        }

        const measures = [0];
        let totalMeasure = 0;
        for (const cubic of cubics) {
            const measure = measurer.measureCubic(cubic);
            if (measure < 0) {
                throw new Error("Measured cubic is expected to be greater or equal to zero");
            }
            totalMeasure += measure;
            measures.push(totalMeasure);
        }

        const outlineProgress = measures.map(m => totalMeasure === 0 ? 0 : m / totalMeasure);
        if(outlineProgress.length > 0) {
            outlineProgress[outlineProgress.length - 1] = 1.0; // Ensure it ends exactly at 1.0
        }


        if (DEBUG) debugLog(LOG_TAG, `Total size: ${totalMeasure}`);

        const features = featureToCubic.map(({ feature, index }) => {
            const progress = positiveModulo(
                (outlineProgress[index] + outlineProgress[index + 1]) / 2,
                1.0
            );
            return new ProgressableFeature(progress, feature);
        });

        return new MeasuredPolygon(measurer, features, cubics, outlineProgress);
    }
}

/**
 * Interface for measuring a cubic.
 * @internal
 */
export class Measurer {
    /**
     * Returns size of given cubic. It has to be greater or equal to 0.
     * @param {Cubic} c
     * @returns {number}
     */
    measureCubic(c) {
        throw new Error("Not implemented");
    }

    /**
     * Given a cubic and a measure, finds the parameter t of the cubic at which that measure is reached.
     * @param {Cubic} c
     * @param {number} m
     * @returns {number}
     */
    findCubicCutPoint(c, m) {
        throw new Error("Not implemented");
    }
}

/**
 * Approximates the arc lengths of cubics by splitting the arc into segments.
 * @internal
 */
export class LengthMeasurer extends Measurer {
    #segments = 3;

    measureCubic(c) {
        return this.#closestProgressTo(c, Infinity).second;
    }

    findCubicCutPoint(c, m) {
        return this.#closestProgressTo(c, m).first;
    }

    /**
     * @param {Cubic} cubic
     * @param {number} threshold
     * @returns {{first: number, second: number}} A pair of (progress, total length)
     * @private
     */
    #closestProgressTo(cubic, threshold) {
        let total = 0;
        let remainder = threshold;
        let prev = new Point(cubic.anchor0X, cubic.anchor0Y);

        for (let i = 1; i <= this.#segments; i++) {
            const progress = i / this.#segments;
            const point = cubic.pointOnCurve(progress);
            const segment = point.minus(prev).getDistance();

            if (segment >= remainder) {
                const p = progress - (1.0 - remainder / segment) / this.#segments;
                return { first: p, second: threshold };
            }

            remainder -= segment;
            total += segment;
            prev = point;
        }

        return { first: 1.0, second: total };
    }
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/morph-fixed.js">
/*
 * Copyright 2022 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import { RoundedPolygon } from "./roundedPolygon.js";
import { Cubic, MutableCubic, createCubic } from "./cubic.js";
import { MeasuredPolygon, LengthMeasurer } from "./measuredPolygon.js";
import { featureMapper } from "./featureMapper.js";
import { interpolate, positiveModulo, AngleEpsilon, debugLog, Point } from "./utils.js";

const LOG_TAG = "Morph";
// Set to true to enable debug logging
const DEBUG = false;

/**
 * This class is used to animate between start and end polygons objects.
 *
 * Morphing between arbitrary objects can be problematic because it can be difficult to determine
 * how the points of a given shape map to the points of some other shape. [Morph] simplifies the
 * problem by only operating on [RoundedPolygon] objects, which are known to have similar,
 * contiguous structures. For one thing, the shape of a polygon is contiguous from start to end
 * (compared to an arbitrary Path object, which could have one or more `moveTo` operations in the
 * shape). Also, all edges of a polygon shape are represented by [Cubic] objects, thus the start and
 * end shapes use similar operations. Two Polygon shapes then only differ in the quantity and
 * placement of their curves. The morph works by determining how to map the curves of the two shapes
 * together (based on proximity and other information, such as distance to polygon vertices and
 * concavity), and splitting curves when the shapes do not have the same number of curves or when
 * the curve placement within the shapes is very different.
 */
export class Morph {
    #start;
    #end;

    /**
     * The structure which holds the actual shape being morphed. It contains all cubics necessary to
     * represent the start and end shapes (the original cubics in the shapes may be cut to align the
     * start/end shapes), matched one to one in each Pair.
     * @private
     */
    #morphMatch;

    /**
     * @param {RoundedPolygon} start
     * @param {RoundedPolygon} end
     */
    constructor(start, end) {
        this.#start = start;
        this.#end = end;
        this.#morphMatch = Morph.match(start, end);
    }

    /**
     * The structure which holds the actual shape being morphed. It contains all cubics necessary to
     * represent the start and end shapes (the original cubics in the shapes may be cut to align the
     * start/end shapes), matched one to one. Each element of the array is an object
     * `{ first: Cubic, second: Cubic }`.
     * @returns {Array<{first: Cubic, second: Cubic}>}
     */
    get morphMatch() {
        return this.#morphMatch;
    }

    /**
     * Returns the bounds of the morph object at a given `progress` value.
     * @param {number} progress - A value from 0 to 1 that determines the morph's current shape.
     * @returns {number[]} An array of [left, top, right, bottom] bounds.
     */
    bounds(progress) {
        if (this.#morphMatch.length === 0) {
            return [0, 0, 0, 0];
        }

        let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;

        for (const pair of this.#morphMatch) {
            const points = new Float32Array(8);
            for (let j = 0; j < 8; j++) {
                points[j] = interpolate(pair.first.points[j], pair.second.points[j], progress);
            }

            // Check all points in the cubic
            for (let i = 0; i < 8; i += 2) {
                const x = points[i];
                const y = points[i + 1];
                minX = Math.min(minX, x);
                maxX = Math.max(maxX, x);
                minY = Math.min(minY, y);
                maxY = Math.max(maxY, y);
            }
        }

        const bounds = [minX, minY, maxX, maxY];
        bounds[3] = Math.max(maxY, bounds[3]);
        return bounds;
    }

    /**
     * Returns a representation of the morph object at a given `progress` value as a list of Cubics.
     * Note that this function causes a new list to be created and populated, so there is some
     * overhead.
     *
     * @param {number} progress - A value from 0 to 1 that determines the morph's current shape,
     *   between the start and end shapes provided at construction time. A value of 0 results in the
     *   start shape, a value of 1 results in the end shape, and any value in between results in a
     *   shape which is a linear interpolation between those two shapes. The range is generally
     *   [0..1] and values outside could result in undefined shapes, but values close to (but
     *   outside) the range can be used to get an exaggerated effect (e.g., for a bounce or
     *   overshoot animation).
     * @returns {Cubic[]} A new array of `Cubic` objects representing the morphed shape.
     */
    asCubics(progress) {
        const result = [];
        if (this.#morphMatch.length === 0) {
            return result;
        }
        // The first/last mechanism here ensures that the final anchor point in the shape
        // exactly matches the first anchor point. There can be rendering artifacts introduced
        // by those points being slightly off, even by much less than a pixel.
        let firstCubic = null;
        let lastCubic = null;
        for (let i = 0; i < this.#morphMatch.length; i++) {
            const pair = this.#morphMatch[i];
            const points = new Float32Array(8);
            for (let j = 0; j < 8; j++) {
                points[j] = interpolate(pair.first.points[j], pair.second.points[j], progress);
            }
            const cubic = new Cubic(points);
            if (firstCubic === null) {
                firstCubic = cubic;
            }
            if (lastCubic !== null) {
                result.push(lastCubic);
            }
            lastCubic = cubic;
        }
        if (lastCubic !== null && firstCubic !== null) {
            // FIXED: Use createCubic instead of new Cubic with individual arguments
            result.push(
                createCubic(
                    lastCubic.anchor0X,
                    lastCubic.anchor0Y,
                    lastCubic.control0X,
                    lastCubic.control0Y,
                    lastCubic.control1X,
                    lastCubic.control1Y,
                    firstCubic.anchor0X,
                    firstCubic.anchor0Y
                )
            );
        }
        return result;
    }

    /**
     * Returns a representation of the morph object at a given `progress` value, iterating over the
     * cubics and calling the callback. This function is faster than `asCubics`, since it doesn't
     * allocate new `Cubic` instances, but to do this it reuses the same `MutableCubic` instance
     * during iteration.
     *
     * @param {number} progress - A value from 0 to 1 that determines the morph's current shape.
     * @param {(cubic: MutableCubic) => void} callback - The function to be called for each Cubic.
     * @param {MutableCubic} [mutableCubic=new MutableCubic()] - An instance of `MutableCubic` that
     *   will be used to set each cubic in time.
     */
    forEachCubic(progress, callback, mutableCubic = new MutableCubic()) {
        for (let i = 0; i < this.#morphMatch.length; i++) {
            const pair = this.#morphMatch[i];
            mutableCubic.interpolate(pair.first, pair.second, progress);
            callback(mutableCubic);
        }
    }

    /**
     * `match`, called at Morph construction time, creates the structure used to animate between
     * the start and end shapes. The technique is to match geometry (curves) between the shapes
     * when and where possible, and to create new/placeholder curves when necessary (when one of
     * the shapes has more curves than the other). The result is a list of pairs of Cubic
     * curves. Those curves are the matched pairs: the first of each pair holds the geometry of
     * the start shape, the second holds the geometry for the end shape. Changing the progress
     * of a Morph object simply interpolates between all pairs of curves for the morph shape.
     *
     * Curves on both shapes are matched by running a `Measurer` to determine where the points
     * are in each shape (proportionally, along the outline), and then running `featureMapper`
     * which decides how to map (match) all of the curves with each other.
     *
     * @param {RoundedPolygon} p1
     * @param {RoundedPolygon} p2
     * @returns {Array<{first: Cubic, second: Cubic}>}
     * @private
     */
    static match(p1, p2) {
        // Measure the polygons. This gives us a list of measured cubics for each polygon, which
        // we then use to match start/end curves
        const measuredPolygon1 = MeasuredPolygon.measurePolygon(new LengthMeasurer(), p1);
        const measuredPolygon2 = MeasuredPolygon.measurePolygon(new LengthMeasurer(), p2);

        // features1 and 2 will contain the list of corners (just the inner circular curve)
        // along with the progress at the middle of those corners. These measurement values
        // are then used to compare and match between the two polygons
        const features1 = measuredPolygon1.features;
        const features2 = measuredPolygon2.features;

        // Map features: doubleMapper is the result of mapping the features in each shape to the
        // closest feature in the other shape.
        // Given a progress in one of the shapes it can be used to find the corresponding
        // progress in the other shape (in both directions)
        const doubleMapper = featureMapper(features1, features2);

        // cut point on poly2 is the mapping of the 0 point on poly1
        const polygon2CutPoint = doubleMapper.map(0);
        if (DEBUG) debugLog(LOG_TAG, `polygon2CutPoint = ${polygon2CutPoint}`);

        // Cut and rotate.
        // Polygons start at progress 0, and the featureMapper has decided that we want to match
        // progress 0 in the first polygon to `polygon2CutPoint` on the second polygon.
        // So we need to cut the second polygon there and "rotate it", so as we walk through
        // both polygons we can find the matching.
        // The resulting bs1/2 are MeasuredPolygons, whose MeasuredCubics start from
        // outlineProgress=0 and increasing until outlineProgress=1
        const bs1 = measuredPolygon1;
        const bs2 = measuredPolygon2.cutAndShift(polygon2CutPoint);

        if (DEBUG) {
            for (let index = 0; index < bs1.size; index++) {
                const b1 = bs1.get(index);
                debugLog(LOG_TAG, `bs1[${index}] = ${b1.startOutlineProgress} .. ${b1.endOutlineProgress}`);
            }
            for (let index = 0; index < bs2.size; index++) {
                const b2 = bs2.get(index);
                debugLog(LOG_TAG, `bs2[${index}] = ${b2.startOutlineProgress} .. ${b2.endOutlineProgress}`);
            }
        }

        // Match
        // Now we can compare the two lists of measured cubics and create a list of pairs
        // of cubics [ret], which are the start/end curves that represent the Morph object
        // and the start and end shapes, and which can be interpolated to animate the
        // between those shapes.
        const ret = [];
        // i1/i2 are the indices of the current cubic on the start (1) and end (2) shapes
        let i1 = 0;
        let i2 = 0;
        // b1, b2 are the current measured cubic for each polygon
        let b1 = bs1.get(i1++);
        let b2 = bs2.get(i2++);
        // Iterate until all curves are accounted for and matched
        while (b1 && b2) {
            // Progresses are in shape1's perspective
            // b1a, b2a are ending progress values of current measured cubics in [0,1] range
            const b1a = (i1 === bs1.size) ? 1.0 : b1.endOutlineProgress;
            const b2a = (i2 === bs2.size) ? 1.0 :
                doubleMapper.mapBack(
                    positiveModulo(b2.endOutlineProgress + polygon2CutPoint, 1.0)
                );
            const minb = Math.min(b1a, b2a);
            if (DEBUG) debugLog(LOG_TAG, `${b1a} ${b2a} | ${minb}`);

            // minb is the progress at which the curve that ends first ends.
            // If both curves end roughly there, no cutting is needed, we have a match.
            // If one curve extends beyond, we need to cut it.
            let seg1, newb1;
            if (b1a > minb + AngleEpsilon) {
                if (DEBUG) debugLog(LOG_TAG, "Cut 1");
                [seg1, newb1] = b1.cutAtProgress(minb);
            } else {
                seg1 = b1;
                newb1 = bs1.get(i1++);
            }

            let seg2, newb2;
            if (b2a > minb + AngleEpsilon) {
                if (DEBUG) debugLog(LOG_TAG, "Cut 2");
                [seg2, newb2] = b2.cutAtProgress(
                    positiveModulo(doubleMapper.map(minb) - polygon2CutPoint, 1.0)
                );
            } else {
                seg2 = b2;
                newb2 = bs2.get(i2++);
            }

            ret.push({ first: seg1.cubic, second: seg2.cubic });
            b1 = newb1;
            b2 = newb2;
        }

        return ret;
    }
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/roundedPolygon.js">
/*
 * Copyright 2022 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

import {
    Cubic,
    MutableCubic
} from "./cubic.js";
import {
    Point,
    distance,
    distanceSquared,
    square,
    FloatPi,
    radialToCartesian,
    convex,
    debugLog,
    DistanceEpsilon,
    Zero,
    directionVector
} from "./utils.js";
// CornerRounding functionality will be implemented inline
const CornerRounding = { Unrounded: 0 };

/**
 * A feature represents a segment of the polygon's outline, which can be either a
 * rounded corner or a straight edge connecting two corners.
 * @abstract
 */
export class Feature {
    /** @type {Cubic[]} */
    cubics;
    /** @type {boolean} */
    isCorner = false;

    /** @param {Cubic[]} cubics */
    constructor(cubics) {
        this.cubics = cubics;
    }

    /**
     * @param {PointTransformer} f
     * @returns {Feature}
     */
    transformed(f) {
        throw new Error("Not implemented");
    }
}

/** A feature representing a rounded corner. */
Feature.Corner = class Corner extends Feature {
    /** @type {boolean} */
    convex;
    isCorner = true;

    /**
     * @param {Cubic[]} cubics
     * @param {boolean} convex
     */
    constructor(cubics, convex) {
        super(cubics);
        this.convex = convex;
    }

    transformed(f) {
        return new Feature.Corner(this.cubics.map(c => c.transformed(f)), this.convex);
    }
};

/** A feature representing a straight edge. */
Feature.Edge = class Edge extends Feature {
    transformed(f) {
        return new Feature.Edge(this.cubics.map(c => c.transformed(f)));
    }
};


/**
 * The RoundedPolygon class allows simple construction of polygonal shapes with optional rounding at
 * the vertices. Polygons can be constructed with either the number of vertices desired or an
 * ordered list of vertices.
 */
export class RoundedPolygon {
    /** @type {Feature[]} */
    features;
    /** @type {Point} */
    center;
    /** @type {Cubic[]} */
    cubics;

    get centerX() { return this.center.x; }
    get centerY() { return this.center.y; }

    /**
     * This constructor handles multiple signatures to create a RoundedPolygon.
     * 1. `new RoundedPolygon(numVertices, radius, centerX, centerY, rounding, perVertexRounding)`
     * 2. `new RoundedPolygon(vertices, rounding, perVertexRounding, centerX, centerY)`
     * 3. `new RoundedPolygon(features, centerX, centerY)` - Internal use mostly
     * 4. `new RoundedPolygon(sourcePolygon)` - Copy constructor
     *
     * @param {number | Float32Array | number[] | Feature[] | RoundedPolygon} arg1
     * @param {...any} args
     */
    constructor(arg1, ...args) {
        let features, center;

        if (arg1 instanceof RoundedPolygon) {
            // Copy constructor: new RoundedPolygon(source)
            features = arg1.features;
            center = arg1.center;
        } else if (typeof arg1 === 'number') {
            // Vertices from number: new RoundedPolygon(numVertices, ...)
            const [
                radius = 1,
                centerX = 0,
                centerY = 0,
                rounding = 0,
                perVertexRounding = null
            ] = args;
            const vertices = verticesFromNumVerts(arg1, radius, centerX, centerY);
            ({ features, center } =
                computeFeaturesFromVertices(vertices, rounding, perVertexRounding, centerX, centerY));
        } else if (Array.isArray(arg1) && (arg1.length === 0 || arg1[0] instanceof Feature)) {
            // From features: new RoundedPolygon(features, centerX, centerY)
            const [centerX = NaN, centerY = NaN] = args;
            features = arg1;

            if (features.length < 2 && features.length > 0) throw new Error("Polygons must have at least 2 features");

            const vertices = [];
            for (const feature of features) {
                for (const cubic of feature.cubics) {
                    vertices.push(cubic.anchor0X, cubic.anchor0Y);
                }
            }
            const calculatedCenter = calculateCenter(vertices);
            const cX = !isNaN(centerX) ? centerX : calculatedCenter.x;
            const cY = !isNaN(centerY) ? centerY : calculatedCenter.y;
            center = new Point(cX, cY);
        } else if (arg1 instanceof Float32Array || Array.isArray(arg1)) {
            // From vertices array: new RoundedPolygon(vertices, ...)
            const [
                rounding = 0,
                perVertexRounding = null,
                centerX = NaN,
                centerY = NaN
            ] = args;
            ({ features, center } =
                computeFeaturesFromVertices(arg1, rounding, perVertexRounding, centerX, centerY));
        } else {
            throw new Error("Invalid arguments for RoundedPolygon constructor");
        }

        this.features = features;
        this.center = center;
        this.cubics = this.#flattenCubics(features, center);
        this.#validateContinuity();
    }

    #flattenCubics(features, center) {
        const cubics = [];
        if (features.length === 0) {
            // Empty / 0-sized polygon.
            cubics.push(new Cubic(new Float32Array([
                center.x, center.y, center.x, center.y,
                center.x, center.y, center.x, center.y
            ])));
            return cubics;
        }

        let firstCubic = null;
        let lastCubic = null;

        for (const feature of features) {
            for (const cubic of feature.cubics) {
                if (!cubic.zeroLength()) {
                    if (lastCubic) cubics.push(lastCubic);
                    lastCubic = cubic;
                    if (!firstCubic) firstCubic = cubic;
                } else if (lastCubic) {
                    const newPoints = lastCubic.points.slice();
                    newPoints[6] = cubic.anchor1X;
                    newPoints[7] = cubic.anchor1Y;
                    lastCubic = new Cubic(newPoints);
                }
            }
        }

        if (lastCubic && firstCubic) {
            cubics.push(new Cubic(new Float32Array([
                lastCubic.anchor0X, lastCubic.anchor0Y,
                lastCubic.control0X, lastCubic.control0Y,
                lastCubic.control1X, lastCubic.control1Y,
                firstCubic.anchor0X, firstCubic.anchor0Y,
            ])));
        }
        return cubics;
    }

    #validateContinuity() {
        if (this.cubics.length <= 1) return;
        let prevCubic = this.cubics[this.cubics.length - 1];
        for (let index = 0; index < this.cubics.length; index++) {
            const cubic = this.cubics[index];
            if (Math.abs(cubic.anchor0X - prevCubic.anchor1X) > DistanceEpsilon ||
                Math.abs(cubic.anchor0Y - prevCubic.anchor1Y) > DistanceEpsilon) {
                throw new Error(
                    "RoundedPolygon must be contiguous, with the anchor points of all curves " +
                    "matching the anchor points of the preceding and succeeding cubics"
                );
            }
            prevCubic = cubic;
        }
    }

    transformed(f) {
        const newCenter = f.transform(this.center.x, this.center.y);
        const newFeatures = this.features.map(feat => feat.transformed(f));
        // Use internal constructor signature
        return new RoundedPolygon(newFeatures, newCenter.first, newCenter.second);
    }

    normalized() {
        const bounds = this.calculateBounds();
        const width = bounds[2] - bounds[0];
        const height = bounds[3] - bounds[1];
        const side = Math.max(width, height);
        if (side === 0) return this;
        const offsetX = (side - width) / 2 - bounds[0];
        const offsetY = (side - height) / 2 - bounds[1];
        return this.transformed((x, y) => ({
            first: (x + offsetX) / side,
            second: (y + offsetY) / side
        }));
    }

    calculateMaxBounds(bounds = new Float32Array(4)) {
        if (bounds.length < 4) throw new Error("Required bounds size of 4");
        let maxDistSquared = 0;
        for (const cubic of this.cubics) {
            const anchorDistance = distanceSquared(cubic.anchor0X - this.centerX, cubic.anchor0Y - this.centerY);
            const middlePoint = cubic.pointOnCurve(0.5);
            const middleDistance = distanceSquared(middlePoint.x - this.centerX, middlePoint.y - this.centerY);
            maxDistSquared = Math.max(maxDistSquared, anchorDistance, middleDistance);
        }
        const dist = Math.sqrt(maxDistSquared);
        bounds[0] = this.centerX - dist;
        bounds[1] = this.centerY - dist;
        bounds[2] = this.centerX + dist;
        bounds[3] = this.centerY + dist;
        return bounds;
    }

    calculateBounds(bounds = new Float32Array(4), approximate = true) {
        if (bounds.length < 4) throw new Error("Required bounds size of 4");
        let minX = Infinity, minY = Infinity, maxX = -Infinity, maxY = -Infinity;
        const tempBounds = new Float32Array(4);
        for (const cubic of this.cubics) {
            cubic.calculateBounds(tempBounds, approximate);
            minX = Math.min(minX, tempBounds[0]);
            minY = Math.min(minY, tempBounds[1]);
            maxX = Math.max(maxX, tempBounds[2]);
            maxY = Math.max(maxY, tempBounds[3]);
        }
        bounds[0] = minX;
        bounds[1] = minY;
        bounds[2] = maxX;
        bounds[3] = maxY;
        return bounds;
    }

    equals(other) {
        if (this === other) return true;
        if (!(other instanceof RoundedPolygon)) return false;
        if (this.features.length !== other.features.length) return false;
        // This is a deep equality check, might be slow.
        return JSON.stringify(this.features) === JSON.stringify(other.features);
    }
}

/**
 * @param {Float32Array | number[]} vertices
 * @returns {Point}
 * @internal
 */
function calculateCenter(vertices) {
    let cumulativeX = 0, cumulativeY = 0;
    for (let i = 0; i < vertices.length; i += 2) {
        cumulativeX += vertices[i];
        cumulativeY += vertices[i + 1];
    }
    const numPoints = vertices.length / 2;
    return new Point(
        numPoints > 0 ? cumulativeX / numPoints : 0,
        numPoints > 0 ? cumulativeY / numPoints : 0
    );
}

/**
 * @param {number} numVertices
 * @param {number} radius
 * @param {number} centerX
 * @param {number} centerY
 * @returns {Float32Array}
 * @private
 */
function verticesFromNumVerts(numVertices, radius, centerX, centerY) {
    const result = new Float32Array(numVertices * 2);
    const centerPoint = new Point(centerX, centerY);
    for (let i = 0; i < numVertices; i++) {
        const angle = (FloatPi / numVertices * 2 * i);
        const vertex = radialToCartesian(radius, angle).plus(centerPoint);
        result[i * 2] = vertex.x;
        result[i * 2 + 1] = vertex.y;
    }
    return result;
}

/**
 * Main logic to generate features from a list of vertices.
 * @param {Float32Array | number[]} vertices
 * @param {CornerRounding} rounding
 * @param {CornerRounding[] | null} perVertexRounding
 * @param {number} centerX
 * @param {number} centerY
 * @returns {{features: Feature[], center: Point}}
 * @private
 */
function computeFeaturesFromVertices(vertices, rounding, perVertexRounding, centerX, centerY) {
    if (vertices.length < 6) throw new Error("Polygons must have at least 3 vertices");
    if (vertices.length % 2 !== 0) throw new Error("The vertices array should have even size");
    const numVerts = vertices.length / 2;
    if (perVertexRounding && perVertexRounding.length !== numVerts) {
        throw new Error("perVertexRounding list size must match the number of vertices");
    }

    const roundedCorners = [];
    for (let i = 0; i < numVerts; i++) {
        const vtxRounding = perVertexRounding ? perVertexRounding[i] : rounding;
        const prevI = (i + numVerts - 1) % numVerts;
        const nextI = (i + 1) % numVerts;
        roundedCorners.push(
            new RoundedCorner(
                new Point(vertices[prevI * 2], vertices[prevI * 2 + 1]),
                new Point(vertices[i * 2], vertices[i * 2 + 1]),
                new Point(vertices[nextI * 2], vertices[nextI * 2 + 1]),
                vtxRounding,
            )
        );
    }

    const cutAdjusts = roundedCorners.map((rc, i) => {
        const nextRc = roundedCorners[(i + 1) % numVerts];
        const expectedRoundCut = rc.expectedRoundCut + nextRc.expectedRoundCut;
        const expectedCut = rc.expectedCut + nextRc.expectedCut;
        const sideSize = distance(
            vertices[i * 2] - vertices[((i + 1) % numVerts) * 2],
            vertices[i * 2 + 1] - vertices[((i + 1) % numVerts) * 2 + 1]
        );

        if (expectedRoundCut > sideSize) {
            return { roundRatio: sideSize / expectedRoundCut, smoothRatio: 0 };
        } else if (expectedCut > sideSize) {
            return { roundRatio: 1, smoothRatio: (sideSize - expectedRoundCut) / (expectedCut - expectedRoundCut) };
        } else {
            return { roundRatio: 1, smoothRatio: 1 };
        }
    });

    const corners = [];
    for (let i = 0; i < numVerts; i++) {
        const allowedCuts = [];
        for (const delta of [0, 1]) {
            const adjust = cutAdjusts[(i + numVerts - 1 + delta) % numVerts];
            allowedCuts.push(
                roundedCorners[i].expectedRoundCut * adjust.roundRatio +
                (roundedCorners[i].expectedCut - roundedCorners[i].expectedRoundCut) * adjust.smoothRatio
            );
        }
        corners.push(roundedCorners[i].getCubics(allowedCuts[0], allowedCuts[1]));
    }

    const tempFeatures = [];
    for (let i = 0; i < numVerts; i++) {
        const prevI = (i + numVerts - 1) % numVerts;
        const nextI = (i + 1) % numVerts;
        const currVertex = new Point(vertices[i * 2], vertices[i * 2 + 1]);
        const prevVertex = new Point(vertices[prevI * 2], vertices[prevI * 2 + 1]);
        const nextVertex = new Point(vertices[nextI * 2], vertices[nextI * 2 + 1]);
        const isConvex = convex(prevVertex, currVertex, nextVertex);

        tempFeatures.push(new Feature.Corner(corners[i], isConvex));
        const lastOfCorner = corners[i][corners[i].length - 1];
        const firstOfNextCorner = corners[(i + 1) % numVerts][0];
        tempFeatures.push(new Feature.Edge([
            Cubic.straightLine(
                lastOfCorner.anchor1X, lastOfCorner.anchor1Y,
                firstOfNextCorner.anchor0X, firstOfNextCorner.anchor0Y
            )
        ]));
    }

    const center = (isNaN(centerX) || isNaN(centerY)) ?
        calculateCenter(vertices) :
        new Point(centerX, centerY);

    return { features: tempFeatures, center };
}


// --- Private RoundedCorner helper class ---

class RoundedCorner {
    constructor(p0, p1, p2, rounding) {
        this.p0 = p0;
        this.p1 = p1;
        this.p2 = p2;
        this.rounding = rounding || 0;

        const v01 = p0.minus(p1);
        const v21 = p2.minus(p1);
        const d01 = v01.getDistance();
        const d21 = v21.getDistance();

        if (d01 > 0 && d21 > 0) {
            this.d1 = v01.times(1 / d01);
            this.d2 = v21.times(1 / d21);
            // Handle both number and object rounding
            this.cornerRadius = (typeof this.rounding === 'number') ? this.rounding : (this.rounding.radius || 0);
            this.smoothing = (typeof this.rounding === 'number') ? 0 : (this.rounding.smoothing || 0);
            this.cosAngle = this.d1.dotProduct(this.d2);
            this.sinAngle = Math.sqrt(1 - square(this.cosAngle));
            this.expectedRoundCut = (this.sinAngle > 1e-3) ?
                this.cornerRadius * (this.cosAngle + 1) / this.sinAngle : 0;
        } else {
            this.d1 = Zero; this.d2 = Zero; this.cornerRadius = 0;
            this.smoothing = 0; this.cosAngle = 0; this.sinAngle = 0;
            this.expectedRoundCut = 0;
        }
    }

    get expectedCut() {
        return (1 + this.smoothing) * this.expectedRoundCut;
    }

    getCubics(allowedCut0, allowedCut1) {
        const allowedCut = Math.min(allowedCut0, allowedCut1);
        if (this.expectedRoundCut < DistanceEpsilon || allowedCut < DistanceEpsilon || this.cornerRadius < DistanceEpsilon) {
            return [Cubic.empty(this.p1.x, this.p1.y)];
        }

        const actualRoundCut = Math.min(allowedCut, this.expectedRoundCut);
        const actualSmoothing0 = this.#calculateActualSmoothingValue(allowedCut0);
        const actualSmoothing1 = this.#calculateActualSmoothingValue(allowedCut1);
        const actualR = this.cornerRadius * actualRoundCut / this.expectedRoundCut;
        const centerDistance = Math.sqrt(square(actualR) + square(actualRoundCut));
        const center = this.p1.plus(this.d1.plus(this.d2).times(0.5).getDirection().times(centerDistance));

        const circleIntersection0 = this.p1.plus(this.d1.times(actualRoundCut));
        const circleIntersection2 = this.p1.plus(this.d2.times(actualRoundCut));

        const flanking0 = this.#computeFlankingCurve(
            actualRoundCut, actualSmoothing0, this.p1, this.p0,
            circleIntersection0, circleIntersection2, center, actualR
        );
        const flanking2 = this.#computeFlankingCurve(
            actualRoundCut, actualSmoothing1, this.p1, this.p2,
            circleIntersection2, circleIntersection0, center, actualR
        ).reverse();

        return [
            flanking0,
            Cubic.circularArc(
                center.x, center.y,
                flanking0.anchor1X, flanking0.anchor1Y,
                flanking2.anchor0X, flanking2.anchor0Y
            ),
            flanking2,
        ];
    }

    #calculateActualSmoothingValue(allowedCut) {
        if (allowedCut > this.expectedCut) {
            return this.smoothing;
        } else if (allowedCut > this.expectedRoundCut) {
            const denom = this.expectedCut - this.expectedRoundCut;
            return this.smoothing * (denom > 0 ? (allowedCut - this.expectedRoundCut) / denom : 0);
        } else {
            return 0;
        }
    }

    #computeFlankingCurve(
        actualRoundCut, actualSmoothingValue, corner, sideStart,
        circleSegmentIntersection, otherCircleSegmentIntersection,
        circleCenter, actualR
    ) {
        const sideDirection = sideStart.minus(corner).getDirection();
        const curveStart = corner.plus(sideDirection.times(actualRoundCut * (1 + actualSmoothingValue)));

        const p = circleSegmentIntersection.times(1 - actualSmoothingValue).plus(
            circleSegmentIntersection.plus(otherCircleSegmentIntersection).times(0.5 * actualSmoothingValue)
        );
        const curveEnd = circleCenter.plus(
            directionVector(p.x - circleCenter.x, p.y - circleCenter.y).times(actualR)
        );

        const circleTangent = curveEnd.minus(circleCenter).rotate90();
        const anchorEnd = lineIntersection(sideStart, sideDirection, curveEnd, circleTangent) ||
                          circleSegmentIntersection;
        const anchorStart = curveStart.plus(anchorEnd.times(2)).times(1 / 3);

        return new Cubic(new Float32Array([
            curveStart.x, curveStart.y,
            anchorStart.x, anchorStart.y,
            anchorEnd.x, anchorEnd.y,
            curveEnd.x, curveEnd.y
        ]));
    }
}

function lineIntersection(p0, d0, p1, d1) {
    const rotatedD1 = d1.rotate90();
    const den = d0.dotProduct(rotatedD1);
    if (Math.abs(den) < DistanceEpsilon) return null;
    const num = p1.minus(p0).dotProduct(rotatedD1);
    if (Math.abs(den) < DistanceEpsilon * Math.abs(num)) return null;
    const k = num / den;
    return p0.plus(d0.times(k));
}
</file>

<file path="promptdj-midi/components/react/LoadingIndicator/utils.js">
/*
 * Copyright 2022 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

/**
 * A simple class representing a 2D point.
 */
export class Point {
    /**
     * @param {number} x
     * @param {number} y
     */
    constructor(x, y) {
        this.x = x;
        this.y = y;
    }

    /** Rotates the point 90 degrees counter-clockwise around the origin. */
    rotate90() {
        return new Point(-this.y, this.x);
    }

    /** Calculates the dot product with another point or vector. */
    dotProduct(otherX, otherY) {
        if (otherX instanceof Point) {
            return this.x * otherX.x + this.y * otherX.y;
        }
        return this.x * otherX + this.y * otherY;
    }

    /** Calculates the Euclidean distance from the origin (0, 0). */
    getDistance() {
        return Math.sqrt(this.x * this.x + this.y * this.y);
    }

    /** Adds another point to this one, returning a new Point. */
    plus(other) {
        return new Point(this.x + other.x, this.y + other.y);
    }

    /** Subtracts another point from this one, returning a new Point. */
    minus(other) {
        return new Point(this.x - other.x, this.y - other.y);
    }

    /** Multiplies the point's coordinates by a scalar, returning a new Point. */
    times(scalar) {
        return new Point(this.x * scalar, this.y * scalar);
    }

    /**
     * Determines if the vector from the origin to `other` is clockwise relative to the
     * vector from the origin to `this`.
     * This is equivalent to checking the sign of the Z component of the 2D cross product.
     * @param {Point} other
     * @returns {boolean}
     */
    clockwise(other) {
        return this.x * other.y - this.y * other.x >= 0;
    }

    // Aliases for compatibility with roundedPolygon.js
    add(other) { return this.plus(other); }
    subtract(other) { return this.minus(other); }
    scale(factor) { return this.times(factor); }

    /** Returns the direction vector (unit vector) from origin to this point */
    getDirection() {
        const d = this.getDistance();
        return d > DistanceEpsilon ? this.scale(1 / d) : new Point(0, 0);
    }

    /** Transform this point using a transformation function */
    transformed(f) {
        const result = f(this.x, this.y);
        return new Point(result.x, result.y);
    }

    /** Check if this point equals another point within epsilon tolerance */
    equals(other) {
        if (!other) return false;
        return Math.abs(this.x - other.x) < DistanceEpsilon && Math.abs(this.y - other.y) < DistanceEpsilon;
    }
}

/**
 * Calculates the Euclidean distance of a point (x, y) from the origin.
 * @internal
 */
export function distance(x, y) {
    return Math.sqrt(x * x + y * y);
}

/**
 * Calculates the squared Euclidean distance of a point (x, y) from the origin.
 * @internal
 */
export function distanceSquared(x, y) {
    return x * x + y * y;
}

/**
 * Returns a unit vector representing the direction to the point (x, y) from (0, 0).
 * @internal
 * @throws {Error} if the distance is zero.
 */
export function directionVector(x, y) {
    if (arguments.length === 2) {
        const d = distance(x, y);
        if (d <= 0) {
            throw new Error("Required distance greater than zero");
        }
        return new Point(x / d, y / d);
    }
    // Overload for angle in radians
    const angleRadians = x;
    return new Point(Math.cos(angleRadians), Math.sin(angleRadians));
}

/** The origin point (0, 0). @internal */
export const Zero = new Point(0, 0);

/**
 * Converts polar coordinates to Cartesian coordinates.
 * @internal
 */
export function radialToCartesian(radius, angleRadians, center = Zero) {
    return directionVector(angleRadians).times(radius).plus(center);
}

/**
 * Epsilon value used for comparing distances, to account for floating-point inaccuracies.
 * @internal
 */
export const DistanceEpsilon = 1e-4;

/**
 * Epsilon value used for comparing angles.
 * @internal
 */
export const AngleEpsilon = 1e-6;

/**
 * A more relaxed epsilon for operations where human perception allows for higher tolerances,
 * such as checking for collinearity.
 * @internal
 */
export const RelaxedDistanceEpsilon = 5e-3;

/** The value of PI as a float. @internal */
export const FloatPi = Math.PI;

/** The value of 2 * PI as a float. @internal */
export const TwoPi = 2 * Math.PI;

/**
 * Squares a number.
 * @internal
 */
export function square(x) {
    return x * x;
}

/**
 * Linearly interpolates between `start` and `stop` with `fraction`.
 * @internal
 */
export function interpolate(start, stop, fraction) {
    return (1 - fraction) * start + fraction * stop;
}

/**
 * Similar to `num % mod`, but ensures the result is always positive.
 * For example: `4 % 3` -> `1`, `-4 % 3` -> `-1`, but `positiveModulo(-4, 3)` -> `2`.
 * @internal
 */
export function positiveModulo(num, mod) {
    return ((num % mod) + mod) % mod;
}

/**
 * Checks if point C is on the line defined by points A and B, within a given tolerance.
 * @internal
 */
export function collinearIsh(aX, aY, bX, bY, cX, cY, tolerance = DistanceEpsilon) {
    // The dot product of a perpendicular angle is 0. By rotating one of the vectors,
    // we save the calculations to convert the dot product to degrees afterwards.
    const ab = new Point(bX - aX, bY - aY).rotate90();
    const ac = new Point(cX - aX, cY - aY);
    const dotProduct = Math.abs(ab.dotProduct(ac));
    const relativeTolerance = tolerance * ab.getDistance() * ac.getDistance();

    return dotProduct < tolerance || dotProduct < relativeTolerance;
}

/**
 * Approximates whether a corner at a vertex is concave or convex.
 * @internal
 */
export function convex(previous, current, next) {
    // TODO: b/369320447 - This is a fast, but not reliable calculation.
    return current.minus(previous).clockwise(next.minus(current));
}

/**
 * A function to be minimized by `findMinimum`.
 * @callback FindMinimumFunction
 * @param {number} value - The input value.
 * @returns {number} The result of the function at that value.
 */

/**
 * Performs a ternary search in the range [v0..v1] to find the parameter that minimizes the given function.
 * @internal
 * @param {number} v0 - The start of the search range.
 * @param {number} v1 - The end of the search range.
 * @param {number} [tolerance=1e-3] - The desired precision. The search stops when the range is smaller than this.
 * @param {FindMinimumFunction} f - The function to minimize.
 * @returns {number} The value in the range that minimizes the function.
 */
export function findMinimum(v0, v1, tolerance = 1e-3, f) {
    let a = v0;
    let b = v1;
    while (b - a > tolerance) {
        const c1 = (2 * a + b) / 3;
        const c2 = (2 * b + a) / 3;
        if (f(c1) < f(c2)) {
            b = c2;
        } else {
            a = c1;
        }
    }
    return (a + b) / 2;
}

/** @internal */
export const DEBUG = false;

/**
 * Logs a message to the console if DEBUG is true.
 * The message is only generated if it will be logged.
 * @internal
 * @param {string} tag
 * @param {() => string} messageFactory
 */
export function debugLog(tag, messageFactory) {
    if (DEBUG) {
        console.log(`${tag}: ${messageFactory()}`);
    }
}
</file>

<file path="promptdj-midi/components/react/material-switch.css">
/* Material Web Switch Styling */

/* Import Material Symbols font for icons */
@import url('https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL@20..48,100..700,0..1');

/* Global Material Web Switch theming */
md-switch {
  /* Use Material Design 3 color tokens */
  --md-switch-selected-track-color: var(--md-primary, #6750a4);
  --md-switch-selected-handle-color: var(--md-on-primary, #ffffff);
  --md-switch-selected-pressed-track-color: var(--md-primary, #6750a4);
  --md-switch-selected-pressed-handle-color: var(--md-on-primary, #ffffff);
  --md-switch-selected-hover-track-color: var(--md-primary, #6750a4);
  --md-switch-selected-hover-handle-color: var(--md-on-primary, #ffffff);
  --md-switch-selected-focus-track-color: var(--md-primary, #6750a4);
  --md-switch-selected-focus-handle-color: var(--md-on-primary, #ffffff);
  
  --md-switch-unselected-track-color: var(--md-surface-variant, #e7e0ec);
  --md-switch-unselected-handle-color: var(--md-outline, #79747e);
  --md-switch-unselected-pressed-track-color: var(--md-surface-variant, #e7e0ec);
  --md-switch-unselected-pressed-handle-color: var(--md-on-surface-variant, #49454f);
  --md-switch-unselected-hover-track-color: var(--md-surface-variant, #e7e0ec);
  --md-switch-unselected-hover-handle-color: var(--md-on-surface-variant, #49454f);
  --md-switch-unselected-focus-track-color: var(--md-surface-variant, #e7e0ec);
  --md-switch-unselected-focus-handle-color: var(--md-on-surface-variant, #49454f);
  
  --md-switch-disabled-selected-track-color: var(--md-on-surface, #1d1b20);
  --md-switch-disabled-selected-handle-color: var(--md-surface, #fef7ff);
  --md-switch-disabled-unselected-track-color: var(--md-on-surface, #1d1b20);
  --md-switch-disabled-unselected-handle-color: var(--md-on-surface, #1d1b20);
  
  /* Track and handle shape */
  --md-switch-track-shape: 16px;
  --md-switch-handle-shape: 50%;
  
  /* Track dimensions */
  --md-switch-track-width: 52px;
  --md-switch-track-height: 32px;
  
  /* Handle dimensions */
  --md-switch-handle-width: 24px;
  --md-switch-handle-height: 24px;
  --md-switch-selected-handle-width: 24px;
  --md-switch-selected-handle-height: 24px;
  
  /* Icon styling - Default check/close icons */
  --md-switch-icon-size: 16px;
  --md-switch-selected-icon-color: var(--md-on-primary, #ffffff);
  --md-switch-unselected-icon-color: var(--md-on-surface-variant, #49454f);
}

/* Container for switch with label */
.material-switch-container {
  display: flex;
  align-items: center;
  gap: 12px;
  cursor: pointer;
}

.material-switch-container:has(md-switch[disabled]) {
  cursor: not-allowed;
  opacity: 0.6;
}

/* Label styling */
.material-switch-label {
  font-size: var(--md-sys-typescale-body-medium-size, 0.875rem);
  font-weight: var(--md-sys-typescale-body-medium-weight, 400);
  line-height: var(--md-sys-typescale-body-medium-line-height, 1.25rem);
  color: var(--md-on-surface, #1d1b20);
  user-select: none;
}

/* Disabled label styling */
.material-switch-container:has(md-switch[disabled]) .material-switch-label {
  color: var(--md-on-surface-variant, #49454f);
}

/* Focus ring styling with enhanced icon visibility */
md-switch:focus-visible {
  outline: 2px solid var(--md-primary, #6750a4);
  outline-offset: 2px;
  border-radius: 20px;
}

/* Enhanced icon colors for focus state - better contrast */
md-switch[icons]:focus-visible svg[slot="on-icon"] {
  color: var(--md-primary, #6750a4);
  opacity: 0.9;
}

md-switch[icons]:focus-visible svg[slot="off-icon"] {
  color: var(--md-on-surface, #1d1b20);
  opacity: 0.9;
}

/* Focus state for selected switch */
md-switch[icons]:focus-visible[selected] svg[slot="on-icon"] {
  color: var(--md-primary, #6750a4);
  opacity: 1;
}

/* Focus state for unselected switch */
md-switch[icons]:focus-visible:not([selected]) svg[slot="off-icon"] {
  color: var(--md-on-surface, #1d1b20);
  opacity: 1;
}

/* High contrast mode support */
@media (prefers-contrast: high) {
  md-switch {
    --md-switch-selected-track-color: var(--md-primary, #0000ff);
    --md-switch-unselected-track-color: var(--md-outline, #000000);
    --md-switch-selected-handle-color: var(--md-on-primary, #ffffff);
    --md-switch-unselected-handle-color: var(--md-on-surface, #000000);
  }
}

/* Reduced motion support */
@media (prefers-reduced-motion: reduce) {
  md-switch {
    --md-switch-transition-duration: 0ms;
  }
}

/* Dark theme support */
@media (prefers-color-scheme: dark) {
  md-switch {
    --md-switch-selected-track-color: var(--md-primary, #d0bcff);
    --md-switch-selected-handle-color: var(--md-on-primary, #381e72);
    --md-switch-unselected-track-color: var(--md-surface-variant, #49454f);
    --md-switch-unselected-handle-color: var(--md-outline, #938f99);

    --md-switch-disabled-selected-track-color: var(--md-on-surface, #e6e0e9);
    --md-switch-disabled-selected-handle-color: var(--md-surface, #141218);
    --md-switch-disabled-unselected-track-color: var(--md-on-surface, #e6e0e9);
    --md-switch-disabled-unselected-handle-color: var(--md-on-surface, #e6e0e9);

    /* Dark theme icon colors - contrast with dark theme thumb */
    --md-switch-selected-icon-color: var(--md-primary, #d0bcff);
    --md-switch-unselected-icon-color: var(--md-on-surface, #e6e0e9);
  }
  
  .material-switch-label {
    color: var(--md-on-surface, #e6e0e9);
  }
  
  .material-switch-container:has(md-switch[disabled]) .material-switch-label {
    color: var(--md-on-surface-variant, #938f99);
  }

  /* Dark theme focus state icon colors - better contrast */
  md-switch[icons]:focus-visible svg[slot="on-icon"] {
    color: var(--md-primary, #d0bcff);
    opacity: 0.9;
  }

  md-switch[icons]:focus-visible svg[slot="off-icon"] {
    color: var(--md-on-surface, #e6e0e9);
    opacity: 0.9;
  }

  md-switch[icons]:focus-visible[selected] svg[slot="on-icon"] {
    color: var(--md-primary, #d0bcff);
    opacity: 1;
  }

  md-switch[icons]:focus-visible:not([selected]) svg[slot="off-icon"] {
    color: var(--md-on-surface, #e6e0e9);
    opacity: 1;
  }
}

/* Compact switch variant */
.material-switch-compact md-switch {
  --md-switch-track-width: 44px;
  --md-switch-track-height: 24px;
  --md-switch-handle-width: 20px;
  --md-switch-handle-height: 20px;
  --md-switch-selected-handle-width: 20px;
  --md-switch-selected-handle-height: 20px;
  --md-switch-icon-size: 12px;
}

/* Large switch variant */
.material-switch-large md-switch {
  --md-switch-track-width: 60px;
  --md-switch-track-height: 36px;
  --md-switch-handle-width: 28px;
  --md-switch-handle-height: 28px;
  --md-switch-selected-handle-width: 28px;
  --md-switch-selected-handle-height: 28px;
  --md-switch-icon-size: 20px;
}

/* Ensure slotted icons are properly styled */
md-switch[icons] svg[slot="on-icon"],
md-switch[icons] svg[slot="off-icon"] {
  width: var(--md-switch-icon-size, 16px);
  height: var(--md-switch-icon-size, 16px);
  fill: currentColor;
}

/* Icon colors for different states - contrast with thumb background */
md-switch[icons] svg[slot="on-icon"] {
  color: var(--md-switch-selected-icon-color, var(--md-primary, #6750a4));
}

md-switch[icons] svg[slot="off-icon"] {
  color: var(--md-switch-unselected-icon-color, var(--md-on-surface, #1d1b20));
}

/* High contrast mode - ensure maximum contrast with thumb */
@media (prefers-contrast: high) {
  md-switch[icons] svg[slot="on-icon"] {
    color: #000000; /* Black icon on white/light thumb */
  }

  md-switch[icons] svg[slot="off-icon"] {
    color: #000000; /* Black icon on white/light thumb */
  }

  /* High contrast focus states */
  md-switch[icons]:focus-visible svg[slot="on-icon"] {
    color: #000000;
    opacity: 1;
  }

  md-switch[icons]:focus-visible svg[slot="off-icon"] {
    color: #000000;
    opacity: 1;
  }
}
</file>

<file path="promptdj-midi/components/react/PlayPauseMorphType4.jsx">
import { useCallback, useEffect, useLayoutEffect, useMemo, useRef, useState } from 'react';
import React from 'react';


/**
 * PlayPauseMorphType4
 *
 * Goal: Visual style inspired by Type 2 (rotate/scale, hybrid feel)
 * with the robust morphing of Type 3 (clip-path polygon + Web Animations API).
 * - No requestAnimationFrame loops for morphing
 * - Uses WAAPI to animate CSS clip-path polygon between play/pause shapes
 * - Graceful fallback to SVG crossfade if clip-path/WAAPI unsupported
 *
 * Tuning in one place: edit TYPE4_DEFAULTS below or pass a `config` prop to override.
 */

export const TYPE4_DEFAULTS = {
  duration: 700,            // ms morph duration
  samples: 150,             // number of sampled points along the path
  easing: 'cubic-bezier(0.2, 0, 0, 1)',
  rotateDegrees: 5,         // degrees applied depending on state
  fillOpacity: 1,         // opacity of fill layer
  outlineScale: 1,          // scales the drop-shadow “stroke” intensity
  outlineShadow1Px: 1,      // base px for first shadow
  outlineShadow2Px: 2,      // base px for second shadow
  fallbackCrossfadeMs: 250, // ms for fallback crossfade
  // Morph behavior knobs
  morphOvershoot: 0.0,      // 0..0.35 extrapolation beyond target for elastic feel
  morphMidOffset: 0.7,      // 0..1 position of the overshoot keyframe
  keyframeEasings: null,    // optional array like ['ease-out','ease-in']
};
// Utility to build intermediate polygon with overshoot
function lerpPoints(a, b, t) {
  if (!a || !b) return a || b || [];
  const n = Math.min(a.length, b.length);
  const out = new Array(n);
  for (let i = 0; i < n; i++) {
    const ax = a[i][0], ay = a[i][1];
    const bx = b[i][0], by = b[i][1];
    out[i] = [ax + (bx - ax) * t, ay + (by - ay) * t];
  }
  return out;
}


// Detect the largest jump between consecutive points and split into two sequences.
function splitByLargestJump(points) {
  if (!points || points.length < 4) return null;
  let maxDist = -1;
  let idx = -1;
  for (let i = 1; i < points.length; i++) {
    const dx = points[i][0] - points[i - 1][0];
    const dy = points[i][1] - points[i - 1][1];
    const d2 = dx * dx + dy * dy;
    if (d2 > maxDist) { maxDist = d2; idx = i; }
  }
  if (idx <= 0 || idx >= points.length - 1) return null;
  const a = points.slice(0, idx);
  const b = points.slice(idx);
  // Heuristic: ensure the two parts are reasonably sized
  if (a.length < 8 || b.length < 8) return null;
  return [a, b];
}

// Simple resampler to produce "count" points from an existing sequence
function resamplePoints(points, count) {
  if (!points || points.length === 0 || count <= 0) return [];
  const res = new Array(count);
  for (let i = 0; i < count; i++) {
    const t = (i / count) * (points.length - 1);
    const i0 = Math.floor(t);
    const i1 = Math.min(points.length - 1, i0 + 1);
    const frac = t - i0;
    const x = points[i0][0] + (points[i1][0] - points[i0][0]) * frac;
    const y = points[i0][1] + (points[i1][1] - points[i0][1]) * frac;
    res[i] = [x, y];
  }
  return res;
}

const VIEW_BOX = '0 -960 960 960';

const PLAY_D = 'M275-248v-464q0-29.85 20.64-48.92Q316.29-780 343.48-780q8.68 0 18.1 2.5Q371-775 380-770l365 233q16.5 9 24.25 24.84T777-480q0 16.32-8 32.16Q761-432 745-423L380-190q-9 5-18.64 7.5t-18.22 2.5q-26.85 0-47.5-19.08Q275-218.15 275-248Z';
const PAUSE_D = 'M675.48-128q-56.48 0-95.98-39.31Q540-206.63 540-264v-433q0-55.97 39.32-95.99Q618.64-833 676.02-833 732-833 772-792.99q40 40.02 40 95.99v433q0 57.37-40.02 96.69Q731.96-128 675.48-128Zm-391.5 0Q228-128 188-167.31q-40-39.32-40-96.69v-433q0-55.97 40.02-95.99Q228.04-833 284.52-833t95.98 40.01Q420-752.97 420-697v433q0 57.37-39.32 96.69Q341.36-128 283.98-128Z';

function useSampledPoints(playD, pauseD, samples) {
  const playRef = useRef(null);
  const pauseRef = useRef(null);
  const [playPts, setPlayPts] = useState(null);
  const [pausePts, setPausePts] = useState(null);

  const hidden = (
    <svg viewBox={VIEW_BOX} width={1} height={1} style={{ position: 'absolute', width: 1, height: 1, opacity: 0, left: -9999, top: -9999 }} aria-hidden focusable="false">
      <path ref={playRef} d={playD} />
      <path ref={pauseRef} d={pauseD} />
    </svg>
  );

  useLayoutEffect(() => {
    const p1 = playRef.current; const p2 = pauseRef.current;
    if (!p1 || !p2) return;
    const sample = (pathEl) => {
      let len = 0;
      try { len = pathEl.getTotalLength(); } catch { len = 0; }
      if (!len || !isFinite(len)) len = 1;
      const pts = [];
      for (let i = 0; i < samples; i++) {
        const t = (i / samples) * len;
        const { x, y } = pathEl.getPointAtLength(t);
        pts.push([+x, +y]);
      }
      return pts;
    };
    const pPts = sample(p1);
    const qPts = sample(p2);
    setPlayPts(pPts);
    setPausePts(qPts);

  }, [samples]);

  return { hidden, playPts, pausePts };
}

// Ensure polygon has a consistent winding to reduce self-intersections
function normalizePolygon(points) {
  if (!points || points.length < 3) return points || [];
  let cx = 0, cy = 0;
  for (const [x, y] of points) { cx += x; cy += y; }
  cx /= points.length; cy /= points.length;
  const pts = points.slice().map(([x, y]) => ({ x, y, a: Math.atan2(y - cy, x - cx) }));
  pts.sort((p, q) => p.a - q.a);
  return pts.map(p => [p.x, p.y]);
}

// Convert sampled SVG points to a CSS polygon() string in percentages
function toCssPolygon(points) {
  if (!points || !points.length) return 'polygon(50% 50%, 50% 50%, 50% 50%)';
  const norm = normalizePolygon(points);
  const coords = norm.map(([px, py]) => {
    const x = (px / 960) * 100;
    const y = ((py + 960) / 960) * 100;
    return `${x.toFixed(2)}% ${y.toFixed(2)}%`;
  });
  return `polygon(${coords.join(', ')})`;
}

export default function PlayPauseMorphType4({
  playing: controlledPlaying,
  onToggle,
  size = 48,
  color = 'currentColor',
  title = 'Play/Pause',
  className,
  style,
  config,
}) {
  const isControlled = typeof controlledPlaying === 'boolean';
  const [uncontrolledPlaying, setUncontrolledPlaying] = useState(false);
  const playing = isControlled ? controlledPlaying : uncontrolledPlaying;

  const cfg = useMemo(() => ({ ...TYPE4_DEFAULTS, ...(config || {}) }), [config]);

  const { hidden, playPts, pausePts } = useSampledPoints(PLAY_D, PAUSE_D, cfg.samples);

  const split = useMemo(() => {
    if (!playPts || !pausePts) return null;

    const qSplit = splitByLargestJump(pausePts);
    if (!qSplit) return null;

    let [qA_raw, qB_raw] = qSplit;

    const avgX = (pts) => pts.reduce((sum, p) => sum + p[0], 0) / pts.length;
    if (avgX(qA_raw) > avgX(qB_raw)) {
      [qA_raw, qB_raw] = [qB_raw, qA_raw];
    }

    let minX = Infinity, maxX = -Infinity;
    playPts.forEach(([x]) => {
      if (x < minX) minX = x;
      if (x > maxX) maxX = x;
    });

    const centerX = (minX + maxX) / 2;
    const overlapWidth = (maxX - minX) * 0.25;

    const pA_raw = playPts.filter(([x]) => x < centerX + overlapWidth);
    const pB_raw = playPts.filter(([x]) => x > centerX - overlapWidth);

    const perPart = Math.max(20, Math.floor(cfg.samples / 2));

    return {
      playA: resamplePoints(pA_raw, perPart),
      playB: resamplePoints(pB_raw, perPart),
      pauseA: resamplePoints(qA_raw, perPart),
      pauseB: resamplePoints(qB_raw, perPart),
    };
  }, [playPts, pausePts, cfg.samples]);


  const containerRef = useRef(null); // [FIX] Add a ref for the rotating container
  const boxRef1 = useRef(null);
  const boxRef2 = useRef(null);
  const [ready, setReady] = useState(false);
  const animTokenRef = useRef(0);

  useEffect(() => { setReady(!!(playPts && pausePts)); }, [playPts, pausePts]);

  const handleClick = useCallback(() => {
    const next = !playing;
    if (onToggle) {
      try { onToggle.length > 0 ? onToggle(next) : onToggle(); } catch { onToggle(); }
    }
    if (!isControlled) setUncontrolledPlaying(next);
  }, [onToggle, isControlled, playing]);

  const pulseAnim = useMemo(() => 'ppm4_pulse_' + Math.random().toString(36).slice(2), []);
  useEffect(() => {
    const el = document.createElement('style');
    el.setAttribute('data-ppm4', pulseAnim);
    el.textContent = `@keyframes ${pulseAnim}{0%{transform:scale(1)}40%{transform:scale(1.06)}100%{transform:scale(1)}}`;
    document.head.appendChild(el);
    return () => { try { document.head.removeChild(el); } catch(_){} };
  }, [pulseAnim]);

  const anim1Ref = useRef(null);
  const anim2Ref = useRef(null);
  const animContainerRef = useRef(null); // [FIX] Add a ref to hold the container's animation instance

  useEffect(() => {
    if (!ready) return;
    const token = ++animTokenRef.current;

    // --- [FIX] START: Rotation animation logic ---
    const containerEl = containerRef.current;
    if (animContainerRef.current) {
        try { animContainerRef.current.cancel(); } catch {}
        animContainerRef.current = null;
    }
    // Define the start and end rotation states
    const fromRot = playing ? -cfg.rotateDegrees : cfg.rotateDegrees;
    const toRot = playing ? cfg.rotateDegrees : -cfg.rotateDegrees;
    // --- [FIX] END: Rotation animation logic ---

    const parts = split ? [
      { fromPts: playing ? split.playA : split.pauseA, toPts: playing ? split.pauseA : split.playA, el: boxRef1.current, animRef: anim1Ref, lastClipRef: lastClip1Ref },
      { fromPts: playing ? split.playB : split.pauseB, toPts: playing ? split.pauseB : split.playB, el: boxRef2.current, animRef: anim2Ref, lastClipRef: lastClip2Ref },
    ] : [
      { fromPts: playing ? playPts : pausePts, toPts: playing ? pausePts : playPts, el: boxRef1.current, animRef: anim1Ref, lastClipRef: lastClip1Ref },
    ];

    const validParts = parts.filter(p => p.el && typeof p.el.animate === 'function');
    if (validParts.length === 0 && !containerEl) return;

    const startPaths = new Map();
    validParts.forEach(({ el, fromPts, lastClipRef }) => {
      const cs = getComputedStyle(el);
      let currentClip = cs.clipPath || cs.webkitClipPath;
      if (!currentClip || currentClip === 'none') {
        currentClip = lastClipRef.current || toCssPolygon(fromPts);
      }
      startPaths.set(el, currentClip);
    });

    validParts.forEach(({ el, animRef }) => {
      el.getAnimations?.().forEach(a => a.cancel());
      if (animRef.current) {
        try { animRef.current.cancel(); } catch {}
        animRef.current = null;
      }
    });

    // --- [FIX] Animate the container's rotation using WAAPI ---
    if (containerEl && typeof containerEl.animate === 'function') {
        animContainerRef.current = containerEl.animate(
            [{ transform: `rotate(${fromRot}deg)` }, { transform: `rotate(${toRot}deg)` }],
            { duration: Math.max(250, Math.min(1600, cfg.duration)), easing: cfg.easing, fill: 'forwards' }
        );
    }

    validParts.forEach(({ fromPts, toPts, el, animRef, lastClipRef }) => {
      const fromPath = startPaths.get(el);
      const toPath = toCssPolygon(toPts);

      el.style.clipPath = fromPath;
      el.style.webkitClipPath = fromPath;
      lastClipRef.current = fromPath;

      const overshoot = Math.max(0, Math.min(0.35, cfg.morphOvershoot || 0));
      const midOffset = Math.max(0.05, Math.min(0.95, cfg.morphMidOffset || 0.7));

      const frames = [];
      frames.push({ clipPath: fromPath, offset: 0 });
      if (overshoot > 0) {
        const midPts = lerpPoints(fromPts, toPts, 1 + overshoot);
        const midPath = toCssPolygon(midPts);
        const midFrame = { clipPath: midPath, offset: midOffset };
        if (Array.isArray(cfg.keyframeEasings) && cfg.keyframeEasings[0]) midFrame.easing = cfg.keyframeEasings[0];
        frames.push(midFrame);
      }
      const endFrame = { clipPath: toPath, offset: 1 };
      if (Array.isArray(cfg.keyframeEasings)) {
        const idx = overshoot > 0 ? 1 : 0;
        if (cfg.keyframeEasings[idx]) endFrame.easing = cfg.keyframeEasings[idx];
      }
      frames.push(endFrame);

      try {
        const anim = el.animate(frames, { duration: Math.max(250, Math.min(1600, cfg.duration)), easing: cfg.easing, fill: 'forwards' });
        animRef.current = anim;
        anim.onfinish = () => {
          if (animTokenRef.current === token) {
            el.style.clipPath = toPath; el.style.webkitClipPath = toPath;
            lastClipRef.current = toPath;
          }
        };
      } catch (e) {
        el.style.clipPath = toPath;
        el.style.webkitClipPath = toPath;
        lastClipRef.current = toPath;
      }
    });
  }, [playing, ready, playPts, pausePts, split, cfg.duration, cfg.easing, cfg.morphOvershoot, cfg.morphMidOffset, cfg.keyframeEasings, cfg.rotateDegrees]);

  // [FIX] This is no longer needed for the transition but useful for setting the initial state.
  const currentRotation = playing ? cfg.rotateDegrees : -cfg.rotateDegrees;

  const lastClip1Ref = useRef(null);
  const lastClip2Ref = useRef(null);

  const defaultStart = useMemo(() => {
    if (!ready) return ['none', 'none'];
    if (split) {
      return [
        toCssPolygon(playing ? split.playA : split.pauseA),
        toCssPolygon(playing ? split.playB : split.pauseB),
      ];
    }
    return [toCssPolygon(playing ? playPts : pausePts)];
  }, [ready, split, playing, playPts, pausePts]);

  return (
    <div
      role="button"
      aria-label={title}
      onClick={handleClick}
      style={{ display: 'inline-flex', cursor: 'pointer', lineHeight: 0, position: 'relative', width: size, height: size, ...style }}
      className={className}
      title={title}
    >
      {hidden}

      {/* [FIX] The container now gets a ref and has its transition properties removed. */}
      <div
        ref={containerRef}
        style={{
          position: 'relative',
          width: size,
          height: size,
          animation: `${pulseAnim} 650ms ease-out`,
          // The WAAPI will control the transform, but we set the initial state here
          // to prevent a jump on first render before the animation runs.
          transform: `rotate(${currentRotation}deg)`,
          // NO `transition` property here anymore!
        }}
      >
        {/* Fill layer(s) */}
        <div
          ref={boxRef1}
          style={{
            position: 'absolute', inset: 0,
            background: color,
            opacity: cfg.fillOpacity,
            clipPath: lastClip1Ref.current || defaultStart[0],
            willChange: 'clip-path, transform',
          }}
        />
        {split && (
          <div
            ref={boxRef2}
            style={{
              position: 'absolute', inset: 0,
              background: color,
              opacity: cfg.fillOpacity,
              clipPath: lastClip2Ref.current || defaultStart[1],
              willChange: 'clip-path, transform',
            }}
          />
        )}

        {/* Stroke-ish layer(s) */}
        <div
          style={{
            position: 'absolute', inset: 0,
            background: 'transparent',
            clipPath: lastClip1Ref.current || defaultStart[0],
            filter: `drop-shadow(0 0 ${cfg.outlineShadow1Px * cfg.outlineScale}px ${color}) drop-shadow(0 0 ${cfg.outlineShadow2Px * cfg.outlineScale}px ${color})`,
            pointerEvents: 'none',
          }}
        />
        {split && (
          <div
            style={{
              position: 'absolute', inset: 0,
              background: 'transparent',
              clipPath: lastClip2Ref.current || defaultStart[1],
              filter: `drop-shadow(0 0 ${cfg.outlineShadow1Px * cfg.outlineScale}px ${color}) drop-shadow(0 0 ${cfg.outlineShadow2Px * cfg.outlineScale}px ${color})`,
              pointerEvents: 'none',
            }}
          />
        )}
      </div>
    </div>
  );
}
</file>

<file path="promptdj-midi/components/ToastMessage.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import { css, html, LitElement } from 'lit';
import { customElement, property } from 'lit/decorators.js';
import { classMap } from 'lit/directives/class-map.js';

@customElement('toast-message')
export class ToastMessage extends LitElement {
  static override styles = css`
    .toast {
      position: fixed;
      left: 50%;
      bottom: 24px;
      transform: translate(-50%, 16px);
      opacity: 0;
      font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;

      display: inline-flex;
      align-items: center;
      gap: 12px;
      padding: 12px 16px;
      max-width: min(520px, 88vw);

      border-radius: 16px;
      border: 1px solid var(--md-outline-variant);
      background: color-mix(in srgb, var(--md-surface), transparent 0%);
      color: var(--md-on-surface);
      box-shadow: var(--md-elevation-level3);
      backdrop-filter: blur(6px);

      line-height: 1.5;
      text-wrap: pretty;
      z-index: 999999;
      transition: transform var(--md-duration-medium3) var(--md-easing-emphasized),
                  opacity var(--md-duration-medium3) var(--md-easing-emphasized),
                  box-shadow var(--md-duration-short4) var(--md-easing-standard);
    }

    .toast.showing {
      transform: translate(-50%, 0);
      opacity: 1;
      box-shadow: var(--md-elevation-level4);
    }

    .message {
      flex: 1 1 auto;
      color: var(--md-on-surface);
    }

    button {
      flex: 0 0 auto;
      display: inline-flex;
      align-items: center;
      justify-content: center;
      width: 28px;
      height: 28px;
      border-radius: 9999px;
      border: 1px solid var(--md-outline-variant);
      background: var(--md-primary-container);
      color: var(--md-on-primary-container);
      cursor: pointer;
      transition: box-shadow var(--md-duration-short3) var(--md-easing-standard),
                  background-color var(--md-duration-short3) var(--md-easing-standard);
    }

    button:hover { box-shadow: var(--md-elevation-level1); }
    button:active { box-shadow: var(--md-elevation-level0, none); }

    a {
      color: var(--md-primary);
      text-decoration: underline;
    }
  `;

  @property({ type: String }) message = '';
  @property({ type: Boolean }) showing = false;

  private renderMessageWithLinks() {
    const urlRegex = /(https?:\/\/[^\s]+)/g;
    const parts = this.message.split(urlRegex);
    return parts.map((part, i) => {
      if (i % 2 === 0) return part;
      return html`<a href=${part} target="_blank" rel="noopener">${part}</a>`;
    });
  }

  override render() {
    return html`<div class=${classMap({ showing: this.showing, toast: true })}>
      <div class="message">${this.renderMessageWithLinks()}</div>
      <button @click=${this.hide}>✕</button>
    </div>`;
  }

  private dismissTimer: number | null = null;

  show(message: string, duration: number = 4000) {
    // Clear any existing timer
    if (this.dismissTimer) {
      clearTimeout(this.dismissTimer);
      this.dismissTimer = null;
    }

    this.showing = true;
    this.message = message;

    // Auto-dismiss after duration
    if (duration > 0) {
      this.dismissTimer = window.setTimeout(() => {
        this.hide();
      }, duration);
    }
  }

  hide() {
    if (this.dismissTimer) {
      clearTimeout(this.dismissTimer);
      this.dismissTimer = null;
    }
    this.showing = false;
  }

}

declare global {
  interface HTMLElementTagNameMap {
    'toast-message': ToastMessage
  }
}
</file>

<file path="promptdj-midi/components/WeightKnob.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import { css, html, LitElement } from 'lit';
import { customElement, property } from 'lit/decorators.js';
import { styleMap } from 'lit/directives/style-map.js';

/** Maps prompt weight to halo size. */
const MIN_HALO_SCALE = 1;
const MAX_HALO_SCALE = 2;

/** The amount of scale to add to the halo based on audio level. */
const HALO_LEVEL_MODIFIER = 1;

/** A knob for adjusting and visualizing prompt weight. */
@customElement('weight-knob')
export class WeightKnob extends LitElement {
  static override styles = css`
    :host {
      cursor: grab;
      position: relative;
      width: 100%;
      aspect-ratio: 1;
      flex-shrink: 0;
      touch-action: none;
    }

    :host(:active) {
      cursor: grabbing;
      filter: drop-shadow(0 4px 8px rgba(0, 0, 0, 0.4))
              drop-shadow(0 2px 4px rgba(0, 0, 0, 0.3));
      transform: translateY(1px);
    }

    svg {
      position: absolute;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      transition: transform 0.1s ease-out;
    }

    #halo {
      position: absolute;
      z-index: -1;
      top: 0;
      left: 0;
      width: 100%;
      height: 100%;
      border-radius: 50%;
      mix-blend-mode: lighten;
      transform: scale(2);
      will-change: transform;
      filter: blur(8px);
      opacity: 0.8;
    }

    /* Improve halo contrast in light theme */
    :host-context([data-theme="light"]) #halo {
      mix-blend-mode: multiply;
      opacity: 0.55;
      filter: saturate(1.15) contrast(1.05) blur(8px);
    }

    /* Add subtle ambient lighting effect */
    :host::before {
      content: '';
      position: absolute;
      top: -10%;
      left: -10%;
      right: -10%;
      bottom: -10%;
      background: radial-gradient(
        ellipse at 30% 20%,
        rgba(255, 255, 255, 0.1) 0%,
        rgba(255, 255, 255, 0.05) 40%,
        transparent 70%
      );
      border-radius: 50%;
      pointer-events: none;
      z-index: 1;
    }
  `;

  @property({ type: Number }) value = 0;
  @property({ type: String }) color = '#000';
  @property({ type: Number }) audioLevel = 0;

  private dragStartPos = 0;
  private dragStartValue = 0;
  private activePointerId: number | null = null;
  private isDragging = false;

  constructor() {
    super();
    this.handlePointerDown = this.handlePointerDown.bind(this);
    this.handlePointerMove = this.handlePointerMove.bind(this);
    this.handlePointerUp = this.handlePointerUp.bind(this);
    this.handlePointerCancel = this.handlePointerCancel.bind(this);
    this.onLostPointerCapture = this.onLostPointerCapture.bind(this);
    this.onWindowBlur = this.onWindowBlur.bind(this);
  }

  connectedCallback(): void {
    super.connectedCallback();
    this.addEventListener('wheel', this.handleWheel, { passive: true });
  }

  disconnectedCallback(): void {
    // Ensure we always cleanup listeners if the element is removed
    this.teardownDragListeners();
    this.removeEventListener('wheel', this.handleWheel);
    super.disconnectedCallback();
  }

  private setupDragListeners() {
    window.addEventListener('pointermove', this.handlePointerMove);
    window.addEventListener('pointerup', this.handlePointerUp);
    window.addEventListener('pointercancel', this.handlePointerCancel);
    window.addEventListener('blur', this.onWindowBlur);
    // Fallback for mouse leaving the iframe without a pointerup firing
    window.addEventListener('mouseleave', this.handlePointerCancel as any);
    this.addEventListener('lostpointercapture', this.onLostPointerCapture);
  }

  private teardownDragListeners() {
    window.removeEventListener('pointermove', this.handlePointerMove);
    window.removeEventListener('pointerup', this.handlePointerUp);
    window.removeEventListener('pointercancel', this.handlePointerCancel);
    window.removeEventListener('blur', this.onWindowBlur);
    window.removeEventListener('mouseleave', this.handlePointerCancel as any);
    this.removeEventListener('lostpointercapture', this.onLostPointerCapture);
  }

  private handlePointerDown(e: PointerEvent) {
    e.preventDefault();
    this.dragStartPos = e.clientY;
    this.dragStartValue = this.value;
    this.activePointerId = e.pointerId;
    this.isDragging = true;
    document.body.classList.add('dragging');
    // Try to retain events even when pointer leaves the iframe/element
    try {
      (this as unknown as Element).setPointerCapture(e.pointerId);
    } catch {}
    this.setupDragListeners();
  }

  private handlePointerMove(e: PointerEvent) {
    if (!this.isDragging || (this.activePointerId !== null && e.pointerId !== this.activePointerId)) return;
    const delta = this.dragStartPos - e.clientY;
    this.value = this.dragStartValue + delta * 0.01;
    this.value = Math.max(0, Math.min(2, this.value));
    this.dispatchEvent(new CustomEvent<number>('input', { detail: this.value }));
  }

  private endDrag() {
    if (!this.isDragging) return;
    this.isDragging = false;
    if (this.activePointerId !== null) {
      try {
        (this as unknown as Element).releasePointerCapture(this.activePointerId);
      } catch {}
    }
    this.activePointerId = null;
    this.teardownDragListeners();
    document.body.classList.remove('dragging');
  }

  private handlePointerUp() {
    this.endDrag();
  }

  private handlePointerCancel() {
    this.endDrag();
  }

  private onLostPointerCapture() {
    // If we lose capture without a pointerup, end the drag to avoid sticky state
    this.endDrag();
  }

  private onWindowBlur() {
    // If iframe/window loses focus while dragging, end drag
    this.endDrag();
  }

  private handleWheel(e: WheelEvent) {
    const delta = e.deltaY;
    this.value = this.value + delta * -0.0025;
    this.value = Math.max(0, Math.min(2, this.value));
    this.dispatchEvent(new CustomEvent<number>('input', { detail: this.value }));
  }

  private describeArc(
    centerX: number,
    centerY: number,
    startAngle: number,
    endAngle: number,
    radius: number,
  ): string {
    const startX = centerX + radius * Math.cos(startAngle);
    const startY = centerY + radius * Math.sin(startAngle);
    const endX = centerX + radius * Math.cos(endAngle);
    const endY = centerY + radius * Math.sin(endAngle);

    const largeArcFlag = endAngle - startAngle <= Math.PI ? '0' : '1';

    return (
      `M ${startX} ${startY}` +
      `A ${radius} ${radius} 0 ${largeArcFlag} 1 ${endX} ${endY}`
    );
  }

  override render() {
    const rotationRange = Math.PI * 2 * 0.75;
    const minRot = -rotationRange / 2 - Math.PI / 2;
    const maxRot = rotationRange / 2 - Math.PI / 2;
    const rot = minRot + (this.value / 2) * (maxRot - minRot);
    const dotStyle = styleMap({
      transform: `translate(40px, 40px) rotate(${rot}rad)`,
    });

    let scale = (this.value / 2) * (MAX_HALO_SCALE - MIN_HALO_SCALE);
    scale += MIN_HALO_SCALE;
    scale += this.audioLevel * HALO_LEVEL_MODIFIER;


    const haloStyle = styleMap({
      display: this.value > 0 ? 'block' : 'none',
      background: this.color,
      transform: `scale(${scale})`,
    });

    return html`
      <div id="halo" style=${haloStyle}></div>
      <!-- Static SVG elements -->
      ${this.renderStaticSvg()}
      <!-- SVG elements that move, separated to limit redraws -->
      <svg
        viewBox="0 0 80 80"
        @pointerdown=${this.handlePointerDown}>
        <g style=${dotStyle}>
          <!-- Enhanced 3D indicator with depth -->
          <g filter="url(#indicatorShadow)">
            <rect x="5" y="-1.5" width="10" height="3" rx="1.5" fill="url(#indicatorGradient)" />
          </g>
          <!-- Highlight on top of indicator -->
          <rect x="5.5" y="-1" width="9" height="1" rx="0.5" fill="url(#indicatorHighlight)" opacity="0.8" />
        </g>
        <path
          d=${this.describeArc(40, 40, minRot, maxRot, 34.5)}
          fill="none"
          stroke="#0003"
          stroke-width="3"
          stroke-linecap="round" />
        <path
          d=${this.describeArc(40, 40, minRot, rot, 34.5)}
          fill="none"
          stroke="#fff"
          stroke-width="3"
          stroke-linecap="round" />
      </svg>
    `;
  }

  private renderStaticSvg() {
    return html`<svg viewBox="0 0 80 80">
        <!-- Outer shadow/base -->
        <ellipse
          opacity="0.6"
          cx="40"
          cy="42"
          rx="38"
          ry="38"
          fill="url(#baseShadow)" />

        <!-- Main knob body with enhanced depth -->
        <g filter="url(#mainShadow)">
          <ellipse cx="40" cy="40" rx="29" ry="29" fill="url(#knobBody)" />
        </g>

        <!-- Inner beveled ring -->
        <g filter="url(#innerShadow)">
          <circle cx="40" cy="40" r="20" fill="url(#innerRing)" stroke="url(#ringStroke)" stroke-width="0.5" />
        </g>

        <!-- Center knob surface -->
        <g filter="url(#centerShadow)">
          <circle cx="40" cy="40" r="16" fill="url(#centerSurface)" />
        </g>

        <!-- Top highlight -->
        <ellipse cx="40" cy="37" rx="14" ry="12" fill="url(#topHighlight)" opacity="0.8" />

        <!-- Subtle texture lines -->
        <g opacity="0.15" stroke="url(#textureStroke)" stroke-width="0.3">
          <circle cx="40" cy="40" r="26" fill="none" />
          <circle cx="40" cy="40" r="24" fill="none" />
          <circle cx="40" cy="40" r="20" fill="none" />
        </g>

        <defs>
          <!-- Enhanced shadow filters for 3D depth -->
          <filter id="mainShadow" x="-50%" y="-50%" width="200%" height="200%">
            <feGaussianBlur in="SourceAlpha" stdDeviation="3"/>
            <feOffset dx="0" dy="4" result="offset"/>
            <feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.4 0"/>
            <feBlend in2="SourceGraphic" mode="normal"/>
          </filter>

          <filter id="innerShadow" x="-50%" y="-50%" width="200%" height="200%">
            <feGaussianBlur in="SourceAlpha" stdDeviation="3"/>
            <feOffset dx="0" dy="4" result="offset"/>
            <feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.5 0"/>
            <feBlend in2="SourceGraphic" mode="normal"/>
          </filter>

          <filter id="centerShadow" x="-50%" y="-50%" width="200%" height="200%">
            <feGaussianBlur in="SourceAlpha" stdDeviation="1.5"/>
            <feOffset dx="0" dy="1" result="offset"/>
            <feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.2 0"/>
            <feBlend in2="SourceGraphic" mode="normal"/>
          </filter>

          <!-- Inset shadow effect for depth -->
          <filter id="insetShadow" x="-50%" y="-50%" width="200%" height="200%">
            <feOffset in="SourceAlpha" dx="0" dy="2"/>
            <feGaussianBlur stdDeviation="2" result="offset-blur"/>
            <feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.5 0" result="shadow"/>
            <feComposite in="SourceGraphic" in2="shadow" operator="over"/>
          </filter>
          <!-- Gradients for realistic materials and lighting -->
          <radialGradient id="baseShadow" cx="50%" cy="50%" r="50%">
            <stop offset="80%" stop-color="#000" stop-opacity="0.3" />
            <stop offset="100%" stop-color="#000" stop-opacity="0" />
          </radialGradient>

          <radialGradient id="knobBody" cx="50%" cy="50%" r="50%">
            <stop offset="0%" stop-color="white" />
            <stop offset="100%" stop-color="white" stop-opacity="0.7" />
          </radialGradient>

          <linearGradient id="innerRing" x1="0%" y1="0%" x2="0%" y2="100%">
            <stop offset="0%" stop-color="white" />
            <stop offset="100%" stop-color="#F2F2F2" />
          </linearGradient>

          <linearGradient id="ringStroke" x1="0%" y1="0%" x2="0%" y2="100%">
            <stop offset="0%" stop-color="#E0E0E0" />
            <stop offset="100%" stop-color="#C0C0C0" />
          </linearGradient>

          <linearGradient id="centerSurface" x1="0%" y1="0%" x2="0%" y2="100%">
            <stop offset="0%" stop-color="#EBEBEB" />
            <stop offset="100%" stop-color="white" />
          </linearGradient>

          <radialGradient id="topHighlight" cx="30%" cy="30%" r="40%">
            <stop offset="0%" stop-color="white" stop-opacity="0.6" />
            <stop offset="70%" stop-color="white" stop-opacity="0.3" />
            <stop offset="100%" stop-color="white" stop-opacity="0" />
          </radialGradient>


          <filter id="indicatorShadow" x="-50%" y="-50%" width="200%" height="200%">
            <feGaussianBlur in="SourceAlpha" stdDeviation="0.5"/>
            <feOffset dx="0" dy="0.5" result="offset"/>
            <feColorMatrix values="0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0.6 0"/>
            <feBlend in2="SourceGraphic" mode="normal"/>
          </filter>

          <linearGradient id="indicatorGradient" x1="0%" y1="0%" x2="0%" y2="100%">
            <stop offset="0%" stop-color="#FF8C00" />
            <stop offset="100%" stop-color="#E07B00" />
          </linearGradient>

          <linearGradient id="indicatorHighlight" x1="0%" y1="0%" x2="0%" y2="100%">
            <stop offset="0%" stop-color="#FFFFFF" stop-opacity="0.9" />
            <stop offset="100%" stop-color="#FFFFFF" stop-opacity="0.7" />
          </linearGradient>

          <linearGradient id="textureStroke" x1="0%" y1="0%" x2="0%" y2="100%">
            <stop offset="0%" stop-color="#fff" stop-opacity="0.1" />
            <stop offset="100%" stop-color="#000" stop-opacity="0.1" />
          </linearGradient>
        </defs>
      </svg>`
  }

}

declare global {
  interface HTMLElementTagNameMap {
    'weight-knob': WeightKnob;
  }
}
</file>

<file path="promptdj-midi/index.css">
@import url('https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600;700&display=swap');
@import url('https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200');
@import url('./styles/material-tokens.css');

html,
body {
  height: 100%;
  margin: 0;
}

body {
  font-family: var(--font-primary, 'Google Sans Flex', 'Google Sans', 'Open Sans', sans-serif);
  font-size: 14px;
  overflow: hidden;
  background: transparent;
  /* Fix white borders */
  margin: 0;
  padding: 0;
}

body.dragging {
  cursor: ns-resize;
}

body.dragging * {
  user-select: none;
  pointer-events: none;
}
</file>

<file path="promptdj-midi/index.html">
<!doctype html>
<html>

<head>
  <link rel="stylesheet" href="/index.css">
  <link rel="stylesheet"
    href="https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" />
  <script type="importmap">
      {
        "imports": {
          "@google/genai": "https://esm.sh/@google/genai@^1.0.0",
          "lit/": "https://esm.sh/lit@^3.3.0/",
          "lit": "https://esm.sh/lit@^3.3.0"
        }
      }
    </script>
</head>

<body>
  <script type="module" src="/index.tsx"></script>
</body>

</html>
</file>

<file path="promptdj-midi/index.tsx">
/**
 * @fileoverview Control real time music with a MIDI controller
 * @license
 * SPDX-License-Identifier: Apache-2.0
 */

import type { PlaybackState, Prompt } from './types';
import { GoogleGenAI, LiveMusicFilteredPrompt } from '@google/genai';
import { PromptDjMidi } from './components/PromptDjMidi';
import { ToastMessage } from './components/ToastMessage';
import { LiveMusicHelper } from './utils/LiveMusicHelper';
import { AudioAnalyser } from './utils/AudioAnalyser';
import { processAudioBlob } from './utils/AudioProcessing';
import { LOCALES, Lang } from './utils/Locales';

let ai: GoogleGenAI | null = null;
// Temporary debug logging
console.log('[PDJ] index.tsx loaded');
const model = 'lyria-realtime-exp';

// Recorder plumbing shared across message handlers
let teeNode: GainNode | null = null;
let mediaDest: MediaStreamAudioDestinationNode | null = null;
let mediaRecorder: MediaRecorder | null = null;
let recordedChunks: BlobPart[] = [];

// Lazy-initialized helper and analyser (created after API key is provided by parent)
let liveMusicHelper: LiveMusicHelper | null = null;
let audioAnalyser: AudioAnalyser | null = null;

// Track current playback state
let currentPlaybackState: PlaybackState = 'stopped';


function main() {
  console.log('[PDJ] main() start');
  const initialPrompts = buildInitialPrompts();

  // Default to light theme unless parent tells us otherwise
  try { document.documentElement.setAttribute('data-theme', 'light'); } catch { }

  const pdjMidi = new PromptDjMidi(initialPrompts);
  document.body.appendChild(pdjMidi);
  console.log('[PDJ] <prompt-dj-midi> attached');

  const toastMessage = new ToastMessage();
  document.body.appendChild(toastMessage);
  console.log('[PDJ] <toast-message> attached');

  // Wire UI events regardless of helper init timing
  pdjMidi.addEventListener('prompts-changed', ((e: Event) => {
    const customEvent = e as CustomEvent<Map<string, Prompt>>;
    const prompts = customEvent.detail;
    liveMusicHelper?.setWeightedPrompts(prompts);
  }));

  pdjMidi.addEventListener('error', ((e: Event) => {
    const customEvent = e as CustomEvent<string>;
    const error = customEvent.detail;
    toastMessage.show(error);
  }));

  // Wire up UI buttons from PromptDjMidi
  pdjMidi.addEventListener('start-recording', () => startRecording());
  pdjMidi.addEventListener('stop-recording', () => stopRecording());
  pdjMidi.addEventListener('reset-all', () => {
    (pdjMidi as any).resetAll?.();
  });

  // New explicit play/pause events to avoid accidental re-toggles
  pdjMidi.addEventListener('play', () => {
    if (!liveMusicHelper) {
      toastMessage.show(LOCALES[pdjMidi.lang as Lang].api_key_toast);
      pdjMidi.playbackState = 'stopped';
      return;
    }
    liveMusicHelper.play();
  });
  pdjMidi.addEventListener('pause', () => {
    if (!liveMusicHelper) {
      toastMessage.show(LOCALES[pdjMidi.lang as Lang].api_key_toast);
      pdjMidi.playbackState = 'stopped';
      return;
    }
    // Use stop() to fully stop and prevent stray chunks from re-triggering
    liveMusicHelper.stop();
  });
  // Back-compat: if any 'play-pause' is emitted, map based on current state
  pdjMidi.addEventListener('play-pause', () => {
    if (!liveMusicHelper) {
      toastMessage.show(LOCALES[pdjMidi.lang as Lang].api_key_toast);
      pdjMidi.playbackState = 'stopped';
      return;
    }
    const stateMsg = '[PDJ] back-compat play-pause used; mapping to explicit action';
    try { console.log(stateMsg); } catch { }
    // Best-effort mapping: if not playing, play; else stop
    // This minimizes chance of spurious re-plays
    liveMusicHelper?.play?.();
  });

  const attachHelperListeners = () => {
    if (!liveMusicHelper) return;

    liveMusicHelper.addEventListener('playback-state-changed', ((e: Event) => {
      const customEvent = e as CustomEvent<PlaybackState>;
      const playbackState = customEvent.detail;
      currentPlaybackState = playbackState;
      pdjMidi.playbackState = playbackState;
      if (audioAnalyser) {
        if (playbackState === 'playing') {
          audioAnalyser.start();
        } else {
          audioAnalyser.stop();
          pdjMidi.audioLevel = 0;
        }
      }
    }));

    liveMusicHelper.addEventListener('filtered-prompt', ((e: Event) => {
      const customEvent = e as CustomEvent<LiveMusicFilteredPrompt>;
      const filteredPrompt = customEvent.detail;
      toastMessage.show(filteredPrompt.filteredReason!)
      pdjMidi.addFilteredPrompt(filteredPrompt.text!);
    }));

    liveMusicHelper.addEventListener('error', ((e: Event) => {
      const customEvent = e as CustomEvent<string>;
      const error = customEvent.detail;
      toastMessage.show(error);
    }));
  };

  // Listen for analyser events if/when created
  const attachAnalyserListener = () => {
    if (!audioAnalyser) return;
    audioAnalyser.addEventListener('audio-level-changed', ((e: Event) => {
      const customEvent = e as CustomEvent<number>;
      const level = customEvent.detail;
      pdjMidi.audioLevel = level;
    }));
  };

  function initWithApiKey(apiKey: string) {
    try {
      ai = new GoogleGenAI({ apiKey, apiVersion: 'v1alpha' });
      liveMusicHelper = new LiveMusicHelper(ai, model);
      liveMusicHelper.setWeightedPrompts(initialPrompts);
      audioAnalyser = new AudioAnalyser(liveMusicHelper.audioContext);
      // Create a tee node so we can fan out to analyser and (optionally) recorder
      teeNode = liveMusicHelper.audioContext.createGain();
      teeNode.connect(audioAnalyser.node);
      liveMusicHelper.extraDestination = teeNode;
      pdjMidi.apiKeySet = true;
      attachHelperListeners();
      attachAnalyserListener();
    } catch (e: any) {
      window.parent?.postMessage({ type: 'pm-dj-recording-error', error: e?.message || String(e) }, '*');
    }
  }

  // Expose recording controls via postMessage from parent iframe
  function startRecording() {
    try {
      if (!teeNode || !liveMusicHelper) return;
      if (mediaRecorder && mediaRecorder.state !== 'inactive') return;
      mediaDest = liveMusicHelper.audioContext.createMediaStreamDestination();
      teeNode.connect(mediaDest);
      const mime = MediaRecorder.isTypeSupported('audio/webm;codecs=opus') ? 'audio/webm;codecs=opus' : 'audio/webm';
      mediaRecorder = new MediaRecorder(mediaDest.stream, { mimeType: mime });
      recordedChunks = [];
      mediaRecorder.ondataavailable = (e) => {
        if (e.data && e.data.size > 0) recordedChunks.push(e.data);
      };
      mediaRecorder.onstop = async () => {
        const rawBlob = new Blob(recordedChunks, { type: mediaRecorder?.mimeType || 'audio/webm' });
        try {
          // Process audio: decode, trim silence, encode to WAV
          const processedBlob = await processAudioBlob(rawBlob, liveMusicHelper!.audioContext);

          // Show recording result modal with processed audio
          if (typeof (pdjMidi as any).showRecording === 'function') {
            (pdjMidi as any).showRecording(processedBlob);
          }
          // Send processed blob back to parent
          window.parent?.postMessage({ type: 'pm-dj-recording-stopped', blob: processedBlob }, '*');
        } catch (e: any) {
          console.error("[PDJ] Audio processing failed:", e);
          const errorMsg = e?.message || String(e);

          if (errorMsg.includes('silence')) {
            toastMessage.show(LOCALES[pdjMidi.lang as Lang].no_sound_toast);
            window.parent?.postMessage({ type: 'pm-dj-recording-stopped', error: 'silence' }, '*');
            return;
          }

          // If it was just a decoding error on a tiny chunk, treat as silence too
          if (recordedChunks.length === 0 || rawBlob.size < 1000) {
            toastMessage.show(LOCALES[pdjMidi.lang as Lang].too_short_toast);
            window.parent?.postMessage({ type: 'pm-dj-recording-stopped', error: 'silent/short' }, '*');
            return;
          }

          // Fallback to raw blob ONLY if there is actual data and it wasn't a silence error
          if (typeof (pdjMidi as any).showRecording === 'function') {
            (pdjMidi as any).showRecording(rawBlob);
          }
          window.parent?.postMessage({ type: 'pm-dj-recording-stopped', blob: rawBlob }, '*');
        }
      };
      mediaRecorder.start(250);
      window.parent?.postMessage({ type: 'pm-dj-recording-started' }, '*');
    } catch (e) {
      window.parent?.postMessage({ type: 'pm-dj-recording-error', error: (e as any)?.message || String(e) }, '*');
    }
  }

  function stopRecording() {
    try {
      if (mediaRecorder && mediaRecorder.state !== 'inactive') {
        mediaRecorder.stop();
      }
    } catch (e) {
      window.parent?.postMessage({ type: 'pm-dj-recording-error', error: (e as any)?.message || String(e) }, '*');
    }
  }

  function normalizeLang(lang: string | undefined): 'en' | 'ko' | 'vi' {
    const lc = (lang || 'en').toLowerCase();
    if (lc.startsWith('ko')) return 'ko';
    if (lc.startsWith('vi')) return 'vi';
    return 'en';
  }

  // Forward MIDI input updates to parent
  pdjMidi.addEventListener('midi-inputs-changed', (e: Event) => {
    const { inputs, activeId } = (e as CustomEvent).detail || {};
    // Map to include device names from dispatcher
    const named = (inputs || []).map((id: string) => ({ id, name: pdjMidi ? (pdjMidi as any).midiDispatcher?.getDeviceName?.(id) : id }));
    window.parent?.postMessage({ type: 'midi:inputs', inputs: named, activeId, show: (pdjMidi as any).showMidi }, '*');
  });

  window.addEventListener('message', (event: MessageEvent) => {
    const data = event.data as any;
    if (!data || typeof data !== 'object') return;
    if (data.type === 'pm-dj-start-recording') startRecording();
    if (data.type === 'pm-dj-stop-recording') stopRecording();
    if (data.type === 'pm-dj-set-api-key' && typeof data.apiKey === 'string' && data.apiKey) {
      if (data.lang && pdjMidi) {
        pdjMidi.lang = normalizeLang(data.lang);
      }
      initWithApiKey(data.apiKey);
    }
    if (data.type === 'pm-dj-set-lang' && pdjMidi) {
      pdjMidi.lang = normalizeLang(data.lang);
    }
    if (data.type === 'pm-dj-set-theme' && typeof data.theme === 'string') {
      try { document.documentElement.setAttribute('data-theme', data.theme === 'dark' ? 'dark' : 'light'); } catch { }
    }
    if (data.type === 'pm-dj-set-font' && typeof data.font === 'string') {
      const root = document.documentElement;
      let primary = `"Google Sans Flex", "Google Sans", "Open Sans", sans-serif`;
      let title = `"Google Sans Flex", "Google Sans", "Be Vietnam Pro", sans-serif`;

      if (data.font === 'google-sans-flex') {
        primary = `"Google Sans Flex", "Google Sans", "Open Sans", sans-serif`;
        title = `"Google Sans Flex", "Google Sans", "Be Vietnam Pro", sans-serif`;
      }

      root.style.setProperty('--font-primary', primary);
      root.style.setProperty('--font-title', title);
    }

    // Bridge: control MIDI from parent
    if (data.type === 'midi:getInputs') {
      (pdjMidi as any).refreshMidiInputs?.();
      // Also respond immediately with current snapshot
      const ids = (pdjMidi as any).getMidiInputs?.() || [];
      const activeId = (pdjMidi as any).getActiveMidiInputId?.() || null;
      const named = ids.map((id: string) => ({ id, name: (pdjMidi as any).midiDispatcher?.getDeviceName?.(id) || id }));
      window.parent?.postMessage({ type: 'midi:inputs', inputs: named, activeId, show: (pdjMidi as any).getShowMidi?.() }, '*');
    }
    if (data.type === 'midi:setShow') {
      (pdjMidi as any).setShowMidi?.(!!data.show);
    }
    if (data.type === 'midi:setActiveInput' && typeof data.id === 'string') {
      (pdjMidi as any).setActiveMidiInputId?.(data.id);
    }
    if (data.type === 'pm-dj-reset') {
      (pdjMidi as any).resetAll?.();
    }
    if (data.type === 'pm-dj-stop-audio') {
      liveMusicHelper?.stop();
      if (pdjMidi) pdjMidi.playbackState = 'stopped';
    }
  });

}

function buildInitialPrompts() {
  // Pick 3 random prompts to start at weight = 1
  const startOn = [...DEFAULT_PROMPTS]
    .sort(() => Math.random() - 0.5)
    .slice(0, 3);

  const prompts = new Map<string, Prompt>();

  for (let i = 0; i < DEFAULT_PROMPTS.length; i++) {
    const promptId = `prompt-${i}`;
    const prompt = DEFAULT_PROMPTS[i];
    const { text, color } = prompt;
    prompts.set(promptId, {
      promptId,
      text,
      weight: startOn.includes(prompt) ? 1 : 0,
      cc: i,
      color,
    });
  }

  return prompts;
}

const DEFAULT_PROMPTS = [
  { color: '#9900ff', text: 'Bossa Nova' },
  { color: '#5200ff', text: 'Chillwave' },
  { color: '#ff25f6', text: 'Drum and Bass' },
  { color: '#2af6de', text: 'Post Punk' },
  { color: '#ffdd28', text: 'Shoegaze' },
  { color: '#2af6de', text: 'Funk' },
  { color: '#9900ff', text: 'Chiptune' },
  { color: '#3dffab', text: 'Lush Strings' },
  { color: '#d8ff3e', text: 'Sparkling Arpeggios' },
  { color: '#d9b2ff', text: 'Staccato Rhythms' },
  { color: '#3dffab', text: 'Punchy Kick' },
  { color: '#ffdd28', text: 'Dubstep' },
  { color: '#ff25f6', text: 'K Pop' },
  { color: '#d8ff3e', text: 'Neo Soul' },
  { color: '#5200ff', text: 'Trip Hop' },
  { color: '#d9b2ff', text: 'Thrash' },
  { color: '#D2691E', text: 'City Pop' },
  { color: '#FFA500', text: 'Phonk' },
  { color: '#9905c6', text: 'Baile Funk' },
  { color: '#049ea1', text: 'Lo-fi' },
  { color: '#FF0000', text: 'Vietnamese Military March' },
  { color: '#FF0099', text: 'Vinahouse Vietnamese EDM' },
  { color: '#cccccc', text: '' },
  { color: '#cccccc', text: '' },
];

main();
</file>

<file path="promptdj-midi/metadata.json">
{
  "name": "PromptDJ MIDI",
  "description": "Control real time music with a MIDI controller.",
  "requestFramePermissions": [],
  "prompt": ""
}
</file>

<file path="promptdj-midi/package.json">
{
  "name": "promptdj-midi",
  "private": true,
  "version": "0.0.0",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "vite build",
    "preview": "vite preview"
  },
  "dependencies": {
    "@google/genai": "^1.0.0",
    "lit": "^3.3.0",
    "react": "^18.3.1",
    "react-dom": "^18.3.1"
  },
  "devDependencies": {
    "@types/node": "^22.14.0",
    "@types/react": "^18.3.12",
    "@types/react-dom": "^18.3.1",
    "typescript": "~5.8.2",
    "vite": "^5.4.0"
  }
}
</file>

<file path="promptdj-midi/README.md">
<div align="center">
<img width="1200" height="475" alt="GHBanner" src="https://github.com/user-attachments/assets/0aa67016-6eaf-458a-adb2-6e31a0763ed6" />
</div>

# Run and deploy your AI Studio app

This contains everything you need to run your app locally.

View your app in AI Studio: https://ai.studio/apps/bundled/promptdj-midi

## Run Locally

**Prerequisites:**  Node.js


1. Install dependencies:
   `npm install`
2. Set the `GEMINI_API_KEY` in [.env.local](.env.local) to your Gemini API key
3. Run the app:
   `npm run dev`
</file>

<file path="promptdj-midi/styles/material-tokens.css">
/* Material Design 3 Token System */

:root {
  /* Color tokens - Light theme - more vibrant colors */
  --md-primary: #5D5FEF; /* More vibrant purple */
  --md-on-primary: #FEFEFE; /* Very slightly softer white */
  --md-primary-container: #E8E7FF; /* Very slightly softer purple container */
  --md-on-primary-container: #322e6e;

  --md-secondary: #2979FF; /* Vibrant blue */
  --md-on-secondary: #FFFFFF;
  --md-secondary-container: #E0ECFF;
  --md-on-secondary-container: #004BA0;

  --md-tertiary: #F50057; /* Vibrant pink */
  --md-on-tertiary: #FFFFFF;
  --md-tertiary-container: #FFD9E3;
  --md-on-tertiary-container: #C51162;

  --md-error: #B3261E;
  --md-on-error: #FFFFFF;
  --md-error-container: #F9DEDC;
  --md-on-error-container: #410E0B;

  --md-surface: #FEF7FF;
  --md-on-surface: #1C1B1F;
  --md-surface-variant: #E7E0EC;
  --md-on-surface-variant: #49454E;

  --md-outline: #79747E;
  --md-outline-variant: #CAC4D0;

  --md-surface-1: #F4EEFF;
  --md-surface-2: #F3ECFA;
  --md-surface-3: #EFE8F6;
  --md-surface-4: #EBE4F2;
  --md-surface-5: #E8E0EE;

  /* Surface container tokens */
  --md-surface-container: #F9F1FF;
  --md-surface-container-low: #F5EDFC;
  --md-surface-container-high: #F0E7F8;
  --md-surface-container-highest: #EBE1F4;

  /* State layer opacities */
  --md-state-hover-opacity: 0.08;
  --md-state-focus-opacity: 0.12;
  --md-state-pressed-opacity: 0.12;
  --md-state-dragged-opacity: 0.16;

  /* Shape tokens - using pill shapes for buttons */
  --md-shape-small: 12px;
  --md-shape-medium: 32px;
  --md-shape-large: 24px;
  --md-shape-extra-large: 32px;
  --md-shape-pill: 9999px; /* For pill-shaped buttons */

  /* Elevation tokens - enhanced for more visible shadows */
  --md-elevation-level1: 0 2px 6px rgba(0,0,0,0.2), 0 1px 4px rgba(0,0,0,0.1);
  --md-elevation-level2: 0 4px 10px rgba(0,0,0,0.2), 0 2px 8px rgba(0,0,0,0.1);
  --md-elevation-level3: 0 8px 16px rgba(0,0,0,0.2), 0 4px 12px rgba(0,0,0,0.1);
  --md-elevation-level4: 0 12px 24px rgba(0,0,0,0.2), 0 6px 16px rgba(0,0,0,0.1);
  --md-elevation-level5: 0 16px 32px rgba(0,0,0,0.2), 0 8px 24px rgba(0,0,0,0.1);

  /* Typography tokens */
  --md-display-large-size: 57px;
  --md-display-large-height: 64px;
  --md-display-large-weight: 400;

  --md-display-medium-size: 45px;
  --md-display-medium-height: 52px;
  --md-display-medium-weight: 400;

  --md-display-small-size: 36px;
  --md-display-small-height: 44px;
  --md-display-small-weight: 400;

  --md-headline-large-size: 32px;
  --md-headline-large-height: 40px;
  --md-headline-large-weight: 400;

  --md-headline-medium-size: 28px;
  --md-headline-medium-height: 36px;
  --md-headline-medium-weight: 400;

  --md-headline-small-size: 24px;
  --md-headline-small-height: 32px;
  --md-headline-small-weight: 400;

  --md-title-large-size: 22px;
  --md-title-large-height: 28px;
  --md-title-large-weight: 500;

  --md-title-medium-size: 16px;
  --md-title-medium-height: 24px;
  --md-title-medium-weight: 500;

  --md-title-small-size: 14px;
  --md-title-small-height: 20px;
  --md-title-small-weight: 500;

  --md-body-large-size: 16px;
  --md-body-large-height: 24px;
  --md-body-large-weight: 400;

  --md-body-medium-size: 14px;
  --md-body-medium-height: 20px;
  --md-body-medium-weight: 400;

  --md-body-small-size: 12px;
  --md-body-small-height: 16px;
  --md-body-small-weight: 400;

  --md-label-large-size: 14px;
  --md-label-large-height: 20px;
  --md-label-large-weight: 500;

  --md-label-medium-size: 12px;
  --md-label-medium-height: 16px;
  --md-label-medium-weight: 500;

  --md-label-small-size: 11px;
  --md-label-small-height: 16px;
  --md-label-small-weight: 500;

  /* Motion tokens */
  --md-easing-standard: cubic-bezier(0.2, 0.0, 0, 1.0);
  --md-easing-emphasized: cubic-bezier(0.2, 0.0, 0, 1.0);
  --md-easing-emphasized-decelerate: cubic-bezier(0.05, 0.7, 0.1, 1.0);
  --md-easing-emphasized-accelerate: cubic-bezier(0.3, 0.0, 0.8, 0.15);

  --md-duration-short1: 50ms;
  --md-duration-short2: 100ms;
  --md-duration-short3: 150ms;
  --md-duration-short4: 200ms;
  --md-duration-medium1: 250ms;
  --md-duration-medium2: 300ms;
  --md-duration-medium3: 350ms;
  --md-duration-medium4: 400ms;
  --md-duration-long1: 450ms;
  --md-duration-long2: 500ms;
  --md-duration-long3: 550ms;
  --md-duration-long4: 600ms;
  --md-duration-extra-long1: 700ms;
  --md-duration-extra-long2: 800ms;
  --md-duration-extra-long3: 900ms;
  --md-duration-extra-long4: 1000ms;
}

/* Dark theme tokens - more vibrant colors */
[data-theme="dark"] {
  --md-primary: #B4B5FF; /* More vibrant purple for dark theme */
  --md-on-primary: #302b7f;
  --md-primary-container: #2d2e6d; /* Very slightly softer purple container */
  --md-on-primary-container: #E8E7FF;

  --md-secondary: #82B1FF; /* Vibrant blue for dark theme */
  --md-on-secondary: #004BA0;
  --md-secondary-container: #0D5DB3;
  --md-on-secondary-container: #E0ECFF;

  --md-tertiary: #FF80AB; /* Vibrant pink for dark theme */
  --md-on-tertiary: #C51162;
  --md-tertiary-container: #D81B60;
  --md-on-tertiary-container: #FFD9E3;

  --md-error: #F2B8B5;
  --md-on-error: #601410;
  --md-error-container: #8C1D18;
  --md-on-error-container: #F9DEDC;

  --md-surface: #1C1B1F;
  --md-on-surface: #E6E1E5;
  --md-surface-variant: #49454F;
  --md-on-surface-variant: #CAC4D0;

  --md-outline: #938F99;
  --md-outline-variant: #49454F;

  --md-surface-1: #1C1B1F;
  --md-surface-2: #211F26;
  --md-surface-3: #282731;
  --md-surface-4: #2E2C38;
  --md-surface-5: #31303C;

  /* Surface container tokens for dark theme */
  --md-surface-container: #211F26;
  --md-surface-container-low: #1D1B20;
  --md-surface-container-high: #2B2930;
  --md-surface-container-highest: #322F39;
}

/* Typography utility classes */
.md-display-large {
  font-size: var(--md-display-large-size);
  line-height: var(--md-display-large-height);
  font-weight: var(--md-display-large-weight);
}

.md-display-medium {
  font-size: var(--md-display-medium-size);
  line-height: var(--md-display-medium-height);
  font-weight: var(--md-display-medium-weight);
}

.md-display-small {
  font-size: var(--md-display-small-size);
  line-height: var(--md-display-small-height);
  font-weight: var(--md-display-small-weight);
}

.md-headline-large {
  font-size: var(--md-headline-large-size);
  line-height: var(--md-headline-large-height);
  font-weight: var(--md-headline-large-weight);
}

.md-headline-medium {
  font-size: var(--md-headline-medium-size);
  line-height: var(--md-headline-medium-height);
  font-weight: var(--md-headline-medium-weight);
}

.md-headline-small {
  font-size: var(--md-headline-small-size);
  line-height: var(--md-headline-small-height);
  font-weight: var(--md-headline-small-weight);
}

.md-title-large {
  font-size: var(--md-title-large-size);
  line-height: var(--md-title-large-height);
  font-weight: var(--md-title-large-weight);
}

.md-title-medium {
  font-size: var(--md-title-medium-size);
  line-height: var(--md-title-medium-height);
  font-weight: var(--md-title-medium-weight);
}

.md-title-small {
  font-size: var(--md-title-small-size);
  line-height: var(--md-title-small-height);
  font-weight: var(--md-title-small-weight);
}

.md-body-large {
  font-size: var(--md-body-large-size);
  line-height: var(--md-body-large-height);
  font-weight: var(--md-body-large-weight);
}

.md-body-medium {
  font-size: var(--md-body-medium-size);
  line-height: var(--md-body-medium-height);
  font-weight: var(--md-body-medium-weight);
}

.md-body-small {
  font-size: var(--md-body-small-size);
  line-height: var(--md-body-small-height);
  font-weight: var(--md-body-small-weight);
}

.md-label-large {
  font-size: var(--md-label-large-size);
  line-height: var(--md-label-large-height);
  font-weight: var(--md-label-large-weight);
}

.md-label-medium {
  font-size: var(--md-label-medium-size);
  line-height: var(--md-label-medium-height);
  font-weight: var(--md-label-medium-weight);
}

.md-label-small {
  font-size: var(--md-label-small-size);
  line-height: var(--md-label-small-height);
  font-weight: var(--md-label-small-weight);
}

/* Animation utility classes */
.md-fade-in {
  animation: fadeIn var(--md-duration-medium2) var(--md-easing-standard);
}

.md-slide-in {
  animation: slideIn var(--md-duration-medium4) var(--md-easing-emphasized-decelerate);
}

.md-slide-up {
  animation: slideUp var(--md-duration-medium3) var(--md-easing-emphasized-decelerate);
}

@keyframes fadeIn {
  from { opacity: 0; }
  to { opacity: 1; }
}

@keyframes slideIn {
  from { transform: translateY(20px); opacity: 0; }
  to { transform: translateY(0); opacity: 1; }
}

@keyframes slideUp {
  from { transform: translateY(10px); opacity: 0; }
  to { transform: translateY(0); opacity: 1; }
}

/* Material Design 3 Component Styles */

/* Buttons */
.md-button {
  position: relative;
  display: inline-flex;
  align-items: center;
  justify-content: center;
  gap: 8px;
  padding: 10px 24px;
  border-radius: var(--md-shape-small);
  font-size: var(--md-label-large-size);
  line-height: var(--md-label-large-height);
  font-weight: var(--md-label-large-weight);
  cursor: pointer;
  transition: box-shadow var(--md-duration-medium2) var(--md-easing-standard),
              background-color var(--md-duration-medium2) var(--md-easing-standard);
  overflow: hidden;
}

.md-button:disabled {
  opacity: 0.38;
  cursor: not-allowed;
}

/* Filled button */
.md-filled-button {
  background-color: var(--md-primary);
  color: var(--md-on-primary);
  border: none;
  box-shadow: var(--md-elevation-level1);
}

.md-filled-button:hover:not(:disabled) {
  box-shadow: var(--md-elevation-level2);
  background-color: color-mix(in srgb, var(--md-primary), rgba(255, 255, 255, var(--md-state-hover-opacity)));
}

.md-filled-button:active:not(:disabled) {
  box-shadow: var(--md-elevation-level1);
  background-color: color-mix(in srgb, var(--md-primary), rgba(255, 255, 255, var(--md-state-pressed-opacity)));
}

/* Outlined button */
.md-outlined-button {
  background-color: transparent;
  color: var(--md-primary);
  border: 1px solid var(--md-outline);
}

.md-outlined-button:hover:not(:disabled) {
  background-color: color-mix(in srgb, var(--md-primary), transparent var(--md-state-hover-opacity));
}

.md-outlined-button:active:not(:disabled) {
  background-color: color-mix(in srgb, var(--md-primary), transparent var(--md-state-pressed-opacity));
}

/* Text button */
.md-text-button {
  background-color: transparent;
  color: var(--md-primary);
  border: none;
  padding: 10px 12px;
}

.md-text-button:hover:not(:disabled) {
  background-color: color-mix(in srgb, var(--md-primary), transparent var(--md-state-hover-opacity));
}

.md-text-button:active:not(:disabled) {
  background-color: color-mix(in srgb, var(--md-primary), transparent var(--md-state-pressed-opacity));
}

/* Elevated button */
.md-elevated-button {
  background-color: var(--md-surface);
  color: var(--md-primary);
  border: none;
  box-shadow: var(--md-elevation-level1);
}

.md-elevated-button:hover:not(:disabled) {
  box-shadow: var(--md-elevation-level2);
  background-color: color-mix(in srgb, var(--md-surface), rgba(0, 0, 0, var(--md-state-hover-opacity)));
}

.md-elevated-button:active:not(:disabled) {
  box-shadow: var(--md-elevation-level1);
  background-color: color-mix(in srgb, var(--md-surface), rgba(0, 0, 0, var(--md-state-pressed-opacity)));
}

/* Tonal button */
.md-tonal-button {
  background-color: var(--md-secondary-container);
  color: var(--md-on-secondary-container);
  border: none;
}

.md-tonal-button:hover:not(:disabled) {
  box-shadow: var(--md-elevation-level1);
  background-color: color-mix(in srgb, var(--md-secondary-container), rgba(0, 0, 0, var(--md-state-hover-opacity)));
}

.md-tonal-button:active:not(:disabled) {
  background-color: color-mix(in srgb, var(--md-secondary-container), rgba(0, 0, 0, var(--md-state-pressed-opacity)));
}

/* Cards */
.md-card {
  background-color: var(--md-surface);
  color: var(--md-on-surface);
  border-radius: var(--md-shape-medium);
  padding: 16px;
  transition: box-shadow var(--md-duration-medium2) var(--md-easing-standard);
}

.md-elevated-card {
  box-shadow: var(--md-elevation-level1);
}

.md-elevated-card:hover {
  box-shadow: var(--md-elevation-level2);
}

.md-filled-card {
  background-color: var(--md-surface-variant);
  color: var(--md-on-surface-variant);
}

.md-outlined-card {
  border: 1px solid var(--md-outline-variant);
}

/* Text fields */
.md-text-field {
  position: relative;
  display: flex;
  flex-direction: column;
  gap: 4px;
}

.md-text-field-input {
  padding: 12px 16px;
  border-radius: var(--md-shape-small);
  border: 1px solid var(--md-outline);
  background-color: var(--md-surface);
  color: var(--md-on-surface);
  font-size: var(--md-body-large-size);
  line-height: var(--md-body-large-height);
  transition: border-color var(--md-duration-medium2) var(--md-easing-standard),
              box-shadow var(--md-duration-medium2) var(--md-easing-standard);
}

.md-text-field-input:focus {
  outline: none;
  border-color: var(--md-primary);
  box-shadow: 0 0 0 1px var(--md-primary);
}

.md-text-field-input:disabled {
  opacity: 0.38;
  cursor: not-allowed;
}

.md-text-field-label {
  font-size: var(--md-body-small-size);
  line-height: var(--md-body-small-height);
  color: var(--md-on-surface-variant);
}

.md-text-field-error {
  font-size: var(--md-body-small-size);
  line-height: var(--md-body-small-height);
  color: var(--md-error);
  margin-top: 4px;
}
</file>

<file path="promptdj-midi/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2022",
    "experimentalDecorators": true,
    "useDefineForClassFields": false,
    "module": "ESNext",
    "lib": [
      "ES2022",
      "DOM",
      "DOM.Iterable"
    ],
    "skipLibCheck": true,
    "types": [
      "node"
    ],
    "moduleResolution": "bundler",
    "isolatedModules": true,
    "moduleDetection": "force",
    "allowJs": true,
    "jsx": "react-jsx",
    "paths": {
      "@/*": [
        "./*"
      ]
    },
    "allowImportingTsExtensions": true,
    "noEmit": true
  }
}
</file>

<file path="promptdj-midi/types.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
export interface Prompt {
  readonly promptId: string;
  text: string;
  weight: number;
  cc: number;
  color: string;
}

export interface ControlChange {
  channel: number;
  cc: number;
  value: number;
}

export type PlaybackState = 'stopped' | 'playing' | 'loading' | 'paused';
</file>

<file path="promptdj-midi/utils/audio.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/

import {Blob} from '@google/genai';

function encode(bytes: Uint8Array) {
  let binary = '';
  const len = bytes.byteLength;
  for (let i = 0; i < len; i++) {
    binary += String.fromCharCode(bytes[i]);
  }
  return btoa(binary);
}

function decode(base64: string) {
  const binaryString = atob(base64);
  const len = binaryString.length;
  const bytes = new Uint8Array(len);
  for (let i = 0; i < len; i++) {
    bytes[i] = binaryString.charCodeAt(i);
  }
  return bytes;
}

function createBlob(data: Float32Array): Blob {
  const l = data.length;
  const int16 = new Int16Array(l);
  for (let i = 0; i < l; i++) {
    // convert float32 -1 to 1 to int16 -32768 to 32767
    int16[i] = data[i] * 32768;
  }

  return {
    data: encode(new Uint8Array(int16.buffer)),
    mimeType: 'audio/pcm;rate=16000',
  };
}

async function decodeAudioData(
  data: Uint8Array,
  ctx: AudioContext,
  sampleRate: number,
  numChannels: number,
): Promise<AudioBuffer> {
  const buffer = ctx.createBuffer(
    numChannels,
    data.length / 2 / numChannels,
    sampleRate,
  );

  const dataInt16 = new Int16Array(data.buffer);
  const l = dataInt16.length;
  const dataFloat32 = new Float32Array(l);
  for (let i = 0; i < l; i++) {
    dataFloat32[i] = dataInt16[i] / 32768.0;
  }
  // Extract interleaved channels
  if (numChannels === 0) {
    buffer.copyToChannel(dataFloat32, 0);
  } else {
    for (let i = 0; i < numChannels; i++) {
      const channel = dataFloat32.filter(
        (_, index) => index % numChannels === i,
      );
      buffer.copyToChannel(channel, i);
    }
  }

  return buffer;
}

export {createBlob, decode, decodeAudioData, encode};
</file>

<file path="promptdj-midi/utils/AudioAnalyser.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
/** Simple class for getting the current audio level. */
export class AudioAnalyser extends EventTarget {
  readonly node: AnalyserNode;
  private readonly freqData: Uint8Array;
  private rafId: number | null = null;
  constructor(context: AudioContext) {
    super();
    this.node = context.createAnalyser();
    this.node.smoothingTimeConstant = 0;
    this.freqData = new Uint8Array(this.node.frequencyBinCount);
    this.loop = this.loop.bind(this);
  }
  getCurrentLevel() {
    this.node.getByteFrequencyData(this.freqData);
    const avg = this.freqData.reduce((a, b) => a + b, 0) / this.freqData.length;
    return avg / 0xff;
  }
  loop() {
    this.rafId = requestAnimationFrame(this.loop);
    const level = this.getCurrentLevel();
    this.dispatchEvent(new CustomEvent('audio-level-changed', { detail: level }));
  }
  start = this.loop;
  stop() {
    if (this.rafId) cancelAnimationFrame(this.rafId);
  }
}
</file>

<file path="promptdj-midi/utils/AudioProcessing.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
 */

// Helper to write string to DataView
function writeString(view: DataView, offset: number, string: string) {
    for (let i = 0; i < string.length; i++) {
        view.setUint8(offset + i, string.charCodeAt(i));
    }
}

// Convert AudioBuffer to WAV Blob
export function audioBufferToWav(buffer: AudioBuffer): Blob {
    const numOfChan = buffer.numberOfChannels;
    const length = buffer.length * numOfChan * 2 + 44;
    const bufferArr = new ArrayBuffer(length);
    const view = new DataView(bufferArr);
    const channels = [];
    let i;
    let sample;
    let offset = 0;
    let pos = 0;

    // write WAVE header
    writeString(view, 0, 'RIFF');
    view.setUint32(4, 36 + buffer.length * numOfChan * 2, true);
    writeString(view, 8, 'WAVE');
    writeString(view, 12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numOfChan, true);
    view.setUint32(24, buffer.sampleRate, true);
    view.setUint32(28, buffer.sampleRate * 2 * numOfChan, true);
    view.setUint16(32, numOfChan * 2, true);
    view.setUint16(34, 16, true);
    writeString(view, 36, 'data');
    view.setUint32(40, buffer.length * numOfChan * 2, true);

    // write interleaved data
    for (i = 0; i < buffer.numberOfChannels; i++) {
        channels.push(buffer.getChannelData(i));
    }

    offset = 44;
    while (pos < buffer.length) {
        for (i = 0; i < numOfChan; i++) {
            // clamp
            sample = Math.max(-1, Math.min(1, channels[i][pos]));
            // scale to 16-bit
            sample = (0.5 + sample < 0 ? sample * 32768 : sample * 32767) | 0;
            view.setInt16(offset, sample, true);
            offset += 2;
        }
        pos++;
    }

    return new Blob([view], { type: 'audio/wav' });
}

// Trim silence from start and end
export function trimSilence(buffer: AudioBuffer, threshold = 0.02): AudioBuffer {
    const numChannels = buffer.numberOfChannels;
    let start = 0;
    let end = buffer.length;

    // Find start
    let foundStart = false;
    for (let i = 0; i < buffer.length; i++) {
        let max = 0;
        for (let c = 0; c < numChannels; c++) {
            const v = Math.abs(buffer.getChannelData(c)[i]);
            if (v > max) max = v;
        }
        if (max > threshold) {
            start = i;
            foundStart = true;
            break;
        }
    }

    if (!foundStart) return null;

    // Find end
    let foundEnd = false;
    for (let i = buffer.length - 1; i >= start; i--) {
        let max = 0;
        for (let c = 0; c < numChannels; c++) {
            const v = Math.abs(buffer.getChannelData(c)[i]);
            if (v > max) max = v;
        }
        if (max > threshold) {
            end = i + 1;
            foundEnd = true;
            break;
        }
    }

    if (!foundEnd) return null;

    const length = end - start;
    if (length <= 0) {
        // Return null if completely silent
        return null;
    }

    const newBuffer = new AudioContext().createBuffer(
        numChannels,
        length,
        buffer.sampleRate
    );

    for (let c = 0; c < numChannels; c++) {
        const chanData = buffer.getChannelData(c);
        const newChanData = newBuffer.getChannelData(c);
        // copy slice
        for (let i = 0; i < length; i++) {
            newChanData[i] = chanData[start + i];
        }
    }

    return newBuffer;
}

export async function processAudioBlob(blob: Blob, context: AudioContext): Promise<Blob> {
    const arrayBuffer = await blob.arrayBuffer();
    const audioBuffer = await context.decodeAudioData(arrayBuffer);
    const trimmed = trimSilence(audioBuffer);
    if (!trimmed) {
        throw new Error('No audio recorded (silence).');
    }
    return audioBufferToWav(trimmed);
}
</file>

<file path="promptdj-midi/utils/LiveMusicHelper.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import type { PlaybackState, Prompt } from '../types';
import type { AudioChunk, GoogleGenAI, LiveMusicFilteredPrompt, LiveMusicServerMessage, LiveMusicSession } from '@google/genai';
import { decode, decodeAudioData } from './audio';
import { throttle } from './throttle';

export class LiveMusicHelper extends EventTarget {

  private ai: GoogleGenAI;
  private model: string;

  private session: LiveMusicSession | null = null;
  private sessionPromise: Promise<LiveMusicSession> | null = null;

  private connectionError = true;

  private filteredPrompts = new Set<string>();
  private nextStartTime = 0;
  private bufferTime = 2;

  public readonly audioContext: AudioContext;
  public extraDestination: AudioNode | null = null;

  private outputNode: GainNode;
  private playbackState: PlaybackState = 'stopped';
  private loadingTimer: number | null = null;
  private bufferTimer: number | null = null;
  private retryTimer: number | null = null;
  private retryCount = 0;
  private readonly maxRetries = 3;

  private prompts: Map<string, Prompt>;
  private sessionSeq: number = 0; // increments to invalidate stale callbacks

  constructor(ai: GoogleGenAI, model: string) {
    super();
    this.ai = ai;
    this.model = model;
    this.prompts = new Map();
    this.audioContext = new AudioContext({ sampleRate: 48000 });
    this.outputNode = this.audioContext.createGain();
  }

  // DEBUG
  private debug(...args: any[]) { try { console.log('[PDJ][Helper]', ...args); } catch {} }

  private getSession(): Promise<LiveMusicSession> {
    if (!this.sessionPromise) this.sessionPromise = this.connect();
    return this.sessionPromise;
  }

  private async connect(): Promise<LiveMusicSession> {
    // Bump sequence and capture for this connection to ignore stale callbacks on stop()
    const mySeq = ++this.sessionSeq;
    this.sessionPromise = this.ai.live.music.connect({
      model: this.model,
      callbacks: {
        onmessage: async (e: LiveMusicServerMessage) => {
          if (mySeq !== this.sessionSeq) { this.debug('onmessage ignored (stale seq)'); return; }
          this.debug('onmessage', {
            setupComplete: !!e.setupComplete,
            filteredPrompt: !!e.filteredPrompt,
            chunks: e.serverContent?.audioChunks?.length || 0,
          });
          if (e.setupComplete) {
            this.debug('setupComplete received');
            this.connectionError = false;
            this.retryCount = 0;
            if (this.loadingTimer) { clearTimeout(this.loadingTimer); this.loadingTimer = null; }
          }
          if (e.filteredPrompt) {
            this.debug('filteredPrompt received', e.filteredPrompt);
            this.filteredPrompts = new Set([...this.filteredPrompts, e.filteredPrompt.text!])
            this.dispatchEvent(new CustomEvent<LiveMusicFilteredPrompt>('filtered-prompt', { detail: e.filteredPrompt }));
          }
          if (e.serverContent?.audioChunks) {
            if (mySeq !== this.sessionSeq) { this.debug('audioChunks ignored (stale seq)'); return; }
            this.debug('audioChunks received', e.serverContent.audioChunks.length);
            if (this.loadingTimer) { clearTimeout(this.loadingTimer); this.loadingTimer = null; }
            await this.processAudioChunks(e.serverContent.audioChunks);
          }
        },
        onerror: () => {
          if (mySeq !== this.sessionSeq) { this.debug('onerror ignored (stale seq)'); return; }
          this.debug('onerror');
          this.connectionError = true;
          if (this.loadingTimer) { clearTimeout(this.loadingTimer); this.loadingTimer = null; }
          this.stop();
          this.dispatchEvent(new CustomEvent('error', { detail: 'Connection error, please restart audio.' }));
        },
        onclose: () => {
          if (mySeq !== this.sessionSeq) { this.debug('onclose ignored (stale seq)'); return; }
          this.debug('onclose');
          this.connectionError = true;
          
          if (this.retryCount < this.maxRetries) {
            this.retryCount++;
            this.debug(`onclose: retrying connection (${this.retryCount}/${this.maxRetries}) in 1s...`);
            this.stop();
            this.retryTimer = (setTimeout(() => {
              this.retryTimer = null;
              this.play(false);
            }, 1000) as unknown) as number;
            return;
          }

          if (this.loadingTimer) { clearTimeout(this.loadingTimer); this.loadingTimer = null; }
          this.stop();
          this.dispatchEvent(new CustomEvent('error', { detail: 'Connection error, please restart audio.' }));
        },
      },
    });
    return this.sessionPromise;
  }

  private setPlaybackState(state: PlaybackState) {
    this.debug('setPlaybackState ->', state);
    this.playbackState = state;
    this.dispatchEvent(new CustomEvent('playback-state-changed', { detail: state }));
  }

  private async processAudioChunks(audioChunks: AudioChunk[]) {
    // Only schedule when we're in playing or loading states; ignore if paused or stopped
    if (this.playbackState !== 'playing' && this.playbackState !== 'loading') {
      this.debug('processAudioChunks: early return due to state', this.playbackState);
      return;
    }

    const audioBuffer = await decodeAudioData(
      decode(audioChunks[0].data!),
      this.audioContext,
      48000,
      2,
    );
    const source = this.audioContext.createBufferSource();
    source.buffer = audioBuffer;
    source.connect(this.outputNode);

    const now = this.audioContext.currentTime;
    this.debug('processAudioChunks: now=', now.toFixed(3), 'nextStartTime=', this.nextStartTime.toFixed(3), 'bufDur=', audioBuffer.duration.toFixed(3));

    if (this.nextStartTime === 0) {
      this.nextStartTime = now + this.bufferTime;
      this.debug('processAudioChunks: scheduling first start at', this.nextStartTime.toFixed(3), 'bufferTime=', this.bufferTime);
      setTimeout(() => {
        this.debug('processAudioChunks: set playing after buffer');
        this.setPlaybackState('playing');
      }, this.bufferTime * 1000);
    }
    if (this.nextStartTime < now) {
      this.debug('processAudioChunks: fell behind, resetting to loading and rescheduling');
      this.setPlaybackState('loading');
      this.nextStartTime = 0;
      return;
    }
    try {
      source.start(this.nextStartTime);
      this.debug('processAudioChunks: scheduled source at', this.nextStartTime.toFixed(3));
    } catch (e) {
      this.debug('processAudioChunks: start() error', e);
    }
    this.nextStartTime += audioBuffer.duration;
  }

  public get activePrompts() {
    return Array.from(this.prompts.values())
      .filter((p) => {
        return !this.filteredPrompts.has(p.text) && p.weight !== 0;
      })
  }

  public readonly setWeightedPrompts = throttle(async (prompts: Map<string, Prompt>) => {
    this.prompts = prompts;

    if (this.activePrompts.length === 0) {
      this.dispatchEvent(new CustomEvent('error', { detail: 'There needs to be one active prompt to play.' }));
      this.pause();
      return;
    }

    // store the prompts to set later if we haven't connected yet
    // there should be a user interaction before calling setWeightedPrompts
    if (!this.session) return;

    try {
      await this.session.setWeightedPrompts({
        weightedPrompts: this.activePrompts.map(p => ({ text: p.text, weight: p.weight })),
      });
    } catch (e: any) {
      this.dispatchEvent(new CustomEvent('error', { detail: e.message }));
      this.pause();
    }
  }, 200);

  public async play(resetRetries = true) {
    this.debug('play() called');
    if (resetRetries) {
      this.retryCount = 0;
    }
    this.setPlaybackState('loading');
    // Start a safety timer: if no audio or setupComplete within 12s, abort and show error
    if (this.loadingTimer) { clearTimeout(this.loadingTimer); this.loadingTimer = null; }
    this.loadingTimer = (setTimeout(() => {
      this.loadingTimer = null;
      this.debug('play() timeout hit (no audio/setupComplete)');
      this.dispatchEvent(new CustomEvent('error', { detail: 'Starting audio timed out. Please check API key/network and try again.' }));
      this.pause();
    }, 12000) as unknown) as number;

    this.debug('play(): awaiting getSession()');
    this.session = await this.getSession();
    this.debug('play(): got session');
    this.debug('play(): setWeightedPrompts()');
    await this.setWeightedPrompts(this.prompts);
    this.debug('play(): audioContext.resume()');
    await this.audioContext.resume();
    this.debug('play(): session.play()');
    this.session.play();
    this.debug('play(): connect destinations');
    this.outputNode.connect(this.audioContext.destination);
    if (this.extraDestination) this.outputNode.connect(this.extraDestination);
    this.outputNode.gain.setValueAtTime(0, this.audioContext.currentTime);
    this.outputNode.gain.linearRampToValueAtTime(1, this.audioContext.currentTime + 0.1);
  }

  public pause() {
    if (this.session) this.session.pause();
    this.setPlaybackState('paused');
    this.outputNode.gain.setValueAtTime(1, this.audioContext.currentTime);
    this.outputNode.gain.linearRampToValueAtTime(0, this.audioContext.currentTime + 0.1);
    this.nextStartTime = 0;
    this.outputNode = this.audioContext.createGain();
  }

  public stop() {
    // Invalidate any in-flight callbacks from previous connection
    this.sessionSeq++;
    if (this.retryTimer) { clearTimeout(this.retryTimer); this.retryTimer = null; }
    try { this.session?.stop(); } catch {}
    // Hard mute and disconnect
    try { this.outputNode.disconnect(); } catch {}
    this.outputNode = this.audioContext.createGain();
    this.nextStartTime = 0;
    this.setPlaybackState('stopped');
    this.session = null;
    this.sessionPromise = null;
    if (this.loadingTimer) { clearTimeout(this.loadingTimer); this.loadingTimer = null; }
  }

  public async playPause() {
    switch (this.playbackState) {
      case 'playing':
        return this.pause();
      case 'paused':
      case 'stopped':
        return this.play();
      case 'loading':
        return this.stop();
    }
  }

}
</file>

<file path="promptdj-midi/utils/Locales.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
 */

export const LOCALES = {
    en: {
        recording_ready: 'Recording Ready',
        silence_removed: 'Silent audio parts have been removed',
        saved: 'Saved!',
        download_btn: 'Download Recording',
        downloaded_msg: 'Downloaded to Downloads folder',
        record_tooltip: 'Record',
        stop_tooltip: 'Stop Recording',
        midi_tooltip: 'MIDI Settings',
        reset_tooltip: 'Reset All Weights',
        no_sound_toast: 'No sound detected in recording.',
        too_short_toast: 'Recording too short or silent.',
        api_key_toast: 'Please set your Gemini API key in the main app first.',
        add_tooltip: 'Add',
        edit_btn: 'edit',
        edit_tooltip: 'Edit prompt',
        clear_tooltip: 'Clear',
        prompt_placeholder: 'Enter audio prompt...',
        onboarding_title: 'Note',
        onboarding_msg: 'Playback may be interrupted due to Gemini, but recording will not be interrupted as silence removal is in place.',
        onboarding_btn: 'Got it',
    },
    vi: {
        recording_ready: 'Bản ghi đã sẵn sàng',
        silence_removed: 'Những đoạn im lặng đã được loại bỏ',
        saved: 'Đã lưu!',
        download_btn: 'Tải bản ghi xuống',
        downloaded_msg: 'Đã tải vào thư mục Downloads',
        record_tooltip: 'Ghi âm',
        stop_tooltip: 'Dừng ghi',
        midi_tooltip: 'Cài đặt MIDI',
        reset_tooltip: 'Đặt lại tất cả',
        no_sound_toast: 'Không phát hiện âm thanh trong bản ghi.',
        too_short_toast: 'Bản ghi quá ngắn hoặc không có tiếng.',
        api_key_toast: 'Vui lòng thiết lập Gemini API key trong ứng dụng chính.',
        add_tooltip: 'Thêm',
        edit_btn: 'sửa',
        edit_tooltip: 'Sửa prompt',
        clear_tooltip: 'Xóa',
        prompt_placeholder: 'Nhập prompt âm thanh',
        onboarding_title: 'Lưu ý',
        onboarding_msg: 'Lúc nghe có thể gián đoạn do phía Gemini, nhưng lúc thu âm sẽ không bị gián đoạn do đã có cơ chế loại bỏ tĩnh lặng.',
        onboarding_btn: 'Đã hiểu',
    },
    ko: {
        recording_ready: '녹음 완료',
        silence_removed: '무음 구간이 제거되었습니다',
        saved: '저장됨!',
        download_btn: '녹음 파일 다운로드',
        downloaded_msg: '다운로드 폴더에 저장되었습니다',
        record_tooltip: '녹음 시작',
        stop_tooltip: '녹음 중지',
        midi_tooltip: 'MIDI 설정',
        reset_tooltip: '모든 가중치 초기화',
        no_sound_toast: '녹음에서 소리가 감지되지 않았습니다.',
        too_short_toast: '녹음이 너무 짧거나 소리가 없습니다.',
        api_key_toast: '메인 앱에서 Gemini API 키를 먼저 설정해주세요.',
        add_tooltip: '추가',
        edit_btn: '편집',
        edit_tooltip: '프롬프트 편집',
        clear_tooltip: '지우기',
        prompt_placeholder: '오디오 프롬프트 입력...',
        onboarding_title: '알림',
        onboarding_msg: 'Gemini 측 문제로 재생이 중단될 수 있으나, 녹음 시에는 무음 제거 기능이 있어 중단되지 않습니다.',
        onboarding_btn: '확인',
    }
};

export type Lang = keyof typeof LOCALES;
</file>

<file path="promptdj-midi/utils/MidiDispatcher.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
import type { ControlChange } from '../types';

/** Simple class for dispatching MIDI CC messages as events. */
export class MidiDispatcher extends EventTarget {
  private access: MIDIAccess | null = null;
  private denied: boolean = false;
  activeMidiInputId: string | null = null;

  /** Reset the MIDI state to allow retrying after denial */
  reset() {
    this.access = null;
    this.denied = false;
    this.activeMidiInputId = null;
  }

  async getMidiAccess(): Promise<string[]> {

    if (this.access) {
      return [...this.access.inputs.keys()];
    }

    if (!navigator.requestMIDIAccess) {
      throw new Error('Your browser does not support the Web MIDI API. For a list of compatible browsers, see https://caniuse.com/midi');
    }

    // If previously denied, give a more helpful message
    if (this.denied) {
      throw new Error('MIDI access was previously denied. Please restart the application to try again, or check that your MIDI device is connected.');
    }

    try {
      this.access = await navigator.requestMIDIAccess({ sysex: false });
      this.denied = false;
    } catch (e) {
      console.warn('MIDI Access refused or not available:', e);
      this.access = null;
      this.denied = true;
      throw new Error('MIDI access denied. Please connect a MIDI device and restart the application to try again.');
    }

    if (!this.access || !this.access.inputs) {
      this.denied = true;
      throw new Error('MIDI access unavailable. Please ensure a MIDI device is connected and restart the application.');
    }

    const inputIds = [...this.access.inputs.keys()];

    if (inputIds.length > 0 && this.activeMidiInputId === null) {
      this.activeMidiInputId = inputIds[0];
    }

    for (const input of this.access.inputs.values()) {
      input.onmidimessage = (event: MIDIMessageEvent) => {
        if (input.id !== this.activeMidiInputId) return;

        const { data } = event;
        if (!data) {
          console.error('MIDI message has no data');
          return;
        }

        const statusByte = data[0];
        const channel = statusByte & 0x0f;
        const messageType = statusByte & 0xf0;

        const isControlChange = messageType === 0xb0;
        if (!isControlChange) return;

        const detail: ControlChange = { cc: data[1], value: data[2], channel };
        this.dispatchEvent(
          new CustomEvent<ControlChange>('cc-message', { detail }),
        );
      };
    }

    return inputIds;
  }

  getDeviceName(id: string): string | null {
    if (!this.access) {
      return null;
    }
    const input = this.access.inputs.get(id);
    return input ? input.name : null;
  }
}
</file>

<file path="promptdj-midi/utils/throttle.ts">
/**
 * @license
 * SPDX-License-Identifier: Apache-2.0
*/
/**
 * Throttles a callback to be called at most once per `delay` milliseconds.
 * Also returns the result of the last "fresh" call...
 */
export function throttle<T extends (...args: Parameters<T>) => ReturnType<T>>(
  func: T,
  delay: number,
): (...args: Parameters<T>) => ReturnType<T> {
  let lastCall = -Infinity;
  let lastResult: ReturnType<T>;
  return (...args: Parameters<T>) => {
    const now = Date.now();
    const timeSinceLastCall = now - lastCall;
    if (timeSinceLastCall >= delay) {
      lastResult = func(...args);
      lastCall = now;
    }
    return lastResult;
  };
}
</file>

<file path="promptdj-midi/vite.config.ts">
import path from 'path';
import { defineConfig, loadEnv } from 'vite';


export default defineConfig(({ mode }) => {
  const env = loadEnv(mode, '.', '');
  return {
    server: {
      port: 3037,
      host: '0.0.0.0',
    },
    plugins: [],
    define: {
      'process.env.API_KEY': JSON.stringify(env.GEMINI_API_KEY),
      'process.env.GEMINI_API_KEY': JSON.stringify(env.GEMINI_API_KEY)
    },
    build: {
      rollupOptions: {
        output: {
          entryFileNames: `assets/[name].js`,
          chunkFileNames: `assets/[name].js`,
          assetFileNames: `assets/[name].[ext]`
        }
      }
    },
    resolve: {
      alias: {
        '@': path.resolve(__dirname, '.'),
      }
    }
  };
});
</file>

<file path="scripts/setup-egui-snarl.ps1">
# Setup script for patched egui-snarl
# This clones egui-snarl and patches it for scroll-to-zoom support

$snarlDir = Join-Path $PSScriptRoot "..\libs\egui-snarl"
$patchFile = Join-Path $PSScriptRoot "egui-snarl-scroll-zoom.patch"

# Check if already set up
if (Test-Path $snarlDir) {
    Write-Host "egui-snarl already exists at $snarlDir"
    Write-Host "To re-patch, delete the folder and run this script again."
    exit 0
}

# Clone egui-snarl (latest version)
Write-Host "Cloning egui-snarl..."
git clone --depth 1 https://github.com/zakarumych/egui-snarl.git $snarlDir

if (-not (Test-Path $snarlDir)) {
    Write-Error "Failed to clone egui-snarl"
    exit 1
}

# Apply the patch
Write-Host "Applying scroll-to-zoom patch..."

# Read the ui.rs file
$uiRsPath = Join-Path $snarlDir "src\ui.rs"
$content = Get-Content $uiRsPath -Raw

# The original code we're replacing (Scene::register_pan_and_zoom)
$originalCode = @"
    clamp_scale(&mut to_global, min_scale, max_scale, ui_rect);

    let mut snarl_resp = ui.response();
    Scene::new()
        .zoom_range(min_scale..=max_scale)
        .register_pan_and_zoom(&ui, &mut snarl_resp, &mut to_global);

    if snarl_resp.changed() {
        ui.ctx().request_repaint();
    }
"@

# The patched code (scroll-to-zoom without Ctrl + double-click reset + external reset trigger)
$patchedCode = @"
    clamp_scale(&mut to_global, min_scale, max_scale, ui_rect);

    let mut snarl_resp = ui.response();
    
    // CUSTOM SCROLL-TO-ZOOM: Instead of using Scene::register_pan_and_zoom which uses Ctrl+scroll for zoom,
    // we manually handle scroll as zoom directly (no Ctrl required)
    
    // Disable native double-click centering to prevent it from overriding our custom reset logic
    style.centering = Some(false);

    {
        let scroll_delta = ui.ctx().input(|i| i.raw_scroll_delta);
        let zoom_delta = ui.ctx().input(|i| i.zoom_delta());
        let pointer_in_canvas = ui.ctx().input(|i| {
            i.pointer.hover_pos().map(|pos| ui_rect.contains(pos)).unwrap_or(false)
        });
        
        // Check for external reset request (set by application code via egui context data)
        let reset_id = egui::Id::new("snarl_reset_view");
        let should_reset = ui.ctx().data_mut(|d| {
            let reset = d.get_temp::<bool>(reset_id).unwrap_or(false);
            if reset {
                d.insert_temp(reset_id, false); // Clear the flag
            }
            reset
        });
        
        // Reset view on double-click OR external reset request
        let double_clicked = snarl_resp.double_clicked();
        if (double_clicked && pointer_in_canvas) || should_reset {
            to_global.scaling = 1.0;
            
            // "Fit View" - Center the nodes in the viewport
            let mut min_pos = egui::pos2(f32::INFINITY, f32::INFINITY);
            let mut max_pos = egui::pos2(f32::NEG_INFINITY, f32::NEG_INFINITY);
            let mut has_nodes = false;
            
            for (pos, _) in snarl.nodes_pos() {
                has_nodes = true;
                if pos.x < min_pos.x { min_pos.x = pos.x; }
                if pos.y < min_pos.y { min_pos.y = pos.y; }
                
                // Assume generic node size approx 200x150 for centering
                let right = pos.x + 200.0;
                let bottom = pos.y + 150.0;
                
                if right > max_pos.x { max_pos.x = right; }
                if bottom > max_pos.y { max_pos.y = bottom; }
            }
            
            if has_nodes {
                 let graph_center = min_pos.lerp(max_pos, 0.5);
                 // Center the graph content
                 to_global.translation = ui_rect.center().to_vec2() - graph_center.to_vec2();
            } else {
                 // Fallback if no nodes (center origin logic)
                 to_global.translation = ui_rect.center().to_vec2();
            }
            
            snarl_resp.mark_changed();
        }
        
        // Check if any popup is open (ComboBox dropdowns, context menus, etc.)
        // If a popup is open, we should NOT capture scroll, let the popup handle it
        let any_popup_open = egui::Popup::is_any_open(ui.ctx());
        
        // Check if pointer is over a higher layer (Modal windows, Panels, etc.)
        // Only capture scroll if the pointer is on the Background layer (the canvas itself)
        let pointer_on_foreground = if let Some(pos) = ui.ctx().input(|i| i.pointer.hover_pos()) {
            if let Some(layer_id) = ui.ctx().layer_id_at(pos) {
                // Background order is 0, anything higher means a window/panel/modal is above
                layer_id.order != egui::Order::Background && layer_id.order != egui::Order::Middle
            } else {
                false
            }
        } else {
            false
        };
        
        // Handle scroll wheel as zoom (not pan) - works anywhere in the canvas, including over nodes
        // BUT skip if a popup is open OR pointer is over a modal/window so they can scroll properly
        if scroll_delta.y.abs() > 0.1 && pointer_in_canvas && !any_popup_open && !pointer_on_foreground {
            let zoom_factor = if scroll_delta.y > 0.0 { 1.1 } else { 0.9 };
            let pointer_pos = ui.ctx().input(|i| i.pointer.hover_pos()).unwrap_or(ui_rect.center());
            
            // Apply zoom centered on pointer position
            let new_scale = (to_global.scaling * zoom_factor).clamp(min_scale, max_scale);
            if new_scale != to_global.scaling {
                // Zoom towards the pointer: adjust translation so pointer stays at same graph position
                let scale_ratio = new_scale / to_global.scaling;
                to_global.translation = pointer_pos.to_vec2() + (to_global.translation - pointer_pos.to_vec2()) * scale_ratio;
                to_global.scaling = new_scale;
                snarl_resp.mark_changed();
            }
        }
        
        // Also handle pinch zoom gestures (zoom_delta from touch)
        if zoom_delta != 1.0 && pointer_in_canvas {
            let pointer_pos = ui.ctx().input(|i| i.pointer.hover_pos()).unwrap_or(ui_rect.center());
            let new_scale = (to_global.scaling * zoom_delta).clamp(min_scale, max_scale);
            if new_scale != to_global.scaling {
                let scale_ratio = new_scale / to_global.scaling;
                to_global.translation = pointer_pos.to_vec2() + (to_global.translation - pointer_pos.to_vec2()) * scale_ratio;
                to_global.scaling = new_scale;
                snarl_resp.mark_changed();
            }
        }
        
        // Handle drag for panning (left mouse button, middle mouse button, or right mouse button)
        if snarl_resp.dragged_by(PointerButton::Primary) || snarl_resp.dragged_by(PointerButton::Middle) || snarl_resp.dragged_by(PointerButton::Secondary) {
            to_global.translation += snarl_resp.drag_delta();
            snarl_resp.mark_changed();
        }
    }

    if snarl_resp.changed() {
        ui.ctx().request_repaint();
    }
"@

# Replace the code
$newContent = $content -replace [regex]::Escape($originalCode), $patchedCode

if ($newContent -eq $content) {
    Write-Warning "Could not find the exact code to patch. egui-snarl may have updated."
    Write-Warning "Please check libs/egui-snarl/src/ui.rs manually around line 989."
    exit 1
}

# Also remove unused Scene import to avoid warning
$newContent = $newContent -replace "Pos2, Rect, Scene, Sense,", "Pos2, Rect, Sense,"

# Write the patched file
Set-Content -Path $uiRsPath -Value $newContent -NoNewline

Write-Host "Patch applied successfully!"
Write-Host "egui-snarl is ready at: $snarlDir"
</file>

<file path="src/api/audio.rs">
use super::client::UREQ_AGENT;
use crate::config::Preset;
use crate::model_config::{get_model_by_id, model_is_non_llm};
use crate::overlay::result::{
    create_result_window, get_chain_color, update_window_text, RefineContext, WindowType,
};
use crate::win_types::SendHwnd;
use crate::APP;
use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use std::io::{BufRead, BufReader, Cursor};
use std::sync::{
    atomic::{AtomicBool, Ordering},
    mpsc, Arc,
};
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;

fn encode_wav(samples: &[i16], sample_rate: u32, channels: u16) -> Vec<u8> {
    let spec = hound::WavSpec {
        channels,
        sample_rate,
        bits_per_sample: 16,
        sample_format: hound::SampleFormat::Int,
    };
    let mut wav_cursor = Cursor::new(Vec::new());
    {
        let mut writer =
            hound::WavWriter::new(&mut wav_cursor, spec).expect("Failed to create memory writer");
        for sample in samples {
            writer
                .write_sample(*sample)
                .expect("Failed to write sample");
        }
        writer.finalize().expect("Failed to finalize WAV");
    }
    wav_cursor.into_inner()
}

pub fn transcribe_audio_gemini<F>(
    gemini_api_key: &str,
    prompt: String,
    model: String,
    wav_data: Vec<u8>,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(&str),
{
    if gemini_api_key.trim().is_empty() {
        return Err(anyhow::anyhow!("NO_API_KEY:google"));
    }

    let b64_audio = general_purpose::STANDARD.encode(&wav_data);
    let url = format!(
        "https://generativelanguage.googleapis.com/v1beta/models/{}:streamGenerateContent?alt=sse",
        model
    );

    let mut payload = serde_json::json!({
        "contents": [{
            "role": "user",
            "parts": [
                { "text": prompt },
                {
                    "inline_data": {
                        "mime_type": "audio/wav",
                        "data": b64_audio
                    }
                }
            ]
        }]
    });

    // Add grounding tools for all models except gemma-3-27b-it
    if !model.contains("gemma-3-27b-it") {
        payload["tools"] = serde_json::json!([
            { "url_context": {} },
            { "google_search": {} }
        ]);
    }

    let resp = UREQ_AGENT
        .post(&url)
        .header("x-goog-api-key", gemini_api_key)
        .send_json(payload)
        .map_err(|e| {
            let err_str = e.to_string();
            if err_str.contains("401") || err_str.contains("403") {
                anyhow::anyhow!("INVALID_API_KEY")
            } else {
                anyhow::anyhow!("Gemini Audio API Error: {}", err_str)
            }
        })?;

    let mut full_content = String::new();
    let reader = BufReader::new(resp.into_body().into_reader());

    for line in reader.lines() {
        let line = line.map_err(|e| anyhow::anyhow!("Failed to read line: {}", e))?;
        if line.starts_with("data: ") {
            let json_str = &line["data: ".len()..];
            if json_str.trim() == "[DONE]" {
                break;
            }

            if let Ok(chunk_resp) = serde_json::from_str::<serde_json::Value>(json_str) {
                if let Some(candidates) = chunk_resp.get("candidates").and_then(|c| c.as_array()) {
                    if let Some(first_candidate) = candidates.first() {
                        if let Some(parts) = first_candidate
                            .get("content")
                            .and_then(|c| c.get("parts"))
                            .and_then(|p| p.as_array())
                        {
                            if let Some(first_part) = parts.first() {
                                if let Some(text) = first_part.get("text").and_then(|t| t.as_str())
                                {
                                    full_content.push_str(text);
                                    on_chunk(text);
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    if full_content.is_empty() {
        return Err(anyhow::anyhow!("No content received from Gemini Audio API"));
    }

    Ok(full_content)
}

/// Transcribe audio using Gemini Live WebSocket with INPUT transcription
/// (transcribes what was recorded, not AI response)
fn transcribe_with_gemini_live_input(api_key: &str, wav_data: Vec<u8>) -> anyhow::Result<String> {
    use crate::api::realtime_audio::websocket::{
        connect_websocket, parse_input_transcription, send_audio_chunk, send_setup_message,
        set_socket_nonblocking, set_socket_short_timeout,
    };
    use crate::overlay::recording::AUDIO_INITIALIZING;
    use std::time::{Duration, Instant};

    println!(
        "[GeminiLiveInput] Starting transcription, WAV data size: {} bytes",
        wav_data.len()
    );

    // Signal that we're initializing (WebSocket connection)
    AUDIO_INITIALIZING.store(true, Ordering::SeqCst);

    // Connect and setup WebSocket
    println!("[GeminiLiveInput] Connecting to WebSocket...");
    let mut socket = match connect_websocket(api_key) {
        Ok(s) => {
            println!("[GeminiLiveInput] WebSocket connected successfully");
            s
        }
        Err(e) => {
            println!("[GeminiLiveInput] WebSocket connection failed: {}", e);
            AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
            return Err(e);
        }
    };

    println!("[GeminiLiveInput] Sending setup message...");
    if let Err(e) = send_setup_message(&mut socket) {
        println!("[GeminiLiveInput] Setup message failed: {}", e);
        AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
        return Err(e);
    }

    // Set short timeout for setup phase
    if let Err(e) = set_socket_short_timeout(&mut socket) {
        AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
        return Err(e);
    }

    // Wait for setup complete
    println!("[GeminiLiveInput] Waiting for setupComplete...");
    let setup_start = Instant::now();
    loop {
        match socket.read() {
            Ok(tungstenite::Message::Text(msg)) => {
                let msg = msg.as_str();
                println!(
                    "[GeminiLiveInput] Received text message: {}",
                    &msg[..msg.len().min(200)]
                );
                if msg.contains("setupComplete") {
                    println!("[GeminiLiveInput] Setup complete received!");
                    break;
                }
                if msg.contains("error") || msg.contains("Error") {
                    println!("[GeminiLiveInput] Server error: {}", msg);
                    AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
                    return Err(anyhow::anyhow!("Server returned error: {}", msg));
                }
            }
            Ok(tungstenite::Message::Binary(data)) => {
                println!(
                    "[GeminiLiveInput] Received binary message: {} bytes",
                    data.len()
                );
                if let Ok(text) = String::from_utf8(data.to_vec()) {
                    if text.contains("setupComplete") {
                        println!("[GeminiLiveInput] Setup complete (from binary)!");
                        break;
                    }
                }
            }
            Ok(other) => {
                println!("[GeminiLiveInput] Received other message type: {:?}", other);
            }
            Err(tungstenite::Error::Io(ref e))
                if e.kind() == std::io::ErrorKind::WouldBlock
                    || e.kind() == std::io::ErrorKind::TimedOut =>
            {
                if setup_start.elapsed() > Duration::from_secs(30) {
                    println!("[GeminiLiveInput] Setup timeout after 30s");
                    AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
                    return Err(anyhow::anyhow!("Setup timeout"));
                }
                std::thread::sleep(Duration::from_millis(50));
            }
            Err(e) => {
                println!("[GeminiLiveInput] Socket error during setup: {}", e);
                AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
                return Err(e.into());
            }
        }
    }

    // Setup complete - switch to non-blocking mode and clear initializing state
    if let Err(e) = set_socket_nonblocking(&mut socket) {
        AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
        return Err(e);
    }
    AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
    // Now signal warmup complete so UI shows recording state
    crate::overlay::recording::AUDIO_WARMUP_COMPLETE.store(true, Ordering::SeqCst);

    // Extract PCM samples from WAV data
    println!("[GeminiLiveInput] Extracting PCM samples from WAV...");
    let pcm_samples = extract_pcm_from_wav(&wav_data)?;
    println!(
        "[GeminiLiveInput] Extracted {} PCM samples",
        pcm_samples.len()
    );

    // Send audio in chunks (16kHz, 100ms chunks = 1600 samples)
    let chunk_size = 1600;
    let mut accumulated_text = String::new();
    let mut offset = 0;
    let mut chunks_sent = 0;
    let mut transcripts_received = 0;

    println!("[GeminiLiveInput] Sending audio chunks...");
    while offset < pcm_samples.len() {
        let end = (offset + chunk_size).min(pcm_samples.len());
        let chunk = &pcm_samples[offset..end];

        if send_audio_chunk(&mut socket, chunk).is_err() {
            println!(
                "[GeminiLiveInput] Failed to send audio chunk at offset {}",
                offset
            );
            break;
        }
        chunks_sent += 1;
        offset = end;

        // Read any available transcriptions
        loop {
            match socket.read() {
                Ok(tungstenite::Message::Text(msg)) => {
                    let msg = msg.as_str();
                    println!(
                        "[GeminiLiveInput] Message while sending: {}",
                        &msg[..msg.len().min(300)]
                    );
                    if let Some(transcript) = parse_input_transcription(msg) {
                        if !transcript.is_empty() {
                            println!("[GeminiLiveInput] Got transcript: '{}'", transcript);
                            transcripts_received += 1;
                            accumulated_text.push_str(&transcript);
                        }
                    }
                }
                Ok(tungstenite::Message::Binary(data)) => {
                    if let Ok(text) = String::from_utf8(data.to_vec()) {
                        if let Some(transcript) = parse_input_transcription(&text) {
                            if !transcript.is_empty() {
                                println!(
                                    "[GeminiLiveInput] Got transcript (binary): '{}'",
                                    transcript
                                );
                                transcripts_received += 1;
                                accumulated_text.push_str(&transcript);
                            }
                        }
                    }
                }
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock
                        || e.kind() == std::io::ErrorKind::TimedOut =>
                {
                    break; // No more messages available, continue sending
                }
                Err(_) => break,
            }
        }

        // Small delay between chunks to not overwhelm the connection
        std::thread::sleep(Duration::from_millis(10));
    }

    println!(
        "[GeminiLiveInput] Sent {} chunks, waiting 2s for final transcriptions...",
        chunks_sent
    );

    // Wait 2 seconds after sending all audio for final transcriptions
    let conclude_start = Instant::now();
    let conclude_duration = Duration::from_secs(2);

    while conclude_start.elapsed() < conclude_duration {
        match socket.read() {
            Ok(tungstenite::Message::Text(msg)) => {
                let msg = msg.as_str();
                println!(
                    "[GeminiLiveInput] Message in conclude phase: {}",
                    &msg[..msg.len().min(300)]
                );
                if let Some(transcript) = parse_input_transcription(msg) {
                    if !transcript.is_empty() {
                        println!("[GeminiLiveInput] Got final transcript: '{}'", transcript);
                        transcripts_received += 1;
                        accumulated_text.push_str(&transcript);
                    }
                }
            }
            Ok(tungstenite::Message::Binary(data)) => {
                if let Ok(text) = String::from_utf8(data.to_vec()) {
                    if let Some(transcript) = parse_input_transcription(&text) {
                        if !transcript.is_empty() {
                            println!(
                                "[GeminiLiveInput] Got final transcript (binary): '{}'",
                                transcript
                            );
                            transcripts_received += 1;
                            accumulated_text.push_str(&transcript);
                        }
                    }
                }
            }
            Ok(_) => {}
            Err(tungstenite::Error::Io(ref e))
                if e.kind() == std::io::ErrorKind::WouldBlock
                    || e.kind() == std::io::ErrorKind::TimedOut =>
            {
                std::thread::sleep(Duration::from_millis(50));
            }
            Err(_) => break,
        }
    }

    let _ = socket.close(None);

    println!(
        "[GeminiLiveInput] Done! Transcripts received: {}, Total text length: {}",
        transcripts_received,
        accumulated_text.len()
    );
    println!("[GeminiLiveInput] Final result: '{}'", accumulated_text);

    if accumulated_text.is_empty() {
        // This is actually okay - could be silence or inaudible
        Ok(String::new())
    } else {
        Ok(accumulated_text)
    }
}

/// Extract PCM i16 samples from WAV data
fn extract_pcm_from_wav(wav_data: &[u8]) -> anyhow::Result<Vec<i16>> {
    use std::io::Cursor;

    let cursor = Cursor::new(wav_data);
    let reader = hound::WavReader::new(cursor)?;
    let spec = reader.spec();

    // Get samples based on format
    let samples: Vec<i16> = match spec.sample_format {
        hound::SampleFormat::Int => reader
            .into_samples::<i16>()
            .filter_map(|s| s.ok())
            .collect(),
        hound::SampleFormat::Float => reader
            .into_samples::<f32>()
            .filter_map(|s| s.ok())
            .map(|f| (f * i16::MAX as f32) as i16)
            .collect(),
    };

    // Convert to mono 16kHz if needed
    let mono_samples: Vec<i16> = if spec.channels > 1 {
        samples
            .chunks(spec.channels as usize)
            .map(|chunk| {
                let sum: i32 = chunk.iter().map(|&s| s as i32).sum();
                (sum / chunk.len() as i32) as i16
            })
            .collect()
    } else {
        samples
    };

    // Resample to 16kHz if needed
    let target_rate = 16000;
    if spec.sample_rate != target_rate {
        let ratio = target_rate as f64 / spec.sample_rate as f64;
        let new_len = (mono_samples.len() as f64 * ratio) as usize;
        let mut resampled = Vec::with_capacity(new_len);

        for i in 0..new_len {
            let src_idx = (i as f64 / ratio) as usize;
            if src_idx < mono_samples.len() {
                resampled.push(mono_samples[src_idx]);
            }
        }
        Ok(resampled)
    } else {
        Ok(mono_samples)
    }
}

/// Simple nearest-neighbor resampling to 16kHz
fn resample_to_16khz(samples: &[i16], source_rate: u32) -> Vec<i16> {
    if source_rate == 16000 {
        return samples.to_vec();
    }
    let ratio = 16000.0 / source_rate as f64;
    let new_len = (samples.len() as f64 * ratio) as usize;
    let mut resampled = Vec::with_capacity(new_len);
    for i in 0..new_len {
        let src_idx = (i as f64 / ratio) as usize;
        if src_idx < samples.len() {
            resampled.push(samples[src_idx]);
        }
    }
    resampled
}

#[derive(Clone, Copy, PartialEq)]
enum AudioMode {
    Normal,
    Silence,
    CatchUp,
}

fn try_reconnect(
    socket: &mut tungstenite::WebSocket<native_tls::TlsStream<std::net::TcpStream>>,
    api_key: &str,
    audio_buffer: &Arc<std::sync::Mutex<Vec<i16>>>,
    silence_buffer: &mut Vec<i16>,
    audio_mode: &mut AudioMode,
    mode_start: &mut std::time::Instant,
    last_transcription_time: &mut std::time::Instant,
    consecutive_empty_reads: &mut u32,
    stop_signal: &Arc<std::sync::atomic::AtomicBool>,
) -> bool {
    use crate::api::realtime_audio::websocket::{
        connect_websocket, send_setup_message, set_socket_nonblocking,
    };
    use std::sync::atomic::Ordering;
    use std::time::{Duration, Instant};

    let mut reconnect_buffer: Vec<i16> = Vec::new();
    let _ = socket.close(None);

    // Retry indefinitely until success or user stop
    loop {
        // Check if user stopped the recording while we were trying to reconnect
        if stop_signal.load(Ordering::Relaxed) {
            println!("[GeminiLiveStream] Stop signal received during reconnection.");
            return false;
        }

        {
            let mut buf = audio_buffer.lock().unwrap();
            reconnect_buffer.extend(std::mem::take(&mut *buf));
        }

        match connect_websocket(api_key) {
            Ok(mut new_socket) => {
                if send_setup_message(&mut new_socket).is_err() {
                    std::thread::sleep(Duration::from_millis(500));
                    continue;
                }
                if set_socket_nonblocking(&mut new_socket).is_err() {
                    let _ = new_socket.close(None);
                    std::thread::sleep(Duration::from_millis(500));
                    continue;
                }

                // Final flush of buffer before resuming
                {
                    let mut buf = audio_buffer.lock().unwrap();
                    reconnect_buffer.extend(std::mem::take(&mut *buf));
                }

                silence_buffer.clear();
                silence_buffer.extend(reconnect_buffer);
                *audio_mode = AudioMode::CatchUp;
                *mode_start = Instant::now();
                *socket = new_socket;
                *last_transcription_time = Instant::now();
                *consecutive_empty_reads = 0;

                return true;
            }
            Err(e) => {
                println!(
                    "[GeminiLiveStream] Reconnection failed: {}. Retrying in 1s...",
                    e
                );
                std::thread::sleep(Duration::from_secs(1));
            }
        }
    }
}

/// Real-time record and stream to Gemini Live WebSocket
/// Connects WebSocket FIRST, then streams audio in real-time during recording
pub fn record_and_stream_gemini_live(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
    abort_signal: Arc<AtomicBool>,
    overlay_hwnd: HWND,
    _target_window: Option<HWND>,
) {
    use crate::api::realtime_audio::websocket::{
        connect_websocket, parse_input_transcription, send_audio_chunk, send_setup_message,
        set_socket_nonblocking, set_socket_short_timeout,
    };
    use crate::overlay::recording::AUDIO_INITIALIZING;
    use std::sync::Mutex;
    use std::time::{Duration, Instant};

    println!("[GeminiLiveStream] Starting real-time streaming...");

    // Check if streaming is enabled
    // Enable if explicit flag is set OR render_mode is "stream"
    // Find the relevant audio block for streaming settings
    let audio_block = preset
        .blocks
        .iter()
        .find(|b| b.block_type == "audio")
        .or_else(|| preset.blocks.first());

    let streaming_enabled = audio_block
        .map(|b| {
            b.show_overlay
                && (b.streaming_enabled || b.render_mode == "stream")
                && b.render_mode != "plain"
        })
        .unwrap_or(false);
    let mut streaming_hwnd: Option<HWND> = None;

    struct WindowGuard(HWND);
    impl Drop for WindowGuard {
        fn drop(&mut self) {
            unsafe {
                let _ = PostMessageW(Some(self.0), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
    }

    // Launch Result Overlay if streaming is enabled
    if streaming_enabled {
        let (tx, rx) = mpsc::channel();
        let preset_for_thread = preset.clone();

        std::thread::spawn(move || {
            let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
            let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };
            let (rect, _) = if preset_for_thread.blocks.len() > 1 {
                let w = 600;
                let h = 300;
                let gap = 20;
                let total = w * 2 + gap;
                let x = (screen_w - total) / 2;
                let y = (screen_h - h) / 2;
                (
                    RECT {
                        left: x,
                        top: y,
                        right: x + w,
                        bottom: y + h,
                    },
                    Some(RECT {
                        left: x + w + gap,
                        top: y,
                        right: x + w + gap + w,
                        bottom: y + h,
                    }),
                )
            } else {
                let w = 700;
                let h = 300;
                let x = (screen_w - w) / 2;
                let y = (screen_h - h) / 2;
                (
                    RECT {
                        left: x,
                        top: y,
                        right: x + w,
                        bottom: y + h,
                    },
                    None,
                )
            };

            let active_block = preset_for_thread
                .blocks
                .iter()
                .find(|b| b.block_type == "audio")
                .or_else(|| preset_for_thread.blocks.first());

            let model_id = active_block.map(|b| b.model.clone()).unwrap_or_default();
            let render_mode = active_block
                .map(|b| b.render_mode.clone())
                .unwrap_or_default();

            // Get provider
            let model_conf = crate::model_config::get_model_by_id(&model_id);
            let provider = model_conf
                .map(|m| m.provider)
                .unwrap_or("gemini".to_string());

            let hwnd = create_result_window(
                rect,
                WindowType::Primary,
                RefineContext::Audio(Vec::new()), // Audio context placeholder
                model_id,
                provider,
                true,          // streaming_enabled
                false,         // start_editing
                String::new(), // preset_prompt
                get_chain_color(0),
                &render_mode,
                "Listening...".to_string(),
            );

            unsafe {
                let _ = ShowWindow(hwnd, SW_SHOW);
            }

            let _ = tx.send(SendHwnd(hwnd));

            // Message Loop
            unsafe {
                let mut m = MSG::default();
                while GetMessageW(&mut m, None, 0, 0).into() {
                    let _ = TranslateMessage(&m);
                    DispatchMessageW(&m);
                    if !IsWindow(Some(hwnd)).as_bool() {
                        break;
                    }
                }
            }
        });

        if let Ok(SendHwnd(h)) = rx.recv() {
            streaming_hwnd = Some(h);
        }
    }

    let _window_guard = streaming_hwnd.map(WindowGuard);

    let update_stream_text = |text: &str| {
        if let Some(h) = streaming_hwnd {
            update_window_text(h, text);
        }
    };

    let gemini_api_key = {
        let app = APP.lock().unwrap();
        app.config.gemini_api_key.clone()
    };

    if gemini_api_key.trim().is_empty() {
        eprintln!("[GeminiLiveStream] No API key");
        unsafe {
            let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
        return;
    }

    // Connect WebSocket (Initializing state)
    AUDIO_INITIALIZING.store(true, Ordering::SeqCst);
    println!("[GeminiLiveStream] Connecting WebSocket...");

    let mut socket = match connect_websocket(&gemini_api_key) {
        Ok(s) => {
            println!("[GeminiLiveStream] Connected");
            s
        }
        Err(e) => {
            println!("[GeminiLiveStream] Connection failed: {}", e);
            AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
            unsafe {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
            return;
        }
    };

    if let Err(e) = send_setup_message(&mut socket) {
        println!("[GeminiLiveStream] Setup failed: {}", e);
        AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
        unsafe {
            let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
        return;
    }

    let _ = set_socket_short_timeout(&mut socket);

    // Wait for setupComplete
    let setup_start = Instant::now();
    loop {
        match socket.read() {
            Ok(tungstenite::Message::Text(msg)) => {
                if msg.as_str().contains("setupComplete") {
                    break;
                }
            }
            Ok(tungstenite::Message::Binary(data)) => {
                if String::from_utf8(data.to_vec())
                    .map(|t| t.contains("setupComplete"))
                    .unwrap_or(false)
                {
                    break;
                }
            }
            Ok(_) => {}
            Err(tungstenite::Error::Io(ref e))
                if e.kind() == std::io::ErrorKind::WouldBlock
                    || e.kind() == std::io::ErrorKind::TimedOut =>
            {
                if setup_start.elapsed() > Duration::from_secs(30) {
                    AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
                    unsafe {
                        let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                    return;
                }
                std::thread::sleep(Duration::from_millis(50));
            }
            Err(_) => {
                AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
                unsafe {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
                return;
            }
        }
    }

    let _ = set_socket_nonblocking(&mut socket);
    AUDIO_INITIALIZING.store(false, Ordering::SeqCst);
    crate::overlay::recording::AUDIO_WARMUP_COMPLETE.store(true, Ordering::SeqCst);
    println!("[GeminiLiveStream] Setup complete, starting audio...");

    // Start audio capture
    #[cfg(target_os = "windows")]
    let host = if preset.audio_source == "device" {
        cpal::host_from_id(cpal::HostId::Wasapi).unwrap_or(cpal::default_host())
    } else {
        cpal::default_host()
    };
    #[cfg(not(target_os = "windows"))]
    let host = cpal::default_host();

    let device = if preset.audio_source == "device" {
        match host.default_output_device() {
            Some(d) => d,
            None => {
                let _ = socket.close(None);
                unsafe {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
                return;
            }
        }
    } else {
        match host.default_input_device() {
            Some(d) => d,
            None => {
                let _ = socket.close(None);
                unsafe {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
                return;
            }
        }
    };

    let config = if preset.audio_source == "device" {
        device
            .default_output_config()
            .or_else(|_| device.default_input_config())
    } else {
        device.default_input_config()
    };
    let config = match config {
        Ok(c) => c,
        Err(_) => {
            let _ = socket.close(None);
            unsafe {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
            return;
        }
    };

    let sample_rate = config.sample_rate();
    let channels = config.channels() as usize;
    let audio_buffer: Arc<Mutex<Vec<i16>>> = Arc::new(Mutex::new(Vec::new()));
    let full_audio_buffer: Arc<Mutex<Vec<i16>>> = Arc::new(Mutex::new(Vec::new()));
    let accumulated_text: Arc<Mutex<String>> = Arc::new(Mutex::new(String::new()));
    let audio_buffer_clone = audio_buffer.clone();
    let full_buffer_clone = full_audio_buffer.clone();
    let pause_clone = pause_signal.clone();

    let stream = match config.sample_format() {
        cpal::SampleFormat::F32 => device.build_input_stream(
            &config.into(),
            move |data: &[f32], _: &_| {
                if pause_clone.load(Ordering::Relaxed) {
                    return;
                }
                let mut rms = 0.0;
                for &x in data {
                    rms += x * x;
                }
                rms = (rms / data.len() as f32).sqrt();
                crate::overlay::recording::update_audio_viz(rms);
                let mono: Vec<i16> = if channels > 1 {
                    data.chunks(channels)
                        .map(|c| {
                            ((c.iter().sum::<f32>() / channels as f32) * i16::MAX as f32) as i16
                        })
                        .collect()
                } else {
                    data.iter().map(|&f| (f * i16::MAX as f32) as i16).collect()
                };
                let resampled = resample_to_16khz(&mono, sample_rate);
                if let Ok(mut buf) = audio_buffer_clone.lock() {
                    buf.extend(resampled.clone());
                }
                if let Ok(mut full) = full_buffer_clone.lock() {
                    full.extend(resampled);
                }
            },
            |e| eprintln!("Stream error: {}", e),
            None,
        ),
        cpal::SampleFormat::I16 => device.build_input_stream(
            &config.into(),
            move |data: &[i16], _: &_| {
                if pause_clone.load(Ordering::Relaxed) {
                    return;
                }
                let mut rms = 0.0;
                for &x in data {
                    let f = x as f32 / i16::MAX as f32;
                    rms += f * f;
                }
                rms = (rms / data.len() as f32).sqrt();
                crate::overlay::recording::update_audio_viz(rms);
                let mono: Vec<i16> = if channels > 1 {
                    data.chunks(channels)
                        .map(|c| (c.iter().map(|&s| s as i32).sum::<i32>() / c.len() as i32) as i16)
                        .collect()
                } else {
                    data.to_vec()
                };
                let resampled = resample_to_16khz(&mono, sample_rate);
                if let Ok(mut buf) = audio_buffer_clone.lock() {
                    buf.extend(resampled.clone());
                }
                if let Ok(mut full) = full_buffer_clone.lock() {
                    full.extend(resampled);
                }
            },
            |e| eprintln!("Stream error: {}", e),
            None,
        ),
        _ => {
            let _ = socket.close(None);
            unsafe {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
            return;
        }
    };

    let stream = match stream {
        Ok(s) => s,
        Err(_) => {
            let _ = socket.close(None);
            unsafe {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
            return;
        }
    };
    if stream.play().is_err() {
        let _ = socket.close(None);
        unsafe {
            let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
        return;
    }

    println!("[GeminiLiveStream] Streaming audio...");
    let chunk_size = 1600;
    let mut last_send = Instant::now();
    let send_interval = Duration::from_millis(100);
    let auto_stop = preset.auto_stop_recording;
    let mut has_spoken = false;
    let mut first_speech: Option<Instant> = None;
    let mut last_active = Instant::now();

    // Reconnection & CatchUp state
    let mut audio_mode = AudioMode::Normal;
    let mut mode_start = Instant::now();
    let mut silence_buffer: Vec<i16> = Vec::new();
    let mut last_transcription_time = Instant::now();
    let mut consecutive_empty_reads: u32 = 0;

    const NORMAL_DURATION: Duration = Duration::from_secs(20);
    const SILENCE_DURATION: Duration = Duration::from_secs(2);
    const SAMPLES_PER_100MS: usize = 1600;
    const NO_RESULT_THRESHOLD_SECS: u64 = 8;
    const EMPTY_READ_CHECK_COUNT: u32 = 50;

    while !stop_signal.load(Ordering::SeqCst) && !abort_signal.load(Ordering::SeqCst) {
        if !preset.hide_recording_ui && !unsafe { IsWindow(Some(overlay_hwnd)).as_bool() } {
            break;
        }

        // State machine transitions
        match audio_mode {
            AudioMode::Normal => {
                if mode_start.elapsed() >= NORMAL_DURATION {
                    audio_mode = AudioMode::Silence;
                    mode_start = Instant::now();
                    silence_buffer.clear();
                }
            }
            AudioMode::Silence => {
                if mode_start.elapsed() >= SILENCE_DURATION {
                    audio_mode = AudioMode::CatchUp;
                    mode_start = Instant::now();
                }
            }
            AudioMode::CatchUp => {
                if silence_buffer.is_empty() {
                    audio_mode = AudioMode::Normal;
                    mode_start = Instant::now();
                }
            }
        }

        if last_send.elapsed() >= send_interval {
            let real_audio: Vec<i16> = {
                let mut buf = audio_buffer.lock().unwrap();
                std::mem::take(&mut *buf)
            };

            match audio_mode {
                AudioMode::Normal => {
                    if !real_audio.is_empty() && !pause_signal.load(Ordering::Relaxed) {
                        for chunk in real_audio.chunks(chunk_size) {
                            if send_audio_chunk(&mut socket, chunk).is_err() {
                                break;
                            }
                        }
                    }
                }
                AudioMode::Silence => {
                    silence_buffer.extend(real_audio);
                    let silence: Vec<i16> = vec![0i16; SAMPLES_PER_100MS];
                    if send_audio_chunk(&mut socket, &silence).is_err() {
                        break;
                    }
                }
                AudioMode::CatchUp => {
                    silence_buffer.extend(real_audio);
                    let double_chunk = SAMPLES_PER_100MS * 2;
                    let to_send: Vec<i16> = if silence_buffer.len() >= double_chunk {
                        silence_buffer.drain(..double_chunk).collect()
                    } else if !silence_buffer.is_empty() {
                        silence_buffer.drain(..).collect()
                    } else {
                        Vec::new()
                    };
                    if !to_send.is_empty() {
                        if send_audio_chunk(&mut socket, &to_send).is_err() {
                            break;
                        }
                    }
                }
            }
            last_send = Instant::now();
        }

        // Read transcriptions
        loop {
            match socket.read() {
                Ok(tungstenite::Message::Text(msg)) => {
                    if let Some(t) = parse_input_transcription(msg.as_str()) {
                        if !t.is_empty() {
                            last_transcription_time = Instant::now();
                            consecutive_empty_reads = 0;
                            if let Ok(mut txt) = accumulated_text.lock() {
                                txt.push_str(&t);
                                update_stream_text(&txt);
                            }
                            if preset.auto_paste {
                                crate::overlay::utils::type_text_to_window(None, &t);
                            }
                        }
                    }
                }
                Ok(tungstenite::Message::Binary(data)) => {
                    if let Ok(s) = String::from_utf8(data.to_vec()) {
                        if let Some(t) = parse_input_transcription(&s) {
                            if !t.is_empty() {
                                last_transcription_time = Instant::now();
                                consecutive_empty_reads = 0;
                                if let Ok(mut txt) = accumulated_text.lock() {
                                    txt.push_str(&t);
                                    update_stream_text(&txt);
                                }
                                if preset.auto_paste {
                                    crate::overlay::utils::type_text_to_window(None, &t);
                                }
                            }
                        }
                    }
                }
                Ok(tungstenite::Message::Close(_)) => {
                    if !try_reconnect(
                        &mut socket,
                        &gemini_api_key,
                        &audio_buffer,
                        &mut silence_buffer,
                        &mut audio_mode,
                        &mut mode_start,
                        &mut last_transcription_time,
                        &mut consecutive_empty_reads,
                        &stop_signal,
                    ) {
                        break;
                    }
                }
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock
                        || e.kind() == std::io::ErrorKind::TimedOut =>
                {
                    consecutive_empty_reads += 1;
                    if consecutive_empty_reads >= EMPTY_READ_CHECK_COUNT
                        && last_transcription_time.elapsed()
                            > Duration::from_secs(NO_RESULT_THRESHOLD_SECS)
                    {
                        if !try_reconnect(
                            &mut socket,
                            &gemini_api_key,
                            &audio_buffer,
                            &mut silence_buffer,
                            &mut audio_mode,
                            &mut mode_start,
                            &mut last_transcription_time,
                            &mut consecutive_empty_reads,
                            &stop_signal,
                        ) {
                            break;
                        }
                    }
                    break;
                }
                Err(e) => {
                    let error_str = e.to_string();
                    if error_str.contains("reset")
                        || error_str.contains("closed")
                        || error_str.contains("broken")
                    {
                        if !try_reconnect(
                            &mut socket,
                            &gemini_api_key,
                            &audio_buffer,
                            &mut silence_buffer,
                            &mut audio_mode,
                            &mut mode_start,
                            &mut last_transcription_time,
                            &mut consecutive_empty_reads,
                            &stop_signal,
                        ) {
                            break;
                        }
                    } else {
                        break;
                    }
                }
            }
        }

        // Auto-stop: only active if not paused
        if auto_stop && !pause_signal.load(Ordering::Relaxed) {
            let rms =
                f32::from_bits(crate::overlay::recording::CURRENT_RMS.load(Ordering::Relaxed));
            if rms > 0.015 {
                if !has_spoken {
                    first_speech = Some(Instant::now());
                }
                has_spoken = true;
                last_active = Instant::now();
            } else if has_spoken
                && first_speech.map(|t| t.elapsed().as_millis()).unwrap_or(0) >= 2000
                && last_active.elapsed().as_millis() > 800
            {
                stop_signal.store(true, Ordering::SeqCst);
            }
        }
        std::thread::sleep(Duration::from_millis(10));
    }

    drop(stream);
    println!("[GeminiLiveStream] Stopped, waiting 2s...");

    if !abort_signal.load(Ordering::SeqCst) {
        let remaining: Vec<i16> = std::mem::take(&mut *audio_buffer.lock().unwrap());
        if !remaining.is_empty() {
            let _ = send_audio_chunk(&mut socket, &remaining);
        }

        // Adaptive wait: Start with 500ms
        // If we get data, extend by 600ms (was 300ms), up to max 4.0s (was 2.5s)
        let mut conclude_end = Instant::now() + Duration::from_millis(500);
        let max_stop_time = Instant::now() + Duration::from_millis(4000);
        let extension = Duration::from_millis(600);

        println!("[GeminiLiveStream] Waiting for tail...");

        while Instant::now() < conclude_end && Instant::now() < max_stop_time {
            // We need to set the socket timeout dynamically or just rely on non-blocking + sleep
            // Since we set non-blocking earlier, read() retrieves immediately.

            match socket.read() {
                Ok(tungstenite::Message::Text(msg)) => {
                    if let Some(t) = parse_input_transcription(msg.as_str()) {
                        if !t.is_empty() {
                            if let Ok(mut txt) = accumulated_text.lock() {
                                txt.push_str(&t);
                                update_stream_text(&txt);
                            }
                            // Found data, extend wait
                            conclude_end = Instant::now() + extension;
                        }
                    }
                }
                Ok(tungstenite::Message::Binary(data)) => {
                    if let Ok(s) = String::from_utf8(data.to_vec()) {
                        if let Some(t) = parse_input_transcription(&s) {
                            if !t.is_empty() {
                                if let Ok(mut txt) = accumulated_text.lock() {
                                    txt.push_str(&t);
                                }
                                if preset.auto_paste {
                                    crate::overlay::utils::type_text_to_window(None, &t);
                                }
                                // Found data, extend wait
                                conclude_end = Instant::now() + extension;
                            }
                        }
                    }
                }
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock
                        || e.kind() == std::io::ErrorKind::TimedOut =>
                {
                    std::thread::sleep(Duration::from_millis(20));
                }
                Err(_) => break,
            }
        }
    }

    let _ = socket.close(None);
    let final_text = accumulated_text.lock().unwrap().clone();
    println!("[GeminiLiveStream] Result: '{}'", final_text);

    if abort_signal.load(Ordering::SeqCst) || final_text.is_empty() {
        unsafe {
            if IsWindow(Some(overlay_hwnd)).as_bool() {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    {
        let app = APP.lock().unwrap();
        app.history.save_audio(Vec::new(), final_text.clone());
    }

    let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
    let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };
    let (rect, retrans) = if preset.blocks.len() > 1 {
        let w = 600;
        let h = 300;
        let gap = 20;
        let total = w * 2 + gap;
        let x = (screen_w - total) / 2;
        let y = (screen_h - h) / 2;
        (
            RECT {
                left: x,
                top: y,
                right: x + w,
                bottom: y + h,
            },
            Some(RECT {
                left: x + w + gap,
                top: y,
                right: x + w + gap + w,
                bottom: y + h,
            }),
        )
    } else {
        let w = 700;
        let h = 300;
        let x = (screen_w - w) / 2;
        let y = (screen_h - h) / 2;
        (
            RECT {
                left: x,
                top: y,
                right: x + w,
                bottom: y + h,
            },
            None,
        )
    };

    let final_wav = {
        let samples = full_audio_buffer.lock().unwrap();
        encode_wav(&samples, 16000, 1)
    };

    crate::overlay::process::show_audio_result(
        preset,
        final_text,
        final_wav,
        rect,
        retrans,
        overlay_hwnd,
        true, // is_streaming_result: disable auto-paste for Gemini Live
    );
}

pub fn record_and_stream_parakeet(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
    abort_signal: Arc<AtomicBool>,
    overlay_hwnd: HWND,
    target_window: Option<HWND>,
) {
    use std::sync::Mutex;
    let accumulated_text: Arc<Mutex<String>> = Arc::new(Mutex::new(String::new()));
    let full_audio_buffer: Arc<Mutex<Vec<i16>>> = Arc::new(Mutex::new(Vec::new()));
    let acc_clone = accumulated_text.clone();
    let preset_clone = preset.clone();
    let _target_window_clone = target_window;

    // Check if streaming is enabled in the first block (Audio block)
    // Enable if explicit flag is set OR render_mode is "stream"
    // Find the relevant audio block for streaming settings
    let audio_block = preset
        .blocks
        .iter()
        .find(|b| b.block_type == "audio")
        .or_else(|| preset.blocks.first());

    let streaming_enabled = audio_block
        .map(|b| {
            b.show_overlay
                && (b.streaming_enabled || b.render_mode == "stream")
                && b.render_mode != "plain"
        })
        .unwrap_or(false);
    let mut streaming_hwnd: Option<HWND> = None;

    // Launch Result Overlay if streaming is enabled
    if streaming_enabled {
        let (tx, rx) = mpsc::channel();
        let preset_for_thread = preset.clone();

        std::thread::spawn(move || {
            let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
            let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };
            let (rect, _) = if preset_for_thread.blocks.len() > 1 {
                let w = 600;
                let h = 300;
                let gap = 20;
                let total = w * 2 + gap;
                let x = (screen_w - total) / 2;
                let y = (screen_h - h) / 2;
                (
                    RECT {
                        left: x,
                        top: y,
                        right: x + w,
                        bottom: y + h,
                    },
                    Some(RECT {
                        left: x + w + gap,
                        top: y,
                        right: x + w + gap + w,
                        bottom: y + h,
                    }),
                )
            } else {
                let w = 700;
                let h = 300;
                let x = (screen_w - w) / 2;
                let y = (screen_h - h) / 2;
                (
                    RECT {
                        left: x,
                        top: y,
                        right: x + w,
                        bottom: y + h,
                    },
                    None,
                )
            };

            let first_block = preset_for_thread.blocks.first();
            let model_id = first_block.map(|b| b.model.clone()).unwrap_or_default();
            let render_mode = first_block
                .map(|b| b.render_mode.clone())
                .unwrap_or_default();

            // Get provider
            let model_conf = crate::model_config::get_model_by_id(&model_id);
            let provider = model_conf
                .map(|m| m.provider)
                .unwrap_or("parakeet".to_string());

            let hwnd = create_result_window(
                rect,
                WindowType::Primary,
                RefineContext::Audio(Vec::new()), // Audio context placeholder
                model_id,
                provider,
                true,          // streaming_enabled
                false,         // start_editing
                String::new(), // preset_prompt (not used here)
                get_chain_color(0),
                &render_mode,
                "Listening...".to_string(),
            );

            unsafe {
                let _ = ShowWindow(hwnd, SW_SHOW);
            }

            let _ = tx.send(SendHwnd(hwnd));

            // Message Loop
            unsafe {
                let mut m = MSG::default();
                while GetMessageW(&mut m, None, 0, 0).into() {
                    let _ = TranslateMessage(&m);
                    DispatchMessageW(&m);
                    if !IsWindow(Some(hwnd)).as_bool() {
                        break;
                    }
                }
            }
        });

        if let Ok(SendHwnd(h)) = rx.recv() {
            streaming_hwnd = Some(h);
        }
    }

    let streaming_hwnd_clone = streaming_hwnd;

    let callback = move |text: String| {
        if !text.is_empty() {
            if let Ok(mut txt) = acc_clone.lock() {
                txt.push_str(&text);

                // Update streaming window if active
                if let Some(h) = streaming_hwnd_clone {
                    update_window_text(h, &txt);
                }
            }
            // Real-time typing
            if preset_clone.auto_paste {
                // Always use current foreground window (None) for continuous typing
                // This allows user to switch windows while talking
                crate::overlay::utils::type_text_to_window(None, &text);
            }
        }
    };

    println!("[ParakeetStream] Starting Parakeet session...");

    // Run Parakeet session (blocks until stopped)
    let res = crate::api::realtime_audio::parakeet::run_parakeet_session(
        stop_signal.clone(),
        pause_signal.clone(),
        Some(full_audio_buffer.clone()),
        Some(overlay_hwnd), // Send volume updates to overlay
        preset_clone.hide_recording_ui,
        true, // Enable download badge
        Some(preset_clone.audio_source.clone()),
        preset_clone.auto_stop_recording,
        callback,
    );

    // Close streaming window immediately after recording stops
    if let Some(h) = streaming_hwnd {
        unsafe {
            let _ = PostMessageW(Some(h), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
    }

    if let Err(e) = res {
        eprintln!("[ParakeetStream] Error: {:?}", e);
    }

    // Check for abort
    if abort_signal.load(Ordering::SeqCst) {
        unsafe {
            if IsWindow(Some(overlay_hwnd)).as_bool() {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    let final_text = accumulated_text.lock().unwrap().clone();
    println!("[ParakeetStream] Final Result: '{}'", final_text);

    if final_text.is_empty() {
        unsafe {
            if IsWindow(Some(overlay_hwnd)).as_bool() {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    let final_wav = {
        let samples = full_audio_buffer.lock().unwrap();
        encode_wav(&samples, 16000, 1)
    };

    // Save history
    {
        let app = crate::APP.lock().unwrap();
        app.history
            .save_audio(final_wav.clone(), final_text.clone());
    }

    let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
    let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };
    let (rect, retrans) = if preset.blocks.len() > 1 {
        let w = 600;
        let h = 300;
        let gap = 20;
        let total = w * 2 + gap;
        let x = (screen_w - total) / 2;
        let y = (screen_h - h) / 2;
        (
            RECT {
                left: x,
                top: y,
                right: x + w,
                bottom: y + h,
            },
            Some(RECT {
                left: x + w + gap,
                top: y,
                right: x + w + gap + w,
                bottom: y + h,
            }),
        )
    } else {
        let w = 700;
        let h = 300;
        let x = (screen_w - w) / 2;
        let y = (screen_h - h) / 2;
        (
            RECT {
                left: x,
                top: y,
                right: x + w,
                bottom: y + h,
            },
            None,
        )
    };

    crate::overlay::process::show_audio_result(
        preset,
        final_text,
        final_wav,
        rect,
        retrans,
        overlay_hwnd,
        true, // is_streaming_result: disable auto-paste
    );
}

fn upload_audio_to_whisper(
    api_key: &str,
    model: &str,
    audio_data: Vec<u8>,
) -> anyhow::Result<String> {
    // Create multipart form data
    let boundary = format!(
        "----SGTBoundary{}",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis()
    );

    let mut body = Vec::new();

    // Add model field
    body.extend_from_slice(format!("--{}\r\n", boundary).as_bytes());
    body.extend_from_slice(b"Content-Disposition: form-data; name=\"model\"\r\n\r\n");
    body.extend_from_slice(model.as_bytes());
    body.extend_from_slice(b"\r\n");

    // Add file field
    body.extend_from_slice(format!("--{}\r\n", boundary).as_bytes());
    body.extend_from_slice(
        b"Content-Disposition: form-data; name=\"file\"; filename=\"audio.wav\"\r\n",
    );
    body.extend_from_slice(b"Content-Type: audio/wav\r\n\r\n");
    body.extend_from_slice(&audio_data);
    body.extend_from_slice(b"\r\n");

    // End boundary
    body.extend_from_slice(format!("--{}--\r\n", boundary).as_bytes());

    // Make API request
    let response = UREQ_AGENT
        .post("https://api.groq.com/openai/v1/audio/transcriptions")
        .header("Authorization", &format!("Bearer {}", api_key))
        .header(
            "Content-Type",
            &format!("multipart/form-data; boundary={}", boundary),
        )
        .send(&body);

    let response = match response {
        Ok(resp) => resp,
        Err(e) => {
            let err_str = e.to_string();
            return Err(anyhow::anyhow!("API request failed: {}", err_str));
        }
    };

    // --- CAPTURE RATE LIMITS ---
    if let Some(remaining) = response
        .headers()
        .get("x-ratelimit-remaining-requests")
        .and_then(|v| v.to_str().ok())
    {
        let limit = response
            .headers()
            .get("x-ratelimit-limit-requests")
            .and_then(|v| v.to_str().ok())
            .unwrap_or("?");
        let usage_str = format!("{} / {}", remaining, limit);
        if let Ok(mut app) = APP.lock() {
            app.model_usage_stats.insert(model.to_string(), usage_str);
        }
    }
    // ---------------------------

    // Parse response
    let json: serde_json::Value = response
        .into_body()
        .read_json()
        .map_err(|e| anyhow::anyhow!("Failed to parse response: {}", e))?;

    let text = json
        .get("text")
        .and_then(|t| t.as_str())
        .ok_or_else(|| anyhow::anyhow!("No text in response"))?;

    Ok(text.to_string())
}

/// Shared logic to process audio data based on a preset's configuration
/// Returns the transcription/processing result text
fn execute_audio_processing_logic(preset: &Preset, wav_data: Vec<u8>) -> anyhow::Result<String> {
    // Find the first block that is specifically an "audio" processing block
    // OR allow input_adapter if no audio block exists (for raw audio overlay)
    let (audio_block, is_raw_input_adapter) =
        match preset.blocks.iter().find(|b| b.block_type == "audio") {
            Some(b) => (b.clone(), false),
            None => match preset
                .blocks
                .iter()
                .find(|b| b.block_type == "input_adapter")
            {
                Some(b) => (b.clone(), true),
                None => {
                    let debug_types: Vec<_> = preset.blocks.iter().map(|b| &b.block_type).collect();
                    eprintln!(
                    "DEBUG [Audio]: No 'audio' blocks found in preset. Block types present: {:?}",
                    debug_types
                );
                    return Err(anyhow::anyhow!(
                        "Audio preset has no 'audio' processing blocks configured"
                    ));
                }
            },
        };

    if is_raw_input_adapter {
        return Ok(String::new());
    }

    let model_config = get_model_by_id(&audio_block.model);
    let model_config = match model_config {
        Some(c) => c,
        None => {
            return Err(anyhow::anyhow!(
                "Model config not found for audio model: {}",
                audio_block.model
            ));
        }
    };
    let model_name = model_config.full_name.clone();
    let provider = model_config.provider.clone();

    let (groq_api_key, gemini_api_key) = {
        let app = crate::APP.lock().unwrap();
        (
            app.config.api_key.clone(),
            app.config.gemini_api_key.clone(),
        )
    };

    // Use block's prompt and language settings
    let mut final_prompt = if model_is_non_llm(&audio_block.model) {
        String::new()
    } else {
        audio_block.prompt.clone()
    };

    for (key, value) in &audio_block.language_vars {
        let pattern = format!("{{{}}}", key);
        final_prompt = final_prompt.replace(&pattern, value);
    }

    if final_prompt.contains("{language1}") && !audio_block.language_vars.contains_key("language1")
    {
        final_prompt = final_prompt.replace("{language1}", &audio_block.selected_language);
    }

    final_prompt = final_prompt.replace("{language}", &audio_block.selected_language);

    if provider == "groq" {
        if groq_api_key.trim().is_empty() {
            Err(anyhow::anyhow!("NO_API_KEY:groq"))
        } else {
            upload_audio_to_whisper(&groq_api_key, &model_name, wav_data)
        }
    } else if provider == "google" {
        if gemini_api_key.trim().is_empty() {
            Err(anyhow::anyhow!("NO_API_KEY:google"))
        } else {
            transcribe_audio_gemini(&gemini_api_key, final_prompt, model_name, wav_data, |_| {})
        }
    } else if provider == "gemini-live" {
        // Gemini Live API (WebSocket-based) - uses INPUT transcription (what user said)
        // instead of LLM output transcription
        if gemini_api_key.trim().is_empty() {
            Err(anyhow::anyhow!("NO_API_KEY:gemini"))
        } else {
            transcribe_with_gemini_live_input(&gemini_api_key, wav_data)
        }
    } else {
        Err(anyhow::anyhow!("Unsupported audio provider: {}", provider))
    }
}

pub fn record_audio_and_transcribe(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
    abort_signal: Arc<AtomicBool>,
    overlay_hwnd: HWND,
) {
    let pause_signal_audio = pause_signal.clone();
    #[cfg(target_os = "windows")]
    let host = if preset.audio_source == "device" {
        cpal::host_from_id(cpal::HostId::Wasapi).unwrap_or(cpal::default_host())
    } else {
        cpal::default_host()
    };
    #[cfg(not(target_os = "windows"))]
    let host = cpal::default_host();

    let device = if preset.audio_source == "device" {
        #[cfg(target_os = "windows")]
        {
            match host.default_output_device() {
                Some(d) => d,
                None => {
                    eprintln!("Error: No default output device found for loopback.");
                    unsafe {
                        let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                    return;
                }
            }
        }
        #[cfg(not(target_os = "windows"))]
        {
            // Strict failure if not Windows (device loopback primarily supported on Windows via WASAPI)
            eprintln!("Error: Device capture not supported on this OS or no device found.");
            unsafe {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
            return;
        }
    } else {
        match host.default_input_device() {
            Some(d) => d,
            None => {
                eprintln!("Error: No input device available.");
                unsafe {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
                return;
            }
        }
    };

    let config = if preset.audio_source == "device" {
        match device.default_output_config() {
            Ok(c) => c,
            Err(_) => match device.default_input_config() {
                Ok(c) => c,
                Err(e) => {
                    eprintln!("Failed to get audio config: {}", e);
                    unsafe {
                        let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                    return;
                }
            },
        }
    } else {
        match device.default_input_config() {
            Ok(c) => c,
            Err(e) => {
                eprintln!("Failed to get audio config: {}", e);
                unsafe {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
                return;
            }
        }
    };

    let sample_rate = config.sample_rate();
    let channels = config.channels();

    let spec = hound::WavSpec {
        channels,
        sample_rate,
        bits_per_sample: 16,
        sample_format: hound::SampleFormat::Int,
    };

    let (tx, rx) = mpsc::channel::<Vec<f32>>();

    let err_fn = |err| eprintln!("Audio stream error: {}", err);

    // Threshold for "meaningful audio" - above this RMS means mic is truly receiving sound
    const WARMUP_RMS_THRESHOLD: f32 = 0.001;

    let pause_signal_builder = pause_signal_audio.clone();
    let stream_res = match config.sample_format() {
        cpal::SampleFormat::F32 => device.build_input_stream(
            &config.into(),
            move |data: &[f32], _: &_| {
                if !pause_signal_builder.load(Ordering::Relaxed) {
                    let _ = tx.send(data.to_vec());
                    let mut rms = 0.0;
                    for &x in data {
                        rms += x * x;
                    }
                    rms = (rms / data.len() as f32).sqrt();
                    crate::overlay::recording::update_audio_viz(rms);

                    // Signal warmup complete when we get meaningful audio
                    if rms > WARMUP_RMS_THRESHOLD {
                        crate::overlay::recording::AUDIO_WARMUP_COMPLETE
                            .store(true, Ordering::SeqCst);
                    }
                }
            },
            err_fn,
            None,
        ),
        cpal::SampleFormat::I16 => device.build_input_stream(
            &config.into(),
            move |data: &[i16], _: &_| {
                if !pause_signal_builder.load(Ordering::Relaxed) {
                    let f32_data: Vec<f32> =
                        data.iter().map(|&s| s as f32 / i16::MAX as f32).collect();
                    let _ = tx.send(f32_data);
                    let mut rms = 0.0;
                    for &x in data {
                        let f = x as f32 / i16::MAX as f32;
                        rms += f * f;
                    }
                    rms = (rms / data.len() as f32).sqrt();
                    crate::overlay::recording::update_audio_viz(rms);

                    // Signal warmup complete when we get meaningful audio
                    if rms > WARMUP_RMS_THRESHOLD {
                        crate::overlay::recording::AUDIO_WARMUP_COMPLETE
                            .store(true, Ordering::SeqCst);
                    }
                }
            },
            err_fn,
            None,
        ),
        _ => {
            eprintln!(
                "Unsupported audio sample format: {:?}",
                config.sample_format()
            );
            Err(cpal::BuildStreamError::StreamConfigNotSupported)
        }
    };

    if let Err(e) = stream_res {
        eprintln!("Failed to build stream: {}", e);
        unsafe {
            let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
        return;
    }
    let stream = stream_res.unwrap();

    if let Err(e) = stream.play() {
        eprintln!("Failed to play stream: {}", e);
        unsafe {
            let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
        return;
    }

    let mut collected_samples: Vec<f32> = Vec::new();

    // --- AUTO-STOP LOGIC STATE ---
    // Only active when preset.auto_stop_recording is true
    let auto_stop_enabled = preset.auto_stop_recording;
    let mut has_spoken = false; // True once user starts speaking
    let mut first_speech_time: Option<std::time::Instant> = None; // When user first spoke
    let mut last_active_time = std::time::Instant::now();

    // Thresholds tuned for typical speech vs silence
    const NOISE_THRESHOLD: f32 = 0.015; // RMS above this = speech
    const SILENCE_LIMIT_MS: u128 = 800; // ms of silence after speech to trigger stop
    const MIN_RECORDING_MS: u128 = 2000; // Minimum 2 seconds after first speech

    while !stop_signal.load(Ordering::SeqCst) {
        while let Ok(chunk) = rx.try_recv() {
            collected_samples.extend(chunk);
        }

        // --- AUTO-STOP: Check volume and silence duration ---
        if auto_stop_enabled
            && !stop_signal.load(Ordering::Relaxed)
            && !pause_signal_audio.load(Ordering::Relaxed)
        {
            // Get current RMS from the shared atomic
            let rms_bits = crate::overlay::recording::CURRENT_RMS.load(Ordering::Relaxed);
            let current_rms = f32::from_bits(rms_bits);

            if current_rms > NOISE_THRESHOLD {
                // User is speaking (volume above threshold)
                if !has_spoken {
                    first_speech_time = Some(std::time::Instant::now());
                }
                has_spoken = true;
                last_active_time = std::time::Instant::now();
            } else if has_spoken {
                // User was speaking but now is silent
                // Check minimum recording duration first
                let recording_duration = first_speech_time
                    .map(|t| t.elapsed().as_millis())
                    .unwrap_or(0);
                if recording_duration >= MIN_RECORDING_MS {
                    let silence_duration = last_active_time.elapsed().as_millis();
                    if silence_duration > SILENCE_LIMIT_MS {
                        // Silence exceeded limit after speech - auto-stop!
                        stop_signal.store(true, Ordering::SeqCst);
                    }
                }
            }
        }

        std::thread::sleep(std::time::Duration::from_millis(50));
        if !preset.hide_recording_ui {
            if !unsafe { IsWindow(Some(overlay_hwnd)).as_bool() } {
                return;
            }
        }
    }

    drop(stream);

    if abort_signal.load(Ordering::SeqCst) {
        unsafe {
            if IsWindow(Some(overlay_hwnd)).as_bool() {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    while let Ok(chunk) = rx.try_recv() {
        collected_samples.extend(chunk);
    }

    let samples: Vec<i16> = collected_samples
        .iter()
        .map(|&s| (s.clamp(-1.0, 1.0) * i16::MAX as f32) as i16)
        .collect();

    if samples.is_empty() {
        println!("Warning: Recorded audio buffer is empty.");
        unsafe {
            let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
        return;
    }

    let mut wav_cursor = Cursor::new(Vec::new());
    {
        let mut writer =
            hound::WavWriter::new(&mut wav_cursor, spec).expect("Failed to create memory writer");
        for sample in &samples {
            writer
                .write_sample(*sample)
                .expect("Failed to write sample");
        }
        writer.finalize().expect("Failed to finalize WAV");
    }
    let wav_data = wav_cursor.into_inner();

    // For MASTER presets, show the wheel BEFORE transcription to get the actual preset
    let working_preset = if preset.is_master {
        // Get cursor position for wheel center (use center of screen)
        let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
        let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };
        let cursor_pos = POINT {
            x: screen_w / 2,
            y: screen_h / 2,
        };

        // Show preset wheel - filter by audio source
        let audio_mode = Some(preset.audio_source.as_str());
        let selected =
            crate::overlay::preset_wheel::show_preset_wheel("audio", audio_mode, cursor_pos);

        if let Some(idx) = selected {
            // Get the selected preset from config AND update active_preset_idx
            let mut app = crate::APP.lock().unwrap();
            // CRITICAL: Update active_preset_idx so auto_paste logic works!
            app.config.active_preset_idx = idx;
            app.config.presets[idx].clone()
        } else {
            // User dismissed wheel - close overlay and cancel
            unsafe {
                if IsWindow(Some(overlay_hwnd)).as_bool() {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
            }
            return;
        }
    } else {
        preset.clone()
    };

    // Clone wav_data for history saving
    let wav_data_for_history = wav_data.clone();

    // EXECUTE SHARED AUDIO PROCESSING LOGIC
    let transcription_result = execute_audio_processing_logic(&working_preset, wav_data);

    // DON'T close overlay here - pass it to chain processing instead
    // The chain will keep the recording animation until the first visible block appears

    // Check if user aborted during the API call
    if abort_signal.load(Ordering::SeqCst) {
        unsafe {
            if IsWindow(Some(overlay_hwnd)).as_bool() {
                let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    match transcription_result {
        Ok(transcription_text) => {
            // Clone wav_data for the input overlay BEFORE saving to history
            let wav_data_for_overlay = wav_data_for_history.clone();

            // SAVE HISTORY
            {
                let app = crate::APP.lock().unwrap();
                app.history
                    .save_audio(wav_data_for_history, transcription_text.clone());
            }

            // Use working_preset (already resolved by wheel for MASTER presets)
            let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
            let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };

            // Use block count to determine layout - multiple blocks means multi-window layout
            let has_multiple_blocks = working_preset.blocks.len() > 1;
            let (rect, retranslate_rect) = if has_multiple_blocks {
                let w = 600;
                let h = 300;
                let gap = 20;
                let total_w = w * 2 + gap;
                let start_x = (screen_w - total_w) / 2;
                let y = (screen_h - h) / 2;

                (
                    RECT {
                        left: start_x,
                        top: y,
                        right: start_x + w,
                        bottom: y + h,
                    },
                    Some(RECT {
                        left: start_x + w + gap,
                        top: y,
                        right: start_x + w + gap + w,
                        bottom: y + h,
                    }),
                )
            } else {
                let w = 700;
                let h = 300;
                let x = (screen_w - w) / 2;
                let y = (screen_h - h) / 2;
                (
                    RECT {
                        left: x,
                        top: y,
                        right: x + w,
                        bottom: y + h,
                    },
                    None,
                )
            };

            // Pass overlay_hwnd to chain processing - it will be kept alive until first visible block
            crate::overlay::process::show_audio_result(
                working_preset,
                transcription_text,
                wav_data_for_overlay,
                rect,
                retranslate_rect,
                overlay_hwnd,
                false, // is_streaming_result: standard transcription (allow paste)
            );
        }
        Err(e) => {
            eprintln!("Transcription error: {}", e);
            // Close overlay on error
            unsafe {
                if IsWindow(Some(overlay_hwnd)).as_bool() {
                    let _ = PostMessageW(Some(overlay_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
            }
        }
    }
}

/// Process an existing audio file (WAV data) using a specific preset
/// This is used for drag-and-drop audio file processing without recording
pub fn process_audio_file_request(preset: Preset, wav_data: Vec<u8>) {
    // EXECUTE SHARED AUDIO PROCESSING LOGIC
    let processing_result = execute_audio_processing_logic(&preset, wav_data.clone());

    match processing_result {
        Ok(result_text) => {
            // Save history
            {
                let app = crate::APP.lock().unwrap();
                app.history
                    .save_audio(wav_data.clone(), result_text.clone());
            }

            // Calculate centered position for result
            let (screen_w, screen_h) =
                unsafe { (GetSystemMetrics(SM_CXSCREEN), GetSystemMetrics(SM_CYSCREEN)) };

            // Layout logic same as recording flow
            let has_multiple_blocks = preset.blocks.len() > 1;
            let (rect, retranslate_rect) = if has_multiple_blocks {
                let w = 600;
                let h = 300;
                let gap = 20;
                let total_w = w * 2 + gap;
                let start_x = (screen_w - total_w) / 2;
                let y = (screen_h - h) / 2;

                (
                    RECT {
                        left: start_x,
                        top: y,
                        right: start_x + w,
                        bottom: y + h,
                    },
                    Some(RECT {
                        left: start_x + w + gap,
                        top: y,
                        right: start_x + w + gap + w,
                        bottom: y + h,
                    }),
                )
            } else {
                let w = 700;
                let h = 300;
                let x = (screen_w - w) / 2;
                let y = (screen_h - h) / 2;
                (
                    RECT {
                        left: x,
                        top: y,
                        right: x + w,
                        bottom: y + h,
                    },
                    None,
                )
            };

            // Show result
            crate::overlay::process::show_audio_result(
                preset,
                result_text,
                wav_data,
                rect,
                retranslate_rect,
                HWND(std::ptr::null_mut()), // No recording overlay handle needed
                false,                      // is_streaming_result: file processing (allow paste)
            );
        }
        Err(e) => {
            eprintln!("Audio file processing error: {}", e);
        }
    }
}
</file>

<file path="src/api/client.rs">
use lazy_static::lazy_static;
use std::time::Duration;

lazy_static! {
    pub static ref UREQ_AGENT: ureq::Agent = {
        let config = ureq::Agent::config_builder()
            .timeout_global(Some(Duration::from_secs(120)))
            .build();
        config.into()
    };
}
</file>

<file path="src/api/gemini_live/mod.rs">
//! Gemini Live LLM API
//!
//! This module provides access to Gemini's native audio model as a standard LLM,
//! using the bidirectional WebSocket API for low-latency streaming text responses.
//!
//! Unlike the standard REST API, this uses a connection pool for faster response times.
//! Supports text, image, and audio inputs with text-only output.

pub mod manager;
pub mod types;
pub mod websocket;
pub mod worker;

use std::sync::Arc;

pub use manager::GeminiLiveManager;
pub use types::{LiveEvent, LiveInputContent};

lazy_static::lazy_static! {
    /// Global Gemini Live manager instance
    pub static ref GEMINI_LIVE_MANAGER: Arc<GeminiLiveManager> = Arc::new(GeminiLiveManager::new());
}

/// Number of worker threads for the connection pool
const WORKER_COUNT: usize = 2;

/// Initialize the Gemini Live LLM system - call this at app startup
pub fn init_gemini_live() {
    for _ in 0..WORKER_COUNT {
        let manager = GEMINI_LIVE_MANAGER.clone();
        std::thread::spawn(move || {
            worker::run_live_worker(manager);
        });
    }
}

/// Streaming text generation using Gemini Live API
/// This is the main entry point for using Gemini Live as an LLM
///
/// Arguments:
/// - `text`: The user prompt text
/// - `instruction`: System instruction / prompt template
/// - `image_data`: Optional image data (bytes, mime_type)
/// - `audio_data`: Optional audio data (PCM 16-bit mono 16kHz)
/// - `streaming_enabled`: Whether to stream chunks or wait for complete response
/// - `ui_language`: UI language for thinking message
/// - `on_chunk`: Callback for each text chunk
///
/// Returns: Complete response text or error
pub fn gemini_live_generate<F>(
    text: String,
    instruction: String,
    image_data: Option<(Vec<u8>, String)>,
    audio_data: Option<Vec<u8>>,
    streaming_enabled: bool,
    ui_language: &str,
    mut on_chunk: F,
) -> anyhow::Result<String>
where
    F: FnMut(&str),
{
    // Log what we're sending
    let content_type = match (&image_data, &audio_data) {
        (Some((img, mime)), _) => format!("TextWithImage ({}bytes, {})", img.len(), mime),
        (None, Some(audio)) => format!("TextWithAudio ({}bytes)", audio.len()),
        (None, None) => format!("Text ({}chars)", text.len()),
    };
    println!("[GeminiLive] gemini_live_generate called: {}", content_type);
    println!(
        "[GeminiLive] instruction len: {}, streaming: {}",
        instruction.len(),
        streaming_enabled
    );

    // Build input content based on what's provided
    let content = match (image_data, audio_data) {
        (Some((img, mime)), _) => LiveInputContent::TextWithImage {
            text,
            image_data: img,
            mime_type: mime,
        },
        (None, Some(audio)) => {
            if text.trim().is_empty() {
                LiveInputContent::AudioOnly(audio)
            } else {
                LiveInputContent::TextWithAudio {
                    text,
                    audio_data: audio,
                }
            }
        }
        (None, None) => LiveInputContent::Text(text),
    };

    // Check if model supports thinking (always enabled for this model)
    let show_thinking = true;

    // Send request to the manager
    let (id, rx) = GEMINI_LIVE_MANAGER.request(content, instruction, show_thinking);
    println!("[GeminiLive] Request queued with ID: {}", id);

    let mut full_content = String::new();
    let mut thinking_shown = false;
    let mut content_started = false;
    let mut event_count = 0;

    let locale = crate::gui::locale::LocaleText::get(ui_language);

    // Process events from the worker
    loop {
        match rx.recv() {
            Ok(LiveEvent::Thinking) => {
                event_count += 1;
                println!("[GeminiLive] Event {}: Thinking", event_count);
                if !thinking_shown && !content_started {
                    if streaming_enabled {
                        on_chunk(locale.model_thinking);
                    }
                    thinking_shown = true;
                }
            }
            Ok(LiveEvent::TextChunk(chunk)) => {
                event_count += 1;
                println!(
                    "[GeminiLive] Event {}: TextChunk ({}bytes)",
                    event_count,
                    chunk.len()
                );
                if streaming_enabled {
                    // If we showed thinking, wipe it on first content
                    if !content_started && thinking_shown {
                        content_started = true;
                        full_content.push_str(&chunk);
                        let wipe_content = format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                        on_chunk(&wipe_content);
                    } else {
                        content_started = true;
                        full_content.push_str(&chunk);
                        on_chunk(&chunk);
                    }
                } else {
                    content_started = true;
                    full_content.push_str(&chunk);
                }
            }
            Ok(LiveEvent::TurnComplete) => {
                event_count += 1;
                println!(
                    "[GeminiLive] Event {}: TurnComplete (total content: {}bytes)",
                    event_count,
                    full_content.len()
                );
                if !streaming_enabled && !full_content.is_empty() {
                    on_chunk(&full_content);
                }
                break;
            }
            Ok(LiveEvent::Error(e)) => {
                event_count += 1;
                println!("[GeminiLive] Event {}: Error - {}", event_count, e);
                if e.contains("NO_API_KEY") {
                    return Err(anyhow::anyhow!("{}", e));
                }
                return Err(anyhow::anyhow!("Gemini Live error: {}", e));
            }
            Err(e) => {
                println!("[GeminiLive] Channel error: {:?}", e);
                // Channel closed - worker finished unexpectedly
                break;
            }
        }
    }

    println!(
        "[GeminiLive] gemini_live_generate complete: {}bytes result",
        full_content.len()
    );
    Ok(full_content)
}
</file>

<file path="src/api/gemini_live/websocket.rs">
//! WebSocket connection and communication for Gemini Live LLM API

use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
use native_tls::TlsStream;
use std::net::TcpStream;
use std::time::Duration;
use tungstenite::WebSocket;

use super::types::{LiveInputContent, GEMINI_LIVE_MODEL};

/// Create TLS WebSocket connection to Gemini Live API
pub fn connect_live_websocket(api_key: &str) -> Result<WebSocket<TlsStream<TcpStream>>> {
    let ws_url = format!(
        "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key={}",
        api_key
    );

    let url = url::Url::parse(&ws_url)?;
    let host = url
        .host_str()
        .ok_or_else(|| anyhow::anyhow!("No host in URL"))?;
    let port = 443;

    use std::net::ToSocketAddrs;
    let addr = format!("{}:{}", host, port)
        .to_socket_addrs()?
        .next()
        .ok_or_else(|| anyhow::anyhow!("Failed to resolve hostname: {}", host))?;

    let tcp_stream = TcpStream::connect_timeout(&addr, Duration::from_secs(10))?;
    tcp_stream.set_read_timeout(Some(Duration::from_secs(30)))?;
    tcp_stream.set_write_timeout(Some(Duration::from_secs(30)))?;
    tcp_stream.set_nodelay(true)?;

    let connector = native_tls::TlsConnector::new()?;
    let tls_stream = connector.connect(host, tcp_stream)?;

    let (socket, _response) = tungstenite::client::client(&ws_url, tls_stream)?;

    Ok(socket)
}

/// Send setup message for text-output mode
/// The native audio model REQUIRES responseModalities: ["AUDIO"]
/// but we can still extract text from the response and ignore the audio
pub fn send_live_setup(
    socket: &mut WebSocket<TlsStream<TcpStream>>,
    system_instruction: Option<&str>,
    enable_thinking: bool,
) -> Result<()> {
    // Native audio model requires AUDIO modality - we'll ignore the audio and extract text
    // We also request inputAudioTranscription to get text responses

    // Base configuration
    let mut generation_config = serde_json::json!({
        "responseModalities": ["AUDIO"],  // Required for native audio model
        "speechConfig": {
            "voiceConfig": {
                "prebuiltVoiceConfig": {
                    "voiceName": "Aoede"  // Default voice
                }
            }
        }
    });

    // Configure thinking
    if enable_thinking {
        // Explicitly enable thoughts to ensure they are streamed back
        generation_config["thinkingConfig"] = serde_json::json!({
             "includeThoughts": true
        });
    } else {
        // Explicitly disable thinking
        generation_config["thinkingConfig"] = serde_json::json!({
            "thinkingBudget": 0
        });
    }

    let mut setup = serde_json::json!({
        "setup": {
            "model": format!("models/{}", GEMINI_LIVE_MODEL),
            "tools": [
                { "google_search": {} }
            ],
            "generationConfig": generation_config,
            "outputAudioTranscription": {}  // This gives us text transcription of the audio output
        }
    });

    // Add system instruction if provided
    if let Some(instruction) = system_instruction {
        // Enforce super fast speed in system prompt as requested
        let speed_instruction =
            "IMPORTANT: You must respond as fast as possible. Be concise and direct.";

        let final_instruction = if instruction.trim().is_empty() {
            speed_instruction.to_string()
        } else {
            format!("{} {}", instruction, speed_instruction)
        };

        setup["setup"]["systemInstruction"] = serde_json::json!({
            "parts": [{
                "text": final_instruction
            }]
        });
    }

    let msg_str = setup.to_string();
    socket.write(tungstenite::Message::Text(msg_str.into()))?;
    socket.flush()?;

    Ok(())
}

/// Send content to the model (text, image, or audio)
pub fn send_live_content(
    socket: &mut WebSocket<TlsStream<TcpStream>>,
    content: &LiveInputContent,
) -> Result<()> {
    let parts = match content {
        LiveInputContent::Text(text) => {
            serde_json::json!([{
                "text": text
            }])
        }
        LiveInputContent::TextWithImage {
            text,
            image_data,
            mime_type,
        } => {
            let b64_image = general_purpose::STANDARD.encode(image_data);
            serde_json::json!([
                { "text": text },
                {
                    "inlineData": {
                        "mimeType": mime_type,
                        "data": b64_image
                    }
                }
            ])
        }
        LiveInputContent::TextWithAudio { text, audio_data } => {
            let b64_audio = general_purpose::STANDARD.encode(audio_data);
            serde_json::json!([
                { "text": text },
                {
                    "inlineData": {
                        "mimeType": "audio/pcm;rate=16000",
                        "data": b64_audio
                    }
                }
            ])
        }
        LiveInputContent::AudioOnly(audio_data) => {
            let b64_audio = general_purpose::STANDARD.encode(audio_data);
            serde_json::json!([{
                "inlineData": {
                    "mimeType": "audio/pcm;rate=16000",
                    "data": b64_audio
                }
            }])
        }
    };

    let msg = serde_json::json!({
        "clientContent": {
            "turns": [{
                "role": "user",
                "parts": parts
            }],
            "turnComplete": true
        }
    });

    socket.write(tungstenite::Message::Text(msg.to_string().into()))?;
    socket.flush()?;

    Ok(())
}

/// Parse text content from WebSocket message
/// The native audio model returns audio, but with outputAudioTranscription enabled,
/// we get text transcription of what it "said" as well
/// Returns (text_chunk, is_thought, is_turn_complete)
pub fn parse_live_response(msg: &str) -> (Option<String>, bool, bool) {
    let mut text_chunk = None;
    let is_thought = false; // Native audio model doesn't support thinking
    let mut is_turn_complete = false;

    if let Ok(json) = serde_json::from_str::<serde_json::Value>(msg) {
        if let Some(server_content) = json.get("serverContent") {
            // Check for turn complete
            if let Some(tc) = server_content.get("turnComplete") {
                if tc.as_bool().unwrap_or(false) {
                    is_turn_complete = true;
                }
            }

            // Check for generationComplete (faster signal)
            if let Some(gc) = server_content.get("generationComplete") {
                if gc.as_bool().unwrap_or(false) {
                    is_turn_complete = true;
                }
            }

            // Check for outputTranscription - this is the text we want!
            // Note: The field name is "outputTranscription" (not "outputAudioTranscription")
            // Don't trim - leading spaces are intentional word separators
            if let Some(transcription) = server_content.get("outputTranscription") {
                if let Some(text) = transcription.get("text").and_then(|t| t.as_str()) {
                    // Only skip if it's purely whitespace (like just "\n")
                    if !text.chars().all(char::is_whitespace) {
                        text_chunk = Some(text.to_string());
                    }
                }
            }

            // Also check model turn for any direct text (fallback)
            if text_chunk.is_none() {
                if let Some(model_turn) = server_content.get("modelTurn") {
                    if let Some(parts) = model_turn.get("parts").and_then(|p| p.as_array()) {
                        for part in parts {
                            // Extract text if present
                            if let Some(text) = part.get("text").and_then(|t| t.as_str()) {
                                if !text.is_empty() {
                                    text_chunk = Some(text.to_string());
                                }
                            }
                        }
                    }
                }
            }
        }
    }

    (text_chunk, is_thought, is_turn_complete)
}

/// Check if the message indicates setup is complete
pub fn is_setup_complete(msg: &str) -> bool {
    msg.contains("setupComplete")
}

/// Check if the message contains an error
pub fn parse_error(msg: &str) -> Option<String> {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(msg) {
        if let Some(error) = json.get("error") {
            if let Some(message) = error.get("message").and_then(|m| m.as_str()) {
                return Some(message.to_string());
            }
            return Some(error.to_string());
        }
    }
    None
}
</file>

<file path="src/api/gemini_live/worker.rs">
//! Worker thread for Gemini Live LLM connection pool

use std::sync::atomic::Ordering;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tungstenite::Message;

use super::manager::GeminiLiveManager;
use super::types::LiveEvent;
use super::websocket::{
    connect_live_websocket, is_setup_complete, parse_error, parse_live_response, send_live_content,
    send_live_setup,
};
use crate::APP;

/// Run a worker thread for the Gemini Live connection pool
/// Each worker handles one request at a time with its own WebSocket connection
pub fn run_live_worker(manager: Arc<GeminiLiveManager>) {
    // Stagger worker startup
    std::thread::sleep(Duration::from_millis(50));

    loop {
        if manager.shutdown.load(Ordering::SeqCst) {
            break;
        }

        // Wait for a request
        let queued_request = {
            let mut queue = manager.work_queue.lock().unwrap();
            while queue.is_empty() && !manager.shutdown.load(Ordering::SeqCst) {
                let result = manager.work_signal.wait(queue).unwrap();
                queue = result;
            }
            if manager.shutdown.load(Ordering::SeqCst) {
                return;
            }
            queue.pop_front()
        };

        let Some(request) = queued_request else {
            continue;
        };

        // Check if request is stale (interrupted)
        if !manager.is_generation_valid(request.generation) {
            let _ = request
                .response_tx
                .send(LiveEvent::Error("Request cancelled".to_string()));
            continue;
        }

        // Get API key
        let api_key = match APP.lock() {
            Ok(app) => app.config.gemini_api_key.clone(),
            Err(_) => {
                let _ = request
                    .response_tx
                    .send(LiveEvent::Error("Failed to get config".to_string()));
                continue;
            }
        };

        if api_key.trim().is_empty() {
            let _ = request
                .response_tx
                .send(LiveEvent::Error("NO_API_KEY:gemini".to_string()));
            continue;
        }

        // Connect to WebSocket
        let socket_result = connect_live_websocket(&api_key);
        let mut socket = match socket_result {
            Ok(s) => s,
            Err(e) => {
                let _ = request
                    .response_tx
                    .send(LiveEvent::Error(format!("Connection failed: {}", e)));
                std::thread::sleep(Duration::from_secs(1));
                continue;
            }
        };

        // Send setup message
        let instruction = if request.req.instruction.trim().is_empty() {
            None
        } else {
            Some(request.req.instruction.as_str())
        };

        if let Err(e) = send_live_setup(&mut socket, instruction, request.req.show_thinking) {
            let _ = request
                .response_tx
                .send(LiveEvent::Error(format!("Setup failed: {}", e)));
            let _ = socket.close(None);
            continue;
        }

        // Wait for setup acknowledgment
        let setup_start = Instant::now();
        let mut setup_complete = false;

        loop {
            if !manager.is_generation_valid(request.generation)
                || manager.shutdown.load(Ordering::SeqCst)
            {
                let _ = socket.close(None);
                let _ = request
                    .response_tx
                    .send(LiveEvent::Error("Cancelled".to_string()));
                break;
            }

            match socket.read() {
                Ok(Message::Text(msg)) => {
                    let msg_str = msg.as_str();
                    if is_setup_complete(msg_str) {
                        setup_complete = true;
                        break;
                    }
                    if let Some(error) = parse_error(msg_str) {
                        let _ = request.response_tx.send(LiveEvent::Error(error));
                        break;
                    }
                }
                Ok(Message::Binary(data)) => {
                    if let Ok(text) = String::from_utf8(data.to_vec()) {
                        if is_setup_complete(&text) {
                            setup_complete = true;
                            break;
                        }
                    }
                }
                Ok(Message::Close(_)) => break,
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock =>
                {
                    if setup_start.elapsed() > Duration::from_secs(15) {
                        let _ = request
                            .response_tx
                            .send(LiveEvent::Error("Setup timeout".to_string()));
                        break;
                    }
                    std::thread::sleep(Duration::from_millis(50));
                }
                Err(e) => {
                    let _ = request
                        .response_tx
                        .send(LiveEvent::Error(format!("Setup error: {}", e)));
                    break;
                }
            }
        }

        if !setup_complete {
            let _ = socket.close(None);
            continue;
        }

        // Send the actual content
        if let Err(e) = send_live_content(&mut socket, &request.req.content) {
            let _ = request
                .response_tx
                .send(LiveEvent::Error(format!("Send failed: {}", e)));
            let _ = socket.close(None);
            continue;
        }

        // Read response loop
        let mut thinking_sent = false;
        let mut content_started = false;

        loop {
            if !manager.is_generation_valid(request.generation)
                || manager.shutdown.load(Ordering::SeqCst)
            {
                let _ = socket.close(None);
                break;
            }

            match socket.read() {
                Ok(Message::Text(msg)) => {
                    let msg_str = msg.as_str();

                    // Check for errors first
                    if let Some(error) = parse_error(msg_str) {
                        let _ = request.response_tx.send(LiveEvent::Error(error));
                        break;
                    }

                    // Parse response
                    let (text_chunk, is_thought, is_turn_complete) = parse_live_response(msg_str);

                    if let Some(text) = text_chunk {
                        if is_thought {
                            if !thinking_sent && !content_started {
                                let _ = request.response_tx.send(LiveEvent::Thinking);
                                thinking_sent = true;
                            }
                        } else {
                            content_started = true;
                            let _ = request.response_tx.send(LiveEvent::TextChunk(text));
                        }
                    }

                    if is_turn_complete {
                        let _ = request.response_tx.send(LiveEvent::TurnComplete);
                        break;
                    }
                }
                Ok(Message::Binary(data)) => {
                    // Try to parse as JSON text (ignore raw audio data)
                    if let Ok(text) = String::from_utf8(data.to_vec()) {
                        let (text_chunk, is_thought, is_turn_complete) = parse_live_response(&text);

                        if let Some(chunk) = text_chunk {
                            if is_thought {
                                if !thinking_sent && !content_started {
                                    let _ = request.response_tx.send(LiveEvent::Thinking);
                                    thinking_sent = true;
                                }
                            } else {
                                content_started = true;
                                let _ = request.response_tx.send(LiveEvent::TextChunk(chunk));
                            }
                        }

                        if is_turn_complete {
                            let _ = request.response_tx.send(LiveEvent::TurnComplete);
                            break;
                        }
                    }
                    // Ignore binary audio data (not UTF-8)
                }
                Ok(Message::Close(_)) => {
                    let _ = request.response_tx.send(LiveEvent::TurnComplete);
                    break;
                }
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock =>
                {
                    std::thread::sleep(Duration::from_millis(10));
                }
                Err(e) => {
                    let _ = request
                        .response_tx
                        .send(LiveEvent::Error(format!("Read error: {}", e)));
                    break;
                }
            }
        }

        let _ = socket.close(None);
    }
}
</file>

<file path="src/api/mod.rs">
pub mod audio;
pub mod client;
pub mod gemini_live;
pub mod ollama;
pub mod realtime_audio;
pub mod text;
pub mod tts;
pub mod types;
pub mod vision;

pub use audio::record_and_stream_gemini_live;
// pub use audio::record_and_stream_parakeet;
pub use audio::record_audio_and_transcribe;
pub use text::{refine_text_streaming, translate_text_streaming};
pub use vision::translate_image_streaming;
// realtime_audio types/functions are used directly where needed via crate::api::realtime_audio::

/// Special prefix signal that tells callbacks to clear their accumulator before processing
/// When a chunk starts with this, the callback should: 1) Clear acc 2) Add the content after this prefix
pub const WIPE_SIGNAL: &str = "\x00WIPE\x00";
</file>

<file path="src/api/ollama.rs">
//! Ollama API Integration
//! Supports local LLM inference with vision and text models

use anyhow::Result;
use image::{ImageBuffer, Rgba};
use base64::{Engine as _, engine::general_purpose};
use std::io::{Cursor, BufRead, BufReader};
use serde::Deserialize;
use super::client::UREQ_AGENT;
use crate::gui::locale::LocaleText;

/// Ollama streaming chunk response
#[derive(Deserialize, Debug)]
pub struct OllamaStreamChunk {
    #[serde(default)]
    pub response: String,
    #[serde(default)]
    pub thinking: Option<String>,
    #[serde(default)]
    pub done: bool,
}

/// Ollama non-streaming response
#[derive(Deserialize, Debug)]
pub struct OllamaGenerateResponse {
    #[serde(default)]
    pub response: String,
}

/// Ollama model info from /api/tags
#[derive(Deserialize, Debug, Clone)]
pub struct OllamaModel {
    pub name: String,
}

/// Response from /api/tags
#[derive(Deserialize, Debug)]
pub struct OllamaTagsResponse {
    #[serde(default)]
    pub models: Vec<OllamaModel>,
}

/// Model with detected capabilities
#[derive(Clone, Debug)]
pub struct OllamaModelWithCaps {
    pub name: String,
    pub has_vision: bool,
}

/// Response from /api/show
#[derive(Deserialize, Debug)]
struct OllamaShowResponse {
    #[serde(default)]
    pub modelfile: String,
    #[serde(default)]
    pub details: OllamaModelDetails,
}

#[derive(Deserialize, Debug, Default)]
struct OllamaModelDetails {
    #[serde(default)]
    pub families: Vec<String>,
}

/// Fetch available models from Ollama
pub fn fetch_ollama_models(base_url: &str) -> Result<Vec<OllamaModel>> {
    let url = format!("{}/api/tags", base_url.trim_end_matches('/'));
    
    let resp = UREQ_AGENT.get(&url)
        
                .call()
        .map_err(|e| anyhow::anyhow!("Failed to connect to Ollama: {}", e))?;
    
    let tags: OllamaTagsResponse = resp.into_body().read_json()
        .map_err(|e| anyhow::anyhow!("Failed to parse Ollama response: {}", e))?;
    
    Ok(tags.models)
}

/// Check if a model has vision capability by querying /api/show
fn check_model_has_vision(base_url: &str, model_name: &str) -> bool {
    let url = format!("{}/api/show", base_url.trim_end_matches('/'));
    
    let payload = serde_json::json!({
        "name": model_name
    });
    
    let resp = match UREQ_AGENT.post(&url)
        
                .send_json(&payload) {
            Ok(r) => r,
            Err(_) => return false,
        };
    
    if let Ok(show_resp) = resp.into_body().read_json::<OllamaShowResponse>() {
        // Check families for vision-related names
        let families_str = show_resp.details.families.join(" ").to_lowercase();
        if families_str.contains("clip") || families_str.contains("vision") {
            return true;
        }
        
        // Check modelfile for projector (indicates vision capability)
        let modelfile_lower = show_resp.modelfile.to_lowercase();
        if modelfile_lower.contains("projector") || modelfile_lower.contains("vision") {
            return true;
        }
        
        // Check model name patterns for common vision models
        let name_lower = model_name.to_lowercase();
        if name_lower.contains("vision") || name_lower.contains("-vl") || 
           name_lower.contains("llava") || name_lower.contains("bakllava") ||
           name_lower.contains("moondream") || name_lower.contains("minicpm-v") {
            return true;
        }
    }
    
    false
}

/// Fetch models with their capabilities (vision/text)
pub fn fetch_ollama_models_with_caps(base_url: &str) -> Result<Vec<OllamaModelWithCaps>> {
    let models = fetch_ollama_models(base_url)?;
    
    let mut result = Vec::new();
    for model in models {
        let has_vision = check_model_has_vision(base_url, &model.name);
        result.push(OllamaModelWithCaps {
            name: model.name,
            has_vision,
        });
    }
    
    Ok(result)
}


/// Generate text with Ollama (text-only, no image)
pub fn ollama_generate_text<F>(
    base_url: &str,
    model: &str,
    prompt: &str,
    streaming_enabled: bool,
    ui_language: &str,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(&str),
{
    let url = format!("{}/api/generate", base_url.trim_end_matches('/'));
    
    let payload = serde_json::json!({
        "model": model,
        "prompt": prompt,
        "stream": streaming_enabled
    });
    
    let resp = UREQ_AGENT.post(&url)
        
                .send_json(&payload)
        .map_err(|e| anyhow::anyhow!("Ollama API Error: {}", e))?;
    
    let mut full_content = String::new();
    
    if streaming_enabled {
        let reader = BufReader::new(resp.into_body().into_reader());
        let mut thinking_shown = false;
        let mut content_started = false;
        let locale = LocaleText::get(ui_language);
        
        for line in reader.lines() {
            let line = line?;
            if line.is_empty() { continue; }
            
            match serde_json::from_str::<OllamaStreamChunk>(&line) {
                Ok(chunk) => {
                    // Handle thinking tokens (qwen3 and similar models)
                    if let Some(thinking) = &chunk.thinking {
                        if !thinking.is_empty() && !thinking_shown && !content_started {
                            on_chunk(locale.model_thinking);
                            thinking_shown = true;
                        }
                    }
                    
                    // Handle response content
                    if !chunk.response.is_empty() {
                        if !content_started && thinking_shown {
                            // Wipe thinking message on first content
                            content_started = true;
                            full_content.push_str(&chunk.response);
                            let wipe_content = format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                            on_chunk(&wipe_content);
                        } else {
                            content_started = true;
                            full_content.push_str(&chunk.response);
                            on_chunk(&chunk.response);
                        }
                    }
                    
                    if chunk.done {
                        break;
                    }
                }
                Err(_) => continue,
            }
        }
    } else {
        let ollama_resp: OllamaGenerateResponse = resp.into_body().read_json()
            .map_err(|e| anyhow::anyhow!("Failed to parse Ollama response: {}", e))?;
        
        full_content = ollama_resp.response;
        on_chunk(&full_content);
    }
    
    Ok(full_content)
}

/// Generate with Ollama vision model (image + text)
pub fn ollama_generate_vision<F>(
    base_url: &str,
    model: &str,
    prompt: &str,
    image: ImageBuffer<Rgba<u8>, Vec<u8>>,
    streaming_enabled: bool,
    ui_language: &str,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(&str),
{
    let url = format!("{}/api/generate", base_url.trim_end_matches('/'));
    
    // Encode image as base64 PNG
    let mut image_data = Vec::new();
    image.write_to(&mut Cursor::new(&mut image_data), image::ImageFormat::Png)?;
    let b64_image = general_purpose::STANDARD.encode(&image_data);
    
    let payload = serde_json::json!({
        "model": model,
        "prompt": prompt,
        "images": [b64_image],
        "stream": streaming_enabled
    });
    
    let resp = UREQ_AGENT.post(&url)
        
                .send_json(&payload)
        .map_err(|e| anyhow::anyhow!("Ollama Vision API Error: {}", e))?;
    
    let mut full_content = String::new();
    
    if streaming_enabled {
        let reader = BufReader::new(resp.into_body().into_reader());
        let mut thinking_shown = false;
        let mut content_started = false;
        let locale = LocaleText::get(ui_language);
        
        for line in reader.lines() {
            let line = line?;
            if line.is_empty() { continue; }
            
            match serde_json::from_str::<OllamaStreamChunk>(&line) {
                Ok(chunk) => {
                    // Handle thinking tokens
                    if let Some(thinking) = &chunk.thinking {
                        if !thinking.is_empty() && !thinking_shown && !content_started {
                            on_chunk(locale.model_thinking);
                            thinking_shown = true;
                        }
                    }
                    
                    // Handle response content
                    if !chunk.response.is_empty() {
                        if !content_started && thinking_shown {
                            content_started = true;
                            full_content.push_str(&chunk.response);
                            let wipe_content = format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                            on_chunk(&wipe_content);
                        } else {
                            content_started = true;
                            full_content.push_str(&chunk.response);
                            on_chunk(&chunk.response);
                        }
                    }
                    
                    if chunk.done {
                        break;
                    }
                }
                Err(_) => continue,
            }
        }
    } else {
        let ollama_resp: OllamaGenerateResponse = resp.into_body().read_json()
            .map_err(|e| anyhow::anyhow!("Failed to parse Ollama response: {}", e))?;
        
        full_content = ollama_resp.response;
        on_chunk(&full_content);
    }
    
    Ok(full_content)
}
</file>

<file path="src/api/realtime_audio/capture.rs">
//! Audio capture implementations: per-app WASAPI, device loopback, and microphone

use anyhow::Result;
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc, Mutex,
};
use std::time::Duration;

use super::REALTIME_RMS;

/// Start per-app audio capture using WASAPI process loopback (Windows 10 1903+)
///
/// This function spawns a thread that captures audio from a specific process
/// and pushes samples to the provided buffer.
#[cfg(target_os = "windows")]
pub fn start_per_app_capture(
    process_id: u32,
    audio_buffer: Arc<Mutex<Vec<i16>>>,
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
) -> Result<()> {
    use std::collections::VecDeque;
    use wasapi::{AudioClient, Direction, SampleType, StreamMode, WaveFormat};

    std::thread::spawn(move || {
        // Initialize COM for this thread (required for WASAPI)
        if wasapi::initialize_mta().is_err() {
            eprintln!("Per-app capture: Failed to initialize MTA");
            return;
        }

        // Create loopback capture client for the specified process
        // include_tree=true to include child processes (browsers often use separate audio processes)
        let audio_client = match AudioClient::new_application_loopback_client(process_id, true) {
            Ok(client) => client,
            Err(e) => {
                eprintln!(
                    "Per-app capture: Failed to create loopback client for PID {}: {:?}",
                    process_id, e
                );
                return;
            }
        };

        // Configure desired format: 16kHz mono 16-bit (what Gemini expects)
        // With autoconvert=true, Windows will handle resampling from the app's native format
        let desired_format = WaveFormat::new(
            16, // bits per sample
            16, // valid bits
            &SampleType::Int,
            16000, // 16kHz sample rate
            1,     // mono
            None,
        );

        // Buffer duration: 100ms in 100-nanosecond units
        let buffer_duration_hns = 1_000_000i64; // 100ms

        // Configure stream mode with auto-conversion
        let mode = StreamMode::EventsShared {
            autoconvert: true,
            buffer_duration_hns,
        };

        let mut audio_client = audio_client;
        if let Err(e) = audio_client.initialize_client(&desired_format, &Direction::Capture, &mode)
        {
            eprintln!(
                "Per-app capture: Failed to initialize audio client: {:?}",
                e
            );
            eprintln!("Hint: Per-app capture requires Windows 10 version 1903 or later");
            return;
        }

        // Get the capture client interface
        let capture_client = match audio_client.get_audiocaptureclient() {
            Ok(client) => client,
            Err(e) => {
                eprintln!("Per-app capture: Failed to get capture client: {:?}", e);
                return;
            }
        };

        // Get event handle for efficient waiting
        let event_handle = match audio_client.set_get_eventhandle() {
            Ok(handle) => handle,
            Err(e) => {
                eprintln!("Per-app capture: Failed to get event handle: {:?}", e);
                return;
            }
        };

        // Start the audio stream
        if let Err(e) = audio_client.start_stream() {
            eprintln!("Per-app capture: Failed to start stream: {:?}", e);
            return;
        }

        // Per-app capture started for process_id

        // Buffer for reading audio data
        let mut capture_buffer: VecDeque<u8> = VecDeque::new();

        // Capture loop
        while !stop_signal.load(Ordering::Relaxed) {
            if pause_signal.load(Ordering::Relaxed) {
                std::thread::sleep(Duration::from_millis(100));
                continue;
            }
            // Wait for buffer to be ready (up to 100ms timeout)
            if event_handle.wait_for_event(100).is_err() {
                continue; // Timeout, check stop signal and try again
            }

            // Read captured data
            match capture_client.read_from_device_to_deque(&mut capture_buffer) {
                Ok(_buffer_info) => {
                    // Check if we received any data
                    if !capture_buffer.is_empty() {
                        // Convert bytes to i16 samples (16-bit = 2 bytes per sample)
                        // Format is 16-bit mono at 16kHz
                        let bytes_per_sample = 2;
                        let sample_count = capture_buffer.len() / bytes_per_sample;

                        if sample_count > 0 {
                            // Drain buffer and convert to i16
                            let mut samples: Vec<i16> = Vec::with_capacity(sample_count);

                            while capture_buffer.len() >= bytes_per_sample {
                                let low = capture_buffer.pop_front().unwrap_or(0);
                                let high = capture_buffer.pop_front().unwrap_or(0);
                                let sample = i16::from_le_bytes([low, high]);
                                samples.push(sample);
                            }

                            // Audio received from per-app capture - add to buffer

                            // Push to shared audio buffer
                            if let Ok(mut buf) = audio_buffer.lock() {
                                buf.extend(&samples);
                            }

                            // Calculate RMS for volume visualization
                            if !samples.is_empty() {
                                let sum_sq: f64 =
                                    samples.iter().map(|&s| (s as f64 / 32768.0).powi(2)).sum();
                                let rms = (sum_sq / samples.len() as f64).sqrt() as f32;
                                REALTIME_RMS.store(rms.to_bits(), Ordering::Relaxed);
                            }
                        }
                    }
                }
                Err(e) => {
                    // Check for specific errors that indicate process ended or connection lost
                    eprintln!("Per-app capture: Read error: {:?}", e);
                    // Small delay before retrying
                    std::thread::sleep(Duration::from_millis(10));
                }
            }
        }

        // Cleanup
        let _ = audio_client.stop_stream();
        // Per-app capture stopped
    });

    Ok(())
}

/// Start device loopback capture (captures all system audio)
/// Returns the cpal Stream that must be kept alive
pub fn start_device_loopback_capture(
    audio_buffer: Arc<Mutex<Vec<i16>>>,
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
) -> Result<cpal::Stream> {
    #[cfg(target_os = "windows")]
    let host = cpal::host_from_id(cpal::HostId::Wasapi).unwrap_or(cpal::default_host());
    #[cfg(not(target_os = "windows"))]
    let host = cpal::default_host();

    // Use default output device for loopback
    let device = host
        .default_output_device()
        .ok_or_else(|| anyhow::anyhow!("No output device available"))?;
    let config = device.default_output_config()?;

    let sample_rate = config.sample_rate();
    let channels = config.channels() as usize;

    let audio_buffer_clone = audio_buffer.clone();

    // Resample to 16kHz if needed
    let target_rate = 16000u32;
    let resample_ratio = target_rate as f64 / sample_rate as f64;

    let stop_signal_audio = stop_signal.clone();
    let pause_signal_audio = pause_signal.clone();
    let err_fn = |err| eprintln!("Audio stream error: {}", err);

    let stream = match config.sample_format() {
        cpal::SampleFormat::F32 => device.build_input_stream(
            &config.into(),
            move |data: &[f32], _: &_| {
                if stop_signal_audio.load(Ordering::Relaxed)
                    || pause_signal_audio.load(Ordering::Relaxed)
                {
                    return;
                }

                // Convert to mono and i16
                let mono_samples: Vec<i16> = data
                    .chunks(channels)
                    .map(|frame| {
                        let sum: f32 = frame.iter().sum();
                        let avg = sum / channels as f32;
                        (avg.clamp(-1.0, 1.0) * i16::MAX as f32) as i16
                    })
                    .collect();

                // Simple resampling (linear interpolation)
                let resampled: Vec<i16> = if resample_ratio < 1.0 {
                    let new_len = (mono_samples.len() as f64 * resample_ratio) as usize;
                    (0..new_len)
                        .map(|i| {
                            let src_idx = i as f64 / resample_ratio;
                            let idx0 = src_idx as usize;
                            let idx1 = (idx0 + 1).min(mono_samples.len() - 1);
                            let frac = src_idx - idx0 as f64;
                            let s0 = mono_samples[idx0] as f64;
                            let s1 = mono_samples[idx1] as f64;
                            (s0 + (s1 - s0) * frac) as i16
                        })
                        .collect()
                } else {
                    mono_samples
                };

                if let Ok(mut buf) = audio_buffer_clone.lock() {
                    buf.extend(resampled.iter().cloned());
                }

                // Calculate RMS for volume visualization
                if !resampled.is_empty() {
                    let sum_sq: f64 = resampled
                        .iter()
                        .map(|&s| (s as f64 / 32768.0).powi(2))
                        .sum();
                    let rms = (sum_sq / resampled.len() as f64).sqrt() as f32;
                    REALTIME_RMS.store(rms.to_bits(), Ordering::Relaxed);
                }
            },
            err_fn,
            None,
        )?,
        cpal::SampleFormat::I16 => device.build_input_stream(
            &config.into(),
            move |data: &[i16], _: &_| {
                if stop_signal_audio.load(Ordering::Relaxed)
                    || pause_signal_audio.load(Ordering::Relaxed)
                {
                    return;
                }

                // Convert to mono
                let mono_samples: Vec<i16> = data
                    .chunks(channels)
                    .map(|frame| {
                        let sum: i32 = frame.iter().map(|&s| s as i32).sum();
                        (sum / channels as i32) as i16
                    })
                    .collect();

                // Simple resampling
                let resampled: Vec<i16> = if resample_ratio < 1.0 {
                    let new_len = (mono_samples.len() as f64 * resample_ratio) as usize;
                    (0..new_len)
                        .map(|i| {
                            let src_idx = i as f64 / resample_ratio;
                            let idx0 = src_idx as usize;
                            let idx1 = (idx0 + 1).min(mono_samples.len() - 1);
                            let frac = src_idx - idx0 as f64;
                            let s0 = mono_samples[idx0] as f64;
                            let s1 = mono_samples[idx1] as f64;
                            (s0 + (s1 - s0) * frac) as i16
                        })
                        .collect()
                } else {
                    mono_samples
                };

                if let Ok(mut buf) = audio_buffer_clone.lock() {
                    buf.extend(resampled.iter().cloned());
                }

                // Calculate RMS for volume visualization
                if !resampled.is_empty() {
                    let sum_sq: f64 = resampled
                        .iter()
                        .map(|&s| (s as f64 / 32768.0).powi(2))
                        .sum();
                    let rms = (sum_sq / resampled.len() as f64).sqrt() as f32;
                    REALTIME_RMS.store(rms.to_bits(), Ordering::Relaxed);
                }
            },
            err_fn,
            None,
        )?,
        _ => return Err(anyhow::anyhow!("Unsupported audio format")),
    };

    stream.play()?;
    Ok(stream)
}

/// Start microphone capture
/// Returns the cpal Stream that must be kept alive
pub fn start_mic_capture(
    audio_buffer: Arc<Mutex<Vec<i16>>>,
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
) -> Result<cpal::Stream> {
    let host = cpal::default_host();
    let device = host
        .default_input_device()
        .ok_or_else(|| anyhow::anyhow!("No microphone available. Please connect a microphone."))?;
    let config = device.default_input_config()?;

    let sample_rate = config.sample_rate();
    let channels = config.channels() as usize;
    let audio_buffer_clone = audio_buffer.clone();
    let target_rate = 16000u32;
    let resample_ratio = target_rate as f64 / sample_rate as f64;
    let stop_signal_audio = stop_signal.clone();
    let pause_signal_audio = pause_signal.clone();
    let err_fn = |err| eprintln!("Audio stream error: {}", err);

    let stream = match config.sample_format() {
        cpal::SampleFormat::F32 => device.build_input_stream(
            &config.into(),
            move |data: &[f32], _: &_| {
                if stop_signal_audio.load(Ordering::Relaxed)
                    || pause_signal_audio.load(Ordering::Relaxed)
                {
                    return;
                }

                let mono_samples: Vec<i16> = data
                    .chunks(channels)
                    .map(|frame| {
                        let sum: f32 = frame.iter().sum();
                        let avg = sum / channels as f32;
                        (avg.clamp(-1.0, 1.0) * i16::MAX as f32) as i16
                    })
                    .collect();

                let resampled: Vec<i16> = if resample_ratio < 1.0 {
                    let new_len = (mono_samples.len() as f64 * resample_ratio) as usize;
                    (0..new_len)
                        .map(|i| {
                            let src_idx = i as f64 / resample_ratio;
                            let idx0 = src_idx as usize;
                            let idx1 = (idx0 + 1).min(mono_samples.len() - 1);
                            let frac = src_idx - idx0 as f64;
                            let s0 = mono_samples[idx0] as f64;
                            let s1 = mono_samples[idx1] as f64;
                            (s0 + frac * (s1 - s0)) as i16
                        })
                        .collect()
                } else {
                    mono_samples
                };

                if let Ok(mut buf) = audio_buffer_clone.lock() {
                    buf.extend(resampled.iter().cloned());
                }

                if !resampled.is_empty() {
                    let sum_sq: f64 = resampled
                        .iter()
                        .map(|&s| (s as f64 / 32768.0).powi(2))
                        .sum();
                    let rms = (sum_sq / resampled.len() as f64).sqrt() as f32;
                    REALTIME_RMS.store(rms.to_bits(), Ordering::Relaxed);
                }
            },
            err_fn,
            None,
        )?,
        _ => return Err(anyhow::anyhow!("Unsupported audio format")),
    };

    stream.play()?;
    Ok(stream)
}
</file>

<file path="src/api/realtime_audio/model_loader.rs">
use anyhow::{anyhow, Result};
use std::fs;
use std::io::Read;
use std::path::{Path, PathBuf};

// Helper function to download file or read local file
pub fn download_file(
    url: &str,
    path: &Path,
    stop_signal: &std::sync::atomic::AtomicBool,
    use_badge: bool,
) -> Result<()> {
    if path.exists() {
        return Ok(());
    }

    if let Some(parent) = path.parent() {
        fs::create_dir_all(parent)?;
    }

    use std::io::Write;

    println!("Downloading file from: {}", url);
    let response = ureq::get(url)
        .header("User-Agent", "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36")
        .call()
        .map_err(|e| anyhow!("Download failed: {}", e))?;

    let total_size = response
        .headers()
        .get("content-length")
        .and_then(|h| h.to_str().ok())
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(0);

    let mut reader = response.into_body().into_reader();
    let mut file = fs::File::create(path)?;

    let mut buffer = [0; 8192];
    let mut downloaded: u64 = 0;

    let update_interval = std::time::Duration::from_millis(100);
    let mut last_update = std::time::Instant::now();

    loop {
        if stop_signal.load(std::sync::atomic::Ordering::Relaxed) {
            let _ = fs::remove_file(path);
            return Err(anyhow!("Download cancelled"));
        }

        let bytes_read = reader.read(&mut buffer)?;
        if bytes_read == 0 {
            break;
        }
        file.write_all(&buffer[..bytes_read])?;
        downloaded += bytes_read as u64;

        if total_size > 0 && last_update.elapsed() >= update_interval {
            let progress = (downloaded as f32 / total_size as f32) * 100.0;

            if use_badge {
                let msg = format!("Downloading... {:.0}%", progress);
                crate::overlay::auto_copy_badge::show_notification(&msg);
            }

            use crate::overlay::realtime_webview::state::REALTIME_STATE;
            if let Ok(mut state) = REALTIME_STATE.lock() {
                state.download_progress = progress;
            }
            last_update = std::time::Instant::now();

            use super::WM_DOWNLOAD_PROGRESS;
            use crate::overlay::realtime_webview::state::REALTIME_HWND;
            use windows::Win32::Foundation::{LPARAM, WPARAM};
            use windows::Win32::UI::WindowsAndMessaging::PostMessageW;

            unsafe {
                if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                    let _ = PostMessageW(
                        Some(REALTIME_HWND),
                        WM_DOWNLOAD_PROGRESS,
                        WPARAM(0),
                        LPARAM(0),
                    );
                }
            }
        }
    }

    Ok(())
}

pub fn get_parakeet_model_dir() -> PathBuf {
    dirs::data_dir()
        .unwrap_or_else(|| PathBuf::from("."))
        .join("screen-goated-toolbox")
        .join("models")
        .join("parakeet")
}

pub fn is_model_downloaded() -> bool {
    let dir = get_parakeet_model_dir();
    dir.join("encoder.onnx").exists()
        && dir.join("decoder_joint.onnx").exists()
        && dir.join("tokenizer.json").exists()
}

pub fn download_parakeet_model(
    stop_signal: std::sync::Arc<std::sync::atomic::AtomicBool>,
    use_badge: bool,
) -> Result<()> {
    let dir = get_parakeet_model_dir();

    let locale = {
        let app = crate::APP.lock().unwrap();
        crate::gui::locale::LocaleText::get(&app.config.ui_language)
    };

    use crate::overlay::realtime_webview::state::REALTIME_STATE;
    if let Ok(mut state) = REALTIME_STATE.lock() {
        state.is_downloading = true;
        state.download_title = locale.parakeet_downloading_title.to_string();
        state.download_message = locale.parakeet_downloading_message.to_string();
        state.download_progress = 0.0;
    }

    use super::WM_DOWNLOAD_PROGRESS;
    use crate::overlay::realtime_webview::state::REALTIME_HWND;
    use windows::Win32::Foundation::{LPARAM, WPARAM};
    use windows::Win32::UI::WindowsAndMessaging::PostMessageW;

    println!("Parakeet model not found, starting download. Modal should appear now...");

    // Small delay to ensure WebView is ready to receive the message
    std::thread::sleep(std::time::Duration::from_millis(100));

    // Send the message multiple times initially to ensure WebView receives it
    for _ in 0..3 {
        unsafe {
            if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                let _ = PostMessageW(
                    Some(REALTIME_HWND),
                    WM_DOWNLOAD_PROGRESS,
                    WPARAM(0),
                    LPARAM(0),
                );
            }
        }
        std::thread::sleep(std::time::Duration::from_millis(50));
    }

    let result = (|| {
        let files_to_download = vec![
             ("encoder.onnx", "https://huggingface.co/altunenes/parakeet-rs/resolve/main/realtime_eou_120m-v1-onnx/encoder.onnx"),
             ("decoder_joint.onnx", "https://huggingface.co/altunenes/parakeet-rs/resolve/main/realtime_eou_120m-v1-onnx/decoder_joint.onnx"),
             ("tokenizer.json", "https://huggingface.co/altunenes/parakeet-rs/resolve/main/realtime_eou_120m-v1-onnx/tokenizer.json"),
        ];

        for (filename, url) in files_to_download {
            if let Ok(mut state) = REALTIME_STATE.lock() {
                state.download_message = locale.parakeet_downloading_file.replace("{}", filename);
            }
            unsafe {
                if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                    let _ = PostMessageW(
                        Some(REALTIME_HWND),
                        WM_DOWNLOAD_PROGRESS,
                        WPARAM(0),
                        LPARAM(0),
                    );
                }
            }

            download_file(url, &dir.join(filename), &stop_signal, use_badge)?;
        }

        Ok(())
    })();

    if let Ok(mut state) = REALTIME_STATE.lock() {
        state.is_downloading = false;
    }
    unsafe {
        if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
            let _ = PostMessageW(
                Some(REALTIME_HWND),
                WM_DOWNLOAD_PROGRESS,
                WPARAM(0),
                LPARAM(0),
            );
        }
    }

    result
}
</file>

<file path="src/api/realtime_audio/parakeet.rs">
use super::state::{RealtimeState, TranscriptionMethod};
use crate::config::Preset;
use anyhow::Result;
use parakeet_rs::{ExecutionConfig, ExecutionProvider, ParakeetEOU};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::{Arc, Mutex};
use windows::Win32::Foundation::HWND;
use windows::Win32::Foundation::LPARAM;
use windows::Win32::Foundation::WPARAM;
use windows::Win32::UI::WindowsAndMessaging::PostMessageW;

use super::{REALTIME_RMS, WM_REALTIME_UPDATE, WM_VOLUME_UPDATE};
use crate::overlay::realtime_webview::AUDIO_SOURCE_CHANGE;

/// 160ms chunk at 16kHz = 2560 samples (recommended by parakeet-rs)
const CHUNK_SIZE: usize = 2560;

/// Wrapper for the existing Realtime Overlay functionality
pub fn run_parakeet_transcription(
    _preset: Preset,
    stop_signal: Arc<AtomicBool>,
    dummy_pause_signal: Arc<AtomicBool>,
    full_audio_buffer: Option<Arc<Mutex<Vec<i16>>>>,
    hide_recording_ui: bool,
    hwnd_overlay: Option<HWND>,
    state: Arc<Mutex<RealtimeState>>,
) -> Result<()> {
    // Set state early (best effort)
    if let Ok(mut s) = state.lock() {
        s.set_transcription_method(TranscriptionMethod::Parakeet);
    }

    run_parakeet_session(
        stop_signal.clone(),
        dummy_pause_signal,
        full_audio_buffer,
        hwnd_overlay, // Send volume updates to overlay
        hide_recording_ui,
        true,  // Don't show download badge (webview handles its own modal)
        None,  // Use global config
        false, // auto_stop_enabled - DISABLED for realtime mode to prevent killing the transcription thread on silence
        move |text| {
            // Callback for each text segment
            if let Ok(mut s) = state.lock() {
                s.append_transcript(&text);
            }
            // Notify overlay to update text
            if let Some(h) = hwnd_overlay {
                unsafe {
                    if !h.is_invalid() {
                        let _ = PostMessageW(Some(h), WM_REALTIME_UPDATE, WPARAM(0), LPARAM(0));
                    }
                }
            }
        },
    )
}

/// Generic Parakeet session that can be used by both Realtime Overlay and Prompt DJ
pub fn run_parakeet_session<F>(
    stop_signal: Arc<AtomicBool>,
    pause_signal: Arc<AtomicBool>,
    full_audio_buffer: Option<Arc<Mutex<Vec<i16>>>>,
    overlay_hwnd_opt: Option<HWND>,
    hide_recording_ui: bool,
    use_badge: bool,
    audio_source_override: Option<String>,
    auto_stop_recording: bool,
    mut callback: F,
) -> Result<()>
where
    F: FnMut(String),
{
    // 1. Check/Download Model
    if !super::model_loader::is_model_downloaded() {
        // Pass use_badge to download function
        match super::model_loader::download_parakeet_model(stop_signal.clone(), use_badge) {
            Ok(_) => {}
            Err(e) => {
                let err_msg = e.to_string();
                if err_msg.contains("cancelled") || stop_signal.load(Ordering::Relaxed) {
                    println!("Parakeet download was cancelled by user");
                    return Ok(());
                }
                return Err(e);
            }
        }
        if stop_signal.load(Ordering::Relaxed) {
            return Ok(());
        }
    }

    // 2. Load Model
    let model_dir = super::model_loader::get_parakeet_model_dir();
    let config = ExecutionConfig::new().with_execution_provider(ExecutionProvider::DirectML);

    let mut parakeet = ParakeetEOU::from_pretrained(&model_dir, Some(config))
        .map_err(|e| anyhow::anyhow!("Failed to load Parakeet model: {:?}", e))?;

    // 3. Audio Setup
    let audio_buffer: Arc<Mutex<Vec<i16>>> = Arc::new(Mutex::new(Vec::new()));

    let (audio_source, check_per_app) = if let Some(s) = audio_source_override {
        (s, false)
    } else {
        let app = crate::APP.lock().unwrap();
        (app.config.realtime_audio_source.clone(), true)
    };

    use crate::overlay::realtime_webview::{REALTIME_TTS_ENABLED, SELECTED_APP_PID};
    let tts_enabled = REALTIME_TTS_ENABLED.load(Ordering::SeqCst);
    let selected_pid = SELECTED_APP_PID.load(Ordering::SeqCst);

    let using_per_app_capture =
        check_per_app && audio_source == "device" && tts_enabled && selected_pid > 0;

    let _stream = if using_per_app_capture {
        #[cfg(target_os = "windows")]
        {
            super::capture::start_per_app_capture(
                selected_pid,
                audio_buffer.clone(),
                stop_signal.clone(),
                pause_signal.clone(),
            )?;
            None
        }
        #[cfg(not(target_os = "windows"))]
        {
            None
        }
    } else if audio_source == "mic" {
        Some(super::capture::start_mic_capture(
            audio_buffer.clone(),
            stop_signal.clone(),
            pause_signal.clone(),
        )?)
    } else if audio_source == "device" && tts_enabled && selected_pid == 0 {
        None
    } else {
        Some(super::capture::start_device_loopback_capture(
            audio_buffer.clone(),
            stop_signal.clone(),
            pause_signal.clone(),
        )?)
    };

    let mut sample_accumulator: Vec<f32> = Vec::with_capacity(CHUNK_SIZE * 2);

    let mut has_spoken = false;
    let mut last_active = std::time::Instant::now();
    let mut first_speech: Option<std::time::Instant> = None;

    // 4. Processing Loop
    while !stop_signal.load(Ordering::Relaxed) {
        if !hide_recording_ui {
            if let Some(hwnd) = overlay_hwnd_opt {
                if unsafe {
                    !windows::Win32::UI::WindowsAndMessaging::IsWindow(Some(hwnd)).as_bool()
                } {
                    break;
                }
            }
        }
        if pause_signal.load(Ordering::Relaxed) {
            std::thread::sleep(std::time::Duration::from_millis(50));
            continue;
        }
        if AUDIO_SOURCE_CHANGE.load(Ordering::SeqCst)
            || crate::overlay::realtime_webview::TRANSCRIPTION_MODEL_CHANGE.load(Ordering::SeqCst)
        {
            break;
        }

        let new_samples: Vec<f32> = {
            let mut buf = audio_buffer.lock().unwrap();
            if !buf.is_empty() {
                buf.drain(..).map(|s| s as f32 / 32768.0).collect()
            } else {
                Vec::new()
            }
        };

        if !new_samples.is_empty() {
            // Volume Visualization
            let sum_sq: f64 = new_samples.iter().map(|&s| (s as f64).powi(2)).sum();
            let rms = (sum_sq / new_samples.len() as f64).sqrt() as f32;
            REALTIME_RMS.store(rms.to_bits(), Ordering::Relaxed);
            // Also update recording overlay viz
            crate::overlay::recording::update_audio_viz(rms);
            if rms > 0.001 {
                crate::overlay::recording::AUDIO_WARMUP_COMPLETE.store(true, Ordering::SeqCst);
            }

            if auto_stop_recording {
                if rms > 0.015 {
                    last_active = std::time::Instant::now();
                    if !has_spoken {
                        has_spoken = true;
                        first_speech = Some(std::time::Instant::now());
                    }
                } else if has_spoken {
                    if let Some(start) = first_speech {
                        if last_active.elapsed().as_millis() > 800
                            && start.elapsed().as_millis() > 2000
                        {
                            stop_signal.store(true, Ordering::SeqCst);
                            break;
                        }
                    }
                }
            }

            if let Some(hwnd) = overlay_hwnd_opt {
                unsafe {
                    if !hwnd.is_invalid() {
                        let _ = PostMessageW(Some(hwnd), WM_VOLUME_UPDATE, WPARAM(0), LPARAM(0));
                    }
                }
            }

            if let Some(full_buf) = &full_audio_buffer {
                if let Ok(mut full) = full_buf.lock() {
                    full.extend(new_samples.iter().map(|&s| (s * 32768.0) as i16));
                }
            }

            sample_accumulator.extend(new_samples);
        }

        while sample_accumulator.len() >= CHUNK_SIZE {
            let chunk: Vec<f32> = sample_accumulator.drain(..CHUNK_SIZE).collect();

            match parakeet.transcribe(&chunk, false) {
                Ok(text) => {
                    if !text.is_empty() {
                        let processed = process_sentencepiece_text(&text);
                        if !processed.is_empty() {
                            callback(processed);
                        }
                    }
                }
                Err(e) => {
                    eprintln!("Parakeet transcription error: {:?}", e);
                }
            }
        }

        std::thread::sleep(std::time::Duration::from_millis(10));
    }

    // Flush
    let silence = vec![0.0f32; CHUNK_SIZE];
    for _ in 0..3 {
        if let Ok(text) = parakeet.transcribe(&silence, false) {
            if !text.is_empty() {
                let processed = process_sentencepiece_text(&text);
                if !processed.is_empty() {
                    callback(processed);
                }
            }
        }
    }

    Ok(())
}

fn process_sentencepiece_text(text: &str) -> String {
    let starts_with_word = text.starts_with('\u{2581}') || text.starts_with('▁');
    let processed = text.replace('\u{2581}', " ").replace('▁', " ");
    let processed = processed.trim();

    if processed.is_empty() {
        return String::new();
    }

    if starts_with_word {
        format!(" {}", processed)
    } else {
        processed.to_string()
    }
}
</file>

<file path="src/api/realtime_audio/transcription.rs">
//! Main transcription loop for realtime audio

use anyhow::Result;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc, Mutex,
};
use std::time::{Duration, Instant};
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use crate::config::Preset;
use crate::overlay::realtime_webview::SELECTED_APP_PID;
use crate::APP;

use super::capture::{start_device_loopback_capture, start_mic_capture, start_per_app_capture};
use super::state::SharedRealtimeState;
use super::translation::run_translation_loop;
use super::utils::update_overlay_text;
use super::websocket::{
    connect_websocket, parse_input_transcription, send_audio_chunk, send_setup_message,
    set_socket_nonblocking, set_socket_short_timeout,
};
use super::{REALTIME_RMS, WM_VOLUME_UPDATE};

/// Audio mode state machine for silence injection
#[derive(Clone, Copy, PartialEq)]
enum AudioMode {
    Normal,
    Silence,
    CatchUp,
}

/// Start realtime audio transcription
pub fn start_realtime_transcription(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    overlay_hwnd: HWND,
    translation_hwnd: Option<HWND>,
    state: SharedRealtimeState,
) {
    let overlay_send = crate::win_types::SendHwnd(overlay_hwnd);
    let translation_send = translation_hwnd.map(crate::win_types::SendHwnd);

    // Spawn translation thread if needed (Independent of transcription model)
    let has_translation = translation_hwnd.is_some() && preset.blocks.len() > 1;
    if has_translation {
        let t_send = translation_send.clone().unwrap();
        let t_state = state.clone();
        let t_stop = stop_signal.clone();
        let t_preset = preset.clone();

        std::thread::spawn(move || {
            run_translation_loop(t_preset, t_stop, t_send, t_state);
        });
    }

    std::thread::spawn(move || {
        transcription_thread_entry(preset, stop_signal, overlay_send, translation_send, state);
    });
}

fn transcription_thread_entry(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    overlay_send: crate::win_types::SendHwnd,
    translation_send: Option<crate::win_types::SendHwnd>,
    state: SharedRealtimeState,
) {
    let hwnd_overlay = overlay_send.0;
    let hwnd_translation = translation_send.map(|h| h.0);

    use crate::overlay::realtime_webview::{
        AUDIO_SOURCE_CHANGE, NEW_AUDIO_SOURCE, NEW_TRANSCRIPTION_MODEL, TRANSCRIPTION_MODEL_CHANGE,
    };

    let mut current_preset = preset;

    loop {
        AUDIO_SOURCE_CHANGE.store(false, Ordering::SeqCst);
        TRANSCRIPTION_MODEL_CHANGE.store(false, Ordering::SeqCst);

        // Reset volume indicator to ensure fresh state when switching methods
        REALTIME_RMS.store(0, Ordering::SeqCst);

        let trans_model = {
            let app = APP.lock().unwrap();
            app.config.realtime_transcription_model.clone()
        };

        // Update state with selected method immediately (before potentially slow model loading)
        if let Ok(mut s) = state.lock() {
            if trans_model == "parakeet" {
                s.set_transcription_method(super::state::TranscriptionMethod::Parakeet);
            } else {
                s.set_transcription_method(super::state::TranscriptionMethod::GeminiLive);
            }
        }

        let result = if trans_model == "parakeet" {
            // println!(">>> Starting Parakeet transcription");
            let dummy_pause = Arc::new(AtomicBool::new(false));
            super::parakeet::run_parakeet_transcription(
                current_preset.clone(),
                stop_signal.clone(),
                dummy_pause,
                None,  // No full audio buffer for standard realtime
                false, // hide_recording_ui
                Some(hwnd_overlay),
                state.clone(),
            )
        } else {
            // println!(">>> Starting Gemini Live transcription");
            run_realtime_transcription(
                current_preset.clone(),
                stop_signal.clone(),
                hwnd_overlay,
                hwnd_translation,
                state.clone(),
            )
        };

        if let Err(e) = result {
            // Only show error if it's not a user-initiated action (model/source change, stop signal)
            let is_user_initiated = AUDIO_SOURCE_CHANGE.load(Ordering::SeqCst)
                || TRANSCRIPTION_MODEL_CHANGE.load(Ordering::SeqCst)
                || stop_signal.load(Ordering::Relaxed);

            if !is_user_initiated {
                let err_msg = format!(" [Error: {}]", e);
                eprintln!("Realtime transcription error: {}", e);

                // Append error to state so it's visible in the window
                if let Ok(mut s) = state.lock() {
                    s.append_transcript(&err_msg);
                }

                // Force immediate UI update
                let display_text = if let Ok(s) = state.lock() {
                    s.display_transcript.clone()
                } else {
                    String::new()
                };
                use super::utils::update_overlay_text;
                update_overlay_text(hwnd_overlay, &display_text);

                // Do NOT close the window - let the user see the error
            }
        }

        let restart_source = AUDIO_SOURCE_CHANGE.load(Ordering::SeqCst);
        let restart_model = TRANSCRIPTION_MODEL_CHANGE.load(Ordering::SeqCst);

        if restart_source {
            if let Ok(new_source) = NEW_AUDIO_SOURCE.lock() {
                if !new_source.is_empty() {
                    // println!("Changing audio source to: {}", new_source);
                    let mut app = APP.lock().unwrap();
                    app.config.realtime_audio_source = new_source.clone();
                    current_preset.audio_source = new_source.clone();
                    // Save config? Optional, but UI should sync.
                }
            }
        }

        if restart_model {
            if let Ok(new_model) = NEW_TRANSCRIPTION_MODEL.lock() {
                if !new_model.is_empty() {
                    // println!("Changing transcription model to: {}", new_model);
                    let mut app = APP.lock().unwrap();
                    app.config.realtime_transcription_model = new_model.clone();
                }
            }
        }

        // If a restart is triggered, reset stop signal to allow the new transcription to run
        if restart_source || restart_model {
            stop_signal.store(false, Ordering::SeqCst);
        }

        if !restart_source && !restart_model && stop_signal.load(Ordering::Relaxed) {
            break;
        }
        // If a restart is triggered (source or model changed), the loop continues.
        // Otherwise, if stop_signal is set, we break.
        // If neither, we also break, meaning the transcription loop only runs once
        // unless a restart is explicitly requested.
        if !restart_source && !restart_model {
            break;
        }
    }
}

fn run_realtime_transcription(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    overlay_hwnd: HWND,
    _translation_hwnd: Option<HWND>,
    state: SharedRealtimeState,
) -> Result<()> {
    let gemini_api_key = {
        let app = APP.lock().unwrap();
        app.config.gemini_api_key.clone()
    };

    if gemini_api_key.trim().is_empty() {
        return Err(anyhow::anyhow!("NO_API_KEY:google"));
    }

    // println!("Gemini: Connecting to WebSocket...");
    let mut socket = connect_websocket(&gemini_api_key)?;
    // println!("Gemini: Connected! Sending setup...");
    send_setup_message(&mut socket)?;
    // println!("Gemini: Setup sent, waiting for acknowledgment...");

    // Set transcription method to GeminiLive (uses delimiter-based segmentation)
    if let Ok(mut s) = state.lock() {
        s.set_transcription_method(super::state::TranscriptionMethod::GeminiLive);
    }

    // Set short timeout so we can check for model changes during setup
    set_socket_short_timeout(&mut socket)?;

    // Wait for setup acknowledgment
    let setup_start = Instant::now();
    loop {
        match socket.read() {
            Ok(tungstenite::Message::Text(msg)) => {
                let msg = msg.as_str();
                if msg.contains("setupComplete") {
                    break;
                }
                if msg.contains("error") || msg.contains("Error") {
                    return Err(anyhow::anyhow!("Server returned error: {}", msg));
                }
            }
            Ok(tungstenite::Message::Close(frame)) => {
                let close_info = frame
                    .map(|f| format!("code={}, reason={}", f.code, f.reason))
                    .unwrap_or("no frame".to_string());
                return Err(anyhow::anyhow!(
                    "Connection closed by server: {}",
                    close_info
                ));
            }
            Ok(tungstenite::Message::Binary(data)) => {
                if let Ok(text) = String::from_utf8(data.to_vec()) {
                    if text.contains("setupComplete") {
                        break;
                    }
                } else if data.len() < 100 {
                    break;
                }
            }
            Ok(_) => {}
            Err(tungstenite::Error::Io(ref e))
                if e.kind() == std::io::ErrorKind::WouldBlock
                    || e.kind() == std::io::ErrorKind::TimedOut =>
            {
                if setup_start.elapsed() > Duration::from_secs(30) {
                    return Err(anyhow::anyhow!("Setup timeout - no response from server"));
                }
                std::thread::sleep(Duration::from_millis(100));
            }
            Err(e) => {
                return Err(e.into());
            }
        }
        // Check for stop signal
        if stop_signal.load(Ordering::Relaxed) {
            return Ok(());
        }
        // Check for model change or audio source change signals
        use crate::overlay::realtime_webview::{AUDIO_SOURCE_CHANGE, TRANSCRIPTION_MODEL_CHANGE};
        if TRANSCRIPTION_MODEL_CHANGE.load(Ordering::SeqCst)
            || AUDIO_SOURCE_CHANGE.load(Ordering::SeqCst)
        {
            // println!("Gemini: Model/source change detected during setup, aborting...");
            return Ok(()); // Return cleanly to allow the outer loop to handle the change
        }
    }

    set_socket_nonblocking(&mut socket)?;

    let audio_buffer: Arc<Mutex<Vec<i16>>> = Arc::new(Mutex::new(Vec::new()));

    use crate::overlay::realtime_webview::REALTIME_TTS_ENABLED;
    let tts_enabled = REALTIME_TTS_ENABLED.load(Ordering::SeqCst);
    let selected_pid = SELECTED_APP_PID.load(Ordering::SeqCst);

    let using_per_app_capture = preset.audio_source == "device" && tts_enabled && selected_pid > 0;
    let using_device_loopback = preset.audio_source == "device" && !tts_enabled;

    let _stream: Option<cpal::Stream>;

    let dummy_pause = Arc::new(AtomicBool::new(false));

    if using_per_app_capture {
        #[cfg(target_os = "windows")]
        {
            start_per_app_capture(
                selected_pid,
                audio_buffer.clone(),
                stop_signal.clone(),
                dummy_pause.clone(),
            )?;
        }
        _stream = None;
    } else if using_device_loopback {
        _stream = Some(start_device_loopback_capture(
            audio_buffer.clone(),
            stop_signal.clone(),
            dummy_pause.clone(),
        )?);
    } else if preset.audio_source == "device" && tts_enabled && selected_pid == 0 {
        _stream = None;
    } else {
        _stream = Some(start_mic_capture(
            audio_buffer.clone(),
            stop_signal.clone(),
            dummy_pause.clone(),
        )?);
    }

    // Start translation thread if needed
    // NOTE: Translation thread is now spawned in `start_realtime_transcription`
    // to ensure it runs independent of the transcription model (Parakeet/Gemini).

    // Main loop
    run_main_loop(
        socket,
        audio_buffer,
        stop_signal,
        overlay_hwnd,
        state,
        &gemini_api_key,
    )?;

    drop(_stream);
    Ok(())
}

fn run_main_loop(
    mut socket: tungstenite::WebSocket<native_tls::TlsStream<std::net::TcpStream>>,
    audio_buffer: Arc<Mutex<Vec<i16>>>,
    stop_signal: Arc<AtomicBool>,
    overlay_hwnd: HWND,
    state: SharedRealtimeState,
    gemini_api_key: &str,
) -> Result<()> {
    let mut last_send = Instant::now();
    let send_interval = Duration::from_millis(100);

    let mut audio_mode = AudioMode::Normal;
    let mut mode_start = Instant::now();
    let mut silence_buffer: Vec<i16> = Vec::new();

    const NORMAL_DURATION: Duration = Duration::from_secs(20);
    const SILENCE_DURATION: Duration = Duration::from_secs(2);
    const SAMPLES_PER_100MS: usize = 1600;

    let mut last_transcription_time = Instant::now();
    let mut consecutive_empty_reads: u32 = 0;
    const NO_RESULT_THRESHOLD_SECS: u64 = 8;
    const EMPTY_READ_CHECK_COUNT: u32 = 50;

    while !stop_signal.load(Ordering::Relaxed) {
        if overlay_hwnd.0 != 0 as _ && !unsafe { IsWindow(Some(overlay_hwnd)).as_bool() } {
            stop_signal.store(true, Ordering::SeqCst);
            break;
        }

        {
            use crate::overlay::realtime_webview::{
                AUDIO_SOURCE_CHANGE, TRANSCRIPTION_MODEL_CHANGE,
            };
            if AUDIO_SOURCE_CHANGE.load(Ordering::SeqCst)
                || TRANSCRIPTION_MODEL_CHANGE.load(Ordering::SeqCst)
            {
                break;
            }
        }

        // State machine transitions
        match audio_mode {
            AudioMode::Normal => {
                if mode_start.elapsed() >= NORMAL_DURATION {
                    audio_mode = AudioMode::Silence;
                    mode_start = Instant::now();
                    silence_buffer.clear();
                }
            }
            AudioMode::Silence => {
                if mode_start.elapsed() >= SILENCE_DURATION {
                    audio_mode = AudioMode::CatchUp;
                    mode_start = Instant::now();
                }
            }
            AudioMode::CatchUp => {
                if silence_buffer.is_empty() {
                    audio_mode = AudioMode::Normal;
                    mode_start = Instant::now();
                }
            }
        }

        // Send audio
        if last_send.elapsed() >= send_interval {
            let real_audio: Vec<i16> = {
                let mut buf = audio_buffer.lock().unwrap();
                std::mem::take(&mut *buf)
            };

            match audio_mode {
                AudioMode::Normal => {
                    if !real_audio.is_empty() {
                        if send_audio_chunk(&mut socket, &real_audio).is_err() {
                            break;
                        }
                    }
                }
                AudioMode::Silence => {
                    silence_buffer.extend(real_audio);
                    let silence: Vec<i16> = vec![0i16; SAMPLES_PER_100MS];
                    if send_audio_chunk(&mut socket, &silence).is_err() {
                        break;
                    }
                }
                AudioMode::CatchUp => {
                    silence_buffer.extend(real_audio);
                    let chunk_size = SAMPLES_PER_100MS * 2;
                    let to_send: Vec<i16> = if silence_buffer.len() >= chunk_size {
                        silence_buffer.drain(..chunk_size).collect()
                    } else if !silence_buffer.is_empty() {
                        silence_buffer.drain(..).collect()
                    } else {
                        Vec::new()
                    };
                    if !to_send.is_empty() {
                        if send_audio_chunk(&mut socket, &to_send).is_err() {
                            break;
                        }
                    }
                }
            }
            last_send = Instant::now();
            unsafe {
                let _ = PostMessageW(Some(overlay_hwnd), WM_VOLUME_UPDATE, WPARAM(0), LPARAM(0));
            }
        }

        // Receive transcriptions
        match socket.read() {
            Ok(tungstenite::Message::Text(msg)) => {
                let msg = msg.as_str();
                if let Some(transcript) = parse_input_transcription(msg) {
                    if !transcript.is_empty() {
                        last_transcription_time = Instant::now();
                        consecutive_empty_reads = 0;
                        let display_text = if let Ok(mut s) = state.lock() {
                            s.append_transcript(&transcript);
                            s.display_transcript.clone()
                        } else {
                            String::new()
                        };
                        if !display_text.is_empty() {
                            update_overlay_text(overlay_hwnd, &display_text);
                        }
                    }
                }
            }
            Ok(tungstenite::Message::Binary(data)) => {
                if let Ok(text) = String::from_utf8(data.to_vec()) {
                    if let Some(transcript) = parse_input_transcription(&text) {
                        if !transcript.is_empty() {
                            last_transcription_time = Instant::now();
                            consecutive_empty_reads = 0;
                            let display_text = if let Ok(mut s) = state.lock() {
                                s.append_transcript(&transcript);
                                s.display_transcript.clone()
                            } else {
                                String::new()
                            };
                            if !display_text.is_empty() {
                                update_overlay_text(overlay_hwnd, &display_text);
                            }
                        }
                    }
                }
            }
            Ok(tungstenite::Message::Close(_)) => {
                if !try_reconnect(
                    &mut socket,
                    gemini_api_key,
                    &audio_buffer,
                    &mut silence_buffer,
                    &mut audio_mode,
                    &mut mode_start,
                    &mut last_transcription_time,
                    &mut consecutive_empty_reads,
                ) {
                    break;
                }
            }
            Ok(_) => {}
            Err(tungstenite::Error::Io(ref e))
                if e.kind() == std::io::ErrorKind::WouldBlock
                    || e.kind() == std::io::ErrorKind::TimedOut =>
            {
                consecutive_empty_reads += 1;
                if consecutive_empty_reads >= EMPTY_READ_CHECK_COUNT
                    && last_transcription_time.elapsed()
                        > Duration::from_secs(NO_RESULT_THRESHOLD_SECS)
                {
                    if !try_reconnect(
                        &mut socket,
                        gemini_api_key,
                        &audio_buffer,
                        &mut silence_buffer,
                        &mut audio_mode,
                        &mut mode_start,
                        &mut last_transcription_time,
                        &mut consecutive_empty_reads,
                    ) {
                        break;
                    }
                }
            }
            Err(e) => {
                let error_str = e.to_string();
                if error_str.contains("reset")
                    || error_str.contains("closed")
                    || error_str.contains("broken")
                {
                    if !try_reconnect(
                        &mut socket,
                        gemini_api_key,
                        &audio_buffer,
                        &mut silence_buffer,
                        &mut audio_mode,
                        &mut mode_start,
                        &mut last_transcription_time,
                        &mut consecutive_empty_reads,
                    ) {
                        break;
                    }
                } else {
                    break;
                }
            }
        }

        std::thread::sleep(Duration::from_millis(10));
    }

    let _ = socket.close(None);
    Ok(())
}

fn try_reconnect(
    socket: &mut tungstenite::WebSocket<native_tls::TlsStream<std::net::TcpStream>>,
    api_key: &str,
    audio_buffer: &Arc<Mutex<Vec<i16>>>,
    silence_buffer: &mut Vec<i16>,
    audio_mode: &mut AudioMode,
    mode_start: &mut Instant,
    last_transcription_time: &mut Instant,
    consecutive_empty_reads: &mut u32,
) -> bool {
    let mut reconnect_buffer: Vec<i16> = Vec::new();
    let _ = socket.close(None);

    for _attempt in 1..=3 {
        {
            let mut buf = audio_buffer.lock().unwrap();
            reconnect_buffer.extend(std::mem::take(&mut *buf));
        }

        match connect_websocket(api_key) {
            Ok(mut new_socket) => {
                if send_setup_message(&mut new_socket).is_err() {
                    continue;
                }
                if set_socket_nonblocking(&mut new_socket).is_err() {
                    continue;
                }
                {
                    let mut buf = audio_buffer.lock().unwrap();
                    reconnect_buffer.extend(std::mem::take(&mut *buf));
                }
                silence_buffer.clear();
                silence_buffer.extend(reconnect_buffer);
                *audio_mode = AudioMode::CatchUp;
                *mode_start = Instant::now();
                *socket = new_socket;
                *last_transcription_time = Instant::now();
                *consecutive_empty_reads = 0;
                return true;
            }
            Err(_) => {
                std::thread::sleep(Duration::from_millis(500));
            }
        }
    }
    false
}
</file>

<file path="src/api/realtime_audio/utils.rs">
//! Utility functions and static variables for realtime audio

use std::sync::Mutex;
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use super::{WM_REALTIME_UPDATE, WM_TRANSLATION_UPDATE};

lazy_static::lazy_static! {
    pub static ref REALTIME_DISPLAY_TEXT: Mutex<String> = Mutex::new(String::new());
    pub static ref TRANSLATION_DISPLAY_TEXT: Mutex<String> = Mutex::new(String::new());
}

pub fn update_overlay_text(hwnd: HWND, text: &str) {
    if let Ok(mut display) = REALTIME_DISPLAY_TEXT.lock() {
        *display = text.to_string();
    }
    unsafe {
        let _ = PostMessageW(Some(hwnd), WM_REALTIME_UPDATE, WPARAM(0), LPARAM(0));
    }
}

pub fn update_translation_text(hwnd: HWND, text: &str) {
    if let Ok(mut display) = TRANSLATION_DISPLAY_TEXT.lock() {
        *display = text.to_string();
    }
    unsafe {
        let _ = PostMessageW(Some(hwnd), WM_TRANSLATION_UPDATE, WPARAM(0), LPARAM(0));
    }
}

pub fn refresh_transcription_window() {
    unsafe {
        let realtime_hwnd = crate::overlay::realtime_webview::REALTIME_HWND;
        if !realtime_hwnd.is_invalid() {
            let _ = PostMessageW(Some(realtime_hwnd), WM_REALTIME_UPDATE, WPARAM(0), LPARAM(0));
        }
    }
}
</file>

<file path="src/api/realtime_audio/websocket.rs">
//! WebSocket connection and communication for Gemini Live API

use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
use std::net::TcpStream;
use std::time::Duration;

use super::REALTIME_MODEL;

/// Create TLS WebSocket connection to Gemini Live API
pub fn connect_websocket(
    api_key: &str,
) -> Result<tungstenite::WebSocket<native_tls::TlsStream<TcpStream>>> {
    let ws_url = format!(
        "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key={}",
        api_key
    );

    let url = url::Url::parse(&ws_url)?;
    let host = url
        .host_str()
        .ok_or_else(|| anyhow::anyhow!("No host in URL"))?;
    let port = 443;

    // Resolve hostname to IP address first
    use std::net::ToSocketAddrs;
    let addr = format!("{}:{}", host, port)
        .to_socket_addrs()?
        .next()
        .ok_or_else(|| anyhow::anyhow!("Failed to resolve hostname: {}", host))?;

    // Connect TCP with a long timeout for initial handshake
    let tcp_stream = TcpStream::connect_timeout(&addr, Duration::from_secs(10))?;
    // Use blocking mode with long timeout during setup
    tcp_stream.set_read_timeout(Some(Duration::from_secs(30)))?;
    tcp_stream.set_write_timeout(Some(Duration::from_secs(30)))?;
    tcp_stream.set_nodelay(true)?;

    // Wrap with TLS
    let connector = native_tls::TlsConnector::new()?;
    let tls_stream = connector.connect(host, tcp_stream)?;

    // WebSocket handshake
    let (socket, _response) = tungstenite::client::client(&ws_url, tls_stream)?;

    Ok(socket)
}

/// Set socket to non-blocking mode for the main loop
pub fn set_socket_nonblocking(
    socket: &mut tungstenite::WebSocket<native_tls::TlsStream<TcpStream>>,
) -> Result<()> {
    let stream = socket.get_mut();
    let tcp_stream = stream.get_mut();
    tcp_stream.set_read_timeout(Some(Duration::from_millis(50)))?;
    Ok(())
}

/// Set a short timeout for the setup phase so we can check for model changes frequently
pub fn set_socket_short_timeout(
    socket: &mut tungstenite::WebSocket<native_tls::TlsStream<TcpStream>>,
) -> Result<()> {
    let stream = socket.get_mut();
    let tcp_stream = stream.get_mut();
    // 200ms timeout allows checking for model changes 5 times per second
    tcp_stream.set_read_timeout(Some(Duration::from_millis(200)))?;
    Ok(())
}

/// Send session setup message to configure transcription mode
pub fn send_setup_message(
    socket: &mut tungstenite::WebSocket<native_tls::TlsStream<TcpStream>>,
) -> Result<()> {
    // Using camelCase as per Gemini Live API documentation
    // We set responseModalities to AUDIO to satisfy the native audio model,
    // but we'll only use the inputAudioTranscription (ignore audio talkback)
    let setup = serde_json::json!({
        "setup": {
            "model": format!("models/{}", REALTIME_MODEL),
            "generationConfig": {
                "responseModalities": ["AUDIO"],  // Required for native audio model
                "thinkingConfig": {
                    "thinkingBudget": 0  // Disable thinking for lower latency
                }
            },
            "inputAudioTranscription": {}  // This is what we actually want - input transcription
        }
    });

    let msg_str = setup.to_string();
    socket.write(tungstenite::Message::Text(msg_str.into()))?;
    socket.flush()?;

    Ok(())
}

/// Send audio chunk to the WebSocket
pub fn send_audio_chunk(
    socket: &mut tungstenite::WebSocket<native_tls::TlsStream<TcpStream>>,
    pcm_data: &[i16],
) -> Result<()> {
    // Convert i16 samples to bytes (little-endian)
    let mut bytes = Vec::with_capacity(pcm_data.len() * 2);
    for sample in pcm_data {
        bytes.extend_from_slice(&sample.to_le_bytes());
    }

    let b64_audio = general_purpose::STANDARD.encode(&bytes);

    let msg = serde_json::json!({
        "realtime_input": {
            "media_chunks": [{
                "data": b64_audio,
                "mime_type": "audio/pcm;rate=16000"
            }]
        }
    });

    socket.write(tungstenite::Message::Text(msg.to_string().into()))?;
    socket.flush()?;

    Ok(())
}

/// Parse inputTranscription from WebSocket message (what the user said)
pub fn parse_input_transcription(msg: &str) -> Option<String> {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(msg) {
        if let Some(server_content) = json.get("serverContent") {
            if let Some(input_transcription) = server_content.get("inputTranscription") {
                if let Some(text) = input_transcription.get("text").and_then(|t| t.as_str()) {
                    return Some(text.to_string());
                }
            }
        }
    }
    None
}
</file>

<file path="src/api/text.rs">
use super::client::UREQ_AGENT;
use super::types::{ChatCompletionResponse, StreamChunk};
use super::vision::translate_image_streaming as vision_translate_image_streaming;
use crate::gui::locale::LocaleText;
use crate::overlay::result::RefineContext;
use crate::overlay::utils::get_context_quote;
use crate::APP;
use anyhow::Result;
use std::io::{BufRead, BufReader};

pub fn translate_text_streaming<F>(
    groq_api_key: &str,
    gemini_api_key: &str,
    text: String,
    instruction: String,
    model: String,
    provider: String,
    streaming_enabled: bool,
    use_json_format: bool,
    search_label: Option<String>,
    ui_language: &str,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(&str),
{
    let openrouter_api_key = crate::APP
        .lock()
        .ok()
        .and_then(|app| {
            let config = app.config.clone();
            if config.openrouter_api_key.is_empty() {
                None
            } else {
                Some(config.openrouter_api_key.clone())
            }
        })
        .unwrap_or_default();

    let cerebras_api_key = crate::APP
        .lock()
        .ok()
        .and_then(|app| {
            let config = app.config.clone();
            if config.cerebras_api_key.is_empty() {
                None
            } else {
                Some(config.cerebras_api_key.clone())
            }
        })
        .unwrap_or_default();

    let mut full_content = String::new();
    let prompt = format!("{}\n\n{}", instruction, text);

    if provider == "ollama" {
        // --- OLLAMA LOCAL API ---
        let (ollama_base_url, ollama_text_model) = crate::APP
            .lock()
            .ok()
            .map(|app| {
                let config = app.config.clone();
                (
                    config.ollama_base_url.clone(),
                    config.ollama_text_model.clone(),
                )
            })
            .unwrap_or_else(|| ("http://localhost:11434".to_string(), model.clone()));

        let actual_model = if ollama_text_model.is_empty() {
            model.clone()
        } else {
            ollama_text_model
        };

        return super::ollama::ollama_generate_text(
            &ollama_base_url,
            &actual_model,
            &prompt,
            streaming_enabled,
            ui_language,
            on_chunk,
        );
    } else if provider == "gemini-live" {
        // --- GEMINI LIVE API (WebSocket-based low-latency streaming) ---
        return super::gemini_live::gemini_live_generate(
            text,
            instruction,
            None, // No image for text-only
            None, // No audio for text-only
            streaming_enabled,
            ui_language,
            on_chunk,
        );
    } else if provider == "google-gtx" {
        // --- GOOGLE TRANSLATE (GTX) API ---
        // Non-LLM translation model - no API key required
        // Extract target language from the instruction (e.g., "Translate to Vietnamese" -> "Vietnamese")
        let target_lang = instruction
            .to_lowercase()
            .split("translate to ")
            .nth(1)
            .and_then(|s| s.split('.').next())
            .and_then(|s| s.split(',').next())
            .map(|s| s.trim().to_string())
            .unwrap_or_else(|| "English".to_string());

        // Capitalize first letter for language lookup
        let target_lang = target_lang
            .chars()
            .enumerate()
            .map(|(i, c)| {
                if i == 0 {
                    c.to_uppercase().next().unwrap_or(c)
                } else {
                    c
                }
            })
            .collect::<String>();

        match crate::api::realtime_audio::translate_with_google_gtx(&text, &target_lang) {
            Some(translated) => {
                on_chunk(&translated);
                return Ok(translated);
            }
            None => {
                return Err(anyhow::anyhow!("GTX translation failed"));
            }
        }
    } else if provider == "google" {
        // --- GEMINI TEXT API ---
        if gemini_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:gemini"));
        }

        let method = if streaming_enabled {
            "streamGenerateContent"
        } else {
            "generateContent"
        };
        let url = if streaming_enabled {
            format!(
                "https://generativelanguage.googleapis.com/v1beta/models/{}:{}?alt=sse",
                model, method
            )
        } else {
            format!(
                "https://generativelanguage.googleapis.com/v1beta/models/{}:{}",
                model, method
            )
        };

        let mut payload = serde_json::json!({
            "contents": [{
                "role": "user",
                "parts": [{ "text": prompt }]
            }]
        });

        // Enable thinking for Gemini 2.5+ models (gemini-2.5-flash and gemini-robotics-er)
        // Enable thinking for Gemini 2.5+ models (gemini-2.5-flash, 3.0-flash, and gemini-robotics-er)
        let supports_thinking = (model.contains("gemini-2.5-flash") && !model.contains("lite"))
            || model.contains("gemini-3-flash-preview")
            || model.contains("gemini-robotics");
        if supports_thinking {
            payload["generationConfig"] = serde_json::json!({
                "thinkingConfig": {
                    "includeThoughts": true
                }
            });
        }

        if crate::model_config::model_supports_search_by_name(&model) {
            payload["tools"] = serde_json::json!([
                { "url_context": {} },
                { "google_search": {} }
            ]);
        }

        let resp = UREQ_AGENT
            .post(&url)
            .header("x-goog-api-key", gemini_api_key)
            .send_json(payload)
            .map_err(|e| {
                let err_str = e.to_string();
                if err_str.contains("401") || err_str.contains("403") {
                    anyhow::anyhow!("INVALID_API_KEY")
                } else {
                    anyhow::anyhow!("Gemini Text API Error: {}", err_str)
                }
            })?;

        if streaming_enabled {
            let reader = BufReader::new(resp.into_body().into_reader());
            let mut thinking_shown = false;
            let mut content_started = false;
            let locale = LocaleText::get(ui_language);

            for line in reader.lines() {
                let line = line.map_err(|e| anyhow::anyhow!("Failed to read line: {}", e))?;
                if line.starts_with("data: ") {
                    let json_str = &line["data: ".len()..];
                    if json_str.trim() == "[DONE]" {
                        break;
                    }

                    if let Ok(chunk_resp) = serde_json::from_str::<serde_json::Value>(json_str) {
                        if let Some(candidates) =
                            chunk_resp.get("candidates").and_then(|c| c.as_array())
                        {
                            if let Some(first_candidate) = candidates.first() {
                                if let Some(parts) = first_candidate
                                    .get("content")
                                    .and_then(|c| c.get("parts"))
                                    .and_then(|p| p.as_array())
                                {
                                    for part in parts {
                                        let is_thought = part
                                            .get("thought")
                                            .and_then(|t| t.as_bool())
                                            .unwrap_or(false);

                                        if let Some(text) =
                                            part.get("text").and_then(|t| t.as_str())
                                        {
                                            if is_thought {
                                                // Model is thinking - show thinking indicator (only once)
                                                if !thinking_shown && !content_started {
                                                    on_chunk(locale.model_thinking);
                                                    thinking_shown = true;
                                                }
                                                // Consume thought, don't display
                                            } else {
                                                // Regular content
                                                if !content_started && thinking_shown {
                                                    // Wipe thinking message on first content
                                                    content_started = true;
                                                    full_content.push_str(text);
                                                    let wipe_content = format!(
                                                        "{}{}",
                                                        crate::api::WIPE_SIGNAL,
                                                        full_content
                                                    );
                                                    on_chunk(&wipe_content);
                                                } else {
                                                    content_started = true;
                                                    full_content.push_str(text);
                                                    on_chunk(text);
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        } else {
            let chat_resp: serde_json::Value = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse non-streaming response: {}", e))?;

            if let Some(candidates) = chat_resp.get("candidates").and_then(|c| c.as_array()) {
                if let Some(first_choice) = candidates.first() {
                    if let Some(parts) = first_choice
                        .get("content")
                        .and_then(|c| c.get("parts"))
                        .and_then(|p| p.as_array())
                    {
                        // Filter out thought parts and collect only content
                        full_content = parts
                            .iter()
                            .filter(|p| {
                                !p.get("thought").and_then(|t| t.as_bool()).unwrap_or(false)
                            })
                            .filter_map(|p| p.get("text").and_then(|t| t.as_str()))
                            .collect::<String>();
                        on_chunk(&full_content);
                    }
                }
            }
        }
    } else if provider == "cerebras" {
        // --- CEREBRAS API ---
        if cerebras_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:cerebras"));
        }

        let payload = serde_json::json!({
            "model": model,
            "messages": [
                { "role": "user", "content": prompt }
            ],
            "stream": streaming_enabled
        });

        let resp = UREQ_AGENT
            .post("https://api.cerebras.ai/v1/chat/completions")
            .header("Authorization", &format!("Bearer {}", cerebras_api_key))
            .header("Content-Type", "application/json")
            .send_json(payload)
            .map_err(|e| {
                let err_str = e.to_string();
                if err_str.contains("401") || err_str.contains("403") {
                    anyhow::anyhow!("INVALID_API_KEY")
                } else {
                    anyhow::anyhow!("Cerebras API Error: {}", err_str)
                }
            })?;

        // Extract rate limit info
        // Extract rate limit info
        let remaining = resp
            .headers()
            .get("x-ratelimit-remaining-requests-day")
            .or_else(|| resp.headers().get("x-ratelimit-remaining-requests"))
            .and_then(|v| v.to_str().ok())
            .unwrap_or("?");

        let mut limit = resp
            .headers()
            .get("x-ratelimit-limit-requests-day")
            .or_else(|| resp.headers().get("x-ratelimit-limit-requests"))
            .and_then(|v| v.to_str().ok())
            .unwrap_or("?")
            .to_string();

        if limit == "?" {
            if let Some(conf) = crate::model_config::get_model_by_id(&model) {
                if let Some(val) = conf.quota_limit_en.split_whitespace().next() {
                    limit = val.to_string();
                }
            }
        }

        if remaining != "?" || limit != "?" {
            let usage_str = format!("{} / {}", remaining, limit);
            if let Ok(mut app) = APP.lock() {
                app.model_usage_stats.insert(model.clone(), usage_str);
            }
        }

        if streaming_enabled {
            let reader = BufReader::new(resp.into_body().into_reader());
            let mut thinking_shown = false;
            let mut content_started = false;
            let locale = LocaleText::get(ui_language);

            // Cerebras reasoning models handle thinking phase
            let is_reasoning_model = model.contains("gpt-oss") || model.contains("zai-glm");

            for line in reader.lines() {
                let line = line?;
                if line.starts_with("data: ") {
                    let data = &line[6..];
                    if data == "[DONE]" {
                        break;
                    }

                    match serde_json::from_str::<StreamChunk>(data) {
                        Ok(chunk) => {
                            // Check for reasoning tokens (thinking phase)
                            if let Some(reasoning) = chunk
                                .choices
                                .get(0)
                                .and_then(|c| c.delta.reasoning.as_ref())
                                .filter(|s| !s.is_empty())
                            {
                                // Model is thinking - show thinking indicator (only once)
                                if !thinking_shown && !content_started {
                                    on_chunk(locale.model_thinking);
                                    thinking_shown = true;
                                }
                                let _ = reasoning; // Just consume reasoning, don't display
                            } else if is_reasoning_model && !content_started && !thinking_shown {
                                // Fallback thinking indicator for reasoning models if no reasoning field is present yet
                                on_chunk(locale.model_thinking);
                                thinking_shown = true;
                            }

                            // Check for content tokens (final result)
                            if let Some(content) = chunk
                                .choices
                                .get(0)
                                .and_then(|c| c.delta.content.as_ref())
                                .filter(|s| !s.is_empty())
                            {
                                // Content started - wipe thinking message on first content chunk
                                if !content_started && thinking_shown {
                                    content_started = true;
                                    // Use WIPE_SIGNAL to tell callback to clear accumulator
                                    full_content.push_str(content);
                                    let wipe_content =
                                        format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                                    on_chunk(&wipe_content);
                                } else {
                                    content_started = true;
                                    full_content.push_str(content);
                                    on_chunk(content);
                                }
                            }
                        }
                        Err(_) => continue,
                    }
                }
            }
        } else {
            let chat_resp: ChatCompletionResponse = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse non-streaming response: {}", e))?;

            if let Some(choice) = chat_resp.choices.first() {
                full_content = choice.message.content.clone();
                on_chunk(&full_content);
            }
        }
    } else if provider == "openrouter" {
        // --- OPENROUTER API ---
        if openrouter_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:openrouter"));
        }

        let payload = serde_json::json!({
            "model": model,
            "messages": [
                { "role": "user", "content": prompt }
            ],
            "stream": streaming_enabled
        });

        let resp = UREQ_AGENT
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", &format!("Bearer {}", openrouter_api_key))
            .header("Content-Type", "application/json")
            .send_json(payload)
            .map_err(|e| {
                let err_str = e.to_string();
                if err_str.contains("401") || err_str.contains("403") {
                    anyhow::anyhow!("INVALID_API_KEY")
                } else {
                    anyhow::anyhow!("OpenRouter API Error: {}", err_str)
                }
            })?;

        if streaming_enabled {
            let reader = BufReader::new(resp.into_body().into_reader());
            let mut thinking_shown = false;
            let mut content_started = false;
            let locale = LocaleText::get(ui_language);

            for line in reader.lines() {
                let line = line?;
                if line.starts_with("data: ") {
                    let data = &line[6..];
                    if data == "[DONE]" {
                        break;
                    }

                    match serde_json::from_str::<StreamChunk>(data) {
                        Ok(chunk) => {
                            // Check for reasoning tokens (thinking phase)
                            if let Some(reasoning) = chunk
                                .choices
                                .get(0)
                                .and_then(|c| c.delta.reasoning.as_ref())
                                .filter(|s| !s.is_empty())
                            {
                                // Model is thinking - show thinking indicator (only once)
                                if !thinking_shown && !content_started {
                                    on_chunk(locale.model_thinking);
                                    thinking_shown = true;
                                }
                                let _ = reasoning; // Just consume reasoning, don't display
                            }

                            // Check for content tokens (final result)
                            if let Some(content) = chunk
                                .choices
                                .get(0)
                                .and_then(|c| c.delta.content.as_ref())
                                .filter(|s| !s.is_empty())
                            {
                                // Content started - wipe thinking message on first content chunk
                                if !content_started && thinking_shown {
                                    content_started = true;
                                    // Use WIPE_SIGNAL to tell callback to clear accumulator
                                    full_content.push_str(content);
                                    let wipe_content =
                                        format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                                    on_chunk(&wipe_content);
                                } else {
                                    content_started = true;
                                    full_content.push_str(content);
                                    on_chunk(content);
                                }
                            }
                        }
                        Err(_) => continue,
                    }
                }
            }
        } else {
            let chat_resp: ChatCompletionResponse = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse non-streaming response: {}", e))?;

            if let Some(choice) = chat_resp.choices.first() {
                full_content = choice.message.content.clone();
                on_chunk(&full_content);
            }
        }
    } else {
        // --- GROQ API (Default) ---
        if groq_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:groq"));
        }

        let is_compound = model.starts_with("groq/compound");

        if is_compound {
            // --- COMPOUND MODEL API ---
            let payload = serde_json::json!({
                "model": model,
                "messages": [
                    {
                        "role": "system",
                        "content": "IMPORTANT: Limit yourself to a maximum of 3 tool calls total. Make 1-2 focused searches, then answer. Do not visit websites unless absolutely necessary. Be efficient."
                    },
                    { "role": "user", "content": prompt }
                ],
                "temperature": 1,
                "max_tokens": 8192,
                "stream": false,
                "compound_custom": {
                    "tools": {
                        "enabled_tools": ["web_search", "visit_website"]
                    }
                }
            });

            let locale = LocaleText::get(ui_language);
            let context_quote = get_context_quote(&prompt);
            let search_msg = match &search_label {
                Some(label) => format!(
                    "{}\n\n🔍 {} {}...",
                    context_quote, locale.search_doing, label
                ),
                None => format!(
                    "{}\n\n🔍 {} {}...",
                    context_quote, locale.search_doing, locale.search_searching
                ),
            };
            on_chunk(&search_msg);

            let resp = UREQ_AGENT
                .post("https://api.groq.com/openai/v1/chat/completions")
                .header("Authorization", &format!("Bearer {}", groq_api_key))
                .send_json(payload)
                .map_err(|e| {
                    let err_str = e.to_string();
                    if err_str.contains("401") {
                        anyhow::anyhow!("INVALID_API_KEY")
                    } else {
                        anyhow::anyhow!("{}", err_str)
                    }
                })?;

            if let Some(remaining) = resp
                .headers()
                .get("x-ratelimit-remaining-requests")
                .and_then(|v| v.to_str().ok())
            {
                let limit = resp
                    .headers()
                    .get("x-ratelimit-limit-requests")
                    .and_then(|v| v.to_str().ok())
                    .unwrap_or("?");
                let usage_str = format!("{} / {}", remaining, limit);

                if let Ok(mut app) = APP.lock() {
                    app.model_usage_stats.insert(model.clone(), usage_str);
                }
            }

            let json: serde_json::Value = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse compound response: {}", e))?;

            if let Some(choices) = json.get("choices").and_then(|c| c.as_array()) {
                if let Some(first_choice) = choices.first() {
                    if let Some(message) = first_choice.get("message") {
                        if let Some(executed_tools) =
                            message.get("executed_tools").and_then(|t| t.as_array())
                        {
                            let mut search_queries = Vec::new();
                            for tool in executed_tools {
                                if let Some(tool_type) = tool.get("type").and_then(|t| t.as_str()) {
                                    if tool_type == "search" {
                                        if let Some(args) =
                                            tool.get("arguments").and_then(|a| a.as_str())
                                        {
                                            if let Ok(args_json) =
                                                serde_json::from_str::<serde_json::Value>(args)
                                            {
                                                if let Some(query) =
                                                    args_json.get("query").and_then(|q| q.as_str())
                                                {
                                                    search_queries.push(query.to_string());
                                                }
                                            }
                                        }
                                    }
                                }
                            }

                            let context_quote = get_context_quote(&prompt);
                            if !search_queries.is_empty() {
                                let phase1_header = match &search_label {
                                    Some(label) => format!(
                                        "{}\n\n🔍 {} {}...\n\n",
                                        context_quote,
                                        locale.search_doing.to_uppercase(),
                                        label.to_uppercase()
                                    ),
                                    None => format!(
                                        "{}\n\n🔍 {} {}...\n\n",
                                        context_quote,
                                        locale.search_doing.to_uppercase(),
                                        locale.search_searching.to_uppercase()
                                    ),
                                };
                                let mut phase1 = phase1_header;
                                phase1.push_str(&format!("{}\n", locale.search_query_label));
                                for (i, query) in search_queries.iter().enumerate() {
                                    phase1.push_str(&format!("  {}. \"{}\"\n", i + 1, query));
                                }
                                on_chunk(&phase1);
                                std::thread::sleep(std::time::Duration::from_millis(800));
                            }

                            let mut all_sources = Vec::new();
                            for tool in executed_tools {
                                if let Some(search_results) = tool
                                    .get("search_results")
                                    .and_then(|s| s.get("results"))
                                    .and_then(|r| r.as_array())
                                {
                                    for result in search_results {
                                        let title = result
                                            .get("title")
                                            .and_then(|t| t.as_str())
                                            .unwrap_or(locale.search_no_title);
                                        let url = result
                                            .get("url")
                                            .and_then(|u| u.as_str())
                                            .unwrap_or("");
                                        let score = result
                                            .get("score")
                                            .and_then(|s| s.as_f64())
                                            .unwrap_or(0.0);
                                        let content = result
                                            .get("content")
                                            .and_then(|c| c.as_str())
                                            .unwrap_or("");

                                        all_sources.push((
                                            title.to_string(),
                                            url.to_string(),
                                            score,
                                            content.to_string(),
                                        ));
                                    }
                                }
                            }

                            if !all_sources.is_empty() {
                                all_sources.sort_by(|a, b| {
                                    b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal)
                                });

                                let context_quote = get_context_quote(&prompt);
                                let mut phase2 = format!(
                                    "{}\n\n{}\n\n",
                                    context_quote,
                                    locale
                                        .search_found_sources
                                        .replace("{}", &all_sources.len().to_string())
                                );
                                phase2.push_str(&format!("{}\n\n", locale.search_sources_label));

                                for (i, (title, url, score, content)) in
                                    all_sources.iter().take(6).enumerate()
                                {
                                    let title_display = if title.chars().count() > 60 {
                                        format!("{}...", title.chars().take(57).collect::<String>())
                                    } else {
                                        title.clone()
                                    };

                                    let domain = url.split('/').nth(2).unwrap_or(url);
                                    let score_pct = (score * 100.0) as i32;

                                    phase2.push_str(&format!(
                                        "{}. {} [{}%]\n",
                                        i + 1,
                                        title_display,
                                        score_pct
                                    ));
                                    phase2.push_str(&format!("   🔗 {}\n", domain));

                                    if !content.is_empty() {
                                        let preview = if content.len() > 100 {
                                            format!(
                                                "{}...",
                                                content
                                                    .chars()
                                                    .take(100)
                                                    .collect::<String>()
                                                    .replace('\n', " ")
                                            )
                                        } else {
                                            content.replace('\n', " ")
                                        };
                                        phase2.push_str(&format!("   📄 {}\n", preview));
                                    }
                                    phase2.push('\n');
                                }

                                on_chunk(&phase2);
                                std::thread::sleep(std::time::Duration::from_millis(1200));

                                let context_quote = get_context_quote(&prompt);
                                let phase3 = format!(
                                    "{}\n\n{}\n\n{}\n{}\n",
                                    context_quote,
                                    locale.search_synthesizing,
                                    locale
                                        .search_analyzed_sources
                                        .replace("{}", &all_sources.len().min(6).to_string()),
                                    locale.search_processing
                                );
                                on_chunk(&phase3);
                                std::thread::sleep(std::time::Duration::from_millis(600));
                            }
                        }

                        if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                            full_content = content.to_string();
                            on_chunk(&full_content);
                        }
                    }
                }
            }
        } else {
            // --- STANDARD GROQ API ---
            let payload = if streaming_enabled {
                serde_json::json!({
                    "model": model,
                    "messages": [
                        { "role": "user", "content": prompt }
                    ],
                    "stream": true
                })
            } else {
                let mut payload_obj = serde_json::json!({
                    "model": model,
                    "messages": [
                        { "role": "user", "content": prompt }
                    ],
                    "stream": false
                });

                if use_json_format {
                    payload_obj["response_format"] = serde_json::json!({ "type": "json_object" });
                }

                payload_obj
            };

            let resp = UREQ_AGENT
                .post("https://api.groq.com/openai/v1/chat/completions")
                .header("Authorization", &format!("Bearer {}", groq_api_key))
                .send_json(payload)
                .map_err(|e| {
                    let err_str = e.to_string();
                    if err_str.contains("401") {
                        anyhow::anyhow!("INVALID_API_KEY")
                    } else {
                        anyhow::anyhow!("{}", err_str)
                    }
                })?;

            if let Some(remaining) = resp
                .headers()
                .get("x-ratelimit-remaining-requests")
                .and_then(|v| v.to_str().ok())
            {
                let limit = resp
                    .headers()
                    .get("x-ratelimit-limit-requests")
                    .and_then(|v| v.to_str().ok())
                    .unwrap_or("?");
                let usage_str = format!("{} / {}", remaining, limit);

                if let Ok(mut app) = APP.lock() {
                    app.model_usage_stats.insert(model.clone(), usage_str);
                }
            }

            if streaming_enabled {
                let reader = BufReader::new(resp.into_body().into_reader());

                for line in reader.lines() {
                    let line = line?;
                    if line.starts_with("data: ") {
                        let data = &line[6..];
                        if data == "[DONE]" {
                            break;
                        }

                        match serde_json::from_str::<StreamChunk>(data) {
                            Ok(chunk) => {
                                if let Some(content) =
                                    chunk.choices.get(0).and_then(|c| c.delta.content.as_ref())
                                {
                                    full_content.push_str(content);
                                    on_chunk(content);
                                }
                            }
                            Err(_) => continue,
                        }
                    }
                }
            } else {
                let chat_resp: ChatCompletionResponse =
                    resp.into_body().read_json().map_err(|e| {
                        anyhow::anyhow!("Failed to parse non-streaming response: {}", e)
                    })?;

                if let Some(choice) = chat_resp.choices.first() {
                    let content_str = &choice.message.content;

                    if use_json_format {
                        if let Ok(json_obj) = serde_json::from_str::<serde_json::Value>(content_str)
                        {
                            if let Some(translation) =
                                json_obj.get("translation").and_then(|v| v.as_str())
                            {
                                full_content = translation.to_string();
                            } else {
                                full_content = content_str.clone();
                            }
                        } else {
                            full_content = content_str.clone();
                        }
                    } else {
                        full_content = content_str.clone();
                    }

                    on_chunk(&full_content);
                }
            }
        }
    }

    Ok(full_content)
}

pub fn refine_text_streaming<F>(
    groq_api_key: &str,
    gemini_api_key: &str,
    context: RefineContext,
    previous_text: String,
    user_prompt: String,
    original_model_id: &str,
    original_provider: &str,
    streaming_enabled: bool,
    ui_language: &str,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(&str),
{
    let openrouter_api_key = crate::APP
        .lock()
        .ok()
        .and_then(|app| {
            let config = app.config.clone();
            if config.openrouter_api_key.is_empty() {
                None
            } else {
                Some(config.openrouter_api_key.clone())
            }
        })
        .unwrap_or_default();

    let cerebras_api_key = crate::APP
        .lock()
        .ok()
        .and_then(|app| {
            let config = app.config.clone();
            if config.cerebras_api_key.is_empty() {
                None
            } else {
                Some(config.cerebras_api_key.clone())
            }
        })
        .unwrap_or_default();

    let final_prompt = format!(
        "Content:\n{}\n\nInstruction:\n{}\n\nOutput ONLY the result.",
        previous_text, user_prompt
    );

    let (mut target_id_or_name, mut target_provider) = match context {
        RefineContext::Image(_) => (original_model_id.to_string(), original_provider.to_string()),
        _ => {
            if !original_model_id.trim().is_empty() && original_model_id != "scout" {
                (original_model_id.to_string(), original_provider.to_string())
            } else {
                if !gemini_api_key.trim().is_empty() {
                    ("gemini-flash-lite".to_string(), "google".to_string())
                } else if !cerebras_api_key.trim().is_empty() {
                    (
                        "qwen-3-235b-a22b-instruct-2507".to_string(),
                        "cerebras".to_string(),
                    )
                } else if !groq_api_key.trim().is_empty() {
                    ("text_accurate_kimi".to_string(), "groq".to_string())
                } else {
                    (original_model_id.to_string(), original_provider.to_string())
                }
            }
        }
    };

    if let Some(conf) = crate::model_config::get_model_by_id(&target_id_or_name) {
        target_id_or_name = conf.full_name;
        target_provider = conf.provider;
    }

    let mut exec_text_only = |p_model: String, p_provider: String| -> Result<String> {
        let mut full_content = String::new();

        if p_provider == "google" {
            if gemini_api_key.trim().is_empty() {
                return Err(anyhow::anyhow!("NO_API_KEY:gemini"));
            }

            let method = if streaming_enabled {
                "streamGenerateContent"
            } else {
                "generateContent"
            };
            let url = if streaming_enabled {
                format!(
                    "https://generativelanguage.googleapis.com/v1beta/models/{}:{}?alt=sse",
                    p_model, method
                )
            } else {
                format!(
                    "https://generativelanguage.googleapis.com/v1beta/models/{}:{}",
                    p_model, method
                )
            };

            let mut payload = serde_json::json!({
                "contents": [{ "role": "user", "parts": [{ "text": final_prompt }] }]
            });

            // Enable thinking for Gemini 2.5+ models
            let supports_thinking = (p_model.contains("gemini-2.5-flash")
                && !p_model.contains("lite"))
                || p_model.contains("gemini-3-flash-preview")
                || p_model.contains("gemini-robotics");
            if supports_thinking {
                payload["generationConfig"] = serde_json::json!({
                    "thinkingConfig": {
                        "includeThoughts": true
                    }
                });
            }

            if crate::model_config::model_supports_search_by_name(&p_model) {
                payload["tools"] = serde_json::json!([
                    { "url_context": {} },
                    { "google_search": {} }
                ]);
            }

            let resp = UREQ_AGENT
                .post(&url)
                .header("x-goog-api-key", gemini_api_key)
                .send_json(payload)
                .map_err(|e| anyhow::anyhow!("Gemini Refine Error: {}", e))?;

            if streaming_enabled {
                let reader = BufReader::new(resp.into_body().into_reader());
                let mut thinking_shown = false;
                let mut content_started = false;
                let locale = LocaleText::get(ui_language);

                for line in reader.lines() {
                    let line = line?;
                    if line.starts_with("data: ") {
                        let json_str = &line["data: ".len()..];
                        if json_str.trim() == "[DONE]" {
                            break;
                        }
                        if let Ok(chunk_resp) = serde_json::from_str::<serde_json::Value>(json_str)
                        {
                            if let Some(candidates) =
                                chunk_resp.get("candidates").and_then(|c| c.as_array())
                            {
                                if let Some(first) = candidates.first() {
                                    if let Some(parts) = first
                                        .get("content")
                                        .and_then(|c| c.get("parts"))
                                        .and_then(|p| p.as_array())
                                    {
                                        for part in parts {
                                            let is_thought = part
                                                .get("thought")
                                                .and_then(|t| t.as_bool())
                                                .unwrap_or(false);

                                            if let Some(t) =
                                                part.get("text").and_then(|v| v.as_str())
                                            {
                                                if is_thought {
                                                    if !thinking_shown && !content_started {
                                                        on_chunk(locale.model_thinking);
                                                        thinking_shown = true;
                                                    }
                                                } else {
                                                    if !content_started && thinking_shown {
                                                        content_started = true;
                                                        full_content.push_str(t);
                                                        let wipe_content = format!(
                                                            "{}{}",
                                                            crate::api::WIPE_SIGNAL,
                                                            full_content
                                                        );
                                                        on_chunk(&wipe_content);
                                                    } else {
                                                        content_started = true;
                                                        full_content.push_str(t);
                                                        on_chunk(t);
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            } else {
                let json: serde_json::Value = resp.into_body().read_json()?;
                if let Some(candidates) = json.get("candidates").and_then(|c| c.as_array()) {
                    if let Some(first) = candidates.first() {
                        if let Some(parts) = first
                            .get("content")
                            .and_then(|c| c.get("parts"))
                            .and_then(|p| p.as_array())
                        {
                            // Filter out thought parts
                            full_content = parts
                                .iter()
                                .filter(|p| {
                                    !p.get("thought").and_then(|t| t.as_bool()).unwrap_or(false)
                                })
                                .filter_map(|p| p.get("text").and_then(|t| t.as_str()))
                                .collect::<String>();
                            on_chunk(&full_content);
                        }
                    }
                }
            }
        } else if p_provider == "gemini-live" {
            // --- GEMINI LIVE REFINE ---
            return super::gemini_live::gemini_live_generate(
                final_prompt.clone(),
                String::new(), // instruction part of prompt for now
                None,
                None,
                streaming_enabled,
                ui_language,
                &mut on_chunk,
            );
        } else if p_provider == "cerebras" {
            if cerebras_api_key.trim().is_empty() {
                return Err(anyhow::anyhow!("NO_API_KEY:cerebras"));
            }

            let payload = serde_json::json!({
                "model": p_model,
                "messages": [
                    { "role": "user", "content": final_prompt }
                ],
                "stream": streaming_enabled
            });

            let resp = UREQ_AGENT
                .post("https://api.cerebras.ai/v1/chat/completions")
                .header("Authorization", &format!("Bearer {}", cerebras_api_key))
                .header("Content-Type", "application/json")
                .send_json(payload)
                .map_err(|e| anyhow::anyhow!("Cerebras Refine Error: {}", e))?;

            // Extract rate limit info
            // Extract rate limit info
            let remaining = resp
                .headers()
                .get("x-ratelimit-remaining-requests-day")
                .or_else(|| resp.headers().get("x-ratelimit-remaining-requests"))
                .and_then(|v| v.to_str().ok())
                .unwrap_or("?");

            let mut limit = resp
                .headers()
                .get("x-ratelimit-limit-requests-day")
                .or_else(|| resp.headers().get("x-ratelimit-limit-requests"))
                .and_then(|v| v.to_str().ok())
                .unwrap_or("?")
                .to_string();

            if limit == "?" {
                if let Some(conf) = crate::model_config::get_model_by_id(&p_model) {
                    if let Some(val) = conf.quota_limit_en.split_whitespace().next() {
                        limit = val.to_string();
                    }
                }
            }

            if remaining != "?" || limit != "?" {
                let usage_str = format!("{} / {}", remaining, limit);
                if let Ok(mut app) = APP.lock() {
                    app.model_usage_stats.insert(p_model.clone(), usage_str);
                }
            }

            if streaming_enabled {
                let reader = BufReader::new(resp.into_body().into_reader());
                let mut thinking_shown = false;
                let mut content_started = false;
                let locale = LocaleText::get(ui_language);

                let is_reasoning_model = p_model.contains("gpt-oss") || p_model.contains("zai-glm");

                for line in reader.lines() {
                    let line = line?;
                    if line.starts_with("data: ") {
                        let data = &line[6..];
                        if data == "[DONE]" {
                            break;
                        }

                        match serde_json::from_str::<StreamChunk>(data) {
                            Ok(chunk) => {
                                // Check for reasoning tokens (thinking phase)
                                if let Some(reasoning) = chunk
                                    .choices
                                    .get(0)
                                    .and_then(|c| c.delta.reasoning.as_ref())
                                    .filter(|s| !s.is_empty())
                                {
                                    if !thinking_shown && !content_started {
                                        on_chunk(locale.model_thinking);
                                        thinking_shown = true;
                                    }
                                    let _ = reasoning;
                                } else if is_reasoning_model && !content_started && !thinking_shown
                                {
                                    on_chunk(locale.model_thinking);
                                    thinking_shown = true;
                                }

                                // Check for content tokens (final result)
                                if let Some(content) = chunk
                                    .choices
                                    .get(0)
                                    .and_then(|c| c.delta.content.as_ref())
                                    .filter(|s| !s.is_empty())
                                {
                                    if !content_started && thinking_shown {
                                        content_started = true;
                                        full_content.push_str(content);
                                        let wipe_content =
                                            format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                                        on_chunk(&wipe_content);
                                    } else {
                                        content_started = true;
                                        full_content.push_str(content);
                                        on_chunk(content);
                                    }
                                }
                            }
                            Err(_) => continue,
                        }
                    }
                }
            } else {
                let json: ChatCompletionResponse = resp.into_body().read_json()?;
                if let Some(choice) = json.choices.first() {
                    full_content = choice.message.content.clone();
                    on_chunk(&full_content);
                }
            }
        } else if p_provider == "openrouter" {
            if openrouter_api_key.trim().is_empty() {
                return Err(anyhow::anyhow!("NO_API_KEY:openrouter"));
            }

            let payload = serde_json::json!({
                "model": p_model,
                "messages": [
                    { "role": "user", "content": final_prompt }
                ],
                "stream": streaming_enabled
            });

            let resp = UREQ_AGENT
                .post("https://openrouter.ai/api/v1/chat/completions")
                .header("Authorization", &format!("Bearer {}", openrouter_api_key))
                .header("Content-Type", "application/json")
                .send_json(payload)
                .map_err(|e| anyhow::anyhow!("OpenRouter Refine Error: {}", e))?;

            if streaming_enabled {
                let reader = BufReader::new(resp.into_body().into_reader());
                let mut thinking_shown = false;
                let mut content_started = false;
                let locale = LocaleText::get(ui_language);

                for line in reader.lines() {
                    let line = line?;
                    if line.starts_with("data: ") {
                        let data = &line[6..];
                        if data == "[DONE]" {
                            break;
                        }

                        match serde_json::from_str::<StreamChunk>(data) {
                            Ok(chunk) => {
                                // Check for reasoning tokens (thinking phase)
                                if let Some(reasoning) = chunk
                                    .choices
                                    .get(0)
                                    .and_then(|c| c.delta.reasoning.as_ref())
                                    .filter(|s| !s.is_empty())
                                {
                                    if !thinking_shown && !content_started {
                                        on_chunk(locale.model_thinking);
                                        thinking_shown = true;
                                    }
                                    let _ = reasoning;
                                }

                                // Check for content tokens (final result)
                                if let Some(content) = chunk
                                    .choices
                                    .get(0)
                                    .and_then(|c| c.delta.content.as_ref())
                                    .filter(|s| !s.is_empty())
                                {
                                    if !content_started && thinking_shown {
                                        content_started = true;
                                        full_content.push_str(content);
                                        let wipe_content =
                                            format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                                        on_chunk(&wipe_content);
                                    } else {
                                        content_started = true;
                                        full_content.push_str(content);
                                        on_chunk(content);
                                    }
                                }
                            }
                            Err(_) => continue,
                        }
                    }
                }
            } else {
                let json: ChatCompletionResponse = resp.into_body().read_json()?;
                if let Some(choice) = json.choices.first() {
                    full_content = choice.message.content.clone();
                    on_chunk(&full_content);
                }
            }
        } else {
            if groq_api_key.trim().is_empty() {
                return Err(anyhow::anyhow!("NO_API_KEY:groq"));
            }

            let is_compound = p_model.starts_with("groq/compound");

            if is_compound {
                let payload = serde_json::json!({
                    "model": p_model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "IMPORTANT: Limit yourself to a maximum of 3 tool calls total. Make 1-2 focused searches, then answer. Do not visit websites unless absolutely necessary. Be efficient."
                        },
                        { "role": "user", "content": final_prompt }
                    ],
                    "temperature": 1,
                    "max_completion_tokens": 8192,
                    "stream": false,
                    "compound_custom": {
                        "tools": {
                            "enabled_tools": ["web_search", "visit_website"]
                        }
                    }
                });

                let locale = LocaleText::get(ui_language);
                let context_quote = get_context_quote(&final_prompt);
                on_chunk(&format!(
                    "{}\n\n🔍 {} {}...",
                    context_quote, locale.search_doing, locale.search_searching
                ));

                let resp = UREQ_AGENT
                    .post("https://api.groq.com/openai/v1/chat/completions")
                    .header("Authorization", &format!("Bearer {}", groq_api_key))
                    .send_json(payload)
                    .map_err(|e| anyhow::anyhow!("Groq Compound Refine Error: {}", e))?;

                if let Some(remaining) = resp
                    .headers()
                    .get("x-ratelimit-remaining-requests")
                    .and_then(|v| v.to_str().ok())
                {
                    let limit = resp
                        .headers()
                        .get("x-ratelimit-limit-requests")
                        .and_then(|v| v.to_str().ok())
                        .unwrap_or("?");
                    let usage_str = format!("{} / {}", remaining, limit);
                    if let Ok(mut app) = APP.lock() {
                        app.model_usage_stats.insert(p_model.clone(), usage_str);
                    }
                }

                let json: serde_json::Value = resp.into_body().read_json()?;

                if let Some(choices) = json.get("choices").and_then(|c| c.as_array()) {
                    if let Some(first_choice) = choices.first() {
                        if let Some(message) = first_choice.get("message") {
                            if let Some(executed_tools) =
                                message.get("executed_tools").and_then(|t| t.as_array())
                            {
                                let mut search_queries = Vec::new();
                                for tool in executed_tools {
                                    if tool.get("type").and_then(|t| t.as_str()) == Some("search") {
                                        if let Some(args) =
                                            tool.get("arguments").and_then(|a| a.as_str())
                                        {
                                            if let Ok(args_json) =
                                                serde_json::from_str::<serde_json::Value>(args)
                                            {
                                                if let Some(query) =
                                                    args_json.get("query").and_then(|q| q.as_str())
                                                {
                                                    search_queries.push(query.to_string());
                                                }
                                            }
                                        }
                                    }
                                }

                                if !search_queries.is_empty() {
                                    let context_quote = get_context_quote(&final_prompt);
                                    let mut phase1 = format!(
                                        "{}\n\n🔍 {} {}...\n\n{}\n",
                                        context_quote,
                                        locale.search_doing.to_uppercase(),
                                        locale.search_searching.to_uppercase(),
                                        locale.search_query_label
                                    );
                                    for (i, q) in search_queries.iter().enumerate() {
                                        phase1.push_str(&format!("  {}. \"{}\"\n", i + 1, q));
                                    }
                                    on_chunk(&phase1);
                                    std::thread::sleep(std::time::Duration::from_millis(600));
                                }

                                let mut all_sources = Vec::new();
                                for tool in executed_tools {
                                    if let Some(results) = tool
                                        .get("search_results")
                                        .and_then(|s| s.get("results"))
                                        .and_then(|r| r.as_array())
                                    {
                                        for r in results {
                                            let title = r
                                                .get("title")
                                                .and_then(|t| t.as_str())
                                                .unwrap_or(locale.search_no_title);
                                            let url =
                                                r.get("url").and_then(|u| u.as_str()).unwrap_or("");
                                            let score = r
                                                .get("score")
                                                .and_then(|s| s.as_f64())
                                                .unwrap_or(0.0);
                                            all_sources.push((
                                                title.to_string(),
                                                url.to_string(),
                                                score,
                                            ));
                                        }
                                    }
                                }

                                if !all_sources.is_empty() {
                                    all_sources.sort_by(|a, b| {
                                        b.2.partial_cmp(&a.2).unwrap_or(std::cmp::Ordering::Equal)
                                    });
                                    let context_quote = get_context_quote(&final_prompt);
                                    let mut phase2 = format!(
                                        "{}\n\n{}\n\n",
                                        context_quote,
                                        locale
                                            .search_found_sources
                                            .replace("{}", &all_sources.len().to_string())
                                    );
                                    for (i, (title, url, score)) in
                                        all_sources.iter().take(5).enumerate()
                                    {
                                        let t = if title.chars().count() > 50 {
                                            format!(
                                                "{}...",
                                                title.chars().take(47).collect::<String>()
                                            )
                                        } else {
                                            title.clone()
                                        };
                                        let domain = url.split('/').nth(2).unwrap_or("");
                                        phase2.push_str(&format!(
                                            "{}. {} [{}%]\n   🔗 {}\n",
                                            i + 1,
                                            t,
                                            (score * 100.0) as i32,
                                            domain
                                        ));
                                    }
                                    phase2.push_str(&format!("\n{}", locale.search_synthesizing));
                                    on_chunk(&phase2);
                                    std::thread::sleep(std::time::Duration::from_millis(800));
                                }
                            }

                            if let Some(content) = message.get("content").and_then(|c| c.as_str()) {
                                full_content = content.to_string();
                                on_chunk(&full_content);
                            }
                        }
                    }
                }
            } else {
                let payload = serde_json::json!({
                    "model": p_model,
                    "messages": [{ "role": "user", "content": final_prompt }],
                    "stream": streaming_enabled
                });

                let resp = UREQ_AGENT
                    .post("https://api.groq.com/openai/v1/chat/completions")
                    .header("Authorization", &format!("Bearer {}", groq_api_key))
                    .send_json(payload)
                    .map_err(|e| anyhow::anyhow!("Groq Refine Error: {}", e))?;

                if let Some(remaining) = resp
                    .headers()
                    .get("x-ratelimit-remaining-requests")
                    .and_then(|v| v.to_str().ok())
                {
                    let limit = resp
                        .headers()
                        .get("x-ratelimit-limit-requests")
                        .and_then(|v| v.to_str().ok())
                        .unwrap_or("?");
                    let usage_str = format!("{} / {}", remaining, limit);
                    if let Ok(mut app) = APP.lock() {
                        app.model_usage_stats.insert(p_model.clone(), usage_str);
                    }
                }

                if streaming_enabled {
                    let reader = BufReader::new(resp.into_body().into_reader());
                    for line in reader.lines() {
                        let line = line?;
                        if line.starts_with("data: ") {
                            let data = &line[6..];
                            if data == "[DONE]" {
                                break;
                            }
                            if let Ok(chunk) = serde_json::from_str::<StreamChunk>(data) {
                                if let Some(content) =
                                    chunk.choices.get(0).and_then(|c| c.delta.content.as_ref())
                                {
                                    full_content.push_str(content);
                                    on_chunk(content);
                                }
                            }
                        }
                    }
                } else {
                    let json: ChatCompletionResponse = resp.into_body().read_json()?;
                    if let Some(choice) = json.choices.first() {
                        full_content = choice.message.content.clone();
                        on_chunk(&full_content);
                    }
                }
            }
        }

        Ok(full_content)
    };

    match context {
        RefineContext::Image(img_bytes) => {
            if target_provider == "google" {
                if gemini_api_key.trim().is_empty() {
                    return Err(anyhow::anyhow!("NO_API_KEY:gemini"));
                }
                let img = image::load_from_memory(&img_bytes)?.to_rgba8();
                vision_translate_image_streaming(
                    groq_api_key,
                    gemini_api_key,
                    final_prompt,
                    target_id_or_name,
                    target_provider,
                    img,
                    Some(img_bytes.clone()),
                    streaming_enabled,
                    false,
                    on_chunk,
                )
            } else if target_provider == "gemini-live" {
                // Determine mime type (default to jpeg as per common usage)
                let mime = "image/jpeg".to_string();
                super::gemini_live::gemini_live_generate(
                    final_prompt,
                    String::new(),
                    Some((img_bytes.clone(), mime)),
                    None,
                    streaming_enabled,
                    ui_language,
                    &mut on_chunk,
                )
            } else {
                if groq_api_key.trim().is_empty() {
                    return Err(anyhow::anyhow!("NO_API_KEY:groq"));
                }
                let img = image::load_from_memory(&img_bytes)?.to_rgba8();
                vision_translate_image_streaming(
                    groq_api_key,
                    gemini_api_key,
                    final_prompt,
                    target_id_or_name,
                    target_provider,
                    img,
                    Some(img_bytes.clone()),
                    streaming_enabled,
                    false,
                    on_chunk,
                )
            }
        }
        RefineContext::Audio(_) => {
            // Audio refinement uses text-only processing (transcription already done)
            exec_text_only(target_id_or_name, target_provider)
        }
        RefineContext::None => exec_text_only(target_id_or_name, target_provider),
    }
}
</file>

<file path="src/api/tts/edge_voices.rs">
//! Edge TTS voice list fetching and caching.

use lazy_static::lazy_static;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Mutex;

/// Edge TTS voice information
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EdgeVoice {
    #[serde(rename = "ShortName")]
    pub short_name: String,
    #[serde(rename = "Gender")]
    pub gender: String,
    #[serde(rename = "Locale")]
    pub locale: String,
    #[serde(rename = "FriendlyName")]
    pub friendly_name: String,
}

/// Cached voice list state
pub struct EdgeVoiceCache {
    /// All voices fetched from Edge TTS
    pub voices: Vec<EdgeVoice>,
    /// Grouped by locale (e.g., "en-US" -> [voices])
    pub by_locale: HashMap<String, Vec<EdgeVoice>>,
    /// Grouped by language code (e.g., "en" -> [voices])
    pub by_language: HashMap<String, Vec<EdgeVoice>>,
    /// Whether the cache has been loaded
    pub loaded: bool,
    /// Loading in progress
    pub loading: bool,
    /// Error message if loading failed
    pub error: Option<String>,
}

impl Default for EdgeVoiceCache {
    fn default() -> Self {
        Self {
            voices: Vec::new(),
            by_locale: HashMap::new(),
            by_language: HashMap::new(),
            loaded: false,
            loading: false,
            error: None,
        }
    }
}

lazy_static! {
    /// Global cached Edge TTS voice list
    pub static ref EDGE_VOICE_CACHE: Mutex<EdgeVoiceCache> = Mutex::new(EdgeVoiceCache::default());
}

/// Start loading the Edge TTS voice list in a background thread
pub fn load_edge_voices_async() {
    // Check if already loaded or loading
    {
        let cache = EDGE_VOICE_CACHE.lock().unwrap();
        if cache.loaded || cache.loading {
            return;
        }
    }

    // Mark as loading
    {
        let mut cache = EDGE_VOICE_CACHE.lock().unwrap();
        cache.loading = true;
    }

    // Spawn background thread to fetch voices
    std::thread::spawn(|| {
        let url = "https://speech.platform.bing.com/consumer/speech/synthesize/readaloud/voices/list?trustedclienttoken=6A5AA1D4EAFF4E9FB37E23D68491D6F4";

        match ureq::get(url)
            .header(
                "User-Agent",
                "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
            )
            .call()
        {
            Ok(response) => {
                match response.into_body().read_to_string() {
                    Ok(body) => {
                        match serde_json::from_str::<Vec<EdgeVoice>>(&body) {
                            Ok(voices) => {
                                let mut cache = EDGE_VOICE_CACHE.lock().unwrap();

                                // Group by locale
                                for voice in &voices {
                                    cache
                                        .by_locale
                                        .entry(voice.locale.clone())
                                        .or_insert_with(Vec::new)
                                        .push(voice.clone());

                                    // Group by language code (first part of locale)
                                    let lang_code = voice
                                        .locale
                                        .split('-')
                                        .next()
                                        .unwrap_or(&voice.locale)
                                        .to_lowercase();
                                    cache
                                        .by_language
                                        .entry(lang_code)
                                        .or_insert_with(Vec::new)
                                        .push(voice.clone());
                                }

                                cache.voices = voices;
                                cache.loaded = true;
                                cache.loading = false;
                                cache.error = None;
                            }
                            Err(e) => {
                                let mut cache = EDGE_VOICE_CACHE.lock().unwrap();
                                cache.loading = false;
                                cache.error = Some(format!("Parse error: {}", e));
                            }
                        }
                    }
                    Err(e) => {
                        let mut cache = EDGE_VOICE_CACHE.lock().unwrap();
                        cache.loading = false;
                        cache.error = Some(format!("Read error: {}", e));
                    }
                }
            }
            Err(e) => {
                let mut cache = EDGE_VOICE_CACHE.lock().unwrap();
                cache.loading = false;
                cache.error = Some(format!("Network error: {}", e));
            }
        }
    });
}

/// Get all unique languages with their display names
/// Languages are extracted dynamically from the Edge TTS voice list FriendlyName field
pub fn get_available_languages() -> Vec<(String, String)> {
    let cache = EDGE_VOICE_CACHE.lock().unwrap();
    if !cache.loaded {
        return Vec::new();
    }

    // Build a map of language code -> language name from actual voice data
    let mut lang_map: std::collections::HashMap<String, String> = std::collections::HashMap::new();

    for voice in &cache.voices {
        let lang_code = voice
            .locale
            .split('-')
            .next()
            .unwrap_or(&voice.locale)
            .to_lowercase();

        // Don't overwrite if we already have a name for this language
        if lang_map.contains_key(&lang_code) {
            continue;
        }

        // Extract language name from FriendlyName
        // Format: "Microsoft Xxx Online (Natural) - Language (Region)"
        // We want just "Language" for clarity
        if let Some(dash_pos) = voice.friendly_name.rfind(" - ") {
            let lang_region = &voice.friendly_name[dash_pos + 3..];
            // Get just the language part (before parentheses with region)
            if let Some(paren_pos) = lang_region.find(" (") {
                let lang_only = &lang_region[..paren_pos];
                lang_map.insert(lang_code, lang_only.to_string());
            } else {
                lang_map.insert(lang_code, lang_region.to_string());
            }
        }
    }

    let mut languages: Vec<(String, String)> = lang_map.into_iter().collect();
    languages.sort_by(|a, b| a.1.cmp(&b.1));
    languages
}

/// Get voices for a specific language code
pub fn get_voices_for_language(lang_code: &str) -> Vec<EdgeVoice> {
    let cache = EDGE_VOICE_CACHE.lock().unwrap();
    cache
        .by_language
        .get(&lang_code.to_lowercase())
        .cloned()
        .unwrap_or_default()
}
</file>

<file path="src/api/tts/instance.rs">
use std::sync::Arc;
use lazy_static::lazy_static;
use super::manager::TtsManager;

lazy_static! {
    /// The global TTS connection manager
    pub static ref TTS_MANAGER: Arc<TtsManager> = Arc::new(TtsManager::new());
}
</file>

<file path="src/api/tts/mod.rs">
//! Text-to-Speech using Gemini Live API
//!
//! This module provides persistent TTS capabilities using Gemini's native
//! audio model. The WebSocket connection is maintained at app startup
//! for instant speech synthesis with minimal latency.

pub mod edge_voices;
pub mod instance;
pub mod manager;
pub mod player;
pub mod types;
pub mod utils;
pub mod websocket;
pub mod worker;
pub mod wsola;

// Re-export public API for backward compatibility
pub use instance::TTS_MANAGER;
pub use manager::TtsManager;

/// Initialize the TTS system - call this at app startup
pub fn init_tts() {
    // Spawn 1 Player Thread
    let manager = TTS_MANAGER.clone();
    std::thread::spawn(move || {
        player::run_player_thread(manager);
    });

    // Spawn 2 Socket Worker Threads (Parallel Fetching)
    for _ in 0..2 {
        let manager = TTS_MANAGER.clone();
        std::thread::spawn(move || {
            worker::run_socket_worker(manager);
        });
    }
}
</file>

<file path="src/api/tts/player.rs">
use std::collections::VecDeque;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc, Mutex,
};

use std::time::Duration;
use windows::Win32::Media::Audio::*;
use windows::Win32::System::Com::*;

use super::manager::TtsManager;
use super::types::*;
use super::utils::{clear_tts_loading_state, clear_tts_state};
use super::wsola::WsolaStretcher;

/// Main Player thread - consumes audio streams sequentially
pub fn run_player_thread(manager: Arc<TtsManager>) {
    // Create ONE persistent audio player
    // This avoids the overhead of opening the audio device for every request
    // We pass manager to AudioPlayer so it can check interrupts
    let audio_player = AudioPlayer::new(PLAYBACK_SAMPLE_RATE, manager.clone());

    loop {
        if manager.shutdown.load(Ordering::SeqCst) {
            break;
        }

        let playback_job = {
            let mut pq = manager.playback_queue.lock().unwrap();
            while pq.is_empty() && !manager.shutdown.load(Ordering::SeqCst) {
                let result = manager.playback_signal.wait(pq).unwrap();
                pq = result;
            }
            if manager.shutdown.load(Ordering::SeqCst) {
                return;
            }
            pq.pop_front()
        };

        if let Some((rx, hwnd, _req_id, generation, is_realtime)) = playback_job {
            let mut loading_cleared = false;

            // Mark that we're now playing audio
            manager.is_playing.store(true, Ordering::SeqCst);

            // Loop reading chunks from this channel
            loop {
                match rx.recv() {
                    Ok(AudioEvent::Data(data)) => {
                        // Check interrupt before playing
                        if generation < manager.interrupt_generation.load(Ordering::SeqCst) {
                            audio_player.stop();
                            clear_tts_state(hwnd);
                            break;
                        }

                        if !loading_cleared {
                            loading_cleared = true;
                            clear_tts_loading_state(hwnd);
                        }
                        audio_player.play(&data, is_realtime);
                    }
                    Ok(AudioEvent::End) => {
                        // Check if we were interrupted or finished normally
                        if generation < manager.interrupt_generation.load(Ordering::SeqCst) {
                            audio_player.stop(); // Immediate cut-off
                        } else {
                            audio_player.drain(); // Normal finish
                        }
                        clear_tts_state(hwnd);
                        break; // Job done
                    }
                    Err(_) => {
                        // Sender disconnected
                        if generation < manager.interrupt_generation.load(Ordering::SeqCst) {
                            audio_player.stop();
                        } else {
                            audio_player.drain();
                        }
                        clear_tts_state(hwnd);
                        break;
                    }
                }

                if manager.shutdown.load(Ordering::SeqCst) {
                    manager.is_playing.store(false, Ordering::SeqCst);
                    return;
                }

                // Check interrupt again
                if generation < manager.interrupt_generation.load(Ordering::SeqCst) {
                    audio_player.stop();
                    clear_tts_state(hwnd);
                    break;
                }
            }

            // Mark that we're done playing this job
            manager.is_playing.store(false, Ordering::SeqCst);
        }
    }
}

/// Simple audio player using Windows WASAPI with loopback exclusion
struct AudioPlayer {
    _sample_rate: u32,
    // Shared buffer for audio data (thread-safe)
    shared_buffer: Arc<Mutex<VecDeque<i16>>>,
    // Shutdown signal for the player thread
    shutdown: Arc<AtomicBool>,
    // Player thread handle
    _thread: Option<std::thread::JoinHandle<()>>,
    // WSOLA time stretcher for pitch-preserving speed control
    wsola: Mutex<WsolaStretcher>,
}

impl AudioPlayer {
    fn new(sample_rate: u32, manager: Arc<TtsManager>) -> Self {
        let shared_buffer: Arc<Mutex<VecDeque<i16>>> = Arc::new(Mutex::new(VecDeque::new()));
        let buffer_clone = shared_buffer.clone();
        let shutdown = Arc::new(AtomicBool::new(false));
        let shutdown_clone = shutdown.clone();

        // Read config for device ID
        let target_device_id = {
            if let Ok(app) = crate::APP.lock() {
                let id = app.config.tts_output_device.clone();
                if id.is_empty() {
                    None
                } else {
                    Some(id)
                }
            } else {
                None
            }
        };

        // Spawn a dedicated thread for WASAPI playback
        let thread = std::thread::spawn(move || {
            // Initialize COM for this thread
            if wasapi::initialize_mta().is_err() {
                eprintln!("TTS: Failed to initialize COM");
                return;
            }

            // Try to create an AudioClient with loopback exclusion
            let result = Self::create_excluded_stream(
                sample_rate,
                buffer_clone.clone(),
                shutdown_clone.clone(),
                target_device_id,
                manager,
            );

            if let Err(e) = result {
                eprintln!(
                    "TTS: WASAPI with exclusion failed ({}), falling back to cpal",
                    e
                );
            }
        });

        Self {
            _sample_rate: sample_rate,
            shared_buffer,
            shutdown,
            _thread: Some(thread),
            wsola: Mutex::new(WsolaStretcher::new(SOURCE_SAMPLE_RATE)),
        }
    }

    fn create_excluded_stream(
        _sample_rate: u32,
        shared_buffer: Arc<Mutex<VecDeque<i16>>>,
        shutdown: Arc<AtomicBool>,
        target_device_id: Option<String>,
        manager: Arc<TtsManager>,
    ) -> anyhow::Result<()> {
        let buffer_clone = shared_buffer.clone();
        let shutdown_clone = shutdown.clone();

        // Attempt WASAPI with exclusion
        std::thread::spawn(move || {
            if let Err(e) = unsafe {
                Self::run_wasapi_excluded(
                    _sample_rate,
                    buffer_clone.clone(),
                    shutdown_clone.clone(),
                    target_device_id,
                    manager,
                )
            } {
                eprintln!(
                    "TTS: WASAPI exclusion FAILED with error: {:?}. Call ended.",
                    e
                );
            }
        });

        Ok(())
    }

    unsafe fn run_wasapi_excluded(
        _sample_rate: u32,
        shared_buffer: Arc<Mutex<VecDeque<i16>>>,
        shutdown: Arc<AtomicBool>,
        target_device_id: Option<String>,
        manager: Arc<TtsManager>,
    ) -> anyhow::Result<()> {
        // Use STA for better compatibility with audio drivers
        let _ = CoInitializeEx(None, COINIT_APARTMENTTHREADED).ok();

        let enumerator: IMMDeviceEnumerator =
            CoCreateInstance(&MMDeviceEnumerator, None, CLSCTX_ALL)?;

        let device = if let Some(id_str) = target_device_id {
            // Try to find specific device
            let id_hstring = windows::core::HSTRING::from(id_str);
            enumerator.GetDevice(&id_hstring)?
        } else {
            // Use Console role for TTS (Default)
            enumerator.GetDefaultAudioEndpoint(eRender, eConsole)?
        };

        // Activate IAudioClient
        let client: IAudioClient = device.Activate(CLSCTX_ALL, None)?;

        // Note: We no longer try to exclude from loopback
        let mix_format_ptr = client.GetMixFormat()?;
        let mix_format = *mix_format_ptr;

        // Initialize (Shared Mode)
        client.Initialize(
            AUDCLNT_SHAREMODE_SHARED,
            0,       // flags
            1000000, // 100ms buffer
            0,
            mix_format_ptr,
            None,
        )?;

        let buffer_size = client.GetBufferSize()?;
        let render_client: IAudioRenderClient = client.GetService()?;

        client.Start()?;

        let channels = mix_format.nChannels as usize;
        let is_float = mix_format.wFormatTag == 3 // WAVE_FORMAT_IEEE_FLOAT
                       || (mix_format.wFormatTag == 65534 // WAVE_FORMAT_EXTENSIBLE 
                          && (mix_format.cbSize >= 22));

        let _frames_written = 0;

        let mut last_gen = manager.interrupt_generation.load(Ordering::SeqCst);

        while !shutdown.load(Ordering::Relaxed) {
            let current_gen = manager.interrupt_generation.load(Ordering::SeqCst);
            if current_gen > last_gen {
                if let Ok(mut deck) = shared_buffer.lock() {
                    deck.clear();
                }
                last_gen = current_gen;
            }
            let padding = client.GetCurrentPadding()?;
            let available = buffer_size.saturating_sub(padding);

            if available > 0 {
                let buffer_ptr = render_client.GetBuffer(available)?;

                // Lock inner buffer
                let mut deck = shared_buffer.lock().unwrap();

                if is_float {
                    let out_slice = std::slice::from_raw_parts_mut(
                        buffer_ptr as *mut f32,
                        (available as usize) * channels,
                    );

                    for i in 0..available as usize {
                        if let Some(sample) = deck.pop_front() {
                            let s = (sample as f32) / 32768.0;
                            for c in 0..channels {
                                out_slice[i * channels + c] = s;
                            }
                        } else {
                            // Silence when buffer is empty
                            for c in 0..channels {
                                out_slice[i * channels + c] = 0.0;
                            }
                        }
                    }
                } else {
                    // PCM i16
                    let out_slice = std::slice::from_raw_parts_mut(
                        buffer_ptr as *mut i16,
                        (available as usize) * channels,
                    );
                    for i in 0..available as usize {
                        if let Some(sample) = deck.pop_front() {
                            for c in 0..channels {
                                out_slice[i * channels + c] = sample;
                            }
                        } else {
                            for c in 0..channels {
                                out_slice[i * channels + c] = 0;
                            }
                        }
                    }
                }

                render_client.ReleaseBuffer(available, 0)?;
            }

            std::thread::sleep(Duration::from_millis(10));
        }

        client.Stop()?;
        Ok(())
    }

    fn play(&self, audio_data: &[u8], is_realtime: bool) {
        // Get effective speed
        let effective_speed = if is_realtime {
            use crate::overlay::realtime_webview::state::{
                COMMITTED_TRANSLATION_QUEUE, CURRENT_TTS_SPEED, REALTIME_HWND,
                REALTIME_TTS_AUTO_SPEED, REALTIME_TTS_SPEED, WM_UPDATE_TTS_SPEED,
            };

            let base_speed = REALTIME_TTS_SPEED.load(Ordering::Relaxed);
            let auto_enabled = REALTIME_TTS_AUTO_SPEED.load(Ordering::Relaxed);

            // Auto-catchup: boost speed if queue is building up
            let queue_len = COMMITTED_TRANSLATION_QUEUE
                .lock()
                .map(|q| q.len())
                .unwrap_or(0);

            let speed = if auto_enabled && queue_len > 0 {
                // +15% per queued item, up to +60%
                let boost = (queue_len as u32 * 15).min(60);
                (base_speed + boost).min(200)
            } else {
                base_speed
            };

            // Update current speed for UI if it changed
            let old_speed = CURRENT_TTS_SPEED.swap(speed, Ordering::Relaxed);
            if old_speed != speed {
                unsafe {
                    use crate::overlay::realtime_webview::state::TRANSLATION_HWND;
                    use windows::Win32::Foundation::{LPARAM, WPARAM};
                    use windows::Win32::UI::WindowsAndMessaging::PostMessageW;
                    if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                        let _ = PostMessageW(
                            Some(REALTIME_HWND),
                            WM_UPDATE_TTS_SPEED,
                            WPARAM(speed as usize),
                            LPARAM(0),
                        );
                    }
                    if !std::ptr::addr_of!(TRANSLATION_HWND).read().is_invalid() {
                        let _ = PostMessageW(
                            Some(TRANSLATION_HWND),
                            WM_UPDATE_TTS_SPEED,
                            WPARAM(speed as usize),
                            LPARAM(0),
                        );
                    }
                }
            }
            speed
        } else {
            100 // Normal speed for non-realtime TTS
        };

        let speed_ratio = effective_speed as f64 / 100.0;

        // Convert raw PCM bytes to i16 samples (little-endian)
        let input_samples: Vec<i16> = audio_data
            .chunks_exact(2)
            .map(|chunk| i16::from_le_bytes([chunk[0], chunk[1]]))
            .collect();

        if input_samples.is_empty() {
            return;
        }

        // Apply WSOLA time-stretching
        let stretched_samples = if (speed_ratio - 1.0).abs() < 0.05 {
            input_samples
        } else {
            if let Ok(mut wsola) = self.wsola.lock() {
                let result = wsola.stretch(&input_samples, speed_ratio);
                if result.is_empty() {
                    return;
                }
                result
            } else {
                input_samples
            }
        };

        // Upsample from 24kHz to 48kHz (duplicate each sample)
        let output_samples: Vec<i16> = stretched_samples.iter().flat_map(|&s| [s, s]).collect();

        // Add to shared buffer
        if let Ok(mut buf) = self.shared_buffer.lock() {
            buf.extend(output_samples);
        }
    }

    fn drain(&self) {
        // Wait for buffer to drain
        loop {
            let len = self.shared_buffer.lock().map(|b| b.len()).unwrap_or(0);
            if len == 0 {
                break;
            }
            std::thread::sleep(Duration::from_millis(50));
        }
        std::thread::sleep(Duration::from_millis(100));
    }

    fn stop(&self) {
        if let Ok(mut buf) = self.shared_buffer.lock() {
            buf.clear();
        }
    }
}

impl Drop for AudioPlayer {
    fn drop(&mut self) {
        self.shutdown.store(true, Ordering::SeqCst);
    }
}
</file>

<file path="src/api/tts/types.rs">
/// Model for TTS (same native audio model, configured for output only)
pub const TTS_MODEL: &str = "gemini-2.5-flash-native-audio-preview-12-2025";

/// Output audio sample rate from Gemini (24kHz)
pub const SOURCE_SAMPLE_RATE: u32 = 24000;

/// Playback sample rate (48kHz - most devices support this)
pub const PLAYBACK_SAMPLE_RATE: u32 = 48000;

/// Events passed from socket workers to the player thread
pub enum AudioEvent {
    Data(Vec<u8>),
    End,
}

/// Request paired with its generation ID (to handle interrupts)
#[derive(Clone)]
pub struct QueuedRequest {
    pub req: TtsRequest,
    pub generation: u64,
}

/// TTS request with unique ID for cancellation
#[derive(Clone)]
pub struct TtsRequest {
    pub _id: u64,
    pub text: String,
    pub hwnd: isize,       // Window handle to update state when audio starts
    pub is_realtime: bool, // True if this is from realtime translation (uses REALTIME_TTS_SPEED)
}
</file>

<file path="src/api/tts/websocket.rs">
use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
use native_tls::TlsStream;
use std::net::TcpStream;
use std::time::Duration;
use tungstenite::WebSocket;

use super::types::TTS_MODEL;

/// Create TLS WebSocket connection to Gemini Live API for TTS
pub fn connect_tts_websocket(api_key: &str) -> Result<WebSocket<TlsStream<TcpStream>>> {
    let ws_url = format!(
        "wss://generativelanguage.googleapis.com/ws/google.ai.generativelanguage.v1beta.GenerativeService.BidiGenerateContent?key={}",
        api_key
    );

    let url = url::Url::parse(&ws_url)?;
    let host = url
        .host_str()
        .ok_or_else(|| anyhow::anyhow!("No host in URL"))?;
    let port = 443;

    use std::net::ToSocketAddrs;
    let addr = format!("{}:{}", host, port)
        .to_socket_addrs()?
        .next()
        .ok_or_else(|| anyhow::anyhow!("Failed to resolve hostname: {}", host))?;

    let tcp_stream = TcpStream::connect_timeout(&addr, Duration::from_secs(10))?;
    tcp_stream.set_read_timeout(Some(Duration::from_secs(30)))?;
    tcp_stream.set_write_timeout(Some(Duration::from_secs(30)))?;
    tcp_stream.set_nodelay(true)?;

    let connector = native_tls::TlsConnector::new()?;
    let tls_stream = connector.connect(host, tcp_stream)?;

    let (socket, _response) = tungstenite::client::client(&ws_url, tls_stream)?;

    Ok(socket)
}

/// Send TTS setup message - configures for audio output only, no input transcription
pub fn send_tts_setup(
    socket: &mut WebSocket<TlsStream<TcpStream>>,
    voice_name: &str,
    speed: &str,
    custom_instructions: Option<&str>,
) -> Result<()> {
    // System instruction based on speed
    let mut system_text = "You are a text-to-speech reader. Your ONLY job is to read the user's text out loud, exactly as written, word for word. Do NOT respond conversationally. Do NOT add commentary. Do NOT ask questions. ".to_string();

    match speed {
        "Slow" => system_text.push_str("Speak slowly, clearly, and with deliberate pacing. "),
        "Fast" => system_text.push_str("Speak quickly, efficiently, and with a brisk pace. "),
        _ => system_text.push_str("Simply read the provided text aloud naturally and clearly. "),
    }

    // Append custom tone/style instructions if provided
    if let Some(instructions) = custom_instructions {
        if !instructions.trim().is_empty() {
            system_text.push_str(" Additional instructions: ");
            system_text.push_str(instructions.trim());
            system_text.push(' ');
        }
    }

    system_text.push_str("Start reading immediately.");

    let setup = serde_json::json!({
        "setup": {
            "model": format!("models/{}", TTS_MODEL),
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": {
                    "voiceConfig": {
                        "prebuiltVoiceConfig": {
                            "voiceName": voice_name
                        }
                    }
                },
                "thinkingConfig": {
                    "thinkingBudget": 0
                }
            },
            "systemInstruction": {
                "parts": [{
                    "text": system_text
                }]
            }
        }
    });

    let msg_str = setup.to_string();
    socket.write(tungstenite::Message::Text(msg_str.into()))?;
    socket.flush()?;

    Ok(())
}

/// Send text to be spoken
pub fn send_tts_text(socket: &mut WebSocket<TlsStream<TcpStream>>, text: &str) -> Result<()> {
    // Format with explicit instruction to read verbatim
    let prompt = format!("[READ ALOUD VERBATIM - START NOW]\n\n{}", text);

    let msg = serde_json::json!({
        "clientContent": {
            "turns": [{
                "role": "user",
                "parts": [{
                    "text": prompt
                }]
            }],
            "turnComplete": true
        }
    });

    socket.write(tungstenite::Message::Text(msg.to_string().into()))?;
    socket.flush()?;

    Ok(())
}

/// Parse audio data from WebSocket message
pub fn parse_audio_data(msg: &str) -> Option<Vec<u8>> {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(msg) {
        // Check for serverContent -> modelTurn -> parts -> inlineData
        if let Some(server_content) = json.get("serverContent") {
            if let Some(model_turn) = server_content.get("modelTurn") {
                if let Some(parts) = model_turn.get("parts").and_then(|p| p.as_array()) {
                    for part in parts {
                        if let Some(inline_data) = part.get("inlineData") {
                            if let Some(data_b64) = inline_data.get("data").and_then(|d| d.as_str())
                            {
                                if let Ok(audio_bytes) = general_purpose::STANDARD.decode(data_b64)
                                {
                                    return Some(audio_bytes);
                                }
                            }
                        }
                    }
                }
            }
        }
    }
    None
}

/// Check if the response indicates turn is complete
pub fn is_turn_complete(msg: &str) -> bool {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(msg) {
        if let Some(server_content) = json.get("serverContent") {
            // Check for turnComplete
            if let Some(turn_complete) = server_content.get("turnComplete") {
                if turn_complete.as_bool().unwrap_or(false) {
                    return true;
                }
            }
            // Also check for generationComplete (seen in TTS responses)
            if let Some(gen_complete) = server_content.get("generationComplete") {
                if gen_complete.as_bool().unwrap_or(false) {
                    return true;
                }
            }
        }
    }
    false
}
</file>

<file path="src/api/tts/wsola.rs">
use std::f32;

/// Simple OLA (Overlap-Add) time stretcher for pitch-preserving tempo change.
/// Uses Hann window for perfect reconstruction at 50% overlap.
pub struct WsolaStretcher {
    /// Frame size in samples (20ms at 24kHz = 480 samples)
    frame_size: usize,
    /// Hop size (frame_size / 2 for 50% overlap)
    hop_size: usize,
    /// Hann window
    window: Vec<f32>,
    /// Input buffer for accumulating samples
    pub input_buffer: Vec<f32>,
    /// Output overlap buffer - carries the "tail" that needs to overlap with next chunk
    output_overlap: Vec<f32>,
    /// Search range for alignment (SOLA)
    search_range: usize,
    /// Previous speed ratio (to detect changes)
    last_speed: f64,
}

impl WsolaStretcher {
    pub fn new(sample_rate: u32) -> Self {
        // 20ms frame size for better streaming with small chunks
        // At 24kHz: 20ms = 480 samples
        let frame_size = (sample_rate as usize * 20) / 1000;
        let hop_size = frame_size / 2; // 50% overlap
        
        // Create Hann window - with 50% overlap, Hann windows sum to exactly 1.0
        // This is crucial for artifact-free overlap-add!
        let window: Vec<f32> = (0..frame_size)
            .map(|i| {
                let t = i as f32 / frame_size as f32;
                // Hann window: 0.5 * (1 - cos(2*pi*t))
                0.5 * (1.0 - (2.0 * std::f32::consts::PI * t).cos())
            })
            .collect();
        
        Self {
            frame_size,
            hop_size,
            window,
            input_buffer: Vec::new(),
            output_overlap: Vec::new(),
            search_range: hop_size / 2, // Search +/- 50% of hop size
            last_speed: 1.0,
        }
    }
    
    /// Find best offset using cross-correlation
    fn find_best_offset(&self, input_pos: usize, target_hop: usize) -> usize {
        // Strategy: We want to overlap the END of the previous frame (which is in output buffer)
        // with the BEGINNING of the new frame.
        // We look for self-similarity in the input signal around the analysis hop.
        
        // Search range: [target_hop - search_range, target_hop + search_range]
        let start = target_hop.saturating_sub(self.search_range);
        let end = (target_hop + self.search_range).min(self.input_buffer.len().saturating_sub(self.frame_size + input_pos).saturating_sub(1));
        
        if start >= end {
            return target_hop;
        }

        let mut best_offset = target_hop;
        let mut max_corr = -1.0;
        
        // Use a subset of samples for correlation to save CPU
        let compare_len = self.search_range;
        
        let ref_pos = input_pos + self.hop_size;
        if ref_pos + compare_len > self.input_buffer.len() {
             return target_hop;
        }
        
        let ref_segment = &self.input_buffer[ref_pos..ref_pos + compare_len];

        for k in start..end {
            let candidate_pos = input_pos + k;
             if candidate_pos + compare_len > self.input_buffer.len() {
                continue;
            }
            
            let candidate = &self.input_buffer[candidate_pos..candidate_pos + compare_len];
            
            // Cross-correlation
            let mut corr = 0.0;
            for i in 0..compare_len {
                corr += ref_segment[i] * candidate[i];
            }
            
            if corr > max_corr {
                max_corr = corr;
                best_offset = k;
            }
        }
        
        best_offset
    }

    /// Time-stretch the input samples.
    /// speed_ratio > 1.0 = faster (compress time), < 1.0 = slower (expand time)
    pub fn stretch(&mut self, input: &[i16], speed_ratio: f64) -> Vec<i16> {
        // Bypass for normal speed
        if (speed_ratio - 1.0).abs() < 0.05 || input.is_empty() {
            // Flush any remaining overlap buffer
            if !self.output_overlap.is_empty() {
                let result: Vec<i16> = self.output_overlap.drain(..)
                    .map(|s| s.clamp(-32768.0, 32767.0) as i16)
                    .collect();
                // Also return the input
                let mut combined = result;
                combined.extend(input.iter().cloned());
                return combined;
            }
            return input.to_vec();
        }
        
        // Clear buffers if speed changed significantly (avoid artifacts)
        if (speed_ratio - self.last_speed).abs() > 0.15 {
            self.input_buffer.clear();
            self.output_overlap.clear();
        }
        self.last_speed = speed_ratio;
        
        // Add input samples to buffer (convert to f32)
        self.input_buffer.extend(input.iter().map(|&s| s as f32));
        
        // Need at least one frame + search range to process
        if self.input_buffer.len() < self.frame_size + self.search_range {
            return Vec::new();
        }
        
        // Ideal analysis hop
        let target_analysis_hop = (self.hop_size as f64 * speed_ratio).round() as usize;
        
        // Synthesis hop stays constant at 50% of frame size
        let synthesis_hop = self.hop_size;
        
        // Output buffer
        // We guess size based on target ratio, but it will vary slightly due to SOLA
        let estimated_frames = self.input_buffer.len() / target_analysis_hop.max(1);
        let mut output = vec![0.0f32; estimated_frames * synthesis_hop + self.frame_size];
        
        // Initialize output with overlap from previous call
        for (i, &v) in self.output_overlap.iter().enumerate() {
            if i < output.len() {
                output[i] = v;
            }
        }
        
        let mut input_pos = 0usize;
        let mut output_pos = 0usize;
        
        loop {
            // Ensure we have enough input for:
            // 1. Comparison (at current pos + hop_size)
            // 2. Next frame (at current pos + target_hop + search_range)
            if input_pos + self.frame_size + self.search_range + target_analysis_hop > self.input_buffer.len() {
                break;
            }
            if output_pos + self.frame_size > output.len() {
                output.resize(output_pos + self.frame_size * 2, 0.0);
            }
            
            // Find best alignment offset (SOLA)
            let actual_analysis_hop = self.find_best_offset(input_pos, target_analysis_hop);
            
            // Advance input by the OPTIMIZED hop
            input_pos += actual_analysis_hop;
            
            // Apply window and overlap-add
            for i in 0..self.frame_size {
                let in_sample = self.input_buffer[input_pos + i];
                let w = self.window[i];
                output[output_pos + i] += in_sample * w;
            }
            
            output_pos += synthesis_hop;
        }
        
        // The "complete" output is everything up to the start of the last frame's tail
        let complete_len = output_pos.min(output.len());
        
        // Save the tail for next call's overlap
        self.output_overlap.clear();
        if complete_len < output.len() {
            self.output_overlap.extend_from_slice(&output[complete_len..]);
        }
        
        // Remove consumed input
        let consumed = input_pos.min(self.input_buffer.len());
        
        if consumed > 0 {
            self.input_buffer.drain(0..consumed);
        }
        
        // Return the complete portion as i16
        output[..complete_len].iter()
            .map(|&s| s.clamp(-32768.0, 32767.0) as i16)
            .collect()
    }
}
</file>

<file path="src/api/types.rs">
use serde::{Deserialize, Serialize};

#[derive(Serialize, Deserialize)]
pub struct StreamChunk {
    pub choices: Vec<Choice>,
}

#[derive(Serialize, Deserialize)]
pub struct Choice {
    pub delta: Delta,
}

#[derive(Serialize, Deserialize)]
pub struct Delta {
    pub content: Option<String>,
    #[serde(default)]
    pub reasoning: Option<String>,
}

#[derive(Serialize, Deserialize)]
pub struct ChatCompletionResponse {
    pub choices: Vec<ChatChoice>,
}

#[derive(Serialize, Deserialize)]
pub struct ChatChoice {
    pub message: ChatMessage,
}

#[derive(Serialize, Deserialize)]
pub struct ChatMessage {
    pub content: String,
    // Compound model fields (optional)
    #[serde(default)]
    pub reasoning: Option<String>,
    #[serde(default)]
    pub executed_tools: Option<Vec<ExecutedTool>>,
}

// --- COMPOUND MODEL TYPES ---

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct ExecutedTool {
    #[serde(default)]
    pub index: i32,
    #[serde(rename = "type", default)]
    pub tool_type: String,
    #[serde(default)]
    pub arguments: Option<String>,
    #[serde(default)]
    pub output: Option<String>,
    #[serde(default)]
    pub search_results: Option<SearchResults>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct SearchResults {
    #[serde(default)]
    pub results: Vec<SearchResult>,
}

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct SearchResult {
    #[serde(default)]
    pub title: String,
    #[serde(default)]
    pub url: String,
    #[serde(default)]
    pub content: String,
    #[serde(default)]
    pub score: f64,
}
</file>

<file path="src/api/vision.rs">
use super::client::UREQ_AGENT;
use super::types::{ChatCompletionResponse, StreamChunk};
use crate::gui::locale::LocaleText;
use crate::APP;
use anyhow::Result;
use base64::{engine::general_purpose, Engine as _};
use image::{ImageBuffer, Rgba};
use std::io::{BufRead, BufReader, Cursor};

pub fn translate_image_streaming<F>(
    groq_api_key: &str,
    gemini_api_key: &str,
    prompt: String,
    model: String,
    provider: String,
    image: ImageBuffer<Rgba<u8>, Vec<u8>>,
    original_bytes: Option<Vec<u8>>, // Zero-Copy support
    streaming_enabled: bool,
    use_json_format: bool,
    mut on_chunk: F,
) -> Result<String>
where
    F: FnMut(&str),
{
    let openrouter_api_key = crate::APP
        .lock()
        .ok()
        .and_then(|app| {
            let config = app.config.clone();
            if config.openrouter_api_key.is_empty() {
                None
            } else {
                Some(config.openrouter_api_key.clone())
            }
        })
        .unwrap_or_default();

    let b64_image: String;
    let mut image_data = Vec::new();
    let mut mime_type = "image/png".to_string();

    // Check for "Zero-Copy" path (Google provider + Original Bytes available)
    if provider == "google" && original_bytes.is_some() {
        println!("DEBUG: Zero-Copy optimization active for Google provider");
        // Use original bytes directly (e.g. JPEG) - no resize, no conversion
        let bytes = original_bytes.as_ref().unwrap();
        b64_image = general_purpose::STANDARD.encode(bytes);

        // Sniff mime type
        if bytes.starts_with(&[0xff, 0xd8, 0xff]) {
            mime_type = "image/jpeg".to_string();
        } else if bytes.starts_with(&[0x89, 0x50, 0x4e, 0x47]) {
            mime_type = "image/png".to_string();
        } else if bytes.starts_with(&[0x52, 0x49, 0x46, 0x46])
            && bytes[8..12] == [0x57, 0x45, 0x42, 0x50]
        {
            mime_type = "image/webp".to_string();
        }
        println!("DEBUG: Detected MIME type: {}", mime_type);
    } else {
        // Standard Processing Path (Resize + Convert to PNG)
        let mut final_image = image;
        let max_dim = 2048;

        // Resize if too large (Skip for Google as they handle large images well if we fall back to this path)
        if provider != "google" && (final_image.width() > max_dim || final_image.height() > max_dim)
        {
            println!("DEBUG: Image exceeds {}px, resizing...", max_dim);
            let (n_w, n_h) = if final_image.width() > final_image.height() {
                let ratio = max_dim as f32 / final_image.width() as f32;
                (max_dim, (final_image.height() as f32 * ratio) as u32)
            } else {
                let ratio = max_dim as f32 / final_image.height() as f32;
                ((final_image.width() as f32 * ratio) as u32, max_dim)
            };
            final_image = image::imageops::resize(
                &final_image,
                n_w,
                n_h,
                image::imageops::FilterType::Lanczos3,
            );
            println!(
                "DEBUG: Resized to: {}x{}",
                final_image.width(),
                final_image.height()
            );
        }

        final_image.write_to(&mut Cursor::new(&mut image_data), image::ImageFormat::Png)?;
        b64_image = general_purpose::STANDARD.encode(&image_data);
        mime_type = "image/png".to_string();
    }

    let mut full_content = String::new();

    if provider == "ollama" {
        // Ollama Local API
        let (ollama_base_url, ollama_vision_model, ui_language) = crate::APP
            .lock()
            .ok()
            .map(|app| {
                let config = app.config.clone();
                (
                    config.ollama_base_url.clone(),
                    config.ollama_vision_model.clone(),
                    config.ui_language.clone(),
                )
            })
            .unwrap_or_else(|| {
                (
                    "http://localhost:11434".to_string(),
                    model.clone(),
                    "en".to_string(),
                )
            });

        let actual_model = if ollama_vision_model.is_empty() {
            model.clone()
        } else {
            ollama_vision_model
        };

        // Reload image from PNG data
        let ollama_image = image::load_from_memory(&image_data)?.to_rgba8();

        return super::ollama::ollama_generate_vision(
            &ollama_base_url,
            &actual_model,
            &prompt,
            ollama_image,
            streaming_enabled,
            &ui_language,
            on_chunk,
        );
    } else if provider == "gemini-live" {
        // --- GEMINI LIVE API (WebSocket-based low-latency streaming with image) ---
        // Use image_data which was already populated in the preprocessing step
        // or use original_bytes for zero-copy path
        let img_bytes = if let Some(orig) = original_bytes {
            // Zero-copy path - use original bytes
            orig
        } else if !image_data.is_empty() {
            // Standard path - use processed PNG data
            image_data.clone()
        } else {
            return Err(anyhow::anyhow!("No image data available for Gemini Live"));
        };

        let ui_language = crate::APP
            .lock()
            .ok()
            .map(|app| app.config.ui_language.clone())
            .unwrap_or_else(|| "en".to_string());

        return super::gemini_live::gemini_live_generate(
            prompt.clone(),
            String::new(), // No separate instruction for vision - prompt already contains it
            Some((img_bytes, mime_type)),
            None, // No audio
            streaming_enabled,
            &ui_language,
            on_chunk,
        );
    } else if provider == "qrserver" {
        // --- QR SERVER API ---
        // Non-LLM QR Code scanner - no API key required
        // Uses multipart form upload to api.qrserver.com

        let boundary = format!(
            "----WebKitFormBoundary{}",
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos()
        );

        let mut body = Vec::new();

        // MAX_FILE_SIZE field
        body.extend_from_slice(format!("--{}\r\n", boundary).as_bytes());
        body.extend_from_slice(b"Content-Disposition: form-data; name=\"MAX_FILE_SIZE\"\r\n\r\n");
        body.extend_from_slice(b"1048576\r\n");

        // File field
        body.extend_from_slice(format!("--{}\r\n", boundary).as_bytes());
        body.extend_from_slice(
            b"Content-Disposition: form-data; name=\"file\"; filename=\"qrcode.png\"\r\n",
        );
        body.extend_from_slice(b"Content-Type: image/png\r\n\r\n");
        body.extend_from_slice(&image_data);
        body.extend_from_slice(b"\r\n");

        // End boundary
        body.extend_from_slice(format!("--{}--\r\n", boundary).as_bytes());

        let resp = UREQ_AGENT
            .post("http://api.qrserver.com/v1/read-qr-code/")
            .header(
                "Content-Type",
                &format!("multipart/form-data; boundary={}", boundary),
            )
            .send(&body)
            .map_err(|e| anyhow::anyhow!("QR Server API Error: {}", e))?;

        let json: serde_json::Value = resp
            .into_body()
            .read_json()
            .map_err(|e| anyhow::anyhow!("Failed to parse QR response: {}", e))?;

        // Response format: [{"type":"qrcode","symbol":[{"seq":0,"data":"content","error":null}]}]
        if let Some(first) = json.as_array().and_then(|a| a.first()) {
            if let Some(symbols) = first.get("symbol").and_then(|s| s.as_array()) {
                if let Some(first_symbol) = symbols.first() {
                    if let Some(data) = first_symbol.get("data").and_then(|d| d.as_str()) {
                        if !data.is_empty() {
                            full_content = data.to_string();
                            on_chunk(&full_content);
                            return Ok(full_content);
                        }
                    }
                    // Check for error
                    if let Some(error) = first_symbol.get("error").and_then(|e| e.as_str()) {
                        if !error.is_empty() {
                            return Err(anyhow::anyhow!("QR_NOT_FOUND: {}", error));
                        }
                    }
                }
            }
        }

        return Err(anyhow::anyhow!(
            "QR_NOT_FOUND: No QR code detected in image"
        ));
    } else if provider == "google" {
        // Gemini API
        if gemini_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:gemini"));
        }

        let method = if streaming_enabled {
            "streamGenerateContent"
        } else {
            "generateContent"
        };
        let url = if streaming_enabled {
            format!(
                "https://generativelanguage.googleapis.com/v1beta/models/{}:{}?alt=sse",
                model, method
            )
        } else {
            format!(
                "https://generativelanguage.googleapis.com/v1beta/models/{}:{}",
                model, method
            )
        };

        let mut payload = serde_json::json!({
            "contents": [{
                "role": "user",
                "parts": [
                    { "text": prompt },
                    {
                        "inline_data": {
                            "mime_type": mime_type,
                            "data": b64_image
                        }
                    }
                ]
            }]
        });

        // Enable thinking for Gemini 2.5+ models (gemini-2.5-flash and gemini-robotics-er)
        // Enable thinking for Gemini 2.5+ models (gemini-2.5-flash, 3.0-flash, and gemini-robotics-er)
        let supports_thinking = (model.contains("gemini-2.5-flash") && !model.contains("lite"))
            || model.contains("gemini-3-flash-preview")
            || model.contains("gemini-robotics");
        if supports_thinking {
            payload["generationConfig"] = serde_json::json!({
                "thinkingConfig": {
                    "includeThoughts": true
                }
            });
        }

        if crate::model_config::model_supports_search_by_name(&model) {
            payload["tools"] = serde_json::json!([
                { "url_context": {} },
                { "google_search": {} }
            ]);
        }

        let resp = UREQ_AGENT
            .post(&url)
            .header("x-goog-api-key", gemini_api_key)
            .send_json(payload)
            .map_err(|e| {
                let err_str = e.to_string();
                if err_str.contains("401") || err_str.contains("403") {
                    anyhow::anyhow!("INVALID_API_KEY")
                } else {
                    anyhow::anyhow!("{}", err_str)
                }
            })?;

        if streaming_enabled {
            let reader = BufReader::new(resp.into_body().into_reader());
            let mut thinking_shown = false;
            let mut content_started = false;

            // Get UI language from config for thinking indicator
            let ui_language = crate::APP
                .lock()
                .ok()
                .map(|app| app.config.ui_language.clone())
                .unwrap_or_else(|| "en".to_string());
            let locale = LocaleText::get(&ui_language);

            for line in reader.lines() {
                let line = line.map_err(|e| anyhow::anyhow!("Failed to read line: {}", e))?;
                if line.starts_with("data: ") {
                    let json_str = &line["data: ".len()..];
                    if json_str.trim() == "[DONE]" {
                        break;
                    }

                    if let Ok(chunk_resp) = serde_json::from_str::<serde_json::Value>(json_str) {
                        if let Some(candidates) =
                            chunk_resp.get("candidates").and_then(|c| c.as_array())
                        {
                            if let Some(first_candidate) = candidates.first() {
                                if let Some(parts) = first_candidate
                                    .get("content")
                                    .and_then(|c| c.get("parts"))
                                    .and_then(|p| p.as_array())
                                {
                                    for part in parts {
                                        let is_thought = part
                                            .get("thought")
                                            .and_then(|t| t.as_bool())
                                            .unwrap_or(false);

                                        if let Some(text) =
                                            part.get("text").and_then(|t| t.as_str())
                                        {
                                            if is_thought {
                                                // Model is thinking - show thinking indicator (only once)
                                                if !thinking_shown && !content_started {
                                                    on_chunk(locale.model_thinking);
                                                    thinking_shown = true;
                                                }
                                            } else {
                                                // Regular content
                                                if !content_started && thinking_shown {
                                                    content_started = true;
                                                    full_content.push_str(text);
                                                    let wipe_content = format!(
                                                        "{}{}",
                                                        crate::api::WIPE_SIGNAL,
                                                        full_content
                                                    );
                                                    on_chunk(&wipe_content);
                                                } else {
                                                    content_started = true;
                                                    full_content.push_str(text);
                                                    on_chunk(text);
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }
        } else {
            let chat_resp: serde_json::Value = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse non-streaming response: {}", e))?;

            if let Some(candidates) = chat_resp.get("candidates").and_then(|c| c.as_array()) {
                if let Some(first_choice) = candidates.first() {
                    if let Some(parts) = first_choice
                        .get("content")
                        .and_then(|c| c.get("parts"))
                        .and_then(|p| p.as_array())
                    {
                        // Filter out thought parts and collect only content
                        full_content = parts
                            .iter()
                            .filter(|p| {
                                !p.get("thought").and_then(|t| t.as_bool()).unwrap_or(false)
                            })
                            .filter_map(|p| p.get("text").and_then(|t| t.as_str()))
                            .collect::<String>();

                        on_chunk(&full_content);
                    }
                }
            }
        }
    } else if provider == "openrouter" {
        // --- OPENROUTER API ---
        if openrouter_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:openrouter"));
        }

        let payload = serde_json::json!({
            "model": model,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        { "type": "text", "text": prompt },
                        { "type": "image_url", "image_url": { "url": format!("data:image/png;base64,{}", b64_image) } }
                    ]
                }
            ],
            "stream": streaming_enabled
        });

        let resp = UREQ_AGENT
            .post("https://openrouter.ai/api/v1/chat/completions")
            .header("Authorization", &format!("Bearer {}", openrouter_api_key))
            .header("Content-Type", "application/json")
            .send_json(payload)
            .map_err(|e| {
                let err_str = e.to_string();
                if err_str.contains("401") || err_str.contains("403") {
                    anyhow::anyhow!("INVALID_API_KEY")
                } else {
                    anyhow::anyhow!("OpenRouter API Error: {}", err_str)
                }
            })?;

        if streaming_enabled {
            let reader = BufReader::new(resp.into_body().into_reader());
            let mut thinking_shown = false;
            let mut content_started = false;

            // Get UI language from config for thinking indicator
            let ui_language = crate::APP
                .lock()
                .ok()
                .map(|app| app.config.ui_language.clone())
                .unwrap_or_else(|| "en".to_string());
            let locale = LocaleText::get(&ui_language);

            for line in reader.lines() {
                let line = line?;
                if line.starts_with("data: ") {
                    let data = &line[6..];
                    if data == "[DONE]" {
                        break;
                    }

                    match serde_json::from_str::<StreamChunk>(data) {
                        Ok(chunk) => {
                            // Check for reasoning tokens (thinking phase)
                            if let Some(reasoning) = chunk
                                .choices
                                .get(0)
                                .and_then(|c| c.delta.reasoning.as_ref())
                                .filter(|s| !s.is_empty())
                            {
                                if !thinking_shown && !content_started {
                                    on_chunk(locale.model_thinking);
                                    thinking_shown = true;
                                }
                                let _ = reasoning;
                            }

                            // Check for content tokens (final result)
                            if let Some(content) = chunk
                                .choices
                                .get(0)
                                .and_then(|c| c.delta.content.as_ref())
                                .filter(|s| !s.is_empty())
                            {
                                if !content_started && thinking_shown {
                                    content_started = true;
                                    full_content.push_str(content);
                                    let wipe_content =
                                        format!("{}{}", crate::api::WIPE_SIGNAL, full_content);
                                    on_chunk(&wipe_content);
                                } else {
                                    content_started = true;
                                    full_content.push_str(content);
                                    on_chunk(content);
                                }
                            }
                        }
                        Err(_) => continue,
                    }
                }
            }
        } else {
            let chat_resp: ChatCompletionResponse = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse non-streaming response: {}", e))?;

            if let Some(choice) = chat_resp.choices.first() {
                full_content = choice.message.content.clone();
                on_chunk(&full_content);
            }
        }
    } else {
        // Groq API (default)
        if groq_api_key.trim().is_empty() {
            return Err(anyhow::anyhow!("NO_API_KEY:groq"));
        }

        let payload = if streaming_enabled {
            serde_json::json!({
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            { "type": "text", "text": prompt },
                            { "type": "image_url", "image_url": { "url": format!("data:image/png;base64,{}", b64_image) } }
                        ]
                    }
                ],
                "temperature": 0.1,
                "max_completion_tokens": 8192,
                "stream": true
            })
        } else {
            let payload_obj = serde_json::json!({
                "model": model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            { "type": "text", "text": prompt },
                            { "type": "image_url", "image_url": { "url": format!("data:image/png;base64,{}", b64_image) } }
                        ]
                    }
                ],
                "temperature": 0.1,
                "max_completion_tokens": 8192,
                "stream": false
            });

            payload_obj
        };

        let resp = UREQ_AGENT.post("https://api.groq.com/openai/v1/chat/completions")
            .header("Authorization", &format!("Bearer {}", groq_api_key))
            .send_json(payload)
            .map_err(|e| {
                let err_str = e.to_string();
                if err_str.contains("401") {
                    anyhow::anyhow!("INVALID_API_KEY")
                } else if err_str.contains("400") {
                    anyhow::anyhow!("Groq API 400: Bad request. Check model availability or API request format.")
                } else {
                    anyhow::anyhow!("Error: https://api.groq.com/openai/v1/chat/completions: {}", err_str)
                }
            })?;

        if let Some(remaining) = resp
            .headers()
            .get("x-ratelimit-remaining-requests")
            .and_then(|v| v.to_str().ok())
        {
            let limit = resp
                .headers()
                .get("x-ratelimit-limit-requests")
                .and_then(|v| v.to_str().ok())
                .unwrap_or("?");
            let usage_str = format!("{} / {}", remaining, limit);

            if let Ok(mut app) = APP.lock() {
                app.model_usage_stats.insert(model.clone(), usage_str);
            }
        }

        if streaming_enabled {
            let reader = BufReader::new(resp.into_body().into_reader());
            for line in reader.lines() {
                let line = line?;

                if line.starts_with("data: ") {
                    let data = &line[6..];

                    if data == "[DONE]" {
                        break;
                    }

                    match serde_json::from_str::<StreamChunk>(data) {
                        Ok(chunk) => {
                            if let Some(content) =
                                chunk.choices.get(0).and_then(|c| c.delta.content.as_ref())
                            {
                                full_content.push_str(content);
                                on_chunk(content);
                            }
                        }
                        Err(_) => continue,
                    }
                }
            }
        } else {
            let chat_resp: ChatCompletionResponse = resp
                .into_body()
                .read_json()
                .map_err(|e| anyhow::anyhow!("Failed to parse non-streaming response: {}", e))?;

            if let Some(choice) = chat_resp.choices.first() {
                let content_str = &choice.message.content;

                if use_json_format {
                    if let Ok(json_obj) = serde_json::from_str::<serde_json::Value>(content_str) {
                        if let Some(translation) =
                            json_obj.get("translation").and_then(|v| v.as_str())
                        {
                            full_content = translation.to_string();
                        } else {
                            full_content = content_str.clone();
                        }
                    } else {
                        full_content = content_str.clone();
                    }
                } else {
                    full_content = content_str.clone();
                }

                on_chunk(&full_content);
            }
        }
    }

    Ok(full_content)
}
</file>

<file path="src/config/io.rs">
//! Config I/O operations: load, save, and language utilities.

use std::path::PathBuf;

use crate::config::config::Config;
use crate::config::preset::{get_default_presets, Preset, ProcessingBlock};

// ============================================================================
// CONFIG PATH
// ============================================================================

/// Get the config file path
pub fn get_config_path() -> PathBuf {
    let config_dir = dirs::config_dir()
        .unwrap_or_default()
        .join("screen-goated-toolbox");
    let _ = std::fs::create_dir_all(&config_dir);
    config_dir.join("config_v3.json")
}

// ============================================================================
// CONFIG LOADING
// ============================================================================

/// Load config from disk, merging with defaults as needed
pub fn load_config() -> Config {
    let path = get_config_path();

    if !path.exists() {
        return Config::default();
    }

    let data = match std::fs::read_to_string(&path) {
        Ok(d) => d,
        Err(_) => return Config::default(),
    };

    let mut config: Config = match serde_json::from_str(&data) {
        Ok(c) => c,
        Err(_) => return Config::default(),
    };

    // Apply migrations and merge new defaults
    migrate_config(&mut config);

    config
}

/// Apply config migrations and merge new default presets
fn migrate_config(config: &mut Config) {
    let default_presets = get_default_presets();

    // -------------------------------------------------------------------------
    // 1. AUTO-MERGE NEW DEFAULT PRESETS
    // -------------------------------------------------------------------------
    // This ensures users get new presets from updates without losing their
    // custom presets or modifications to existing presets.
    //
    // Strategy:
    // - Default presets have IDs starting with "preset_"
    // - User-created presets have timestamp-based IDs
    // - For each default preset not in user's config → add it
    // - Keep user's version of existing presets (they may have customized)

    let existing_ids: std::collections::HashSet<String> =
        config.presets.iter().map(|p| p.id.clone()).collect();

    let new_presets: Vec<Preset> = default_presets
        .iter()
        .filter(|p| p.is_builtin() && !existing_ids.contains(&p.id))
        .cloned()
        .collect();

    if !new_presets.is_empty() {
        config.presets.extend(new_presets);
    }

    // -------------------------------------------------------------------------
    // 2. MIGRATE CRITICAL SETTINGS FOR EXISTING BUILT-IN PRESETS
    // -------------------------------------------------------------------------
    // When default presets are updated with new settings (like auto_paste=true),
    // sync those settings to existing user presets.

    for preset in &mut config.presets {
        if !preset.is_builtin() {
            continue;
        }

        if let Some(default_preset) = default_presets.iter().find(|p| p.id == preset.id) {
            // Sync auto_paste and auto_paste_newline
            preset.auto_paste = default_preset.auto_paste;
            preset.auto_paste_newline = default_preset.auto_paste_newline;

            // Sync audio-specific settings
            if preset.preset_type == "audio" {
                preset.auto_stop_recording = default_preset.auto_stop_recording;
            }
        }
    }

    // -------------------------------------------------------------------------
    // 3. ENSURE EVERY PRESET HAS AT LEAST ONE BLOCK
    // -------------------------------------------------------------------------
    for preset in &mut config.presets {
        if preset.blocks.is_empty() && !preset.is_master {
            preset.blocks.push(ProcessingBlock {
                block_type: preset.preset_type.clone(),
                ..Default::default()
            });
        }
    }
}

// ============================================================================
// CONFIG SAVING
// ============================================================================

/// Save config to disk
pub fn save_config(config: &Config) {
    let path = get_config_path();
    if let Ok(data) = serde_json::to_string_pretty(config) {
        let _ = std::fs::write(path, data);
    }
}

// ============================================================================
// LANGUAGE UTILITIES
// ============================================================================

lazy_static::lazy_static! {
    /// All available language names (sorted, deduplicated)
    static ref ALL_LANGUAGES: Vec<String> = {
        let mut languages = Vec::new();
        for i in 0..10000 {
            if let Some(lang) = isolang::Language::from_usize(i) {
                // Only include languages with ISO 639-1 codes (major languages)
                if lang.to_639_1().is_some() {
                    languages.push(lang.to_name().to_string());
                }
            }
        }
        languages.sort();
        languages.dedup();
        languages
    };
}

/// Get all available language names
pub fn get_all_languages() -> &'static Vec<String> {
    &ALL_LANGUAGES
}
</file>

<file path="src/config/mod.rs">
//! Configuration module for screen-goated-toolbox.
//!
//! This module provides a comprehensive, organized configuration system:
//!
//! ## Structure
//! - `config`: Main Config struct
//! - `preset`: Preset and ProcessingBlock with builder patterns
//! - `types`: Core types (enums, TTS settings, hotkeys)
//! - `io`: Load/save operations
//!
//! ## Usage
//! ```rust
//! use crate::config::{Config, Preset, ProcessingBlock, load_config, save_config};
//!
//! // Load config from disk
//! let config = load_config();
//!
//! // Create a new preset using the builder pattern
//! use crate::config::preset::{PresetBuilder, BlockBuilder};
//! let preset = PresetBuilder::new("my_preset", "My Preset")
//!     .image()
//!     .blocks(vec![
//!         BlockBuilder::image("maverick")
//!             .prompt("Extract text.")
//!             .language("Vietnamese")
//!             .build()
//!     ])
//!     .build();
//! ```

mod config;
mod io;
pub mod preset;
pub mod types;

// ============================================================================
// RE-EXPORTS - Primary API
// ============================================================================

// Config struct
pub use config::Config;

// Preset and ProcessingBlock
pub use preset::{Preset, ProcessingBlock};

// I/O functions
pub use io::{get_all_languages, load_config, save_config};

// ============================================================================
// RE-EXPORTS - Types (only what's actually used externally)
// ============================================================================

// Core enums
pub use types::ThemeMode;

// Hotkey
pub use types::Hotkey;

// TTS types
pub use types::{EdgeTtsSettings, EdgeTtsVoiceConfig, TtsLanguageCondition, TtsMethod};
</file>

<file path="src/config/preset/defaults/audio.rs">
//! Default audio presets using the builder pattern.

use crate::config::preset::Preset;
use crate::config::preset::{BlockBuilder, PresetBuilder};

/// Create all default audio presets
pub fn create_audio_presets() -> Vec<Preset> {
    vec![
        // =====================================================================
        // MIC PRESETS
        // =====================================================================

        // Transcribe speech - Basic speech-to-text
        PresetBuilder::new("preset_transcribe", "Transcribe speech")
            .audio_mic()
            .auto_paste()
            .auto_stop()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .markdown() // Upgraded: Thường -> Đẹp
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Viết liên tục - Continuous writing (Online)
        PresetBuilder::new("preset_continuous_writing_online", "Viết liên tục")
            .audio_mic()
            .auto_paste()
            // No auto_stop
            .blocks(vec![
                BlockBuilder::audio("gemini-live-audio")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Fix pronunciation - Transcribe then speak back
        PresetBuilder::new("preset_fix_pronunciation", "Fix pronunciation")
            .audio_mic()
            .auto_stop()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .markdown() // Upgraded: Thường -> Đẹp
                    .auto_speak()
                    .build(),
            ])
            .build(),

        // Quick 4NR reply - Transcribe and translate
        PresetBuilder::new("preset_transcribe_retranslate", "Quick 4NR reply")
            .audio_mic()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .language("Korean")
                    .show_overlay(false)
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Korean")
                    .show_overlay(false)
                    .markdown_stream() // Đẹp+Str
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Quicker foreigner reply - Direct audio translation
        PresetBuilder::new("preset_quicker_foreigner_reply", "Quicker foreigner reply")
            .audio_mic()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::audio("gemini-audio")
                    .prompt("Translate the audio to {language1}. Only output the translated text.")
                    .language("Korean")
                    .show_overlay(false)
                    .markdown_stream() // Đẹp+Str
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Quick AI Question - Speak to ask AI
        PresetBuilder::new("preset_quick_ai_question", "Quick AI Question")
            .audio_mic()
            .auto_stop()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Answer the following question concisely and helpfully. Format as markdown. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .markdown_stream() // Đẹp+Str
                    .build(),
            ])
            .build(),

        // Voice Search - Speak to search
        PresetBuilder::new("preset_voice_search", "Voice Search")
            .audio_mic()
            .auto_stop()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .build(),
                BlockBuilder::text("compound_mini")
                    .prompt("Search the internet for information about the following query and provide a comprehensive summary. Include key facts, recent developments, and relevant details with clickable links to sources if possible. Format the output as markdown creatively. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .markdown_stream() // Đẹp+Str
                    .build(),
            ])
            .build(),

        // Thu âm nhanh - Input Adapter Only
        PresetBuilder::new("preset_quick_record", "Quick Record")
            .audio_mic()
            .auto_stop()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .show_overlay(true)
                    .markdown() // Đẹp
                    .build(),
            ])
            .build(),

        // =====================================================================
        // DEVICE AUDIO PRESETS
        // =====================================================================

        // Study language - Listen and translate
        PresetBuilder::new("preset_study_language", "Study language")
            .audio_device()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .language("Vietnamese")
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
            ])
            .build(),

        // Live Translate - Realtime translation
        PresetBuilder::new("preset_realtime_audio_translate", "Live Translate")
            .audio_device()
            .realtime()
            .blocks(vec![
                BlockBuilder::audio("whisper-accurate")
                    .build(),
                BlockBuilder::text("google-gemma")
                    .language("Vietnamese")
                    .build(),
            ])
            .build(),

        // Thu âm máy - Input Adapter Only
        PresetBuilder::new("preset_record_device", "Record Device")
            .audio_device()
            .auto_stop()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .show_overlay(true)
                    .markdown()
                    .build(),
            ])
            .build(),

        // Chép lời TA - Transcribe English (Offline)
        PresetBuilder::new("preset_transcribe_english_offline", "Chép lời TA")
            .audio_device()
            .auto_paste()
            // No auto_stop
            .blocks(vec![
                BlockBuilder::audio("parakeet-local")
                    .language("English")
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
            ])
            .build(),
    ]
}
</file>

<file path="src/config/preset/defaults/master.rs">
//! Default MASTER presets using the builder pattern.
//!
//! MASTER presets are special presets that show a preset wheel for selection
//! instead of directly processing input.

use crate::config::preset::Preset;
use crate::config::preset::PresetBuilder;

/// Create all default MASTER presets
pub fn create_master_presets() -> Vec<Preset> {
    vec![
        // Image MASTER
        PresetBuilder::new("preset_image_master", "Image MASTER")
            .image()
            .master()
            .build(),
        // Text-Select MASTER
        PresetBuilder::new("preset_text_select_master", "Text-Select MASTER")
            .text_select()
            .master()
            .build(),
        // Text-Type MASTER
        PresetBuilder::new("preset_text_type_master", "Text-Type MASTER")
            .text_type()
            .master()
            .build(),
        // Mic MASTER
        {
            let mut p = PresetBuilder::new("preset_audio_mic_master", "Mic MASTER")
                .audio_mic()
                .master()
                .build();
            p.auto_stop_recording = true; // MASTER presets keep this setting
            p
        },
        // Device Audio MASTER
        PresetBuilder::new("preset_audio_device_master", "Device Audio MASTER")
            .audio_device()
            .master()
            .build(),
    ]
}
</file>

<file path="src/config/preset/mod.rs">
//! Preset module - Preset and ProcessingBlock definitions with builders.
//!
//! This module provides:
//! - `ProcessingBlock`: A single processing step in a chain
//! - `BlockBuilder`: Fluent API for creating blocks
//! - `Preset`: A complete workflow configuration
//! - `PresetBuilder`: Fluent API for creating presets
//! - `defaults`: Built-in preset definitions

mod block;
pub mod defaults;
mod preset;

pub use block::{BlockBuilder, ProcessingBlock};
pub use preset::{Preset, PresetBuilder};

// Re-export default preset functions for convenience
pub use defaults::get_default_presets;
</file>

<file path="src/config/preset/preset.rs">
//! Preset definition with builder pattern for easy creation.
//!
//! A Preset represents a complete workflow configuration, containing:
//! - A chain of processing blocks
//! - Block connections (for graph-based workflows)
//! - Input/output behavior settings
//! - Hotkey bindings

use serde::{Deserialize, Serialize};

use super::block::ProcessingBlock;
use crate::config::types::Hotkey;

// ============================================================================
// PRESET STRUCT
// ============================================================================

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Preset {
    /// Unique identifier. Built-in presets start with "preset_"
    pub id: String,

    /// Display name
    pub name: String,

    /// Chain of processing blocks
    #[serde(default)]
    pub blocks: Vec<ProcessingBlock>,

    /// Graph connections: (from_block_idx, to_block_idx)
    /// Allows branching: one block can connect to multiple downstream blocks
    #[serde(default)]
    pub block_connections: Vec<(usize, usize)>,

    // -------------------------------------------------------------------------
    // Input Behavior
    // -------------------------------------------------------------------------
    /// Prompt mode: "fixed" or "dynamic" (user types custom prompt)
    #[serde(default = "default_prompt_mode")]
    pub prompt_mode: String,

    /// Type of preset: "image", "text", "audio", "video"
    #[serde(default = "default_preset_type")]
    pub preset_type: String,

    /// Text input mode: "select" (highlight text) or "type" (keyboard input)
    #[serde(default = "default_text_input_mode")]
    pub text_input_mode: String,

    /// Audio source: "mic" or "device"
    #[serde(default = "default_audio_source")]
    pub audio_source: String,

    /// Audio processing mode: "record_then_process" or "realtime"
    #[serde(default = "default_audio_processing_mode")]
    pub audio_processing_mode: String,

    /// Realtime window mode: "standard" (webview) or "minimal" (egui)
    #[serde(default = "default_realtime_window_mode")]
    pub realtime_window_mode: String,

    /// Video capture method
    #[serde(default)]
    pub video_capture_method: String,

    // -------------------------------------------------------------------------
    // Output Behavior
    // -------------------------------------------------------------------------
    /// Auto-paste result to active application
    #[serde(default)]
    pub auto_paste: bool,

    /// Add newline before pasting
    #[serde(default = "default_true")]
    pub auto_paste_newline: bool,

    // -------------------------------------------------------------------------
    // Audio Recording Options
    // -------------------------------------------------------------------------
    /// Hide the recording UI overlay
    #[serde(default)]
    pub hide_recording_ui: bool,

    /// Auto-stop recording on silence detection
    #[serde(default)]
    pub auto_stop_recording: bool,

    // -------------------------------------------------------------------------
    // Text Input Options
    // -------------------------------------------------------------------------
    /// Keep input window open after submit (for repeated inputs)
    #[serde(default)]
    pub continuous_input: bool,

    // -------------------------------------------------------------------------
    // Hotkeys
    // -------------------------------------------------------------------------
    /// Keyboard shortcuts to trigger this preset
    #[serde(default)]
    pub hotkeys: Vec<Hotkey>,

    // -------------------------------------------------------------------------
    // Special Flags
    // -------------------------------------------------------------------------
    /// Upcoming/preview feature flag
    #[serde(default)]
    pub is_upcoming: bool,

    /// MASTER preset: shows preset wheel for selection
    #[serde(default)]
    pub is_master: bool,

    /// Controller UI mode: hides advanced UI elements
    #[serde(default)]
    pub show_controller_ui: bool,

    /// Favorite preset for quick access via floating bubble
    #[serde(default)]
    pub is_favorite: bool,
}

// ============================================================================
// DEFAULT VALUE FUNCTIONS
// ============================================================================

fn default_prompt_mode() -> String {
    "fixed".to_string()
}

fn default_preset_type() -> String {
    "image".to_string()
}

fn default_text_input_mode() -> String {
    "select".to_string()
}

fn default_audio_source() -> String {
    "mic".to_string()
}

fn default_audio_processing_mode() -> String {
    "record_then_process".to_string()
}

fn default_realtime_window_mode() -> String {
    "standard".to_string()
}

fn default_true() -> bool {
    true
}

// ============================================================================
// PRESET DEFAULT IMPL
// ============================================================================

impl Default for Preset {
    fn default() -> Self {
        Self {
            id: generate_preset_id(),
            name: "New Preset".to_string(),
            blocks: vec![ProcessingBlock::default()],
            block_connections: vec![],
            prompt_mode: "fixed".to_string(),
            preset_type: "image".to_string(),
            text_input_mode: "select".to_string(),
            audio_source: "mic".to_string(),
            audio_processing_mode: "record_then_process".to_string(),
            realtime_window_mode: "standard".to_string(),
            video_capture_method: "region".to_string(),
            auto_paste: false,
            auto_paste_newline: false,
            hide_recording_ui: false,
            auto_stop_recording: false,
            continuous_input: false,
            hotkeys: vec![],
            is_upcoming: false,
            is_master: false,
            show_controller_ui: false,
            is_favorite: false,
        }
    }
}

fn generate_preset_id() -> String {
    format!(
        "{:x}",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_nanos()
    )
}

// ============================================================================
// PRESET BUILDER
// ============================================================================

/// Builder for creating Presets with a fluent API.
///
/// # Example
/// ```
/// let preset = PresetBuilder::new("preset_translate", "Translate")
///     .image()
///     .blocks(vec![block1, block2])
///     .connections(vec![(0, 1)])
///     .build();
/// ```
#[derive(Clone)]
pub struct PresetBuilder {
    preset: Preset,
}

impl PresetBuilder {
    /// Create a new preset with ID and name
    pub fn new(id: &str, name: &str) -> Self {
        Self {
            preset: Preset {
                id: id.to_string(),
                name: name.to_string(),
                blocks: vec![],
                ..Default::default()
            },
        }
    }

    // -------------------------------------------------------------------------
    // Preset Type Setters
    // -------------------------------------------------------------------------

    /// Set as image preset
    pub fn image(mut self) -> Self {
        self.preset.preset_type = "image".to_string();
        self
    }

    /// Set as text preset with select input mode
    pub fn text_select(mut self) -> Self {
        self.preset.preset_type = "text".to_string();
        self.preset.text_input_mode = "select".to_string();
        self
    }

    /// Set as text preset with type input mode
    pub fn text_type(mut self) -> Self {
        self.preset.preset_type = "text".to_string();
        self.preset.text_input_mode = "type".to_string();
        self
    }

    /// Set as audio preset with mic source
    pub fn audio_mic(mut self) -> Self {
        self.preset.preset_type = "audio".to_string();
        self.preset.audio_source = "mic".to_string();
        self
    }

    /// Set as audio preset with device source
    pub fn audio_device(mut self) -> Self {
        self.preset.preset_type = "audio".to_string();
        self.preset.audio_source = "device".to_string();
        self
    }

    // -------------------------------------------------------------------------
    // Block Configuration
    // -------------------------------------------------------------------------

    /// Set the processing blocks
    pub fn blocks(mut self, blocks: Vec<ProcessingBlock>) -> Self {
        self.preset.blocks = blocks;
        self
    }

    /// Set block connections
    pub fn connections(mut self, connections: Vec<(usize, usize)>) -> Self {
        self.preset.block_connections = connections;
        self
    }

    // -------------------------------------------------------------------------
    // Output Behavior
    // -------------------------------------------------------------------------

    /// Enable auto-paste
    pub fn auto_paste(mut self) -> Self {
        self.preset.auto_paste = true;
        self
    }

    // -------------------------------------------------------------------------
    // Audio Options
    // -------------------------------------------------------------------------

    /// Enable auto-stop recording on silence
    pub fn auto_stop(mut self) -> Self {
        self.preset.auto_stop_recording = true;
        self
    }

    /// Enable realtime audio processing
    pub fn realtime(mut self) -> Self {
        self.preset.audio_processing_mode = "realtime".to_string();
        self
    }

    /// Set realtime window mode to minimal
    #[allow(dead_code)]
    pub fn minimal_mode(mut self) -> Self {
        self.preset.realtime_window_mode = "minimal".to_string();
        self
    }

    // -------------------------------------------------------------------------
    // Text Options
    // -------------------------------------------------------------------------

    /// Enable continuous input mode
    pub fn continuous(mut self) -> Self {
        self.preset.continuous_input = true;
        self
    }

    /// Enable dynamic prompt mode (user types custom prompt)
    pub fn dynamic_prompt(mut self) -> Self {
        self.preset.prompt_mode = "dynamic".to_string();
        self
    }

    // -------------------------------------------------------------------------
    // Special Flags
    // -------------------------------------------------------------------------

    /// Mark as MASTER preset
    pub fn master(mut self) -> Self {
        self.preset.is_master = true;
        self.preset.show_controller_ui = true;
        self.preset.blocks = vec![]; // MASTER presets don't have blocks
        self
    }

    // -------------------------------------------------------------------------
    // Build
    // -------------------------------------------------------------------------

    /// Build the final Preset
    pub fn build(self) -> Preset {
        self.preset
    }
}

// ============================================================================
// PRESET HELPER METHODS
// ============================================================================

impl Preset {
    /// Check if this is a built-in preset (ID starts with "preset_")
    pub fn is_builtin(&self) -> bool {
        self.id.starts_with("preset_")
    }

    /// Check if this is a MASTER preset
    pub fn is_master_preset(&self) -> bool {
        self.is_master
    }

    /// Get the first block (input block)
    pub fn input_block(&self) -> Option<&ProcessingBlock> {
        self.blocks.first()
    }

    /// Get mutable reference to the first block
    pub fn input_block_mut(&mut self) -> Option<&mut ProcessingBlock> {
        self.blocks.first_mut()
    }
}
</file>

<file path="src/config/types/hotkey.rs">
//! Hotkey configuration type.

use serde::{Deserialize, Serialize};

/// Represents a keyboard hotkey binding
#[derive(Serialize, Deserialize, Clone, Debug, PartialEq)]
pub struct Hotkey {
    /// Virtual key code
    pub code: u32,
    /// Human-readable key name (e.g., "` / ~", "F1")
    pub name: String,
    /// Modifier flags (Ctrl, Alt, Shift, Win)
    pub modifiers: u32,
}

impl Hotkey {
    pub fn new(code: u32, name: &str, modifiers: u32) -> Self {
        Self {
            code,
            name: name.to_string(),
            modifiers,
        }
    }
}
</file>

<file path="src/config/types/tts.rs">
//! TTS (Text-to-Speech) related configuration types.

use serde::{Deserialize, Serialize};

// ============================================================================
// TTS METHOD
// ============================================================================

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Default)]
pub enum TtsMethod {
    #[default]
    GeminiLive, // Premium (Gemini Live)
    GoogleTranslate, // Fast (Google Translate)
    EdgeTTS,         // Good (Edge TTS)
}

// ============================================================================
// EDGE TTS VOICE CONFIG
// ============================================================================

/// Edge TTS voice configuration for a specific language
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct EdgeTtsVoiceConfig {
    /// ISO 639-1 language code (e.g., "en", "vi", "ko")
    pub language_code: String,
    /// Human-readable language name
    pub language_name: String,
    /// Edge TTS voice name (e.g., "en-US-AriaNeural", "vi-VN-HoaiMyNeural")
    pub voice_name: String,
}

impl EdgeTtsVoiceConfig {
    pub fn new(language_code: &str, language_name: &str, voice_name: &str) -> Self {
        Self {
            language_code: language_code.to_string(),
            language_name: language_name.to_string(),
            voice_name: voice_name.to_string(),
        }
    }
}

// ============================================================================
// EDGE TTS SETTINGS
// ============================================================================

/// Edge TTS settings with pitch, rate, volume, and per-language voice configs
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct EdgeTtsSettings {
    /// Pitch adjustment (-50 to +50 Hz, 0 = default)
    pub pitch: i32,
    /// Rate adjustment (-50 to +100 percent, 0 = default)
    pub rate: i32,
    /// Volume adjustment (-50 to +50 percent, 0 = default)
    pub volume: i32,
    /// Per-language voice configuration
    pub voice_configs: Vec<EdgeTtsVoiceConfig>,
}

impl Default for EdgeTtsSettings {
    fn default() -> Self {
        Self {
            pitch: 0,
            rate: 0,
            volume: 0,
            voice_configs: default_edge_tts_voice_configs(),
        }
    }
}

/// Default Edge TTS voice configurations for common languages
pub fn default_edge_tts_voice_configs() -> Vec<EdgeTtsVoiceConfig> {
    vec![
        EdgeTtsVoiceConfig::new("en", "English", "en-US-AriaNeural"),
        EdgeTtsVoiceConfig::new("vi", "Vietnamese", "vi-VN-HoaiMyNeural"),
        EdgeTtsVoiceConfig::new("ko", "Korean", "ko-KR-SunHiNeural"),
        EdgeTtsVoiceConfig::new("ja", "Japanese", "ja-JP-NanamiNeural"),
        EdgeTtsVoiceConfig::new("zh", "Chinese", "zh-CN-XiaoxiaoNeural"),
    ]
}

// ============================================================================
// TTS LANGUAGE CONDITION
// ============================================================================

/// A condition for TTS that applies a specific speaking instruction
/// when the detected language matches
#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct TtsLanguageCondition {
    /// ISO 639-3 language code from whatlang (e.g., "vie" for Vietnamese, "kor" for Korean)
    pub language_code: String,
    /// Human-readable language name for display
    pub language_name: String,
    /// The speaking instruction to apply when this language is detected
    pub instruction: String,
}

impl TtsLanguageCondition {
    pub fn new(language_code: &str, language_name: &str, instruction: &str) -> Self {
        Self {
            language_code: language_code.to_string(),
            language_name: language_name.to_string(),
            instruction: instruction.to_string(),
        }
    }
}

/// Default TTS language conditions
pub fn default_tts_language_conditions() -> Vec<TtsLanguageCondition> {
    vec![TtsLanguageCondition::new(
        "vie",
        "Vietnamese",
        "Speak in a \"giọng miền Tây\" accent.",
    )]
}
</file>

<file path="src/gui/icons.rs">
// --- ENHANCED ICON PAINTER MODULE V2 ---
// High-fidelity programmatic vector icons for egui.
// No assets, no fonts, pure math.

use eframe::egui;
use std::f32::consts::PI;

#[derive(Clone, Copy, PartialEq)]
pub enum Icon {
    Settings,

    EyeOpen,
    EyeClosed,
    Microphone,
    Image,

    Text,        // NEW: 'T' icon for text presets
    Delete,      // Renders as Trash Can (used for presets)
    DeleteLarge, // NEW: Centered, larger Trash Can (used for history items)

    Folder,    // NEW: For "Open Media"
    Copy,      // NEW: For "Copy Text"
    CopySmall, // NEW: Smaller copy icon for preset buttons
    Close,     // NEW: "X" for clearing search

    TextSelect,      // NEW: Text with selection cursor for text selection mode
    Speaker,         // NEW: Speaker icon for device audio source
    SpeakerDisabled, // NEW: Speaker with cross (disabled TTS)
    CopyDisabled,    // NEW: Copy icon with cross (disabled auto-copy)
    Lightbulb,       // NEW: Lightbulb icon for tips
    Realtime,        // NEW: Streaming waves icon for realtime audio processing
    Star,            // Outline star for non-favorite presets
    StarFilled,      // Filled star for favorite presets
    Sun,             // New: Sun icon for light mode
    Moon,            // New: Moon icon for dark mode
    Device,          // New: Monitor/Device icon for system theme
    DragHandle,      // New: Drag handle for reordering
    History,         // New: History icon (clock)
    Parakeet,        // New: Parakeet icon (Bird)

    // Window Controls
    Minimize,
    Maximize,
    Restore,
}

/// Main entry point: Draw a clickable icon button (default size 24.0)
pub fn icon_button(ui: &mut egui::Ui, icon: Icon) -> egui::Response {
    icon_button_sized(ui, icon, 24.0)
}

/// Draw a clickable icon button with custom size
pub fn icon_button_sized(ui: &mut egui::Ui, icon: Icon, size_val: f32) -> egui::Response {
    let size = egui::vec2(size_val, size_val);
    let (rect, response) = ui.allocate_exact_size(size, egui::Sense::click());

    // 1. Background Hover Effect
    if response.hovered() {
        ui.painter()
            .rect_filled(rect.shrink(2.0), 4.0, ui.visuals().widgets.hovered.bg_fill);
    }

    // 2. Determine Style
    let color = if response.hovered() {
        ui.visuals().widgets.hovered.fg_stroke.color
    } else {
        ui.visuals().widgets.inactive.fg_stroke.color
    };

    // 3. Paint
    paint_internal(ui.painter(), rect, icon, color);

    response
}

/// Draw a static icon (for labels/headers)
pub fn draw_icon_static(ui: &mut egui::Ui, icon: Icon, size_override: Option<f32>) {
    let side = size_override.unwrap_or(16.0);
    let (rect, _) = ui.allocate_exact_size(egui::vec2(side, side), egui::Sense::hover());
    let color = ui.visuals().text_color();
    paint_internal(ui.painter(), rect, icon, color);
}

// --- INTERNAL PAINTER ENGINE ---

/// Public function to paint an icon directly (for custom layouts where icon_button isn't suitable)
pub fn paint_icon(painter: &egui::Painter, rect: egui::Rect, icon: Icon, color: egui::Color32) {
    paint_internal(painter, rect, icon, color);
}

fn paint_internal(painter: &egui::Painter, rect: egui::Rect, icon: Icon, color: egui::Color32) {
    let center = rect.center();
    // Base scale on a 20x20 reference grid, scaled to actual rect
    let scale = rect.width().min(rect.height()) / 22.0;
    let stroke = egui::Stroke::new(1.5 * scale, color); // Consistent line weight

    match icon {
        Icon::Settings => {
            // Modern Cogwheel
            let teeth = 8;
            let outer_r = 9.0 * scale;
            let inner_r = 6.5 * scale;
            let hole_r = 2.5 * scale;

            let mut points = Vec::new();
            for i in 0..(teeth * 2) {
                let theta = (i as f32 * PI) / teeth as f32;
                let r = if i % 2 == 0 { outer_r } else { inner_r };

                let bevel_angle = (PI / teeth as f32) * 0.25;
                let theta_a = theta - bevel_angle;
                let theta_b = theta + bevel_angle;

                points.push(center + egui::vec2(theta_a.cos() * r, theta_a.sin() * r));
                points.push(center + egui::vec2(theta_b.cos() * r, theta_b.sin() * r));
            }
            points.push(points[0]);

            painter.add(egui::Shape::line(points, stroke));
            painter.circle_stroke(center, hole_r, stroke);
        }

        Icon::EyeOpen => {
            let w = 9.0 * scale;
            let h = 5.0 * scale;
            let p_left = center - egui::vec2(w, 0.0);
            let p_right = center + egui::vec2(w, 0.0);
            let p_top = center - egui::vec2(0.0, h * 1.5);
            let p_bot = center + egui::vec2(0.0, h * 1.5);

            let pts_top = bezier_points(p_left, p_top, p_right, 10);
            let pts_bot = bezier_points(p_right, p_bot, p_left, 10);

            let mut full_eye = pts_top;
            full_eye.extend(pts_bot);

            painter.add(egui::Shape::line(full_eye, stroke));
            painter.circle_filled(center, 2.5 * scale, color);
        }

        Icon::EyeClosed => {
            let w = 9.0 * scale;
            let h = 5.0 * scale;
            let p_left = center - egui::vec2(w, 0.0);
            let p_right = center + egui::vec2(w, 0.0);
            let p_top = center - egui::vec2(0.0, h * 1.5);
            let pts = bezier_points(p_left, p_top, p_right, 12);
            painter.add(egui::Shape::line(pts, stroke));

            let lash_y = center.y + 1.0 * scale;
            let l_len = 3.5 * scale;
            painter.line_segment(
                [
                    egui::pos2(center.x, lash_y),
                    egui::pos2(center.x, lash_y + l_len),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(center.x - 3.0 * scale, lash_y - 1.0 * scale),
                    egui::pos2(center.x - 5.0 * scale, lash_y + l_len * 0.8),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(center.x + 3.0 * scale, lash_y - 1.0 * scale),
                    egui::pos2(center.x + 5.0 * scale, lash_y + l_len * 0.8),
                ],
                stroke,
            );
        }

        Icon::Microphone => {
            // Larger Microphone icon
            let w = 6.5 * scale;
            let h = 12.0 * scale;
            let caps_rect = egui::Rect::from_center_size(
                center - egui::vec2(0.0, 1.5 * scale),
                egui::vec2(w, h),
            );
            painter.rect_stroke(caps_rect, w / 2.0, stroke, egui::StrokeKind::Middle);

            // Horizontal lines on mic head
            let y_start = caps_rect.top() + 3.5 * scale;
            painter.line_segment(
                [
                    egui::pos2(center.x - 2.0 * scale, y_start),
                    egui::pos2(center.x + 2.0 * scale, y_start),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(center.x - 2.0 * scale, y_start + 3.0 * scale),
                    egui::pos2(center.x + 2.0 * scale, y_start + 3.0 * scale),
                ],
                stroke,
            );

            // U-shaped holder
            let u_left = egui::pos2(center.x - 5.5 * scale, center.y);
            let u_right = egui::pos2(center.x + 5.5 * scale, center.y);
            let u_bot = egui::pos2(center.x, center.y + 7.0 * scale);
            let u_path = bezier_points(u_left, u_bot, u_right, 10);
            painter.add(egui::Shape::line(u_path, stroke));

            // Stand
            painter.line_segment(
                [
                    egui::pos2(center.x, center.y + 4.5 * scale),
                    egui::pos2(center.x, center.y + 9.0 * scale),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(center.x - 4.0 * scale, center.y + 9.0 * scale),
                    egui::pos2(center.x + 4.0 * scale, center.y + 9.0 * scale),
                ],
                stroke,
            );
        }

        Icon::Image => {
            let img_rect = rect.shrink(3.0 * scale);
            painter.rect_stroke(img_rect, 2.0 * scale, stroke, egui::StrokeKind::Middle);
            let p1 = img_rect.left_bottom() - egui::vec2(-1.0, 2.0) * scale;
            let p2 = img_rect.left_bottom() + egui::vec2(3.0, -6.0) * scale;
            let p3 = img_rect.left_bottom() + egui::vec2(6.0, -3.0) * scale;
            let p4 = img_rect.left_bottom() + egui::vec2(9.0, -7.0) * scale;
            let p5 = img_rect.right_bottom() - egui::vec2(1.0, 2.0) * scale;
            painter.add(egui::Shape::line(vec![p1, p2, p3, p4, p5], stroke));
            painter.circle_filled(
                img_rect.left_top() + egui::vec2(3.5, 3.5) * scale,
                1.5 * scale,
                color,
            );
        }

        Icon::Text => {
            // Larger Elegant Serif 'T' Icon
            let top_y = center.y - 8.0 * scale;
            let bot_y = center.y + 8.0 * scale;
            let left_x = center.x - 7.0 * scale;
            let right_x = center.x + 7.0 * scale;
            let serif_h = 2.0 * scale; // Height of serifs
            let stem_w = 2.5 * scale; // Half-width of stem base serif

            // Top horizontal bar (thicker)
            let bar_stroke = egui::Stroke::new(2.5 * scale, color);
            painter.line_segment(
                [egui::pos2(left_x, top_y), egui::pos2(right_x, top_y)],
                bar_stroke,
            );

            // Left serif (small vertical line at top-left)
            painter.line_segment(
                [
                    egui::pos2(left_x, top_y),
                    egui::pos2(left_x, top_y + serif_h),
                ],
                stroke,
            );

            // Right serif (small vertical line at top-right)
            painter.line_segment(
                [
                    egui::pos2(right_x, top_y),
                    egui::pos2(right_x, top_y + serif_h),
                ],
                stroke,
            );

            // Vertical stem (thicker)
            let stem_stroke = egui::Stroke::new(2.0 * scale, color);
            painter.line_segment(
                [egui::pos2(center.x, top_y), egui::pos2(center.x, bot_y)],
                stem_stroke,
            );

            // Bottom serif (horizontal line at base of stem)
            painter.line_segment(
                [
                    egui::pos2(center.x - stem_w, bot_y),
                    egui::pos2(center.x + stem_w, bot_y),
                ],
                stroke,
            );
        }

        Icon::Delete => {
            // Trash Can (original, for presets) - centered in hitbox
            let c = center;
            let lid_y = c.y - 3.2 * scale;
            let w_lid = 8.0 * scale;
            let w_can_top = 6.0 * scale;
            let w_can_bot = 4.5 * scale;
            let h_can = 7.0 * scale;

            painter.line_segment(
                [
                    egui::pos2(c.x - w_lid / 2.0, lid_y),
                    egui::pos2(c.x + w_lid / 2.0, lid_y),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(c.x - 1.0 * scale, lid_y),
                    egui::pos2(c.x - 1.0 * scale, lid_y - 1.0 * scale),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(c.x - 1.0 * scale, lid_y - 1.0 * scale),
                    egui::pos2(c.x + 1.0 * scale, lid_y - 1.0 * scale),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(c.x + 1.0 * scale, lid_y - 1.0 * scale),
                    egui::pos2(c.x + 1.0 * scale, lid_y),
                ],
                stroke,
            );

            let p1 = egui::pos2(c.x - w_can_top / 2.0, lid_y);
            let p2 = egui::pos2(c.x - w_can_bot / 2.0, lid_y + h_can);
            let p3 = egui::pos2(c.x + w_can_bot / 2.0, lid_y + h_can);
            let p4 = egui::pos2(c.x + w_can_top / 2.0, lid_y);
            painter.add(egui::Shape::line(vec![p1, p2, p3, p4], stroke));
        }

        Icon::DeleteLarge => {
            // Trash Can (centered and larger, for history items)
            let c = center; // Removed manual offset
            let lid_y = c.y - 4.0 * scale; // Lid line position
            let w_lid = 10.0 * scale; // Wider lid
            let w_can_top = 8.0 * scale; // Wider body top
            let w_can_bot = 6.0 * scale; // Wider body bottom
            let h_can = 9.0 * scale; // Taller body

            // Lid line
            painter.line_segment(
                [
                    egui::pos2(c.x - w_lid / 2.0, lid_y),
                    egui::pos2(c.x + w_lid / 2.0, lid_y),
                ],
                stroke,
            );

            // Handle (small loop above lid)
            painter.line_segment(
                [
                    egui::pos2(c.x - 1.0 * scale, lid_y),
                    egui::pos2(c.x - 1.0 * scale, lid_y - 1.0 * scale),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(c.x - 1.0 * scale, lid_y - 1.0 * scale),
                    egui::pos2(c.x + 1.0 * scale, lid_y - 1.0 * scale),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(c.x + 1.0 * scale, lid_y - 1.0 * scale),
                    egui::pos2(c.x + 1.0 * scale, lid_y),
                ],
                stroke,
            );

            // Can Body (Trapezoid)
            let p1 = egui::pos2(c.x - w_can_top / 2.0, lid_y);
            let p2 = egui::pos2(c.x - w_can_bot / 2.0, lid_y + h_can);
            let p3 = egui::pos2(c.x + w_can_bot / 2.0, lid_y + h_can);
            let p4 = egui::pos2(c.x + w_can_top / 2.0, lid_y);
            painter.add(egui::Shape::line(vec![p1, p2, p3, p4], stroke));
        }

        Icon::Folder => {
            // Folder Icon
            let w = 14.0 * scale;
            let h = 10.0 * scale;
            let body_rect = egui::Rect::from_center_size(
                center + egui::vec2(0.0, 1.0 * scale),
                egui::vec2(w, h),
            );

            // Tab (top left)
            let tab_w = 6.0 * scale;
            let tab_h = 2.0 * scale;

            // Draw Outline
            // Manual path to make it look joined
            let p1 = body_rect.left_top();
            let p2 = body_rect.left_bottom();
            let p3 = body_rect.right_bottom();
            let p4 = body_rect.right_top();
            let p5 = body_rect.left_top() + egui::vec2(tab_w, 0.0);
            let p6 = body_rect.left_top() + egui::vec2(tab_w, -tab_h);
            let p7 = body_rect.left_top() + egui::vec2(0.0, -tab_h);

            painter.add(egui::Shape::line(
                vec![p7, p1, p2, p3, p4, p5, p6, p7],
                stroke,
            ));
        }

        Icon::Copy => {
            // Two overlapping rectangles - REDUCED SIZE to match Trashcan
            let w = 7.0 * scale; // Reduced from 8.0
            let h = 9.0 * scale; // Reduced from 10.0
            let offset = 2.0 * scale; // Reduced from 2.5

            // Back rect (Top Left)
            let back_rect = egui::Rect::from_center_size(
                center - egui::vec2(offset / 2.0, offset / 2.0),
                egui::vec2(w, h),
            );
            painter.rect_stroke(back_rect, 1.0 * scale, stroke, egui::StrokeKind::Middle);

            // Front rect (Bottom Right) - Filled to cover back lines
            let front_rect =
                egui::Rect::from_center_size(center + egui::vec2(offset, offset), egui::vec2(w, h));
            painter.rect_filled(
                front_rect,
                1.0 * scale,
                painter.ctx().style().visuals.panel_fill,
            ); // Mask
            painter.rect_stroke(front_rect, 1.0 * scale, stroke, egui::StrokeKind::Middle);
        }

        Icon::CopySmall => {
            // Two overlapping rectangles - MINI SIZE for preset buttons
            let w = 5.0 * scale;
            let h = 6.5 * scale;
            let offset = 1.2 * scale;

            // Back rect (Top Left)
            let back_rect = egui::Rect::from_center_size(
                center - egui::vec2(offset / 2.0, offset / 2.0),
                egui::vec2(w, h),
            );
            painter.rect_stroke(back_rect, 0.8 * scale, stroke, egui::StrokeKind::Middle);

            // Front rect (Bottom Right) - Filled to cover back lines
            let front_rect =
                egui::Rect::from_center_size(center + egui::vec2(offset, offset), egui::vec2(w, h));
            painter.rect_filled(
                front_rect,
                0.8 * scale,
                painter.ctx().style().visuals.panel_fill,
            ); // Mask
            painter.rect_stroke(front_rect, 0.8 * scale, stroke, egui::StrokeKind::Middle);
        }

        Icon::Close => {
            // 'X' Icon
            let sz = 5.0 * scale;
            let p1 = center - egui::vec2(sz, sz);
            let p2 = center + egui::vec2(sz, sz);
            let p3 = center - egui::vec2(sz, -sz);
            let p4 = center + egui::vec2(sz, -sz);

            painter.line_segment([p1, p2], stroke);
            painter.line_segment([p3, p4], stroke);
        }

        Icon::TextSelect => {
            // Text with selection highlight/cursor - represents "select text" mode
            // Draw 3 horizontal lines (text lines) with middle one highlighted
            let line_w = 12.0 * scale;
            let line_gap = 4.0 * scale;
            let line_y1 = center.y - line_gap;
            let line_y2 = center.y;
            let line_y3 = center.y + line_gap;

            // Text lines
            painter.line_segment(
                [
                    egui::pos2(center.x - line_w / 2.0, line_y1),
                    egui::pos2(center.x + line_w / 2.0, line_y1),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(center.x - line_w / 2.0, line_y3),
                    egui::pos2(center.x + line_w / 2.0, line_y3),
                ],
                stroke,
            );

            // Highlighted middle line (thicker, representing selection)
            let highlight_stroke = egui::Stroke::new(3.0 * scale, color);
            painter.line_segment(
                [
                    egui::pos2(center.x - line_w / 2.0, line_y2),
                    egui::pos2(center.x + line_w / 2.0, line_y2),
                ],
                highlight_stroke,
            );

            // Cursor (vertical line with serifs at ends)
            let cursor_x = center.x + line_w / 2.0 + 2.0 * scale;
            let cursor_top = center.y - 5.0 * scale;
            let cursor_bot = center.y + 5.0 * scale;
            let serif_w = 1.5 * scale;
            painter.line_segment(
                [
                    egui::pos2(cursor_x, cursor_top),
                    egui::pos2(cursor_x, cursor_bot),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(cursor_x - serif_w, cursor_top),
                    egui::pos2(cursor_x + serif_w, cursor_top),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(cursor_x - serif_w, cursor_bot),
                    egui::pos2(cursor_x + serif_w, cursor_bot),
                ],
                stroke,
            );
        }

        Icon::Speaker => {
            // Speaker with sound waves - for device audio (system sound)
            // Speaker body (trapezoid + rectangle)
            let body_x = center.x - 3.0 * scale;
            let body_w = 4.0 * scale;
            let body_h = 6.0 * scale;
            let cone_w = 5.0 * scale;
            let cone_h = 10.0 * scale;

            // Rectangle (back of speaker)
            let rect = egui::Rect::from_center_size(
                egui::pos2(body_x - body_w / 2.0, center.y),
                egui::vec2(body_w, body_h),
            );
            painter.rect_stroke(rect, 0.5 * scale, stroke, egui::StrokeKind::Middle);

            // Cone (trapezoid)
            let cone_pts = vec![
                egui::pos2(body_x, center.y - body_h / 2.0), // top-left
                egui::pos2(body_x + cone_w, center.y - cone_h / 2.0), // top-right
                egui::pos2(body_x + cone_w, center.y + cone_h / 2.0), // bottom-right
                egui::pos2(body_x, center.y + body_h / 2.0), // bottom-left
            ];
            painter.add(egui::Shape::closed_line(cone_pts, stroke));

            // Sound waves (arcs)
            let wave_x = center.x + 4.0 * scale;
            let wave_r1 = 3.0 * scale;
            let wave_r2 = 5.5 * scale;

            // First wave
            let wave_segments = 8;
            let wave_angle = PI / 3.0;
            let mut wave1_pts = Vec::new();
            for i in 0..=wave_segments {
                let t = i as f32 / wave_segments as f32;
                let angle = -wave_angle + 2.0 * wave_angle * t;
                wave1_pts.push(egui::pos2(
                    wave_x + wave_r1 * angle.cos(),
                    center.y + wave_r1 * angle.sin(),
                ));
            }
            painter.add(egui::Shape::line(wave1_pts, stroke));

            // Second wave
            let mut wave2_pts = Vec::new();
            for i in 0..=wave_segments {
                let t = i as f32 / wave_segments as f32;
                let angle = -wave_angle + 2.0 * wave_angle * t;
                wave2_pts.push(egui::pos2(
                    wave_x + wave_r2 * angle.cos(),
                    center.y + wave_r2 * angle.sin(),
                ));
            }
            painter.add(egui::Shape::line(wave2_pts, stroke));
        }

        Icon::SpeakerDisabled => {
            // Speaker with NO sound waves and a cross (gray/disabled look)
            let body_x = center.x - 3.0 * scale;
            let body_w = 4.0 * scale;
            let body_h = 6.0 * scale;
            let cone_w = 5.0 * scale;
            let cone_h = 10.0 * scale;

            // Rectangle (back of speaker)
            let rect = egui::Rect::from_center_size(
                egui::pos2(body_x - body_w / 2.0, center.y),
                egui::vec2(body_w, body_h),
            );
            painter.rect_stroke(rect, 0.5 * scale, stroke, egui::StrokeKind::Middle);

            // Cone (trapezoid)
            let cone_pts = vec![
                egui::pos2(body_x, center.y - body_h / 2.0),
                egui::pos2(body_x + cone_w, center.y - cone_h / 2.0),
                egui::pos2(body_x + cone_w, center.y + cone_h / 2.0),
                egui::pos2(body_x, center.y + body_h / 2.0),
            ];
            painter.add(egui::Shape::closed_line(cone_pts, stroke));

            // Diagonal cross (indicating disabled)
            let cross_stroke = egui::Stroke::new(2.0 * scale, color);
            let cross_sz = 8.0 * scale;
            painter.line_segment(
                [
                    egui::pos2(center.x - cross_sz / 2.0, center.y - cross_sz / 2.0),
                    egui::pos2(center.x + cross_sz / 2.0, center.y + cross_sz / 2.0),
                ],
                cross_stroke,
            );
        }

        Icon::CopyDisabled => {
            // Copy icon with diagonal cross
            let w = 7.0 * scale;
            let h = 9.0 * scale;
            let offset = 2.0 * scale;

            // Back rect (Top Left)
            let back_rect = egui::Rect::from_center_size(
                center - egui::vec2(offset / 2.0, offset / 2.0),
                egui::vec2(w, h),
            );
            painter.rect_stroke(back_rect, 1.0 * scale, stroke, egui::StrokeKind::Middle);

            // Front rect (Bottom Right)
            let front_rect =
                egui::Rect::from_center_size(center + egui::vec2(offset, offset), egui::vec2(w, h));
            painter.rect_filled(
                front_rect,
                1.0 * scale,
                painter.ctx().style().visuals.panel_fill,
            );
            painter.rect_stroke(front_rect, 1.0 * scale, stroke, egui::StrokeKind::Middle);

            // Diagonal cross (indicating disabled)
            let cross_stroke = egui::Stroke::new(2.0 * scale, color);
            let cross_sz = 10.0 * scale;
            painter.line_segment(
                [
                    egui::pos2(center.x - cross_sz / 2.0, center.y - cross_sz / 2.0),
                    egui::pos2(center.x + cross_sz / 2.0, center.y + cross_sz / 2.0),
                ],
                cross_stroke,
            );
        }

        Icon::Lightbulb => {
            // Simple lightbulb icon using explicit coordinates
            // The bulb consists of: circle top + tapered neck + base + rays

            let bulb_r = 4.5 * scale;
            let bulb_cy = center.y - 2.0 * scale; // Center of bulb circle (shifted up)

            // 1. Draw bulb circle (full circle)
            painter.circle_stroke(egui::pos2(center.x, bulb_cy), bulb_r, stroke);

            // 2. Draw neck (two converging lines from bulb bottom to base)
            let neck_top_w = 3.0 * scale; // Width at top of neck
            let neck_bot_w = 2.0 * scale; // Width at bottom of neck
            let neck_top_y = bulb_cy + bulb_r;
            let neck_bot_y = neck_top_y + 3.0 * scale;

            // Left neck line
            painter.line_segment(
                [
                    egui::pos2(center.x - neck_top_w, neck_top_y),
                    egui::pos2(center.x - neck_bot_w, neck_bot_y),
                ],
                stroke,
            );
            // Right neck line
            painter.line_segment(
                [
                    egui::pos2(center.x + neck_top_w, neck_top_y),
                    egui::pos2(center.x + neck_bot_w, neck_bot_y),
                ],
                stroke,
            );

            // 3. Draw base (two horizontal lines)
            painter.line_segment(
                [
                    egui::pos2(center.x - neck_bot_w, neck_bot_y),
                    egui::pos2(center.x + neck_bot_w, neck_bot_y),
                ],
                stroke,
            );
            painter.line_segment(
                [
                    egui::pos2(center.x - neck_bot_w * 0.7, neck_bot_y + 1.5 * scale),
                    egui::pos2(center.x + neck_bot_w * 0.7, neck_bot_y + 1.5 * scale),
                ],
                stroke,
            );

            // 4. Draw rays (3 lines going up from top of bulb)
            let ray_start_y = bulb_cy - bulb_r - 1.5 * scale; // Start above the bulb with gap
            let ray_len = 2.5 * scale;

            // Center ray (straight up)
            painter.line_segment(
                [
                    egui::pos2(center.x, ray_start_y),
                    egui::pos2(center.x, ray_start_y - ray_len),
                ],
                stroke,
            );
            // Left ray (diagonal)
            painter.line_segment(
                [
                    egui::pos2(center.x - 2.5 * scale, ray_start_y + 1.0 * scale),
                    egui::pos2(center.x - 4.0 * scale, ray_start_y - ray_len + 1.5 * scale),
                ],
                stroke,
            );
            // Right ray (diagonal)
            painter.line_segment(
                [
                    egui::pos2(center.x + 2.5 * scale, ray_start_y + 1.0 * scale),
                    egui::pos2(center.x + 4.0 * scale, ray_start_y - ray_len + 1.5 * scale),
                ],
                stroke,
            );
        }

        Icon::Realtime => {
            // Realtime waveform icon - audio oscilloscope pattern
            // Horizontal line with peaks and valleys representing live audio

            let y_center = center.y;
            let wave_stroke = egui::Stroke::new(2.0 * scale, color);

            // Left flat segment
            let left_start = center.x - 10.0 * scale;
            let left_end = center.x - 7.0 * scale;
            painter.line_segment(
                [
                    egui::pos2(left_start, y_center),
                    egui::pos2(left_end, y_center),
                ],
                wave_stroke,
            );

            // Waveform points - small peak, big valley, big peak, small valley pattern
            let wave_pts = vec![
                egui::pos2(left_end, y_center),                             // start
                egui::pos2(center.x - 5.5 * scale, y_center - 3.0 * scale), // small peak
                egui::pos2(center.x - 3.5 * scale, y_center + 7.0 * scale), // big valley
                egui::pos2(center.x, y_center - 7.0 * scale),               // big peak
                egui::pos2(center.x + 3.5 * scale, y_center + 3.0 * scale), // small valley
                egui::pos2(center.x + 5.5 * scale, y_center),               // return to center
            ];
            painter.add(egui::Shape::line(wave_pts, wave_stroke));

            // Right flat segment
            let right_start = center.x + 5.5 * scale;
            let right_end = center.x + 10.0 * scale;
            painter.line_segment(
                [
                    egui::pos2(right_start, y_center),
                    egui::pos2(right_end, y_center),
                ],
                wave_stroke,
            );
        }

        Icon::Star => {
            // 5-pointed star outline - SMALL variant to match CopySmall/Delete
            let outer_r = 5.5 * scale;
            let inner_r = 2.4 * scale;
            let mut points = Vec::new();

            for i in 0..10 {
                let angle = (i as f32 * PI / 5.0) - PI / 2.0; // Start from top
                let r = if i % 2 == 0 { outer_r } else { inner_r };
                points.push(egui::pos2(
                    center.x + r * angle.cos(),
                    center.y + r * angle.sin(),
                ));
            }
            points.push(points[0]); // Close the shape
            painter.add(egui::Shape::line(points, stroke));
        }

        Icon::StarFilled => {
            // 5-pointed star filled with gold color, soft rounded corners, smaller visual footprint
            // Base size reduced to match visual weight of outline star
            let outer_r = 6.0 * scale; // Increased from 5.6
            let inner_r = 2.6 * scale; // Increased from 2.4
            let gold = egui::Color32::from_rgb(255, 193, 7);

            // 1. Calculate the 10 raw vertices
            let mut raw_points = Vec::with_capacity(10);
            for i in 0..10 {
                let angle = (i as f32 * PI / 5.0) - PI / 2.0;
                let r = if i % 2 == 0 { outer_r } else { inner_r };
                raw_points.push(egui::pos2(
                    center.x + r * angle.cos(),
                    center.y + r * angle.sin(),
                ));
            }

            // 2. Generate rounded path
            // We round the Tips (even indices) by cutting corners with a bezier curve
            let mut path_points = Vec::new();
            let round_ratio = 0.35; // How much of the tip to round off

            for i in 0..10 {
                let p = raw_points[i];

                if i % 2 == 0 {
                    // Tip: Replace sharp vertex with a curve
                    let p_prev = raw_points[(i + 9) % 10]; // Previous valley
                    let p_next = raw_points[(i + 1) % 10]; // Next valley

                    // Calculate start and end points of the curve along the star arms
                    let p_start = lerp(p, p_prev, round_ratio);
                    let p_end = lerp(p, p_next, round_ratio);

                    // Generate smooth quadratic bezier curve for the tip
                    let curve = bezier_points(p_start, p, p_end, 5);
                    path_points.extend(curve);
                } else {
                    // Valley: Keep sharp
                    path_points.push(p);
                }
            }

            painter.add(egui::Shape::Path(egui::epaint::PathShape {
                points: path_points,
                closed: true,
                fill: gold,
                stroke: egui::Stroke::new(1.0 * scale, gold).into(),
            }));
        }

        Icon::Sun => {
            painter.circle_stroke(center, 4.0 * scale, stroke);
            for i in 0..8 {
                let angle = (i as f32 * 45.0).to_radians();
                let dir = egui::vec2(angle.cos(), angle.sin());
                let start = center + dir * 6.5 * scale;
                let end = center + dir * 9.0 * scale;
                painter.line_segment([start, end], stroke);
            }
        }

        Icon::Moon => {
            let r = 7.0 * scale;
            let offset = 3.5 * scale;
            painter.circle_filled(center, r, color);
            painter.circle_filled(
                center + egui::vec2(offset, -offset * 0.8),
                r * 0.85,
                painter.ctx().style().visuals.panel_fill,
            );
        }

        Icon::Device => {
            // Monitor / PC Icon
            let w = 12.0 * scale;
            let h = 8.0 * scale;

            // Screen rect
            let screen_rect = egui::Rect::from_center_size(
                center + egui::vec2(0.0, -1.0 * scale),
                egui::vec2(w, h),
            );
            painter.rect_stroke(screen_rect, 1.0 * scale, stroke, egui::StrokeKind::Middle);

            // Stand
            painter.line_segment(
                [
                    egui::pos2(center.x, center.y + 3.0 * scale),
                    egui::pos2(center.x, center.y + 6.0 * scale),
                ],
                stroke,
            );

            // Base feet
            painter.line_segment(
                [
                    egui::pos2(center.x - 3.0 * scale, center.y + 6.0 * scale),
                    egui::pos2(center.x + 3.0 * scale, center.y + 6.0 * scale),
                ],
                stroke,
            );
        }

        Icon::DragHandle => {
            // Hamburger menu style (3 horizontal lines)
            // or 6 dots? 6 dots is more common for drag handles.
            // Let's do 6 dots (2 columns of 3)
            let w_gap = 4.0 * scale;
            let h_gap = 4.0 * scale;
            let r = 1.0 * scale; // dot radius

            for col in 0..2 {
                for row in -1..=1 {
                    let cx = center.x + (col as f32 - 0.5) * w_gap;
                    let cy = center.y + row as f32 * h_gap;
                    painter.circle_filled(egui::pos2(cx, cy), r, color);
                }
            }
        }

        Icon::History => {
            // Clock icon
            let r = 7.0 * scale;
            painter.circle_stroke(center, r, stroke);

            // Hands
            // Hour hand at 3 o'clock
            painter.line_segment([center, center + egui::vec2(4.0 * scale, 0.0)], stroke);
            // Minute hand at 12 o'clock
            painter.line_segment([center, center + egui::vec2(0.0, -5.0 * scale)], stroke);
        }

        Icon::Parakeet => {
            // Bird Head (Parakeet) - Minimalist profile
            let r_head = 7.0 * scale;
            painter.circle_filled(center, r_head, color);

            // Eye (Contrast color - usually background fill)
            let eye_pos = center + egui::vec2(2.0, -2.0) * scale;
            painter.circle_filled(
                eye_pos,
                2.0 * scale,
                painter.ctx().style().visuals.panel_fill,
            );

            // Beak (Triangle on right)
            let beak_pts = vec![
                center + egui::vec2(5.0 * scale, -1.0 * scale), // Top-right of head
                center + egui::vec2(11.0 * scale, 3.0 * scale), // Tip
                center + egui::vec2(4.0 * scale, 5.0 * scale),  // Bottom-right of head
            ];
            painter.add(egui::Shape::convex_polygon(beak_pts, color, stroke));
        }

        Icon::Minimize => {
            let h_line = 0.5 * scale;
            let w = 6.0 * scale;
            painter.line_segment(
                [
                    center - egui::vec2(w, -h_line),
                    center + egui::vec2(w, h_line),
                ],
                stroke,
            );
        }

        Icon::Maximize => {
            let sz = 6.0 * scale;
            let rect = egui::Rect::from_center_size(center, egui::vec2(sz * 2.0, sz * 2.0));
            painter.rect_stroke(rect, 0.0, stroke, egui::StrokeKind::Middle);
        }

        Icon::Restore => {
            let sz = 5.0 * scale;
            let offset = 2.0 * scale;

            // Back rect
            let rect_back = egui::Rect::from_center_size(
                center + egui::vec2(offset, -offset),
                egui::vec2(sz * 2.0, sz * 2.0),
            );
            painter.rect_stroke(rect_back, 0.0, stroke, egui::StrokeKind::Middle);

            // Front rect
            let rect_front = egui::Rect::from_center_size(
                center + egui::vec2(-offset, offset),
                egui::vec2(sz * 2.0, sz * 2.0),
            );
            painter.rect_filled(
                rect_front.expand(stroke.width / 2.0),
                0.0,
                painter.ctx().style().visuals.panel_fill,
            );
            painter.rect_stroke(rect_front, 0.0, stroke, egui::StrokeKind::Middle);
        }
    }
}

// --- MATH HELPERS ---

fn lerp(a: egui::Pos2, b: egui::Pos2, t: f32) -> egui::Pos2 {
    egui::pos2(a.x + (b.x - a.x) * t, a.y + (b.y - a.y) * t)
}

fn lerp_quadratic(p0: egui::Pos2, p1: egui::Pos2, p2: egui::Pos2, t: f32) -> egui::Pos2 {
    let l1 = lerp(p0, p1, t);
    let l2 = lerp(p1, p2, t);
    lerp(l1, l2, t)
}

fn bezier_points(
    p0: egui::Pos2,
    p1: egui::Pos2,
    p2: egui::Pos2,
    segments: usize,
) -> Vec<egui::Pos2> {
    let mut points = Vec::with_capacity(segments + 1);
    for i in 0..=segments {
        let t = i as f32 / segments as f32;
        points.push(lerp_quadratic(p0, p1, p2, t));
    }
    points
}
</file>

<file path="src/gui/key_mapping.rs">
use eframe::egui;

// Expanded Mapping Function: egui Key -> Windows Virtual Key (VK)
// This covers Function keys, arrows, delete/insert, home/end, and standard alphanumerics
pub fn egui_key_to_vk(key: &egui::Key) -> Option<u32> {
    match key {
        // Numbers
        egui::Key::Num0 => Some(0x30), egui::Key::Num1 => Some(0x31), egui::Key::Num2 => Some(0x32),
        egui::Key::Num3 => Some(0x33), egui::Key::Num4 => Some(0x34), egui::Key::Num5 => Some(0x35),
        egui::Key::Num6 => Some(0x36), egui::Key::Num7 => Some(0x37), egui::Key::Num8 => Some(0x38),
        egui::Key::Num9 => Some(0x39),
        // Letters
        egui::Key::A => Some(0x41), egui::Key::B => Some(0x42), egui::Key::C => Some(0x43),
        egui::Key::D => Some(0x44), egui::Key::E => Some(0x45), egui::Key::F => Some(0x46),
        egui::Key::G => Some(0x47), egui::Key::H => Some(0x48), egui::Key::I => Some(0x49),
        egui::Key::J => Some(0x4A), egui::Key::K => Some(0x4B), egui::Key::L => Some(0x4C),
        egui::Key::M => Some(0x4D), egui::Key::N => Some(0x4E), egui::Key::O => Some(0x4F),
        egui::Key::P => Some(0x50), egui::Key::Q => Some(0x51), egui::Key::R => Some(0x52),
        egui::Key::S => Some(0x53), egui::Key::T => Some(0x54), egui::Key::U => Some(0x55),
        egui::Key::V => Some(0x56), egui::Key::W => Some(0x57), egui::Key::X => Some(0x58),
        egui::Key::Y => Some(0x59), egui::Key::Z => Some(0x5A),
        // Function Keys
        egui::Key::F1 => Some(0x70), egui::Key::F2 => Some(0x71), egui::Key::F3 => Some(0x72),
        egui::Key::F4 => Some(0x73), egui::Key::F5 => Some(0x74), egui::Key::F6 => Some(0x75),
        egui::Key::F7 => Some(0x76), egui::Key::F8 => Some(0x77), egui::Key::F9 => Some(0x78),
        egui::Key::F10 => Some(0x79), egui::Key::F11 => Some(0x7A), egui::Key::F12 => Some(0x7B),
        egui::Key::F13 => Some(0x7C), egui::Key::F14 => Some(0x7D), egui::Key::F15 => Some(0x7E),
        egui::Key::F16 => Some(0x7F), egui::Key::F17 => Some(0x80), egui::Key::F18 => Some(0x81),
        egui::Key::F19 => Some(0x82), egui::Key::F20 => Some(0x83),
        // Navigation / Editing
        egui::Key::Escape => Some(0x1B),
        egui::Key::Insert => Some(0x2D),
        egui::Key::Delete => Some(0x2E),
        egui::Key::Home => Some(0x24),
        egui::Key::End => Some(0x23),
        egui::Key::PageUp => Some(0x21),
        egui::Key::PageDown => Some(0x22),
        egui::Key::ArrowLeft => Some(0x25),
        egui::Key::ArrowUp => Some(0x26),
        egui::Key::ArrowRight => Some(0x27),
        egui::Key::ArrowDown => Some(0x28),
        egui::Key::Backspace => Some(0x08),
        egui::Key::Enter => Some(0x0D),
        egui::Key::Space => Some(0x20),
        egui::Key::Tab => Some(0x09),
        // Symbols
        egui::Key::Backtick => Some(0xC0), // `
        egui::Key::Minus => Some(0xBD),    // -
        egui::Key::Plus => Some(0xBB),     // = (Plus is usually shift+=)
        egui::Key::OpenBracket => Some(0xDB), // [
        egui::Key::CloseBracket => Some(0xDD), // ]
        egui::Key::Backslash => Some(0xDC), // \
        egui::Key::Semicolon => Some(0xBA), // ;
        egui::Key::Comma => Some(0xBC),     // ,
        egui::Key::Period => Some(0xBE),    // .
        egui::Key::Slash => Some(0xBF),     // /
        _ => None,
    }
}

// Map egui Pointer (Mouse) Buttons to Windows VK Codes
// Explicitly ignores Primary (Left) and Secondary (Right) to prevent locking clicks
pub fn egui_pointer_to_vk(btn: &egui::PointerButton) -> Option<u32> {
    match btn {
        egui::PointerButton::Middle => Some(0x04), // VK_MBUTTON
        egui::PointerButton::Extra1 => Some(0x05), // VK_XBUTTON1 (Back)
        egui::PointerButton::Extra2 => Some(0x06), // VK_XBUTTON2 (Forward)
        _ => None, // Primary/Secondary excluded
    }
}
</file>

<file path="src/gui/settings_ui/footer.rs">
use crate::gui::icons::{paint_icon, Icon};
use crate::gui::locale::LocaleText;
use eframe::egui;
use egui::text::{LayoutJob, TextFormat};

pub fn render_footer(
    ui: &mut egui::Ui,
    text: &LocaleText,
    current_tip: String,
    tip_alpha: f32,
    show_modal: &mut bool,
) {
    ui.horizontal(|ui| {
        // 1. Left Side: Admin Status
        // Use a fixed width container for left side to ensure stability
        ui.allocate_ui(egui::vec2(180.0, ui.available_height()), |ui| {
            ui.horizontal_centered(|ui| {
                let is_admin =
                    cfg!(target_os = "windows") && crate::gui::utils::is_running_as_admin();
                let footer_text = if is_admin {
                    egui::RichText::new(text.footer_admin_running)
                        .size(11.0)
                        .color(egui::Color32::from_rgb(34, 139, 34))
                } else {
                    egui::RichText::new(text.footer_admin_text)
                        .size(11.0)
                        .color(ui.visuals().weak_text_color())
                };
                ui.label(footer_text);
            });
        });

        // 2. Right Side: Version
        // We use with_layout to pack from right, but we need to reserve space first
        // or egui might push the center content over it.
        // A better approach in horizontal layout: Left -> Expanded Center -> Right.

        // 3. Center: Tips (Takes available space)
        let version_text = format!("{} v{}", text.footer_version, env!("CARGO_PKG_VERSION"));
        let version_galley = ui.painter().layout_no_wrap(
            version_text.clone(),
            egui::FontId::proportional(11.0),
            ui.visuals().weak_text_color(),
        );
        let version_width = version_galley.rect.width() + 10.0;

        // Allocate center space: Total - Left - Right
        let available_w = (ui.available_width() - version_width).max(0.0);

        ui.allocate_ui(egui::vec2(available_w, ui.available_height()), |ui| {
            ui.vertical_centered(|ui| {
                let tip_color = ui.visuals().text_color().linear_multiply(tip_alpha);
                let icon_color =
                    egui::Color32::from_rgba_unmultiplied(255, 200, 50, (tip_alpha * 255.0) as u8); // Yellow/gold color for lightbulb

                // First, calculate text width to properly center everything
                let icon_size = 14.0;
                let icon_spacing = 4.0;

                // Format tip with bold text
                let is_dark_mode = ui.visuals().dark_mode;
                let layout_job =
                    format_footer_tip(&current_tip, tip_color, is_dark_mode, tip_alpha);
                let text_galley = ui.painter().layout_job(layout_job);
                let total_width = icon_size + icon_spacing + text_galley.rect.width();

                // Allocate space for icon + text centered
                let (response, painter) = ui.allocate_painter(
                    egui::vec2(total_width + 8.0, ui.available_height().max(18.0)),
                    egui::Sense::click(),
                );
                let rect = response.rect;

                // Draw lightbulb icon on the left
                let icon_rect = egui::Rect::from_min_size(
                    egui::pos2(rect.left(), rect.center().y - icon_size / 2.0),
                    egui::vec2(icon_size, icon_size),
                );
                paint_icon(&painter, icon_rect, Icon::Lightbulb, icon_color);

                // Draw text to the right of icon
                let text_pos = egui::pos2(
                    icon_rect.right() + icon_spacing,
                    rect.center().y - text_galley.rect.height() / 2.0,
                );
                painter.galley(text_pos, text_galley, egui::Color32::WHITE);

                if response.on_hover_text(text.tips_click_hint).clicked() {
                    *show_modal = true;
                }
            });
        });

        // 4. Draw Version on the far right
        ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
            ui.label(
                egui::RichText::new(version_text)
                    .size(11.0)
                    .color(ui.visuals().weak_text_color()),
            );
        });
    });
}

// Helper function to format footer tip with bold text
fn format_footer_tip(
    text: &str,
    base_color: egui::Color32,
    is_dark_mode: bool,
    alpha_factor: f32,
) -> LayoutJob {
    let mut job = LayoutJob::default();

    // Color scheme for bold text
    let bold_color = if is_dark_mode {
        egui::Color32::from_rgb(150, 200, 255) // Soft cyan for dark mode
    } else {
        egui::Color32::from_rgb(40, 100, 180) // Dark blue for light mode
    };

    // Apply alpha to colors
    let regular_color = egui::Color32::from_rgba_unmultiplied(
        base_color.r(),
        base_color.g(),
        base_color.b(),
        (base_color.a() as f32 * alpha_factor) as u8,
    );

    let bold_color_with_alpha = egui::Color32::from_rgba_unmultiplied(
        bold_color.r(),
        bold_color.g(),
        bold_color.b(),
        (255.0 * alpha_factor) as u8,
    );

    // Create text format
    let mut text_format = TextFormat::default();
    text_format.font_id = egui::FontId::proportional(11.0);
    text_format.color = regular_color;

    // Parse text for **bold** markers
    let mut current_text = String::new();
    let mut chars = text.chars().peekable();
    let mut is_bold = false;

    while let Some(ch) = chars.next() {
        if ch == '*' && chars.peek() == Some(&'*') {
            // Found ** marker
            chars.next(); // consume second *

            if !current_text.is_empty() {
                // Append accumulated text
                let mut fmt = text_format.clone();
                if is_bold {
                    fmt.color = bold_color_with_alpha;
                }
                job.append(&current_text, 0.0, fmt);
                current_text.clear();
            }

            is_bold = !is_bold;
        } else {
            current_text.push(ch);
        }
    }

    // Append remaining text
    if !current_text.is_empty() {
        let mut fmt = text_format.clone();
        if is_bold {
            fmt.color = bold_color_with_alpha;
        }
        job.append(&current_text, 0.0, fmt);
    }

    job
}
</file>

<file path="src/gui/settings_ui/global/tts_settings.rs">
use eframe::egui;
use crate::config::{Config, TtsMethod};
use crate::gui::locale::LocaleText;
use crate::gui::icons::{Icon, icon_button};

pub fn render_tts_settings_modal(
    ui: &mut egui::Ui,
    config: &mut Config,
    text: &LocaleText,
    show_modal: &mut bool,
) -> bool {
    if !*show_modal {
        return false;
    }
    
    let mut changed = false;

    // List of voices (Name, Gender)
    const VOICES: &[(&str, &str)] = &[
        ("Achernar", "Female"), ("Achird", "Male"), ("Algenib", "Male"), ("Algieba", "Male"), 
        ("Alnilam", "Male"), ("Aoede", "Female"), ("Autonoe", "Female"), ("Callirrhoe", "Female"), 
        ("Charon", "Male"), ("Despina", "Female"), ("Enceladus", "Male"), ("Erinome", "Female"), 
        ("Fenrir", "Male"), ("Gacrux", "Female"), ("Iapetus", "Male"), ("Kore", "Female"), 
        ("Laomedeia", "Female"), ("Leda", "Female"), ("Orus", "Male"), ("Pulcherrima", "Female"), 
        ("Puck", "Male"), ("Rasalgethi", "Male"), ("Sadachbia", "Male"), ("Sadaltager", "Male"), 
        ("Schedar", "Male"), ("Sulafat", "Female"), ("Umbriel", "Male"), ("Vindemiatrix", "Female"), 
        ("Zephyr", "Female"), ("Zubenelgenubi", "Male"),
    ];

    let male_voices: Vec<_> = VOICES.iter().filter(|(_, g)| *g == "Male").collect();
    let female_voices: Vec<_> = VOICES.iter().filter(|(_, g)| *g == "Female").collect();

    egui::Window::new(format!("🔊 {}", text.tts_settings_title))
        .collapsible(false)
        .resizable(false)
        .title_bar(false)
        .default_width(650.0)
        .default_height(600.0)
        .anchor(egui::Align2::CENTER_CENTER, egui::vec2(0.0, 0.0))
        .show(ui.ctx(), |ui| {
            ui.set_min_height(500.0); // Force minimum height for the content area

            ui.horizontal(|ui| {
                ui.label(egui::RichText::new(format!("🔊 {}", text.tts_settings_title)).strong().size(14.0));
                ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                    if icon_button(ui, Icon::Close).clicked() {
                        *show_modal = false;
                    }
                });
            });
            ui.separator();
            ui.add_space(8.0);
            
            // === TTS METHOD SELECTION ===
            ui.horizontal(|ui| {
                ui.label(egui::RichText::new(text.tts_method_label).strong());
                
                // Gemini Live (Premium)
                if ui.radio_value(&mut config.tts_method, TtsMethod::GeminiLive, text.tts_method_standard).clicked() {
                    changed = true;
                }
                
                // Edge TTS (Good)
                if ui.radio_value(&mut config.tts_method, TtsMethod::EdgeTTS, text.tts_method_edge).clicked() {
                    changed = true;
                }

                // Google Translate (Fast)
                if ui.radio_value(&mut config.tts_method, TtsMethod::GoogleTranslate, text.tts_method_fast).clicked() {
                    if config.tts_speed == "Fast" {
                        config.tts_speed = "Normal".to_string();
                    }
                    changed = true;
                }
            });
            ui.add_space(10.0);
            ui.separator();
            ui.add_space(10.0);
            
            // Speed and Tone & Style side by side
            if config.tts_method == TtsMethod::GeminiLive {
                ui.columns(2, |columns| {
                    // Left column: Speed
                    columns[0].label(egui::RichText::new(text.tts_speed_label).strong());
                    columns[0].horizontal(|ui| {
                        if ui.radio_value(&mut config.tts_speed, "Slow".to_string(), text.tts_speed_slow).clicked() { changed = true; }
                        if ui.radio_value(&mut config.tts_speed, "Normal".to_string(), text.tts_speed_normal).clicked() { changed = true; }
                        if ui.radio_value(&mut config.tts_speed, "Fast".to_string(), text.tts_speed_fast).clicked() { changed = true; }
                    });
                    
                    // Right column: Language-Specific Instructions
                    columns[1].label(egui::RichText::new(text.tts_instructions_label).strong());
                    
                    // Supported languages from whatlang (70 languages) with ISO 639-3 codes
                    let supported_languages = [
                        ("afr", "Afrikaans"), ("ara", "Arabic"), ("aze", "Azerbaijani"),
                        ("bel", "Belarusian"), ("ben", "Bengali"), ("bul", "Bulgarian"),
                        ("cat", "Catalan"), ("ces", "Czech"), ("cmn", "Mandarin Chinese"),
                        ("dan", "Danish"), ("deu", "German"), ("ell", "Greek"),
                        ("eng", "English"), ("epo", "Esperanto"), ("est", "Estonian"),
                        ("eus", "Basque"), ("fin", "Finnish"), ("fra", "French"),
                        ("guj", "Gujarati"), ("heb", "Hebrew"), ("hin", "Hindi"),
                        ("hrv", "Croatian"), ("hun", "Hungarian"), ("ind", "Indonesian"),
                        ("ita", "Italian"), ("jpn", "Japanese"), ("kan", "Kannada"),
                        ("kat", "Georgian"), ("kor", "Korean"), ("lat", "Latin"),
                        ("lav", "Latvian"), ("lit", "Lithuanian"), ("mal", "Malayalam"),
                        ("mar", "Marathi"), ("mkd", "Macedonian"), ("mya", "Burmese"),
                        ("nep", "Nepali"), ("nld", "Dutch"), ("nno", "Norwegian Nynorsk"),
                        ("nob", "Norwegian Bokmål"), ("ori", "Oriya"), ("pan", "Punjabi"),
                        ("pes", "Persian"), ("pol", "Polish"), ("por", "Portuguese"),
                        ("ron", "Romanian"), ("rus", "Russian"), ("sin", "Sinhala"),
                        ("slk", "Slovak"), ("slv", "Slovenian"), ("som", "Somali"),
                        ("spa", "Spanish"), ("sqi", "Albanian"), ("srp", "Serbian"),
                        ("swe", "Swedish"), ("tam", "Tamil"), ("tel", "Telugu"),
                        ("tgl", "Tagalog"), ("tha", "Thai"), ("tur", "Turkish"),
                        ("ukr", "Ukrainian"), ("urd", "Urdu"), ("uzb", "Uzbek"),
                        ("vie", "Vietnamese"), ("yid", "Yiddish"), ("zho", "Chinese"),
                    ];
                    
                    // Show existing conditions
                    let mut to_remove: Option<usize> = None;
                    for (idx, condition) in config.tts_language_conditions.iter_mut().enumerate() {
                        columns[1].horizontal(|ui| {
                            // Language dropdown (read-only display for now)
                            let display_name = supported_languages.iter()
                                .find(|(code, _)| code.eq_ignore_ascii_case(&condition.language_code))
                                .map(|(_, name)| *name)
                                .unwrap_or(&condition.language_name);
                            
                            ui.label(egui::RichText::new(display_name).strong().color(egui::Color32::from_rgb(100, 180, 100)));
                            ui.label("→");
                            
                            // Instruction input
                            if ui.add(
                                egui::TextEdit::singleline(&mut condition.instruction)
                                    .desired_width(180.0)
                                    .hint_text(text.tts_instructions_hint)
                            ).changed() {
                                changed = true;
                            }
                            
                            // Remove button - use Icon::Close for proper rendering
                            if icon_button(ui, Icon::Close).on_hover_text("Remove").clicked() {
                                to_remove = Some(idx);
                            }
                        });
                    }
                    
                    // Remove condition if needed
                    if let Some(idx) = to_remove {
                        config.tts_language_conditions.remove(idx);
                        changed = true;
                    }
                    
                    // Add condition dropdown - selecting immediately adds the condition
                    columns[1].horizontal(|ui| {
                        // Get languages that are not yet used
                        let used_codes: Vec<_> = config.tts_language_conditions.iter()
                            .map(|c| c.language_code.as_str())
                            .collect();
                        let available: Vec<_> = supported_languages.iter()
                            .filter(|(code, _)| !used_codes.contains(code))
                            .collect();
                        
                        if !available.is_empty() {
                            // Dropdown that immediately adds selected language
                            egui::ComboBox::from_id_salt("tts_add_condition")
                                .selected_text(text.tts_add_condition)
                                .width(140.0)
                                .show_ui(ui, |ui| {
                                    for (code, name) in &available {
                                        if ui.selectable_label(false, *name).clicked() {
                                            config.tts_language_conditions.push(crate::config::TtsLanguageCondition {
                                                language_code: code.to_string(),
                                                language_name: name.to_string(),
                                                instruction: String::new(),
                                            });
                                            changed = true;
                                        }
                                    }
                                });
                        }
                    });
                });
                
                ui.add_space(10.0);
                ui.separator();
                ui.add_space(10.0);
                
                // Voice selection - 4 columns layout to save vertical space
                ui.columns(4, |columns| {
                    use std::sync::atomic::{AtomicUsize, Ordering};
                    use std::time::{SystemTime, UNIX_EPOCH};
                    use std::collections::hash_map::RandomState;
                    use std::hash::{BuildHasher, Hasher};
                    
                    // Shared static to ensure randomness across all columns and no repeats globally
                    static LAST_PREVIEW_IDX: AtomicUsize = AtomicUsize::new(9999);
                    
                    // Helper to render a voice item
                    let render_voice = |ui: &mut egui::Ui, name: &str, config: &mut Config, text: &LocaleText, changed: &mut bool| {
                        ui.horizontal(|ui| {
                            let is_selected = config.tts_voice == name;
                            if ui.radio(is_selected, "").clicked() {
                                config.tts_voice = name.to_string();
                                *changed = true;
                            }
                            if ui.button("🔊").on_hover_text("Preview").clicked() {
                                config.tts_voice = name.to_string();
                                *changed = true;
                                
                                if !text.tts_preview_texts.is_empty() {
                                    let s = RandomState::new();
                                    let mut hasher = s.build_hasher();
                                    hasher.write_usize(SystemTime::now().duration_since(UNIX_EPOCH).unwrap_or_default().subsec_nanos() as usize);
                                    let rand_val = hasher.finish();
                                    let len = text.tts_preview_texts.len();
                                    let mut idx = (rand_val as usize) % len;
                                    
                                    let last = LAST_PREVIEW_IDX.load(Ordering::Relaxed);
                                    if idx == last {
                                        idx = (idx + 1) % len;
                                    }
                                    LAST_PREVIEW_IDX.store(idx, Ordering::Relaxed);
                                    
                                    let preview_text = text.tts_preview_texts[idx].replace("{}", name);
                                    crate::api::tts::TTS_MANAGER.speak_interrupt(&preview_text, 0);
                                } else {
                                    let preview_text = format!("Hello, I am {}. This is a voice preview.", name);
                                    crate::api::tts::TTS_MANAGER.speak_interrupt(&preview_text, 0);
                                }
                            }
                            ui.label(egui::RichText::new(name).strong());
                        });
                    };

                    // Split male voices into 2 columns
                    let male_mid = (male_voices.len() + 1) / 2;
                    let male_col1: Vec<_> = male_voices.iter().take(male_mid).collect();
                    let male_col2: Vec<_> = male_voices.iter().skip(male_mid).collect();
                    
                    // Split female voices into 2 columns
                    let female_mid = (female_voices.len() + 1) / 2;
                    let female_col1: Vec<_> = female_voices.iter().take(female_mid).collect();
                    let female_col2: Vec<_> = female_voices.iter().skip(female_mid).collect();

                    // Column 0: Male (first half)
                    columns[0].vertical(|ui| {
                        ui.label(egui::RichText::new(text.tts_male).strong().underline());
                        ui.add_space(4.0);
                        for (name, _) in male_col1 {
                            render_voice(ui, name, config, text, &mut changed);
                        }
                    });
                    
                    // Column 1: Male (second half)
                    columns[1].vertical(|ui| {
                        ui.label(egui::RichText::new("").strong()); // Empty header for alignment
                        ui.add_space(4.0);
                        for (name, _) in male_col2 {
                            render_voice(ui, name, config, text, &mut changed);
                        }
                    });
                    
                    // Column 2: Female (first half)
                    columns[2].vertical(|ui| {
                        ui.label(egui::RichText::new(text.tts_female).strong().underline());
                        ui.add_space(4.0);
                        for (name, _) in female_col1 {
                            render_voice(ui, name, config, text, &mut changed);
                        }
                    });
                    
                    // Column 3: Female (second half)
                    columns[3].vertical(|ui| {
                        ui.label(egui::RichText::new("").strong()); // Empty header for alignment
                        ui.add_space(4.0);
                        for (name, _) in female_col2 {
                            render_voice(ui, name, config, text, &mut changed);
                        }
                    });
                });
            } else if config.tts_method == TtsMethod::GoogleTranslate {
                // Simplified UI for Google Translate
                ui.vertical_centered(|ui| {
                    ui.add_space(20.0);
                    ui.label(egui::RichText::new(text.tts_google_translate_title).size(18.0).strong());
                    ui.add_space(10.0);
                    ui.label(text.tts_google_translate_desc);
                    ui.add_space(20.0);
                    
                    ui.horizontal(|ui| {
                        ui.label(egui::RichText::new(text.tts_speed_label).strong());
                        if ui.radio_value(&mut config.tts_speed, "Slow".to_string(), text.tts_speed_slow).clicked() { changed = true; }
                        if ui.radio_value(&mut config.tts_speed, "Normal".to_string(), text.tts_speed_normal).clicked() { changed = true; }
                    });
                    
                    ui.add_space(20.0);
                });
            } else if config.tts_method == TtsMethod::EdgeTTS {
                // Trigger voice list loading on first render
                crate::api::tts::edge_voices::load_edge_voices_async();
                
                // Edge TTS Settings
                ui.vertical_centered(|ui| {
                    ui.add_space(10.0);
                    ui.label(egui::RichText::new(text.tts_edge_title).size(18.0).strong());
                    ui.add_space(5.0);
                    ui.label(text.tts_edge_desc);
                    ui.add_space(15.0);
                });
                
                // Pitch and Rate sliders
                ui.horizontal(|ui| {
                    ui.label(egui::RichText::new(text.tts_pitch_label).strong());
                    if ui.add(egui::Slider::new(&mut config.edge_tts_settings.pitch, -50..=50).suffix(" Hz")).changed() {
                        changed = true;
                    }
                });
                
                ui.add_space(5.0);
                ui.horizontal(|ui| {
                    ui.label(egui::RichText::new(text.tts_rate_label).strong());
                    if ui.add(egui::Slider::new(&mut config.edge_tts_settings.rate, -50..=100).suffix("%")).changed() {
                        changed = true;
                    }
                });
                
                ui.add_space(15.0);
                ui.separator();
                ui.add_space(10.0);
                
                // Per-language voice configuration
                ui.label(egui::RichText::new(text.tts_voice_per_language_label).strong());
                ui.add_space(5.0);
                
                // Check voice cache status
                let cache_status = {
                    let cache = crate::api::tts::edge_voices::EDGE_VOICE_CACHE.lock().unwrap();
                    (cache.loaded, cache.loading, cache.error.clone())
                };
                
                if cache_status.1 {
                    // Loading
                    ui.horizontal(|ui| {
                        ui.spinner();
                        ui.label(text.tts_loading_voices);
                    });
                } else if let Some(ref error) = cache_status.2 {
                    // Error
                    ui.colored_label(egui::Color32::RED, format!("{} {}", text.tts_failed_load_voices, error).replace("{}", ""));
                    if ui.button(text.tts_retry_label).clicked() {
                        // Reset cache and retry
                        let mut cache = crate::api::tts::edge_voices::EDGE_VOICE_CACHE.lock().unwrap();
                        cache.loaded = false;
                        cache.loading = false;
                        cache.error = None;
                    }
                } else if cache_status.0 {
                    // Loaded - show voice configuration
                    egui::ScrollArea::vertical().max_height(180.0).show(ui, |ui| {
                        let mut to_remove: Option<usize> = None;
                        
                        for (idx, voice_config) in config.edge_tts_settings.voice_configs.iter_mut().enumerate() {
                            ui.horizontal(|ui| {
                                // Language name (read-only)
                                ui.label(egui::RichText::new(&voice_config.language_name).strong().color(egui::Color32::from_rgb(100, 180, 100)));
                                ui.label("→");
                                
                                // Voice dropdown for this language
                                let voices = crate::api::tts::edge_voices::get_voices_for_language(&voice_config.language_code);
                                
                                egui::ComboBox::from_id_salt(format!("edge_voice_{}", idx))
                                    .selected_text(&voice_config.voice_name)
                                    .width(220.0)
                                    .show_ui(ui, |ui| {
                                        for voice in &voices {
                                            let display = format!("{} ({})", voice.short_name, voice.gender);
                                            if ui.selectable_label(voice_config.voice_name == voice.short_name, &display).clicked() {
                                                voice_config.voice_name = voice.short_name.clone();
                                                changed = true;
                                            }
                                        }
                                    });
                                
                                // Remove button
                                if icon_button(ui, Icon::Close).on_hover_text("Remove").clicked() {
                                    to_remove = Some(idx);
                                }
                            });
                        }
                        
                        if let Some(idx) = to_remove {
                            config.edge_tts_settings.voice_configs.remove(idx);
                            changed = true;
                        }
                    });
                    
                    ui.add_space(10.0);
                    
                    // Add language dropdown
                    ui.horizontal(|ui| {
                        let used_codes: Vec<_> = config.edge_tts_settings.voice_configs.iter()
                            .map(|c| c.language_code.as_str())
                            .collect();
                        
                        let available_langs = crate::api::tts::edge_voices::get_available_languages();
                        let available: Vec<_> = available_langs.iter()
                            .filter(|(code, _)| !used_codes.contains(&code.as_str()))
                            .collect();
                        
                        if !available.is_empty() {
                            egui::ComboBox::from_id_salt("edge_add_language")
                                .selected_text(text.tts_add_language_label)
                                .width(150.0)
                                .show_ui(ui, |ui| {
                                    for (code, name) in &available {
                                        if ui.selectable_label(false, name).clicked() {
                                            // Get first voice for this language as default
                                            let voices = crate::api::tts::edge_voices::get_voices_for_language(code);
                                            let default_voice = voices.first()
                                                .map(|v| v.short_name.clone())
                                                .unwrap_or_else(|| format!("{}-??-??Neural", code));
                                            
                                            config.edge_tts_settings.voice_configs.push(
                                                crate::config::EdgeTtsVoiceConfig {
                                                    language_code: code.clone(),
                                                    language_name: name.clone(),
                                                    voice_name: default_voice,
                                                }
                                            );
                                            changed = true;
                                        }
                                    }
                                });
                        }
                        
                        if ui.button(text.tts_reset_to_defaults_label).clicked() {
                            config.edge_tts_settings = crate::config::EdgeTtsSettings::default();
                            changed = true;
                        }
                    });
                } else {
                    // Not loaded yet, show loading message
                    ui.horizontal(|ui| {
                        ui.spinner();
                        ui.label(text.tts_initializing_voices);
                    });
                }
            }
        });
        
    changed
}
</file>

<file path="src/gui/settings_ui/global/usage_stats.rs">
use eframe::egui;
use crate::gui::locale::LocaleText;
use crate::gui::icons::{Icon, icon_button};
use crate::model_config::{get_all_models, get_all_models_with_ollama};
use std::collections::HashMap;

pub fn render_usage_modal(
    ui: &mut egui::Ui, 
    usage_stats: &HashMap<String, String>, 
    text: &LocaleText,
    show_modal: &mut bool,
    use_groq: bool,
    use_gemini: bool,
    use_openrouter: bool,
    use_ollama: bool,
    use_cerebras: bool,
) {
    if !*show_modal {
        return;
    }
    
    egui::Window::new(format!("📊 {}", text.usage_statistics_title))
        .collapsible(false)
        .resizable(false)
        .title_bar(false)
        .default_width(400.0)
        .anchor(egui::Align2::CENTER_CENTER, egui::vec2(0.0, 0.0))
        .show(ui.ctx(), |ui| {
            // Header with title and close button
            ui.horizontal(|ui| {
                ui.label(egui::RichText::new(format!("📊 {}", text.usage_statistics_title)).strong().size(14.0));
                ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                    if icon_button(ui, Icon::Close).clicked() {
                        *show_modal = false;
                    }
                });
            });
            ui.separator();
            ui.add_space(4.0);
            
            // Get all models including Ollama models from cache
            let all_models = if use_ollama {
                get_all_models_with_ollama()
            } else {
                get_all_models().to_vec()
            };
            
            let mut shown_models = std::collections::HashSet::new();
            
            egui::ScrollArea::vertical()
                .max_height(450.0)
                .auto_shrink([false, false])
                .show(ui, |ui| {
                ui.set_width(ui.available_width());
                if use_groq {
                    egui::CollapsingHeader::new(egui::RichText::new("⚡ Groq").strong().size(13.0))
                        .default_open(true)
                        .show(ui, |ui| {
                        egui::Grid::new("groq_grid").striped(true).show(ui, |ui| {
                            ui.label(egui::RichText::new(text.usage_model_column).strong().size(11.0));
                            ui.label(egui::RichText::new(text.usage_remaining_column).strong().size(11.0));
                            ui.end_row();
                            
                            for model in &all_models {
                                if !model.enabled || model.provider != "groq" { continue; }
                                if shown_models.contains(&model.full_name) { continue; }
                                shown_models.insert(model.full_name.clone());
                                
                                ui.label(&model.full_name);
                                
                                if model.model_type == crate::model_config::ModelType::Audio {
                                    ui.label("");
                                    ui.end_row();
                                    continue;
                                }

                                let static_limit = model.quota_limit_en.split_whitespace().next().unwrap_or("?");
                                let default_status = format!("??? / {}", static_limit);
                                
                                let raw_status = usage_stats.get(&model.full_name).cloned().unwrap_or(default_status);
                                let display_status = if let Some((usage, limit)) = raw_status.split_once(" / ") {
                                    let final_limit = if limit == "?" { static_limit } else { limit };
                                    format!("{} / {}", usage, final_limit)
                                } else {
                                    raw_status
                                };

                                ui.label(display_status);
                                ui.end_row();
                            }
                            
                        });
                    });
                }
                
                if use_cerebras {
                    egui::CollapsingHeader::new(egui::RichText::new("🔥 Cerebras").strong().size(13.0))
                        .default_open(true)
                        .show(ui, |ui| {
                        egui::Grid::new("cerebras_grid").striped(true).show(ui, |ui| {
                            ui.label(egui::RichText::new(text.usage_model_column).strong().size(11.0));
                            ui.label(egui::RichText::new(text.usage_remaining_column).strong().size(11.0));
                            ui.end_row();
                            
                            for model in &all_models {
                                if !model.enabled || model.provider != "cerebras" { continue; }
                                if shown_models.contains(&model.full_name) { continue; }
                                shown_models.insert(model.full_name.clone());
                                
                                ui.label(&model.full_name);

                                let static_limit = model.quota_limit_en.split_whitespace().next().unwrap_or("?");
                                let default_status = format!("??? / {}", static_limit);
                                
                                let raw_status = usage_stats.get(&model.full_name).cloned().unwrap_or(default_status);
                                let display_status = if let Some((usage, limit)) = raw_status.split_once(" / ") {
                                    let final_limit = if limit == "?" { static_limit } else { limit };
                                    format!("{} / {}", usage, final_limit)
                                } else {
                                    raw_status
                                };

                                ui.label(display_status);
                                ui.end_row();
                            }

                            // Add gpt-oss-120b (realtime translation model)
                            if !shown_models.contains("gpt-oss-120b") {
                                shown_models.insert("gpt-oss-120b".to_string());
                                ui.label("gpt-oss-120b");
                                let static_limit = "14400";
                                let default_status = format!("??? / {}", static_limit);
                                let raw_status = usage_stats.get("gpt-oss-120b").cloned().unwrap_or(default_status);
                                let display_status = if let Some((usage, limit)) = raw_status.split_once(" / ") {
                                    let final_limit = if limit == "?" { static_limit } else { limit };
                                    format!("{} / {}", usage, final_limit)
                                } else {
                                    raw_status
                                };
                                ui.label(display_status);
                                ui.end_row();
                            }
                        });
                        ui.add_space(4.0);
                        ui.hyperlink_to(text.usage_check_link, "https://cloud.cerebras.ai/");
                    });
                }
                
                if use_gemini {
                    egui::CollapsingHeader::new(egui::RichText::new("✨ Google Gemini").strong().size(13.0))
                        .default_open(true)
                        .show(ui, |ui| {
                        ui.horizontal(|ui| {
                            ui.label(egui::RichText::new(text.usage_model_column).strong().size(11.0));
                            ui.add_space(120.0);
                            ui.hyperlink_to(text.usage_check_link, "https://aistudio.google.com/usage?timeRange=last-1-day&tab=rate-limit");
                        });
                        ui.add_space(4.0);
                        
                        for model in &all_models {
                            if !model.enabled || model.provider != "google" { continue; }
                            if shown_models.contains(&model.full_name) { continue; }
                            shown_models.insert(model.full_name.clone());
                            
                            ui.label(&model.full_name);
                        }
                    });
                }
                
                if use_openrouter {
                    egui::CollapsingHeader::new(egui::RichText::new("🌐 OpenRouter").strong().size(13.0))
                        .default_open(true)
                        .show(ui, |ui| {
                        ui.horizontal(|ui| {
                            ui.label(egui::RichText::new(text.usage_model_column).strong().size(11.0));
                            ui.add_space(120.0);
                            ui.hyperlink_to(text.usage_check_link, "https://openrouter.ai/activity");
                        });
                        ui.add_space(4.0);
                        
                        for model in &all_models {
                            if !model.enabled || model.provider != "openrouter" { continue; }
                            if shown_models.contains(&model.full_name) { continue; }
                            shown_models.insert(model.full_name.clone());
                            
                            ui.label(&model.full_name);
                        }
                    });
                }
                
                if use_ollama {
                    egui::CollapsingHeader::new(egui::RichText::new("🏠 Ollama (Local)").strong().size(13.0))
                        .default_open(true)
                        .show(ui, |ui| {
                        ui.horizontal(|ui| {
                            ui.label(egui::RichText::new(text.usage_model_column).strong().size(11.0));
                            ui.add_space(120.0);
                            ui.label("∞ Unlimited");
                        });
                        ui.add_space(4.0);
                        
                        for model in &all_models {
                            if !model.enabled || model.provider != "ollama" { continue; }
                            if shown_models.contains(&model.full_name) { continue; }
                            shown_models.insert(model.full_name.clone());
                            
                            ui.label(&model.full_name);
                        }
                    });
                }
            });
        });
}
</file>

<file path="src/gui/settings_ui/history.rs">
use crate::config::Config;
use crate::gui::icons::{draw_icon_static, icon_button, Icon};
use crate::gui::locale::LocaleText;
use crate::history::{HistoryItem, HistoryManager, HistoryType};
use eframe::egui;

pub fn render_history_panel(
    ui: &mut egui::Ui,
    config: &mut Config,
    history_manager: &HistoryManager,
    search_query: &mut String,
    text: &LocaleText,
) -> bool {
    let mut changed = false;

    let is_dark = ui.visuals().dark_mode;
    let card_bg = if is_dark {
        egui::Color32::from_rgba_unmultiplied(28, 32, 42, 250) // Darker for better text contrast
    } else {
        egui::Color32::from_rgba_unmultiplied(255, 255, 255, 255)
    };
    let card_stroke = if is_dark {
        egui::Stroke::new(1.0, egui::Color32::from_gray(50))
    } else {
        egui::Stroke::new(1.0, egui::Color32::from_gray(210))
    };

    // Set max width for entire panel (outside frame so it properly constrains the card)
    ui.set_max_width(510.0);

    // === HEADER CARD ===
    ui.add_space(5.0);
    egui::Frame::new()
        .fill(card_bg)
        .stroke(card_stroke)
        .inner_margin(12.0)
        .corner_radius(10.0)
        .show(ui, |ui| {
            // Row 1: Title + Max items slider
            ui.horizontal(|ui| {
                ui.label(
                    egui::RichText::new(format!("📜 {}", text.history_title))
                        .strong()
                        .size(14.0),
                );
                ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                    if ui
                        .add(egui::Slider::new(&mut config.max_history_items, 10..=200))
                        .changed()
                    {
                        history_manager.request_prune(config.max_history_items);
                        changed = true;
                    }
                    ui.label(text.max_items_label);
                });
            });

            ui.add_space(8.0);

            // Row 2: Search + Actions
            ui.horizontal(|ui| {
                ui.scope(|ui| {
                    if !is_dark {
                        let visuals = ui.visuals_mut();
                        visuals.extreme_bg_color = egui::Color32::from_gray(242);
                        visuals.widgets.inactive.bg_stroke =
                            egui::Stroke::new(1.0, egui::Color32::from_gray(220));
                        visuals.widgets.hovered.bg_stroke =
                            egui::Stroke::new(1.0, egui::Color32::from_gray(200));
                        visuals.widgets.active.bg_stroke =
                            egui::Stroke::new(1.0, egui::Color32::from_gray(180));
                    }
                    ui.add(
                        egui::TextEdit::singleline(search_query)
                            .hint_text(text.search_placeholder)
                            .desired_width(220.0),
                    );
                });

                if !search_query.is_empty() {
                    if icon_button(ui, Icon::Close)
                        .on_hover_text("Clear search")
                        .clicked()
                    {
                        *search_query = "".to_string();
                    }
                }

                if icon_button(ui, Icon::Folder)
                    .on_hover_text("Open Media Folder")
                    .clicked()
                {
                    let config_dir = dirs::config_dir()
                        .unwrap_or_default()
                        .join("screen-goated-toolbox")
                        .join("history_media");
                    let _ = std::fs::create_dir_all(&config_dir);
                    let _ = open::that(config_dir);
                }

                ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                    // Clear All button - styled
                    let clear_bg = if is_dark {
                        egui::Color32::from_rgb(120, 60, 60)
                    } else {
                        egui::Color32::from_rgb(220, 140, 140)
                    };
                    if ui
                        .add(
                            egui::Button::new(
                                egui::RichText::new(text.clear_all_history_btn)
                                    .color(egui::Color32::WHITE)
                                    .small(),
                            )
                            .fill(clear_bg)
                            .corner_radius(8.0),
                        )
                        .clicked()
                    {
                        history_manager.clear_all();
                    }
                });
            });
        });

    ui.add_space(8.0);

    let items = history_manager.items.lock().unwrap().clone();
    let q = search_query.to_lowercase();
    let filtered: Vec<&HistoryItem> = items
        .iter()
        .filter(|i| q.is_empty() || i.text.to_lowercase().contains(&q) || i.timestamp.contains(&q))
        .collect();

    if filtered.is_empty() {
        ui.centered_and_justified(|ui| {
            ui.label(text.history_empty);
        });
    } else {
        // History items in scroll area
        egui::Frame::new().show(ui, |ui| {
            ui.set_height(460.0);

            egui::ScrollArea::vertical().show(ui, |ui| {
                ui.set_max_width(510.0);

                let mut id_to_delete = None;

                for item in filtered {
                    // Distinct but subtle colors based on item type
                    let item_bg = match item.item_type {
                        HistoryType::Image => {
                            if is_dark {
                                // Subtle blue tint for images
                                egui::Color32::from_rgba_unmultiplied(30, 38, 52, 235)
                            } else {
                                egui::Color32::from_rgba_unmultiplied(240, 245, 255, 255)
                            }
                        }
                        HistoryType::Text => {
                            if is_dark {
                                // Subtle green tint for text
                                egui::Color32::from_rgba_unmultiplied(30, 42, 38, 235)
                            } else {
                                egui::Color32::from_rgba_unmultiplied(240, 252, 245, 255)
                            }
                        }
                        HistoryType::Audio => {
                            if is_dark {
                                // Subtle orange/amber tint for audio
                                egui::Color32::from_rgba_unmultiplied(42, 36, 30, 235)
                            } else {
                                egui::Color32::from_rgba_unmultiplied(255, 250, 240, 255)
                            }
                        }
                    };

                    egui::Frame::new()
                        .fill(item_bg)
                        .stroke(card_stroke)
                        .inner_margin(8.0)
                        .corner_radius(8.0)
                        .show(ui, |ui| {
                            ui.horizontal(|ui| {
                                let icon = match item.item_type {
                                    HistoryType::Image => Icon::Image,
                                    HistoryType::Audio => Icon::Microphone,
                                    HistoryType::Text => Icon::Text,
                                };
                                draw_icon_static(ui, icon, Some(14.0));
                                ui.label(egui::RichText::new(&item.timestamp).size(10.0).weak());

                                ui.with_layout(
                                    egui::Layout::right_to_left(egui::Align::Center),
                                    |ui| {
                                        if icon_button(ui, Icon::DeleteLarge)
                                            .on_hover_text("Delete")
                                            .clicked()
                                        {
                                            id_to_delete = Some(item.id);
                                        }

                                        if icon_button(ui, Icon::Copy)
                                            .on_hover_text("Copy Text")
                                            .clicked()
                                        {
                                            crate::gui::utils::copy_to_clipboard_text(&item.text);
                                        }

                                        if !item.media_path.is_empty() {
                                            let btn_text = match item.item_type {
                                                HistoryType::Image => text.view_image_btn,
                                                HistoryType::Audio => text.listen_audio_btn,
                                                HistoryType::Text => text.view_text_btn,
                                            };
                                            if ui.button(btn_text).clicked() {
                                                let config_dir = dirs::config_dir()
                                                    .unwrap()
                                                    .join("screen-goated-toolbox")
                                                    .join("history_media");
                                                let path = config_dir.join(&item.media_path);
                                                let _ = open::that(path);
                                            }
                                        }
                                    },
                                );
                            });

                            ui.label(egui::RichText::new(&item.text).size(13.0));
                        });
                    ui.add_space(4.0);
                }

                if let Some(id) = id_to_delete {
                    history_manager.delete(id);
                }
            });
        });
    }

    changed
}
</file>

<file path="src/gui/settings_ui/node_graph/conversion.rs">
use super::node::ChainNode;
use crate::config::ProcessingBlock;
use eframe::egui;
use egui_snarl::{InPinId, NodeId, OutPinId, Snarl};

/// Convert blocks to snarl graph with intelligent layout
pub fn blocks_to_snarl(
    blocks: &[ProcessingBlock],
    connections: &[(usize, usize)],
    preset_type: &str,
) -> Snarl<ChainNode> {
    let mut snarl = Snarl::new();
    let mut node_ids = Vec::new();

    // Default layout parameters
    let start_x = 50.0;
    let start_y = 300.0; // Center vertically
    let spacing_x = 250.0; // Increased to widen the graph
    let spacing_y = 225.0; // Increased to prevent vertical overlap (nodes are tall)

    // Calculate positions based on graph structure
    let positions: Vec<egui::Pos2> = if !connections.is_empty() {
        use std::collections::{HashMap, VecDeque};

        // 1. Build adjacency
        let mut adj: HashMap<usize, Vec<usize>> = HashMap::new();
        for &(from, to) in connections {
            adj.entry(from).or_default().push(to);
        }

        // 2. Compute depth (layer) for each node via BFS
        let mut depths = vec![0; blocks.len()];
        let mut layer_nodes: HashMap<usize, Vec<usize>> = HashMap::new();

        let mut queue = VecDeque::new();
        queue.push_back((0, 0)); // Start BFS from node 0 (input)

        // Track visited to prevent cycles infinite loop (though unlikely in current DAG)
        let mut visited = vec![false; blocks.len()];
        visited[0] = true;

        while let Some((u, d)) = queue.pop_front() {
            depths[u] = d;
            layer_nodes.entry(d).or_default().push(u);

            if let Some(children) = adj.get(&u) {
                for &v in children {
                    if v < blocks.len() && !visited[v] {
                        visited[v] = true;
                        queue.push_back((v, d + 1));
                    }
                }
            }
        }

        // Handle disconnected nodes (put them at depth 0 or end? let's put at end)
        // Actually, let's just stick to default linear if not reachable, or append

        // 3. Assign positions
        let mut pos_map = vec![egui::pos2(0.0, 0.0); blocks.len()];

        for (depth, nodes) in layer_nodes.iter() {
            let count = nodes.len();
            let layer_height = (count as f32) * spacing_y;
            let layer_start_y = start_y - (layer_height / 2.0) + (spacing_y / 2.0);

            for (i, &node_idx) in nodes.iter().enumerate() {
                let x = start_x + (*depth as f32) * spacing_x;
                let y = layer_start_y + (i as f32) * spacing_y;
                pos_map[node_idx] = egui::pos2(x, y);
            }
        }

        // Fallback for unreachable nodes (if any) -> just place them linearly far away
        for i in 0..blocks.len() {
            if !visited[i] {
                pos_map[i] = egui::pos2(start_x + i as f32 * spacing_x, start_y + 300.0);
            }
        }

        pos_map
    } else {
        // Legacy linear layout
        blocks
            .iter()
            .enumerate()
            .map(|(i, _)| egui::pos2(start_x + i as f32 * spacing_x, start_y))
            .collect()
    };

    // 3. Create nodes
    // Check for input adapter
    let has_input_adapter = blocks.iter().any(|b| b.block_type == "input_adapter");

    // Legacy migration: If no input adapter, inject one virtually?
    // Actually, let's just insert nodes based on blocks.
    // If user opens a legacy preset, blocks[0] is NOT input_adapter.
    // So blocks[0] will be treated as Special.
    // And there will be NO Input Node.
    // This is bad because user can't connect anything to start.
    // So we MUST check if we need to insert a virtual Input Node.

    let mut virtual_input_id: Option<NodeId> = None;

    if !has_input_adapter {
        // Create virtual input node
        let input_block = ProcessingBlock {
            block_type: preset_type.to_string(), // Use preset_type for the virtual input node
            // "input_adapter" is generic, but using preset_type helps with UI logic
            show_overlay: false, // Input adapters should be hidden by default
            ..Default::default()
        };
        let node = ChainNode::from_block(&input_block, "input");
        let pos = egui::pos2(start_x, start_y);
        virtual_input_id = Some(snarl.insert_node(pos, node));
    }

    for (i, block) in blocks.iter().enumerate() {
        let role = if block.block_type == "input_adapter" {
            "input"
        } else {
            // Determine if this is a "first-level" node connected to input
            let is_connected_to_input = connections
                .iter()
                .any(|(from, to)| *to == i && blocks[*from].block_type == "input_adapter");

            let is_legacy_first = i == 0 && !has_input_adapter;

            if is_connected_to_input || is_legacy_first {
                if preset_type == "text" {
                    "process"
                } else {
                    "special"
                }
            } else {
                "process"
            }
        };

        // Adjust position if we added virtual input
        let mut pos = positions[i];
        if virtual_input_id.is_some() {
            // Shift all nodes right
            pos.x += spacing_x;
        }

        let node = ChainNode::from_block(block, role);
        let node_id = snarl.insert_node(pos, node);
        node_ids.push(node_id);
    }

    // Connect virtual input if exists
    if let Some(v_id) = virtual_input_id {
        // Connect to legacy first block (index 0)
        if !node_ids.is_empty() {
            // We need to inject this connection into Snarl
            let from = OutPinId {
                node: v_id,
                output: 0,
            };
            let to = InPinId {
                node: node_ids[0],
                input: 0,
            };
            snarl.connect(from, to);
        }
    }

    // 4. Create connections
    if !connections.is_empty() {
        for &(from_idx, to_idx) in connections {
            if from_idx < node_ids.len() && to_idx < node_ids.len() {
                let from = OutPinId {
                    node: node_ids[from_idx],
                    output: 0,
                };
                let to = InPinId {
                    node: node_ids[to_idx],
                    input: 0,
                };
                snarl.connect(from, to);
            }
        }
    } else if blocks.len() > 1 {
        // Legacy fallback
        for i in 0..node_ids.len() - 1 {
            let from = OutPinId {
                node: node_ids[i],
                output: 0,
            };
            let to = InPinId {
                node: node_ids[i + 1],
                input: 0,
            };
            snarl.connect(from, to);
        }
    }

    snarl
}

/// Convert snarl graph back to blocks and connections
/// Returns (blocks, connections) where connections is Vec<(from_idx, to_idx)>
pub fn snarl_to_graph(snarl: &Snarl<ChainNode>) -> (Vec<ProcessingBlock>, Vec<(usize, usize)>) {
    use std::collections::{HashMap, VecDeque};

    let mut blocks = Vec::new();
    let mut connections = Vec::new();
    let mut node_to_idx: HashMap<NodeId, usize> = HashMap::new();

    // Find input node (the one with is_input() true)
    let mut input_node_id: Option<NodeId> = None;
    for (node_id, node) in snarl.node_ids() {
        if node.is_input() {
            input_node_id = Some(node_id);
            break;
        }
    }

    // BFS traversal from input node to collect all reachable nodes
    if let Some(start_id) = input_node_id {
        let mut queue = VecDeque::new();
        queue.push_back((start_id, true)); // (node_id, is_first)

        while let Some((node_id, _is_first)) = queue.pop_front() {
            // Skip if already processed
            if node_to_idx.contains_key(&node_id) {
                continue;
            }

            if let Some(node) = snarl.get_node(node_id) {
                let block = node.to_block();
                // We don't force block_type="text" anymore, let to_block handle it

                let idx = blocks.len();
                node_to_idx.insert(node_id, idx);
                blocks.push(block);

                // Find all downstream nodes (fan-out support)
                let out_pin = OutPinId {
                    node: node_id,
                    output: 0,
                };
                for (from, to) in snarl.wires() {
                    if from == out_pin {
                        queue.push_back((to.node, false));
                    }
                }
            }
        }

        // Second pass: build connections using node_to_idx mapping
        for (from, to) in snarl.wires() {
            if let (Some(&from_idx), Some(&to_idx)) =
                (node_to_idx.get(&from.node), node_to_idx.get(&to.node))
            {
                connections.push((from_idx, to_idx));
            }
        }
    }

    (blocks, connections)
}
</file>

<file path="src/gui/settings_ui/node_graph/mod.rs">
pub mod body;
pub mod conversion;
pub mod node;
pub mod utils;
pub mod viewer;

pub use conversion::{blocks_to_snarl, snarl_to_graph};
pub use node::ChainNode;
pub use utils::request_node_graph_view_reset;
pub use viewer::ChainViewer;

use crate::gui::locale::LocaleText;
use eframe::egui;
use egui_snarl::ui::SnarlStyle;
use egui_snarl::{InPinId, OutPinId, Snarl};
use std::collections::HashMap;

/// Render the node graph in the preset editor
pub fn render_node_graph(
    ui: &mut egui::Ui,
    snarl: &mut Snarl<ChainNode>,
    ui_language: &str,
    prompt_mode: &str,
    use_groq: bool,
    use_gemini: bool,
    use_openrouter: bool,
    use_ollama: bool,
    preset_type: &str,
    text: &LocaleText,
) -> bool {
    let mut viewer = ChainViewer::new(
        text,
        ui_language,
        prompt_mode,
        use_groq,
        use_gemini,
        use_openrouter,
        use_ollama,
        preset_type,
    );
    let style = SnarlStyle::default();

    snarl.show(&mut viewer, &style, egui::Id::new("chain_graph"), ui);

    // Constraint Enforcement: Post-update cleanup
    // 1. No self-loops
    // 2. Single connection per input
    // 3. (Added) Single connection per output? No, fan-out is allowed.

    let mut to_disconnect = Vec::new();
    let mut input_count: HashMap<InPinId, Vec<OutPinId>> = HashMap::new();

    for (out, inp) in snarl.wires() {
        if out.node == inp.node {
            to_disconnect.push((out, inp));
        } else {
            input_count.entry(inp).or_default().push(out);
        }
    }

    for (_inp, sources) in input_count {
        if sources.len() > 1 {
            // More than 1 connection: Keep the last one encountered (arbitrary but consistent)
            // discard all but last
            for &src in sources.iter().take(sources.len() - 1) {
                // We re-construct iterator to find inp... wait sources is OutPinIDs
                // We need (OutPinId, InPinId) to disconnect
                // But disconnect takes (Out, In)? Yes.
                to_disconnect.push((src, _inp));
            }
        }
    }

    let mut cleanup_changed = false;
    for (out, inp) in to_disconnect {
        snarl.disconnect(out, inp);
        cleanup_changed = true;
    }

    viewer.changed || cleanup_changed
}
</file>

<file path="src/gui/settings_ui/node_graph/utils.rs">
use crate::config::get_all_languages;
use crate::model_config::model_supports_search_by_id;
use eframe::egui;
use std::collections::HashMap;

/// Check if a model supports search capabilities (grounding/web search)
pub fn model_supports_search(model_id: &str) -> bool {
    model_supports_search_by_id(model_id)
}

/// Request a node graph view reset (scale=1.0, centered)
/// This sets a flag that the patched egui-snarl library will check
pub fn request_node_graph_view_reset(ctx: &egui::Context) {
    let reset_id = egui::Id::new("snarl_reset_view");
    ctx.data_mut(|d| d.insert_temp(reset_id, true));
}

pub fn show_language_vars(
    ui: &mut egui::Ui,
    _ui_language: &str,
    prompt: &str,
    language_vars: &mut HashMap<String, String>,
    changed: &mut bool,
    _search_query: &mut String,
) {
    // Find {languageN} tags in prompt
    let mut detected_vars = Vec::new();
    for k in 1..=10 {
        let tag = format!("{{language{}}}", k);
        if prompt.contains(&tag) {
            detected_vars.push(k);
        }
    }

    for num in detected_vars {
        let key = format!("language{}", num);
        if !language_vars.contains_key(&key) {
            language_vars.insert(key.clone(), "Vietnamese".to_string());
        }

        let label = format!("{{language{}}}:", num);

        ui.horizontal(|ui| {
            ui.label(label);
            let current_val = language_vars.get(&key).cloned().unwrap_or_default();

            // Create unique IDs for this specific language selector

            let search_id = egui::Id::new(format!("lang_search_{}", num));

            // Styled button to open popup
            let is_dark = ui.visuals().dark_mode;
            let lang_var_bg = if is_dark {
                egui::Color32::from_rgb(70, 60, 100)
            } else {
                egui::Color32::from_rgb(150, 140, 180)
            };
            let button_response = ui.add(
                egui::Button::new(egui::RichText::new(&current_val).color(egui::Color32::WHITE))
                    .fill(lang_var_bg)
                    .corner_radius(8.0),
            );

            if button_response.clicked() {
                egui::Popup::toggle_id(ui.ctx(), button_response.id);
            }

            let popup_layer_id = button_response.id;
            egui::Popup::from_toggle_button_response(&button_response)
                .close_behavior(egui::PopupCloseBehavior::CloseOnClickOutside)
                .show(|ui| {
                    ui.set_min_width(120.0);

                    // Get or create search state for this popup from temp data
                    let mut search_text: String =
                        ui.data_mut(|d| d.get_temp(search_id).unwrap_or_default());

                    // Search box
                    let _search_response = ui.add(
                        egui::TextEdit::singleline(&mut search_text)
                            .hint_text("Search...")
                            .desired_width(110.0),
                    );

                    // Store search state back
                    ui.data_mut(|d| d.insert_temp(search_id, search_text.clone()));

                    ui.separator();

                    // Language list in scroll area
                    egui::ScrollArea::vertical()
                        .max_height(200.0)
                        .min_scrolled_height(200.0)
                        .auto_shrink([true, false])
                        .show(ui, |ui| {
                            ui.set_width(120.0); // Ensure scrollbar stays on the right edge
                            for lang in get_all_languages() {
                                let matches_search = search_text.is_empty()
                                    || lang.to_lowercase().contains(&search_text.to_lowercase());
                                if matches_search {
                                    let is_selected = current_val == *lang;
                                    if ui.selectable_label(is_selected, lang).clicked() {
                                        language_vars.insert(key.clone(), lang.clone());
                                        *changed = true;
                                        // Clear search and close popup
                                        ui.data_mut(|d| {
                                            d.insert_temp::<String>(search_id, String::new())
                                        });
                                        egui::Popup::toggle_id(ui.ctx(), popup_layer_id);
                                    }
                                }
                            }
                        });
                });
        });
    }
}

pub fn insert_next_language_tag(prompt: &mut String, language_vars: &mut HashMap<String, String>) {
    let mut max_num = 0;
    for k in 1..=10 {
        if prompt.contains(&format!("{{language{}}}", k)) {
            max_num = k;
        }
    }
    let next_num = max_num + 1;
    let tag = format!(" {{language{}}} ", next_num);
    prompt.push_str(&tag);

    let key = format!("language{}", next_num);
    if !language_vars.contains_key(&key) {
        language_vars.insert(key, "Vietnamese".to_string());
    }
}
</file>

<file path="src/gui/settings_ui/node_graph/viewer.rs">
use super::body::show_body;
use super::node::ChainNode;
use crate::gui::icons::{draw_icon_static, Icon};
use crate::gui::locale::LocaleText;
use eframe::egui;
use egui_snarl::ui::{PinInfo, SnarlViewer};
use egui_snarl::{InPin, NodeId, OutPin, Snarl};

pub struct ChainViewer<'a> {
    pub text: &'a LocaleText,
    pub ui_language: String,
    pub changed: bool,
    pub language_search: String,
    pub use_groq: bool,
    pub use_gemini: bool,
    pub use_openrouter: bool,
    pub use_ollama: bool,
    pub preset_type: String, // "image", "audio", "text"
}

impl<'a> ChainViewer<'a> {
    pub fn new(
        text: &'a LocaleText,
        ui_language: &str,
        _prompt_mode: &str,
        use_groq: bool,
        use_gemini: bool,
        use_openrouter: bool,
        use_ollama: bool,
        preset_type: &str,
    ) -> Self {
        Self {
            text,
            ui_language: ui_language.to_string(),
            changed: false,
            language_search: String::new(),
            use_groq,
            use_gemini,
            use_openrouter,
            use_ollama,
            preset_type: preset_type.to_string(),
        }
    }

    /// Check if a model's provider is enabled
    pub fn is_provider_enabled(&self, provider: &str) -> bool {
        match provider {
            "groq" => self.use_groq,
            "google" | "gemini-live" => self.use_gemini,
            "openrouter" => self.use_openrouter,
            "ollama" => self.use_ollama,
            _ => true, // Unknown providers are enabled by default
        }
    }
}

impl<'a> SnarlViewer<ChainNode> for ChainViewer<'a> {
    fn title(&mut self, node: &ChainNode) -> String {
        match node {
            ChainNode::Input { block_type, .. } => {
                let actual_type = if block_type == "input_adapter" {
                    self.preset_type.as_str()
                } else {
                    block_type.as_str()
                };
                let type_name = match actual_type {
                    "audio" => self.text.node_input_audio,
                    "image" => self.text.node_input_image,
                    "text" => self.text.node_input_text,
                    _ => "Input",
                };
                let prefix = self.text.node_input_prefix;
                format!("{} {}", prefix, type_name)
            }
            ChainNode::Special { .. } => {
                // Dynamic title based on preset type
                match self.preset_type.as_str() {
                    "image" => self.text.node_special_image_to_text.to_string(),
                    "audio" => self.text.node_special_audio_to_text.to_string(),
                    _ => self.text.node_special_default.to_string(),
                }
            }
            ChainNode::Process { .. } => self.text.node_process_title.to_string(),
        }
    }

    fn show_header(
        &mut self,
        node: NodeId,
        _inputs: &[InPin],
        _outputs: &[OutPin],
        ui: &mut egui::Ui,
        snarl: &mut Snarl<ChainNode>,
    ) {
        let node = &snarl[node];
        // Reverting to vertical-centered horizontal layout which is standard/safe
        ui.horizontal(|ui| {
            // Add icon based on node type
            match node {
                ChainNode::Input { block_type, .. } => {
                    let actual_type = if block_type == "input_adapter" {
                        self.preset_type.as_str()
                    } else {
                        block_type.as_str()
                    };
                    let icon = match actual_type {
                        "image" => Icon::Image,
                        "audio" => Icon::Microphone,
                        "text" => Icon::Text,
                        _ => Icon::Settings,
                    };
                    draw_icon_static(ui, icon, Some(16.0));

                    let type_name = match actual_type {
                        "audio" => self.text.node_input_audio,
                        "image" => self.text.node_input_image,
                        "text" => self.text.node_input_text,
                        _ => "Input",
                    };
                    let prefix = self.text.node_input_prefix;
                    ui.label(format!("{} {}", prefix, type_name));
                }
                ChainNode::Process { .. } => {
                    draw_icon_static(ui, Icon::Settings, Some(16.0));
                    let title = self.text.node_process_title;
                    ui.label(title);
                }

                ChainNode::Special { .. } => {
                    draw_icon_static(ui, Icon::Settings, Some(16.0));
                    // Dynamic header based on preset type
                    let title = match self.preset_type.as_str() {
                        "image" => self.text.node_special_image_to_text,
                        "audio" => self.text.node_special_audio_to_text,
                        _ => self.text.node_special_default,
                    };
                    let header_color = if ui.visuals().dark_mode {
                        egui::Color32::from_rgb(255, 200, 100)
                    } else {
                        egui::Color32::from_rgb(200, 100, 0)
                    };
                    ui.label(egui::RichText::new(title).color(header_color));
                }
            };
        });
    }

    // Use default header colors (no custom coloring)

    fn inputs(&mut self, node: &ChainNode) -> usize {
        match node {
            ChainNode::Input { .. } => 0, // Input nodes have no inputs
            ChainNode::Process { .. } | ChainNode::Special { .. } => 1, // Process nodes have 1 input
        }
    }

    fn outputs(&mut self, _node: &ChainNode) -> usize {
        1 // All nodes have 1 output
    }

    fn show_input(
        &mut self,
        _pin: &InPin,
        _ui: &mut egui::Ui,
        _snarl: &mut Snarl<ChainNode>,
    ) -> impl egui_snarl::ui::SnarlPin + 'static {
        // Green color for text connections
        PinInfo::circle().with_fill(egui::Color32::from_rgb(100, 200, 100))
    }

    fn show_output(
        &mut self,
        _pin: &OutPin,
        _ui: &mut egui::Ui,
        _snarl: &mut Snarl<ChainNode>,
    ) -> impl egui_snarl::ui::SnarlPin + 'static {
        // Blue color for output
        PinInfo::circle().with_fill(egui::Color32::from_rgb(100, 150, 255))
    }

    fn has_body(&mut self, _node: &ChainNode) -> bool {
        true
    }

    fn show_body(
        &mut self,
        node_id: NodeId,
        _inputs: &[InPin],
        _outputs: &[OutPin],
        ui: &mut egui::Ui,
        snarl: &mut Snarl<ChainNode>,
    ) {
        show_body(self, node_id, ui, snarl);
    }

    fn has_graph_menu(&mut self, _pos: egui::Pos2, _snarl: &mut Snarl<ChainNode>) -> bool {
        true
    }

    fn show_graph_menu(
        &mut self,
        pos: egui::Pos2,
        ui: &mut egui::Ui,
        snarl: &mut Snarl<ChainNode>,
    ) {
        let add_process_label = self.text.node_menu_add_normal;
        let add_special_label = match self.preset_type.as_str() {
            "image" => self.text.node_menu_add_special_image,
            "audio" => self.text.node_menu_add_special_audio,
            _ => self.text.node_menu_add_special_generic,
        };

        if ui.button(add_process_label).clicked() {
            snarl.insert_node(pos, ChainNode::default());
            self.changed = true;
            ui.close();
        }
        if self.preset_type != "text" {
            if ui.button(add_special_label).clicked() {
                let mut node = ChainNode::default();
                // Force it to be Special
                if let ChainNode::Process {
                    id,
                    block_type,
                    model,
                    prompt,
                    language_vars,
                    show_overlay,
                    streaming_enabled,
                    render_mode,
                    auto_copy,
                    auto_speak,
                } = node
                {
                    node = ChainNode::Special {
                        id,
                        block_type,
                        model,
                        prompt,
                        language_vars,
                        show_overlay,
                        streaming_enabled,
                        render_mode,
                        auto_copy,
                        auto_speak,
                    };
                }
                snarl.insert_node(pos, node);
                self.changed = true;
                ui.close();
            }
        }
    }

    fn has_node_menu(&mut self, node: &ChainNode) -> bool {
        !node.is_input() // Only show menu for non-input nodes
    }

    fn show_node_menu(
        &mut self,
        node_id: NodeId,
        _inputs: &[InPin],
        _outputs: &[OutPin],
        ui: &mut egui::Ui,
        snarl: &mut Snarl<ChainNode>,
    ) {
        let delete_label = match self.ui_language.as_str() {
            "vi" => "🗑 Xóa node",
            "ko" => "🗑 노드 삭제",
            _ => "🗑 Delete Node",
        };

        if ui.button(delete_label).clicked() {
            snarl.remove_node(node_id);
            self.changed = true;
            ui.close();
        }
    }

    fn connect(&mut self, from: &OutPin, to: &InPin, snarl: &mut Snarl<ChainNode>) {
        // Enforce constraints:
        // Preceding node of Special Node can ONLY be the Input Node.

        let to_node = snarl.get_node(to.id.node);
        let from_node = snarl.get_node(from.id.node);

        if let (Some(to_node), Some(from_node)) = (to_node, from_node) {
            if to_node.is_special() {
                if !from_node.is_input() {
                    // Violation: Attempting to connect non-input to Special node
                    return;
                }
            }
        }

        snarl.connect(from.id, to.id);
        self.changed = true;
    }

    fn disconnect(&mut self, from: &OutPin, to: &InPin, snarl: &mut Snarl<ChainNode>) {
        snarl.disconnect(from.id, to.id);
        self.changed = true;
    }
}
</file>

<file path="src/history.rs">
use chrono::Local;
use image::{ImageBuffer, Rgba};
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;
use std::sync::mpsc::{channel, Receiver, Sender};
use std::sync::{Arc, Mutex};
use std::thread;

#[derive(Clone, Debug, Serialize, Deserialize, PartialEq)]
pub enum HistoryType {
    Image,
    Audio,
    Text, // NEW: Text-only history entries (no media file)
}

#[derive(Clone, Debug, Serialize, Deserialize)]
pub struct HistoryItem {
    pub id: i64,
    pub timestamp: String,
    pub item_type: HistoryType,
    pub text: String,
    pub media_path: String, // Empty for Text type
}

pub enum HistoryAction {
    SaveImage {
        img: ImageBuffer<Rgba<u8>, Vec<u8>>,
        text: String,
    },
    SaveAudio {
        wav_data: Vec<u8>,
        text: String,
    },
    SaveText {
        result_text: String,
        input_text: String,
    }, // NEW: Save text-only entry
    Delete(i64),
    ClearAll,
    Prune(usize),
}

pub struct HistoryManager {
    tx: Sender<HistoryAction>,
    pub items: Arc<Mutex<Vec<HistoryItem>>>,
}

impl HistoryManager {
    pub fn new(max_items: usize) -> Self {
        let (tx, rx) = channel();
        // Load initial items
        let (_, db_path, _) = get_paths();
        let initial_items = if db_path.exists() {
            let file = fs::File::open(&db_path).ok();
            if let Some(f) = file {
                serde_json::from_reader(f).unwrap_or_default()
            } else {
                Vec::new()
            }
        } else {
            Vec::new()
        };

        let items = Arc::new(Mutex::new(initial_items));
        let items_clone = items.clone();

        thread::spawn(move || {
            process_queue(rx, items_clone, max_items);
        });

        Self { tx, items }
    }

    pub fn save_image(&self, img: ImageBuffer<Rgba<u8>, Vec<u8>>, text: String) {
        let _ = self.tx.send(HistoryAction::SaveImage { img, text });
    }

    pub fn save_audio(&self, wav_data: Vec<u8>, text: String) {
        let _ = self.tx.send(HistoryAction::SaveAudio { wav_data, text });
    }

    pub fn save_text(&self, result_text: String, input_text: String) {
        if !result_text.trim().is_empty() {
            let _ = self.tx.send(HistoryAction::SaveText {
                result_text,
                input_text,
            });
        }
    }

    pub fn delete(&self, id: i64) {
        let _ = self.tx.send(HistoryAction::Delete(id));
        let mut guard = self.items.lock().unwrap();
        if let Some(pos) = guard.iter().position(|x| x.id == id) {
            guard.remove(pos);
        }
    }

    pub fn clear_all(&self) {
        let _ = self.tx.send(HistoryAction::ClearAll);
        let mut guard = self.items.lock().unwrap();
        guard.clear();
    }

    pub fn request_prune(&self, limit: usize) {
        let _ = self.tx.send(HistoryAction::Prune(limit));
    }
}

fn get_paths() -> (PathBuf, PathBuf, PathBuf) {
    let config_dir = dirs::config_dir()
        .unwrap_or_default()
        .join("screen-goated-toolbox");
    let media_dir = config_dir.join("history_media");
    let db_path = config_dir.join("history.json");
    let _ = fs::create_dir_all(&media_dir);
    (config_dir, db_path, media_dir)
}

fn save_db(items: &Vec<HistoryItem>) {
    let (_, db_path, _) = get_paths();
    if let Ok(file) = fs::File::create(db_path) {
        let _ = serde_json::to_writer_pretty(file, items);
    }
}

fn process_queue(
    rx: Receiver<HistoryAction>,
    cache: Arc<Mutex<Vec<HistoryItem>>>,
    mut max_items: usize,
) {
    let (_, _, media_dir) = get_paths();

    while let Ok(action) = rx.recv() {
        let mut should_save = false;
        let mut items = cache.lock().unwrap();

        match action {
            HistoryAction::SaveImage { img, text } => {
                let now = Local::now();
                let timestamp = now.format("%Y-%m-%d %H:%M:%S").to_string();
                let filename = format!("img_{}.png", now.format("%Y%m%d_%H%M%S_%f"));
                let path = media_dir.join(&filename);
                let id = now.timestamp_nanos_opt().unwrap_or(0);

                if img.save(&path).is_ok() {
                    items.insert(
                        0,
                        HistoryItem {
                            id,
                            timestamp,
                            item_type: HistoryType::Image,
                            text,
                            media_path: filename,
                        },
                    );
                    should_save = true;
                }
            }
            HistoryAction::SaveAudio { wav_data, text } => {
                let now = Local::now();
                let timestamp = now.format("%Y-%m-%d %H:%M:%S").to_string();
                let filename = format!("audio_{}.wav", now.format("%Y%m%d_%H%M%S_%f"));
                let path = media_dir.join(&filename);
                let id = now.timestamp_nanos_opt().unwrap_or(0);

                if fs::write(&path, wav_data).is_ok() {
                    items.insert(
                        0,
                        HistoryItem {
                            id,
                            timestamp,
                            item_type: HistoryType::Audio,
                            text,
                            media_path: filename,
                        },
                    );
                    should_save = true;
                }
            }
            HistoryAction::SaveText {
                result_text,
                input_text,
            } => {
                let now = Local::now();
                let timestamp = now.format("%Y-%m-%d %H:%M:%S").to_string();
                let filename = format!("text_{}.txt", now.format("%Y%m%d_%H%M%S_%f"));
                let path = media_dir.join(&filename);
                let id = now.timestamp_nanos_opt().unwrap_or(0);

                if fs::write(&path, &input_text).is_ok() {
                    items.insert(
                        0,
                        HistoryItem {
                            id,
                            timestamp,
                            item_type: HistoryType::Text,
                            text: result_text,
                            media_path: filename,
                        },
                    );
                    should_save = true;
                }
            }
            HistoryAction::Delete(id) => {
                if let Some(pos) = items.iter().position(|x| x.id == id) {
                    let item = items.remove(pos);
                    let _ = fs::remove_file(media_dir.join(item.media_path));
                    should_save = true;
                }
            }
            HistoryAction::ClearAll => {
                if let Ok(entries) = fs::read_dir(&media_dir) {
                    for entry in entries.flatten() {
                        let _ = fs::remove_file(entry.path());
                    }
                }
                items.clear();
                should_save = true;
            }
            HistoryAction::Prune(new_limit) => {
                max_items = new_limit;
                if items.len() > max_items {
                    while items.len() > max_items {
                        if let Some(item) = items.pop() {
                            let _ = fs::remove_file(media_dir.join(item.media_path));
                        }
                    }
                    should_save = true;
                }
            }
        }

        // Handle pruning after saves
        if items.len() > max_items {
            while items.len() > max_items {
                if let Some(item) = items.pop() {
                    let _ = fs::remove_file(media_dir.join(item.media_path));
                }
            }
            should_save = true;
        }

        if should_save {
            save_db(&items);
        }
    }
}
</file>

<file path="src/overlay/broom_assets.rs">
pub const BROOM_W: i32 = 48; // Increased canvas size for rotation space
pub const BROOM_H: i32 = 48;

#[derive(Clone, Copy, Default)]
pub struct BroomRenderParams {
    pub tilt_angle: f32, // Degrees, negative = left, positive = right
    pub squish: f32,     // 1.0 = normal, 0.5 = smashed
    pub bend: f32,       // Curvature of bristles (drag effect)
    pub opacity: f32,    // 0.0 to 1.0
}

pub fn render_procedural_broom(params: BroomRenderParams) -> Vec<u32> {
    let mut pixels = vec![0u32; (BROOM_W * BROOM_H) as usize];

    // Palette
    let alpha = (params.opacity * 255.0) as u32;
    if alpha == 0 { return pixels; }

    let c_handle_dk = (alpha << 24) | 0x005D4037;
    let c_handle_lt = (alpha << 24) | 0x008D6E63;
    let c_band      = (alpha << 24) | 0x00B71C1C;
    let c_straw_dk  = (alpha << 24) | 0x00FBC02D;
    let c_straw_lt  = (alpha << 24) | 0x00FFF176;
    let c_straw_sh  = (alpha << 24) | 0x00F57F17;
    
    // Shadow color (Black with 30% opacity)
    let shadow_alpha = (alpha as f32 * 0.3) as u32;
    let c_shadow = (shadow_alpha << 24) | 0x00000000;

    // Helper to draw pixels
    let mut draw_pixel = |x: i32, y: i32, color: u32, is_shadow: bool| {
        if x >= 0 && x < BROOM_W && y >= 0 && y < BROOM_H {
            let idx = (y * BROOM_W + x) as usize;
            if is_shadow {
                // Only write shadow if pixel is empty
                if pixels[idx] == 0 {
                    pixels[idx] = color;
                }
            } else {
                pixels[idx] = color;
            }
        }
    };

    // Center of the broom's "neck" (pivot point)
    let pivot_x = (BROOM_W / 2) as f32;
    let pivot_y = (BROOM_H as f32) * 0.65; // Lower pivot to allow handle swing

    // --- PHYSICS SEPARATION ---
    // 1. Handle Angle: Dampened (0.25x) to be less sensitive/jittery
    let handle_rad = (params.tilt_angle * 0.25).to_radians();
    let h_sin = handle_rad.sin();
    let h_cos = handle_rad.cos();

    // 2. Bristle Angle: Uses half tilt for "swishy" effect, blended later
    let bristle_target_rad = (params.tilt_angle * 0.5).to_radians();

    let bristle_len = 16.0 * params.squish;
    let top_w = 8.0;
    let bot_w = 16.0 + (1.0 - params.squish) * 10.0;
    let steps = (bristle_len * 2.0) as i32; 

    // Shadow offset
    let sx = 2.0; 
    let sy = 2.0;

    for pass in 0..2 {
        let is_shadow = pass == 0;
        let offset_x = if is_shadow { sx } else { 0.0 };
        let offset_y = if is_shadow { sy } else { 0.0 };

        // ---------------------------------------------------------
        // Draw Bristles
        // ---------------------------------------------------------
        for i in 0..steps {
            let prog = i as f32 / steps as f32;
            let current_angle = handle_rad + (bristle_target_rad - handle_rad) * (prog * prog * prog);
            let b_sin = current_angle.sin();
            let b_cos = current_angle.cos();
            let current_y_rel = prog * bristle_len;
            let bend_offset = params.bend * prog * prog * 8.0; 

            let cx = pivot_x - (current_y_rel * b_sin) + (bend_offset * b_cos) + offset_x;
            let cy = pivot_y + (current_y_rel * b_cos) + (bend_offset * b_sin) + offset_y;

            let current_w = top_w + (bot_w - top_w) * prog;
            let half_w = (current_w / 2.0) + 0.5;

            let start_x = (cx - half_w).round() as i32;
            let end_x = (cx + half_w).round() as i32;
            let py = cy.round() as i32;

            for px in start_x..=end_x {
                if is_shadow {
                    draw_pixel(px, py, c_shadow, true);
                } else {
                    let rel_x = (px as f32 - cx).round() as i32;
                    let seed = ((rel_x + 20) * 7) % 5;
                    let col = match seed {
                        0 => c_straw_sh,
                        1 | 2 => c_straw_lt,
                        _ => c_straw_dk
                    };
                    draw_pixel(px, py, col, false);
                }
            }
        }
        
        // ---------------------------------------------------------
        // Draw Band (Neck) - Rigidly attached to Handle
        // ---------------------------------------------------------
        if !is_shadow {
            let band_h = 3.0;
            for y_step in 0..band_h as i32 {
                let rel_y = -(y_step as f32);
                let cx = pivot_x + (rel_y * h_sin);
                let cy = pivot_y - (rel_y * h_cos);
                let half_w = top_w / 2.0 + 1.5;
                for px in (cx - half_w).round() as i32 ..= (cx + half_w).round() as i32 {
                     draw_pixel(px, cy.round() as i32, c_band, false);
                }
            }

            // ---------------------------------------------------------
            // Draw Handle - Rigid, less sensitive
            // ---------------------------------------------------------
            let handle_len = 20.0;
            for i in 0..handle_len as i32 {
                let rel_y = (i as f32) + 3.0; 
                let cx = pivot_x + (rel_y * h_sin);
                let cy = pivot_y - (rel_y * h_cos);
                let px = cx.round() as i32;
                let py = cy.round() as i32;
                draw_pixel(px, py, c_handle_dk, false);
                draw_pixel(px + 1, py, c_handle_lt, false);
            }
        }
    }

    pixels
}
</file>

<file path="src/overlay/favorite_bubble/mod.rs">
pub mod html;
pub mod panel;
pub mod render;
pub mod state;
pub mod utils;
pub mod window;

pub use panel::update_favorites_panel;
pub use window::{hide_favorite_bubble, show_favorite_bubble, trigger_blink_animation};
</file>

<file path="src/overlay/favorite_bubble/utils.rs">
use windows::Win32::Foundation::HWND;

// HWND wrapper for wry
pub struct HwndWrapper(pub HWND);
unsafe impl Send for HwndWrapper {}
unsafe impl Sync for HwndWrapper {}
impl raw_window_handle::HasWindowHandle for HwndWrapper {
    fn window_handle(
        &self,
    ) -> Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError> {
        let raw = raw_window_handle::Win32WindowHandle::new(
            std::num::NonZeroIsize::new(self.0 .0 as isize).expect("HWND cannot be null"),
        );
        let handle = raw_window_handle::RawWindowHandle::Win32(raw);
        unsafe { Ok(raw_window_handle::WindowHandle::borrow_raw(handle)) }
    }
}
</file>

<file path="src/overlay/html_components/css_main.rs">
pub fn get(glow_color: &str, font_size: u32, is_dark: bool) -> String {
    let (
        bg_color,
        text_color,
        header_bg,
        border_color,
        ctrl_bg,
        ctrl_hover_bg,
        select_bg,
        select_option_bg,
        placeholder_color,
        resize_hint_color,
        scrollbar_track,
        scrollbar_thumb,
        scrollbar_thumb_hover,
        ctrl_hover_text,
        icon_inactive_color,
    ) = if is_dark {
        (
            "rgba(26, 26, 26, 0.95)",    // bg_color
            "#fff",                      // text_color
            "rgba(26, 26, 26, 0.6)",     // header_bg
            format!("{}40", glow_color), // border_color
            "rgba(30,30,30,0.8)",        // ctrl_bg
            "rgba(255,255,255,0.15)",    // ctrl_hover_bg
            "rgba(30, 30, 30, 0.9)",     // select_bg
            "#2a2a2a",                   // select_option_bg
            "#aaa",                      // placeholder_color
            "#888",                      // resize_hint_color
            "#2a2a2a",                   // scrollbar_track
            "#555",                      // scrollbar_thumb
            "#777",                      // scrollbar_thumb_hover
            "#ffffff",                   // ctrl_hover_text
            "#888",                      // icon_inactive_color
        )
    } else {
        (
            "rgba(255, 255, 255, 0.95)",
            "#202124",
            "rgba(255, 255, 255, 0.8)",
            format!("{}80", glow_color),
            "rgba(240, 240, 245, 0.8)",
            "rgba(0, 0, 0, 0.05)",
            "rgba(255, 255, 255, 0.9)",
            "#ffffff",
            "#80868b",
            "#9aa0a6",
            "#f1f3f4",
            "#dadce0",
            "#bdc1c6",
            "#202124",
            "#dadce0", // icon_inactive_color
        )
    };

    let box_shadow = if is_dark {
        format!("0 0 20px {}30", glow_color)
    } else {
        format!("0 0 20px {}20", glow_color)
    };

    let ctrl_border = if is_dark {
        "rgba(255,255,255,0.1)"
    } else {
        "rgba(0,0,0,0.1)"
    };

    format!(
        r###"        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        html, body {{
            height: 100%;
            overflow: hidden;
            background: {bg_color};
            font-family: 'Google Sans Flex', sans-serif;
            color: {text_color};
            border-radius: 8px;
            border: 1px solid {border_color};
            box-shadow: {box_shadow};
        }}
        /* Loading overlay - TEMPORARILY DISABLED FOR TESTING */
        #loading-overlay {{
            display: none; /* TEMP: Remove this line to re-enable overlay */
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: {bg_color};
            z-index: 9999;
            pointer-events: none;
            justify-content: center;
            align-items: center;
            animation: fadeOut 0.4s ease-out 0.9s forwards;
        }}
        .loading-svg {{
            width: 72px;
            height: 72px;
            filter: drop-shadow(0 0 12px {glow_color}90);
            animation: breathe 2.5s ease-in-out infinite;
        }}
        @keyframes breathe {{
            0%, 100% {{ 
                transform: scale(1); 
                opacity: 0.85;
                filter: drop-shadow(0 0 8px {glow_color}60);
            }}
            50% {{ 
                transform: scale(1.08); 
                opacity: 1;
                filter: drop-shadow(0 0 20px {glow_color});
            }}
        }}
        @keyframes fadeOut {{
            from {{ opacity: 1; }}
            to {{ opacity: 0; }}
        }}
        .material-symbols-rounded {{
            font-family: 'Material Symbols Rounded'; /* Fallback */
            font-weight: normal;
            font-style: normal;
            font-size: 24px;
            line-height: 1;
            letter-spacing: normal;
            text-transform: none;
            display: inline-flex; /* Center SVG */
            align-items: center;
            justify-content: center;
            white-space: nowrap;
            word-wrap: normal;
            direction: ltr;
            vertical-align: middle;
            
            /* SVG container sizing */
            width: 1em;
            height: 1em;
        }}
        .material-symbols-rounded svg {{
            width: 100%;
            height: 100%;
            fill: currentColor;
            display: block;
        }}
        #container {{
            display: flex;
            flex-direction: column;
            height: 100%;
            padding: 8px 12px;
            cursor: grab;
            position: relative;
        }}
        #container:active {{
            cursor: grabbing;
        }}
        #header {{
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 6px;
            flex-shrink: 0;
            gap: 8px;
            transition: all 0.25s ease-out;
            overflow: hidden;
            max-height: 40px;
            background: {header_bg};
            backdrop-filter: blur(8px);
            border-radius: 6px;
        }}
        #header.collapsed {{
            max-height: 0;
            margin-bottom: 0;
            opacity: 0;
        }}
        @keyframes pulse {{
            0%, 100% {{ transform: translateX(-50%) scale(1); opacity: 0.7; }}
            50% {{ transform: translateX(-50%) scale(1.2); opacity: 1; }}
        }}
        #header-toggle {{
            position: absolute;
            left: 50%;
            transform: translateX(-50%);
            display: flex;
            justify-content: center;
            align-items: center;
            cursor: pointer;
            padding: 2px 6px;
            color: #666;
            transition: all 0.25s ease-out;
            z-index: 10;
            top: 32px;
            opacity: 0.4;
        }}
        #header:hover ~ #header-toggle {{
            color: #00c8ff;
            opacity: 1;
            animation: pulse 1s ease-in-out infinite;
        }}
        #header-toggle:hover {{
            color: #fff;
            opacity: 1;
            animation: pulse 0.8s ease-in-out infinite;
        }}
        #header-toggle.collapsed {{
            top: 4px;
            opacity: 0.3;
            animation: none;
        }}
        #header-toggle.collapsed:hover {{
            opacity: 0.8;
        }}
        #header-toggle .material-symbols-rounded {{
            font-size: 14px;
            transition: transform 0.25s ease-out;
        }}
        #header-toggle.collapsed .material-symbols-rounded {{
            transform: rotate(180deg);
        }}
        #title {{
            font-size: 12px;
            font-weight: bold;
            color: {placeholder_color};
            flex-shrink: 0;
            display: flex;
            align-items: center;
            gap: 6px;
        }}
        #volume-canvas {{
            height: 24px;
            width: 90px;
            border-radius: 2px;
        }}
        #controls {{
            position: relative;
            z-index: 50;
            display: flex;
            gap: 8px;
            align-items: center;
            flex: 1;
            justify-content: flex-end;
        }}
        .btn-group {{
            display: flex;
            gap: 1px;
            align-items: center;
        }}
        .ctrl-btn {{
            font-size: 20px;
            color: {resize_hint_color};
            cursor: pointer;
            padding: 2px;
            border-radius: 50%;
            background: {ctrl_bg};
            border: 1px solid {ctrl_border};
            transition: all 0.2s;
            user-select: none;
            width: 26px;
            height: 26px;
            display: flex;
            align-items: center;
            justify-content: center;
        }}
        .ctrl-btn:hover {{
            color: {ctrl_hover_text};
            background: {ctrl_hover_bg};
            border-color: {glow_color};
            box-shadow: 0 0 8px {glow_color}40;
        }}
        .ctrl-btn.copied {{
            color: #4caf50 !important;
            border-color: #4caf50;
            box-shadow: 0 0 8px #4caf5040;
        }}
        .pill-group {{
            display: flex;
            align-items: center;
            background: {ctrl_bg};
            border: 1px solid {ctrl_border};
            border-radius: 20px;
            padding: 2px;
            gap: 1px;
            transition: all 0.2s;
        }}
        .pill-group:hover {{
            border-color: {glow_color}60;
            box-shadow: 0 0 10px {glow_color}20;
        }}
        .pill-group .ctrl-btn {{
            background: transparent;
            border: none;
            width: 22px;
            height: 22px;
        }}
        .pill-group .ctrl-btn:hover {{
            background: rgba(255, 255, 255, 0.1);
            box-shadow: none;
        }}
        .vis-btn {{
            font-size: 20px;
            cursor: pointer;
            padding: 2px;
            border-radius: 4px;
            transition: all 0.2s;
            user-select: none;
            background: transparent;
            border: none;
        }}
        .vis-btn.active {{
            opacity: 1;
        }}
        .vis-btn.inactive {{
            opacity: 0.3;
        }}
        .vis-btn:hover {{
            opacity: 0.7;
        }}
        .vis-btn.mic {{
            color: #00c8ff;
        }}
        .vis-btn.trans {{
            color: #ff9633;
        }}
        select {{
            font-family: 'Google Sans Flex', sans-serif;
            font-variation-settings: 'wght' 600, 'ROND' 100;
            background: {select_bg};
            color: {text_color};
            border: 1px solid {ctrl_border};
            border-radius: 50%;
            padding: 0;
            font-size: 10px;
            font-weight: bold;
            cursor: pointer;
            outline: none;
            width: 26px;
            height: 26px;
            scrollbar-width: thin;
            scrollbar-color: {scrollbar_thumb} {scrollbar_track};
            transition: all 0.2s;
            -webkit-appearance: none;
            -moz-appearance: none;
            appearance: none;
            text-align: center;
            text-align-last: center;
        }}
        select:hover {{
            border-color: {glow_color};
            box-shadow: 0 0 6px {glow_color}30;
        }}
        select option {{
            font-family: 'Google Sans Flex', sans-serif;
            background: {select_option_bg};
            color: {text_color};
            padding: 4px 8px;
        }}
        select option:checked {{
            background: linear-gradient(0deg, {glow_color}40, {glow_color}40);
        }}
        /* Custom scrollbar for WebKit browsers */
        select::-webkit-scrollbar {{
            width: 8px;
        }}
        select::-webkit-scrollbar-track {{
            background: {scrollbar_track};
            border-radius: 4px;
        }}
        select::-webkit-scrollbar-thumb {{
            background: {scrollbar_thumb};
            border-radius: 4px;
        }}
        select::-webkit-scrollbar-thumb:hover {{
            background: {scrollbar_thumb_hover};
        }}
        #viewport {{
            flex: 1;
            overflow: hidden;
            position: relative;
        }}
        #content {{
            font-size: {font_size}px;
            line-height: 1.5;
            padding-bottom: 5px;
        }}
        @keyframes wipe-in {{
            from {{
                -webkit-mask-position: 100% 0;
                mask-position: 100% 0;
                transform: translateX(-4px);
                opacity: 0;
                filter: blur(2px);
            }}
            to {{
                -webkit-mask-position: 0% 0;
                mask-position: 0% 0;
                transform: translateX(0);
                opacity: 1;
                filter: blur(0);
            }}
        }}

        /* Base styling for all text chunks */
        .text-chunk {{
            font-family: 'Google Sans Flex', sans-serif !important;
            font-optical-sizing: auto;
            display: inline;
            transition: 
                color 0.6s cubic-bezier(0.2, 0, 0.2, 1),
                font-variation-settings 0.6s cubic-bezier(0.2, 0, 0.2, 1),
                -webkit-mask-position 0.35s cubic-bezier(0.2, 0, 0.2, 1),
                mask-position 0.35s cubic-bezier(0.2, 0, 0.2, 1),
                opacity 0.35s ease-out,
                filter 0.35s ease-out;
        }}
        
        /* Old/committed text styling */
        .text-chunk.old {{
            color: {placeholder_color};
            font-variation-settings: 'wght' 300, 'wdth' 100, 'slnt' 0, 'GRAD' 0, 'ROND' 100, 'ROUN' 100, 'RNDS' 100;
        }}
        
        /* New/uncommitted text styling */
        .text-chunk.new {{
            color: {text_color};
            font-variation-settings: 'wght' 350, 'wdth' 99, 'slnt' 0, 'GRAD' 150, 'ROND' 100, 'ROUN' 100, 'RNDS' 100;
        }}
        
        /* Appearing state - wipe animation */
        .text-chunk.appearing {{
            color: {text_color};
            font-variation-settings: 'wght' 350, 'wdth' 99, 'slnt' 0, 'GRAD' 150, 'ROND' 100, 'ROUN' 100, 'RNDS' 100;
            
            -webkit-mask-image: linear-gradient(to right, black 50%, transparent 100%);
            mask-image: linear-gradient(to right, black 50%, transparent 100%);
            -webkit-mask-size: 200% 100%;
            mask-size: 200% 100%;
            -webkit-mask-position: 100% 0;
            mask-position: 100% 0;
            opacity: 0;
            filter: blur(2px);
        }}
        
        /* Appearing -> visible */
        .text-chunk.appearing.show {{
            -webkit-mask-position: 0% 0;
            mask-position: 0% 0;
            opacity: 1;
            filter: blur(0);
        }}
        .placeholder {{
            color: #666;
            font-style: italic;
        }}
        /* Resize handle - visible grip in corner */
         #resize-hint {{
             position: absolute;
             bottom: 0;
             right: 0;
             width: 16px;
             height: 16px;
             cursor: se-resize;
             opacity: 0.2;
             display: flex;
             align-items: flex-end;
             justify-content: flex-end;
             padding: 2px;
             font-size: 10px;
             color: {resize_hint_color};
             user-select: none;
         }}
        #resize-hint:hover {{
             opacity: 1;
             color: {glow_color};
         }}
        .audio-icon {{
            font-size: 22px;
            padding: 0;
            cursor: pointer;
            color: {icon_inactive_color};
            transition: all 0.2s;
            background: transparent;
            border: none;
        }}
        .audio-icon:hover {{
            color: #aaa;
        }}
        .audio-icon.active {{
            color: #00c8ff;
        }}
        .model-icon {{
            font-size: 22px;
            padding: 0;
            cursor: pointer;
            color: {icon_inactive_color};
            transition: all 0.2s;
            background: transparent;
            border: none;
        }}
        .model-icon:hover {{
            color: #aaa;
        }}
        .model-icon.active {{
            color: #ff9633;
        }}
        @keyframes model-switch-pulse {{
            0% {{ transform: scale(1); box-shadow: 0 0 0 0 rgba(255,150,51,0.7); }}
            25% {{ transform: scale(1.3); box-shadow: 0 0 15px 5px rgba(255,150,51,0.5); }}
            50% {{ transform: scale(1.1); box-shadow: 0 0 10px 3px rgba(255,150,51,0.3); }}
            75% {{ transform: scale(1.2); box-shadow: 0 0 12px 4px rgba(255,150,51,0.4); }}
            100% {{ transform: scale(1); box-shadow: 0 0 0 0 rgba(255,150,51,0); }}
        }}
        .model-icon.switching {{
            animation: model-switch-pulse 2s ease-out;
            color: #ff9633 !important;
            background: rgba(255,150,51,0.3) !important;
        }}
        
        /* Transcription Model Icons */
        .trans-model-icon {{
            font-size: 22px;
            padding: 0;
            cursor: pointer;
            color: {icon_inactive_color};
            transition: all 0.2s;
            background: transparent;
            border: none;
        }}
        .trans-model-icon:hover {{
            color: #aaa;
        }}
        .trans-model-icon.active[data-value="gemini"] {{
            color: #00c8ff;
        }}
        .trans-model-icon.active[data-value="parakeet"] {{
            color: #ff9633;
        }}

        /* Waveform animation for listening state */
        .wave-line {{
             transform-box: fill-box;
             transform-origin: center;
             animation: wave-animation 1.2s ease-in-out infinite;
        }}
        .wave-line.delay-1 {{ animation-delay: 0s; }}
        .wave-line.delay-2 {{ animation-delay: 0.15s; }}
        .wave-line.delay-3 {{ animation-delay: 0.3s; }}
        .wave-line.delay-4 {{ animation-delay: 0.1s; }}
        
        @keyframes wave-animation {{
            0%, 100% {{
                transform: scaleY(1);
            }}
            50% {{
                transform: scaleY(1.8);
            }}
        }}

        /* Translation animation */
        .trans-part-1 {{
            animation: lang-bounce 2s ease-in-out infinite;
        }}
        .trans-part-2 {{
            animation: lang-bounce 2s ease-in-out infinite;
            animation-delay: 1s;
        }}
        @keyframes lang-bounce {{
            0%, 100% {{ transform: translateY(0); opacity: 0.8; }}
            50% {{ transform: translateY(-3px); opacity: 1; }}
        }}
        
        /* Speak button styling */
        .speak-btn {{
            position: relative;
        }}
        .speak-btn.active {{
            color: #4caf50 !important;
            border-color: #4caf50;
            box-shadow: 0 0 8px #4caf5040;
        }}
        .speak-btn.active .material-symbols-rounded {{
            animation: speak-pulse 1.5s ease-in-out infinite;
        }}
        @keyframes speak-pulse {{
            0%, 100% {{ opacity: 1; }}
            50% {{ opacity: 0.5; }}
        }}
        "###,
        bg_color = bg_color,
        text_color = text_color,
        header_bg = header_bg,
        border_color = border_color,
        box_shadow = box_shadow,
        glow_color = glow_color,
        font_size = font_size,
        ctrl_bg = ctrl_bg,
        ctrl_border = ctrl_border,
        select_bg = select_bg,
        select_option_bg = select_option_bg,
        scrollbar_thumb = scrollbar_thumb,
        scrollbar_track = scrollbar_track,
        scrollbar_thumb_hover = scrollbar_thumb_hover,
        placeholder_color = placeholder_color,
        resize_hint_color = resize_hint_color,
        ctrl_hover_bg = ctrl_hover_bg,
        ctrl_hover_text = ctrl_hover_text,
        icon_inactive_color = icon_inactive_color,
    )
}
</file>

<file path="src/overlay/html_components/css_modals.rs">
pub fn get(is_dark: bool) -> String {
    let (
        bg_color,
        text_color,
        border_color,
        border_focus_color,
        label_color,
        slider_bg,
        switch_bg,
        switch_on_bg,
        slider_thumb,
        hover_bg,
        divider_color,
        shadow_lg,
        shadow_sm,
    ) = if is_dark {
        (
            "rgba(30, 30, 30, 0.98)",  // bg_color
            "#ccc",                    // text_color (general)
            "rgba(255, 150, 51, 0.5)", // border_color (default orange)
            "#00c8ff80",               // border_focus_color (blue)
            "#aaa",                    // label_color
            "#444",                    // slider_bg
            "#444",                    // switch_bg
            "#4caf50",                 // switch_on_bg
            "#ff9633",                 // slider_thumb
            "rgba(0, 200, 255, 0.15)", // hover_bg
            "#555",                    // divider_color
            "rgba(0,0,0,0.5)",         // shadow_lg
            "#ff963330",               // shadow_sm (orange glow)
        )
    } else {
        (
            "rgba(255, 255, 255, 0.98)",
            "#202124",
            "rgba(255, 150, 51, 0.3)", // Lighter orange border
            "#00c8ff50",
            "#5f6368",
            "#e0e0e0",
            "#dadce0",
            "#34a853", // Google green
            "#fa7b17", // Slightly darker orange for visibility
            "rgba(0, 200, 255, 0.08)",
            "#dadce0",
            "rgba(0,0,0,0.15)",
            "#ff963320",
        )
    };

    let title_color_tts = "#ff9633"; // Orange
    let title_color_app = "#00c8ff"; // Blue

    format!(
        r###"
        /* TTS Settings Modal */
        #tts-modal {{
            display: none;
            position: fixed !important;
            top: 50% !important;
            left: 50% !important;
            transform: translate(-50%, -50%) !important;
            background: {bg_color};
            border: 1px solid {border_color};
            border-radius: 12px;
            padding: 16px 20px;
            z-index: 2147483647 !important; /* Max Element Z-Index */
            min-width: 200px;
            box-shadow: 0 8px 32px {shadow_lg}, 0 0 20px {shadow_sm};
            color: {text_color};
        }}
        #tts-modal.show {{
            display: block !important;
            animation: modal-appear 0.2s ease-out;
        }}
        @keyframes modal-appear {{
            from {{ opacity: 0; transform: translate(-50%, -50%) scale(0.9); }}
            to {{ opacity: 1; transform: translate(-50%, -50%) scale(1); }}
        }}
        #tts-modal-overlay {{
            display: none;
            position: fixed !important;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.3);
            z-index: 2147483646 !important;
        }}
        #tts-modal-overlay.show {{
            display: block !important;
        }}
        .tts-modal-title {{
            font-size: 13px;
            font-weight: bold;
            color: {title_color_tts};
            margin-bottom: 12px;
            display: flex;
            align-items: center;
            gap: 6px;
        }}
        .tts-modal-row {{
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 12px;
            gap: 12px;
        }}
        .tts-modal-row:last-child {{
            margin-bottom: 0;
        }}
        .tts-modal-label {{
            font-size: 12px;
            color: {label_color};
            white-space: nowrap;
        }}
        /* Toggle Switch */
        .toggle-switch {{
            position: relative;
            width: 40px;
            height: 22px;
            background: {switch_bg};
            border-radius: 11px;
            cursor: pointer;
            transition: background 0.2s;
        }}
        .toggle-switch.on {{
            background: {switch_on_bg};
        }}
        .toggle-switch::after {{
            content: '';
            position: absolute;
            top: 2px;
            left: 2px;
            width: 18px;
            height: 18px;
            background: #fff;
            border-radius: 50%;
            transition: transform 0.2s;
            box-shadow: 0 1px 3px rgba(0,0,0,0.2);
        }}
        .toggle-switch.on::after {{
            transform: translateX(18px);
        }}
        /* Speed Slider */
        .speed-slider-container {{
            display: flex;
            align-items: center;
            gap: 8px;
        }}
        .speed-slider {{
            -webkit-appearance: none;
            width: 100px;
            height: 6px;
            background: {slider_bg};
            border-radius: 3px;
            outline: none;
        }}
        .speed-slider::-webkit-slider-thumb {{
            -webkit-appearance: none;
            width: 14px;
            height: 14px;
            background: {slider_thumb};
            border-radius: 50%;
            cursor: pointer;
            transition: transform 0.1s;
            box-shadow: 0 1px 3px rgba(0,0,0,0.2);
        }}
        .speed-slider::-webkit-slider-thumb:hover {{
            transform: scale(1.2);
        }}
        .speed-value {{
            font-size: 11px;
            color: {slider_thumb};
            font-weight: bold;
            min-width: 32px;
            text-align: right;
        }}
        .auto-toggle {{
            padding: 4px 10px;
            font-size: 10px;
            font-weight: bold;
            border: 1px solid {divider_color};
            border-radius: 12px;
            background: transparent;
            color: {label_color};
            cursor: pointer;
            transition: all 0.2s;
            text-transform: uppercase;
            letter-spacing: 0.5px;
        }}
        .auto-toggle:hover {{
            border-color: {title_color_tts};
            color: {title_color_tts};
        }}
        .auto-toggle.on {{
            background: linear-gradient(135deg, {title_color_tts} 0%, #ff6b00 100%);
            border-color: {title_color_tts};
            color: #fff;
            white-space: nowrap;
        }}
        
        /* App Selection Modal */
        #app-modal {{
            display: none;
            position: fixed !important;
            top: 50% !important;
            left: 50% !important;
            transform: translate(-50%, -50%) !important;
            background: {bg_color};
            border: 1px solid {border_focus_color};
            border-radius: 12px;
            padding: 16px 20px;
            z-index: 2000 !important;
            min-width: 280px;
            max-width: 400px;
            max-height: 70vh;
            box-shadow: 0 8px 32px {shadow_lg}, 0 0 20px {shadow_sm};
            overflow: hidden;
            color: {text_color};
        }}
        #app-modal.show {{
            display: block !important;
            animation: modal-appear 0.2s ease-out;
        }}
        #app-modal-overlay {{
            display: none;
            position: fixed !important;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.3);
            z-index: 1999 !important;
        }}
        #app-modal-overlay.show {{
            display: block !important;
        }}
        .app-modal-title {{
            font-size: 13px;
            font-weight: bold;
            color: {title_color_app};
            margin-bottom: 8px;
            display: flex;
            align-items: center;
            gap: 6px;
        }}
        .app-modal-hint {{
            font-size: 10px;
            color: {label_color};
            margin-bottom: 12px;
        }}
        .app-list {{
            max-height: 300px;
            overflow-y: auto;
            scrollbar-width: thin;
            scrollbar-color: {divider_color} {bg_color};
        }}
        .app-list::-webkit-scrollbar {{
            width: 6px;
        }}
        .app-list::-webkit-scrollbar-track {{
            background: {bg_color};
            border-radius: 3px;
        }}
        .app-list::-webkit-scrollbar-thumb {{
            background: {divider_color};
            border-radius: 3px;
        }}
        .app-item {{
            display: flex;
            align-items: center;
            gap: 8px;
            padding: 8px 10px;
            border-radius: 6px;
            cursor: pointer;
            transition: all 0.15s;
            margin-bottom: 4px;
        }}
        .app-item:hover {{
            background: {hover_bg};
        }}
        .app-item .app-icon {{
            font-size: 18px;
            color: {title_color_app};
        }}
        .app-item .app-title {{
            font-size: 12px;
            color: {text_color};
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            flex: 1;
        }}
        .app-item .app-pid {{
            font-size: 9px;
            color: {label_color};
        }}
        .app-loading {{
            font-size: 12px;
            color: {label_color};
            text-align: center;
            padding: 20px;
        }}
        .app-name-badge {{
            font-size: 10px;
            color: {title_color_app};
            background: {hover_bg};
            padding: 2px 6px;
            border-radius: 10px;
            max-width: 80px;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
        }}
        /* Download Modal */
        #download-modal {{
            display: none;
            position: fixed !important;
            top: 50% !important;
            left: 50% !important;
            transform: translate(-50%, -50%) !important;
            background: {bg_color};
            border: 1px solid {border_focus_color};
            border-radius: 12px;
            padding: 12px 16px;
            z-index: 2147483647 !important;
            min-width: 320px;
            max-width: 90vw;
            box-shadow: 0 8px 32px {shadow_lg}, 0 0 20px {shadow_sm};
            text-align: center;
            color: {text_color};
        }}
        #download-modal.show {{
            display: block !important;
            animation: modal-appear 0.2s ease-out;
        }}
        #download-modal-overlay {{
            display: none;
            position: fixed !important;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: rgba(0,0,0,0.5);
            z-index: 2147483646 !important;
        }}
        #download-modal-overlay.show {{
            display: block !important;
        }}
        .download-modal-title {{
            font-size: 13px;
            font-weight: bold;
            color: {title_color_app};
            margin-bottom: 8px;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 6px;
            line-height: 1.2;
        }}
        .download-modal-title .material-symbols-rounded {{
            font-size: 18px;
            width: 18px;
            height: 18px;
            flex-shrink: 0;
        }}
        .download-modal-msg {{
            font-size: 11px;
            color: {text_color};
            margin-bottom: 12px;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            max-width: 100%;
        }}
        .download-progress-bar {{
            width: 100%;
            height: 6px;
            background: {slider_bg};
            border-radius: 3px;
            overflow: hidden;
            margin-bottom: 8px;
        }}
        .download-progress-fill {{
            height: 100%;
            background: linear-gradient(90deg, #00c8ff, #0080ff);
            width: 0%;
            transition: width 0.2s;
        }}
        .download-modal-footnote {{
            font-size: 10px;
            color: {label_color};
            font-style: italic;
        }}
        .download-cancel-btn {{
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 4px;
            margin-top: 12px;
            padding: 8px 16px;
            background: transparent;
            border: 1px solid #ff4444;
            border-radius: 6px;
            color: #ff6666;
            font-size: 11px;
            font-weight: 500;
            cursor: pointer;
            transition: all 0.2s;
            width: 100%;
        }}
        .download-cancel-btn:hover {{
            background: rgba(255, 68, 68, 0.15);
            border-color: #ff6666;
            color: #ff8888;
        }}
        .download-cancel-btn .material-symbols-rounded {{
            font-size: 14px;
        }}
    "###,
        bg_color = bg_color,
        text_color = text_color,
        border_color = border_color,
        border_focus_color = border_focus_color,
        shadow_lg = shadow_lg,
        shadow_sm = shadow_sm,
        title_color_tts = title_color_tts,
        title_color_app = title_color_app,
        label_color = label_color,
        switch_bg = switch_bg,
        switch_on_bg = switch_on_bg,
        slider_bg = slider_bg,
        slider_thumb = slider_thumb,
        divider_color = divider_color,
        hover_bg = hover_bg
    )
}
</file>

<file path="src/overlay/html_components/js_main.rs">
pub fn get(font_size: u32) -> String {
    format!(
        r###"        const container = document.getElementById('container');
        const viewport = document.getElementById('viewport');
        const content = document.getElementById('content');
        const header = document.getElementById('header');
        const headerToggle = document.getElementById('header-toggle');
        const toggleMic = document.getElementById('toggle-mic');
        const toggleTrans = document.getElementById('toggle-trans');
        const fontDecrease = document.getElementById('font-decrease');
        const fontIncrease = document.getElementById('font-increase');
        const resizeHint = document.getElementById('resize-hint');
        const copyBtn = document.getElementById('copy-btn');
        
        let currentFontSize = {font_size};
        let isResizing = false;
        let resizeStartX = 0;
        let resizeStartY = 0;
        let micVisible = true;
        let transVisible = true;
        let headerCollapsed = false;
        
        // TTS Modal elements
        const speakBtn = document.getElementById('speak-btn');
        const ttsModal = document.getElementById('tts-modal');
        const ttsModalOverlay = document.getElementById('tts-modal-overlay');
        const ttsToggle = document.getElementById('tts-toggle');
        const speedSlider = document.getElementById('speed-slider');
        const speedValue = document.getElementById('speed-value');
        let ttsEnabled = false;
        let ttsSpeed = 100;
        
        // TTS Modal Logic
        if (speakBtn && ttsModal && ttsModalOverlay) {{
            speakBtn.addEventListener('click', function(e) {{
                e.stopPropagation();
                ttsModal.classList.toggle('show');
                ttsModalOverlay.classList.toggle('show');
            }});
            
            ttsModalOverlay.addEventListener('click', function() {{
                ttsModal.classList.remove('show');
                ttsModalOverlay.classList.remove('show');
            }});
        }}
        
        if (ttsToggle) {{
            ttsToggle.addEventListener('click', function(e) {{
                e.stopPropagation();
                ttsEnabled = !ttsEnabled;
                this.classList.toggle('on', ttsEnabled);
                if (speakBtn) speakBtn.classList.toggle('active', ttsEnabled);
                window.ipc.postMessage('ttsEnabled:' + (ttsEnabled ? '1' : '0'));
            }});
        }}
        
        if (speedSlider && speedValue) {{
            const autoToggle = document.getElementById('auto-speed-toggle');
            let autoSpeed = true; // Default: auto is on
            
            speedSlider.addEventListener('input', function(e) {{
                e.stopPropagation();
                ttsSpeed = parseInt(this.value);
                speedValue.textContent = (ttsSpeed / 100).toFixed(1) + 'x';
                window.ipc.postMessage('ttsSpeed:' + ttsSpeed);
                // Auto turns off when user manually adjusts slider
                if (autoSpeed && autoToggle) {{
                    autoSpeed = false;
                    autoToggle.classList.remove('on');
                }}
            }});
            
            if (autoToggle) {{
                autoToggle.addEventListener('click', function(e) {{
                    e.stopPropagation();
                    autoSpeed = !autoSpeed;
                    this.classList.toggle('on', autoSpeed);
                    window.ipc.postMessage('ttsAutoSpeed:' + (autoSpeed ? '1' : '0'));
                }});
            }}
        }}
        
        // Header toggle (with null check in case element is commented out)
        if (headerToggle) {{
            headerToggle.addEventListener('click', function(e) {{
                e.stopPropagation();
                headerCollapsed = !headerCollapsed;
                header.classList.toggle('collapsed', headerCollapsed);
                headerToggle.classList.toggle('collapsed', headerCollapsed);
            }});
        }}
        
        // Copy button handler
        if (copyBtn) {{
            copyBtn.addEventListener('click', function(e) {{
                e.stopPropagation();
                // Get all text content (excluding placeholder)
                const textContent = content.textContent.trim();
                if (textContent && !content.querySelector('.placeholder')) {{
                    // Send to Rust via IPC for clipboard (navigator.clipboard not available in WebView2)
                    window.ipc.postMessage('copyText:' + textContent);
                    // Show success feedback
                    copyBtn.classList.add('copied');
                    const icon = copyBtn.querySelector('.material-symbols-rounded');
                    if (icon) icon.innerHTML = '{check_svg}';
                    setTimeout(() => {{
                        copyBtn.classList.remove('copied');
                        if (icon) icon.innerHTML = '{copy_svg}';
                    }}, 1500);
                }}
            }});
        }}
        
        // Drag support (left click for single window)
        container.addEventListener('mousedown', function(e) {{
            if (e.button !== 0) return; // Only left click
            if (e.target.closest('#controls') || e.target.closest('#header-toggle') || e.target.id === 'resize-hint' || isResizing) return;
            window.ipc.postMessage('startDrag');
        }});
        
        // Right-click group drag support (moves both windows together)
        let isGroupDragging = false;
        let groupDragStartX = 0;
        let groupDragStartY = 0;
        
        container.addEventListener('mousedown', function(e) {{
            if (e.button !== 2) return; // Only right click
            // Allow context menu on interactive controls
            if (e.target.closest('#controls') || e.target.closest('select')) return;
            
            e.preventDefault();
            isGroupDragging = true;
            groupDragStartX = e.screenX;
            groupDragStartY = e.screenY;
            window.ipc.postMessage('startGroupDrag');
            document.addEventListener('mousemove', onGroupDragMove);
            document.addEventListener('mouseup', onGroupDragEnd);
        }});
        
        // Prevent context menu when right-click dragging on the window body
        container.addEventListener('contextmenu', function(e) {{
            // Allow context menu on interactive controls and selects
            if (e.target.closest('#controls') || e.target.closest('select')) return;
            e.preventDefault();
        }});
        
        function onGroupDragMove(e) {{
            if (!isGroupDragging) return;
            const dx = e.screenX - groupDragStartX;
            const dy = e.screenY - groupDragStartY;
            if (dx !== 0 || dy !== 0) {{
                window.ipc.postMessage('groupDragMove:' + dx + ',' + dy);
                groupDragStartX = e.screenX;
                groupDragStartY = e.screenY;
            }}
        }}
        
        function onGroupDragEnd(e) {{
            if (isGroupDragging) {{
                isGroupDragging = false;
                document.removeEventListener('mousemove', onGroupDragMove);
                document.removeEventListener('mouseup', onGroupDragEnd);
            }}
        }}
        
        // Resize support
        resizeHint.addEventListener('mousedown', function(e) {{
            e.stopPropagation();
            e.preventDefault();
            isResizing = true;
            resizeStartX = e.screenX;
            resizeStartY = e.screenY;
            document.addEventListener('mousemove', onResizeMove);
            document.addEventListener('mouseup', onResizeEnd);
        }});
        
        function onResizeMove(e) {{
            if (!isResizing) return;
            const dx = e.screenX - resizeStartX;
            const dy = e.screenY - resizeStartY;
            if (Math.abs(dx) > 5 || Math.abs(dy) > 5) {{
                window.ipc.postMessage('resize:' + dx + ',' + dy);
                resizeStartX = e.screenX;
                resizeStartY = e.screenY;
            }}
        }}
        
        function onResizeEnd(e) {{
            isResizing = false;
            document.removeEventListener('mousemove', onResizeMove);
            document.removeEventListener('mouseup', onResizeEnd);
            window.ipc.postMessage('saveResize');
        }}
        
        // Visibility toggle buttons
        toggleMic.addEventListener('click', function(e) {{
            e.stopPropagation();
            micVisible = !micVisible;
            this.classList.toggle('active', micVisible);
            this.classList.toggle('inactive', !micVisible);
            window.ipc.postMessage('toggleMic:' + (micVisible ? '1' : '0'));
        }});
        
        toggleTrans.addEventListener('click', function(e) {{
            e.stopPropagation();
            transVisible = !transVisible;
            this.classList.toggle('active', transVisible);
            this.classList.toggle('inactive', !transVisible);
            window.ipc.postMessage('toggleTrans:' + (transVisible ? '1' : '0'));
        }});
        
        // Function to update visibility state from native side
        window.setVisibility = function(mic, trans) {{
            micVisible = mic;
            transVisible = trans;
            toggleMic.classList.toggle('active', mic);
            toggleMic.classList.toggle('inactive', !mic);
            toggleTrans.classList.toggle('active', trans);
            toggleTrans.classList.toggle('inactive', !trans);
        }};
        
        // Function to update current TTS speed from native side
        window.updateTtsSpeed = function(speed) {{
            ttsSpeed = speed;
            if (speedSlider) speedSlider.value = speed;
            if (speedValue) speedValue.textContent = (speed / 100).toFixed(1) + 'x';
        }};
        
        // Font size controls
        fontDecrease.addEventListener('click', function(e) {{
            e.stopPropagation();
            if (currentFontSize > 10) {{
                currentFontSize -= 2;
                content.style.fontSize = currentFontSize + 'px';
                // Reset min height so text can shrink properly
                minContentHeight = 0;
                content.style.minHeight = '';
                window.ipc.postMessage('fontSize:' + currentFontSize);
            }}
        }});
        
        fontIncrease.addEventListener('click', function(e) {{
            e.stopPropagation();
            if (currentFontSize < 32) {{
                currentFontSize += 2;
                content.style.fontSize = currentFontSize + 'px';
                // Reset min height for fresh calculation
                minContentHeight = 0;
                content.style.minHeight = '';
                window.ipc.postMessage('fontSize:' + currentFontSize);
            }}
        }});
        
        // Audio source toggle buttons
        const micBtn = document.getElementById('mic-btn');
        const deviceBtn = document.getElementById('device-btn');
        
        if (micBtn) {{
            micBtn.addEventListener('click', (e) => {{
                e.stopPropagation();
                e.preventDefault();
                
                // Switch to mic mode
                micBtn.classList.add('active');
                if (deviceBtn) deviceBtn.classList.remove('active');
                
                window.ipc.postMessage('audioSource:mic');
            }});
        }}
        
        if (deviceBtn) {{
            deviceBtn.addEventListener('click', (e) => {{
                e.stopPropagation();
                e.preventDefault();
                
                // Switch to device mode
                if (micBtn) micBtn.classList.remove('active');
                deviceBtn.classList.add('active');
                
                window.ipc.postMessage('audioSource:device');
            }});
        }}



        // Language Select Logic - show short code when collapsed, full name when open
        const langSelect = document.getElementById('language-select');
        if (langSelect) {{
            // Store original full names
            const options = langSelect.querySelectorAll('option');
            options.forEach(opt => {{
                opt.dataset.fullname = opt.textContent;
            }});
            
            // Function to show short codes (when collapsed)
            function showCodes() {{
                options.forEach(opt => {{
                    opt.textContent = opt.dataset.code || opt.dataset.fullname.substring(0, 2).toUpperCase();
                }});
            }}
            
            // Function to show full names (when dropdown open)
            function showFullNames() {{
                options.forEach(opt => {{
                    opt.textContent = opt.dataset.fullname;
                }});
            }}
            
            // Initially show codes
            showCodes();
            
            // Show full names when dropdown opens
            langSelect.addEventListener('focus', showFullNames);
            langSelect.addEventListener('mousedown', function(e) {{ 
                e.stopPropagation();
                showFullNames();
            }});
            
            // Show codes when dropdown closes
            langSelect.addEventListener('blur', showCodes);
            langSelect.addEventListener('change', function(e) {{
                e.stopPropagation();
                window.ipc.postMessage('language:' + this.value);
                // Delay to let the dropdown close animation finish
                setTimeout(showCodes, 100);
            }});
        }}

        // Model Toggle Switch Logic - for translation
        const modelIcons = document.querySelectorAll('.model-icon');
        if (modelIcons.length) {{
            modelIcons.forEach(icon => {{
                icon.addEventListener('click', (e) => {{
                    e.stopPropagation();
                    e.preventDefault();
                    
                    // Update UI - toggle active class
                    modelIcons.forEach(i => i.classList.remove('active'));
                    icon.classList.add('active');
                    
                    // Send IPC
                    const val = icon.getAttribute('data-value');
                    window.ipc.postMessage('translationModel:' + val);
                }});
            }});
        }}
        
        // Transcription Model Logic
        const transModelIcons = document.querySelectorAll('.trans-model-icon');
        if (transModelIcons.length) {{
            transModelIcons.forEach(icon => {{
                icon.addEventListener('click', (e) => {{
                    e.stopPropagation();
                    e.preventDefault();
                    
                    transModelIcons.forEach(i => i.classList.remove('active'));
                    icon.classList.add('active');
                    
                    const val = icon.getAttribute('data-value');
                    window.ipc.postMessage('transcriptionModel:' + val);
                }});
            }});
        }}

        // Download Modal Functions
        window.showDownloadModal = function(title, msg, progress) {{
            const modal = document.getElementById('download-modal');
            const overlay = document.getElementById('download-modal-overlay');
            const titleEl = document.getElementById('download-title');
            const msgEl = document.getElementById('download-msg');
            const fillEl = document.getElementById('download-fill');
            
            if (modal && overlay) {{
                modal.classList.add('show');
                overlay.classList.add('show');
                if (titleEl) titleEl.textContent = title;
                if (msgEl) msgEl.textContent = msg;
                if (fillEl) fillEl.style.width = progress + '%';
            }}
        }};
        
        window.hideDownloadModal = function() {{
            const modal = document.getElementById('download-modal');
            const overlay = document.getElementById('download-modal-overlay');
            if (modal && overlay) {{
                modal.classList.remove('show');
                overlay.classList.remove('show');
            }}
        }};
        
        // Cancel download button handler
        const downloadCancelBtn = document.getElementById('download-cancel-btn');
        if (downloadCancelBtn) {{
            downloadCancelBtn.addEventListener('click', function(e) {{
                e.stopPropagation();
                // Send cancel message to native side
                window.ipc.postMessage('cancelDownload');
            }});
        }}
        
        // Update settings from native side (used when overlay is shown with saved config)
        window.updateSettings = function(settings) {{
            // Update audio source toggle
            if (settings.audioSource && micBtn && deviceBtn) {{
                if (settings.audioSource === 'device') {{
                    micBtn.classList.remove('active');
                    deviceBtn.classList.add('active');
                }} else {{
                    micBtn.classList.add('active');
                    deviceBtn.classList.remove('active');
                }}
            }}
            
            // Update language select
            if (settings.targetLanguage && langSelect) {{
                langSelect.value = settings.targetLanguage;
            }}
            
            // Update translation model
            if (settings.translationModel && modelIcons.length) {{
                modelIcons.forEach(icon => {{
                    const val = icon.getAttribute('data-value');
                    icon.classList.toggle('active', val === settings.translationModel);
                }});
            }}
            
            // Update transcription model
            if (settings.transcriptionModel && transModelIcons && transModelIcons.length) {{
                transModelIcons.forEach(icon => {{
                    const val = icon.getAttribute('data-value');
                    icon.classList.toggle('active', val === settings.transcriptionModel);
                }});
            }}
            
            // Update font size
            if (settings.fontSize && settings.fontSize !== currentFontSize) {{
                currentFontSize = settings.fontSize;
                content.style.fontSize = currentFontSize + 'px';
                minContentHeight = 0;
                content.style.minHeight = '';
            }}
        }};
        
        // Handle resize to keep text at bottom
        let lastWidth = viewport.clientWidth;
        const resizeObserver = new ResizeObserver(entries => {{
            for (let entry of entries) {{
                if (Math.abs(entry.contentRect.width - lastWidth) > 5) {{
                    lastWidth = entry.contentRect.width;
                    // Reset min height on width change (reflow)
                    minContentHeight = 0;
                    content.style.minHeight = '';
                    
                    // Force scroll to bottom immediately to prevent jump
                    if (content.scrollHeight > viewport.clientHeight) {{
                        viewport.scrollTop = content.scrollHeight - viewport.clientHeight;
                    }}
                    targetScrollTop = viewport.scrollTop;
                    currentScrollTop = targetScrollTop;
                }}
            }}
        }});
        resizeObserver.observe(viewport);
        
        let isFirstText = true;
        let currentScrollTop = 0;
        let targetScrollTop = 0;
        let animationFrame = null;
        let minContentHeight = 0;
        
        function animateScroll() {{
            const diff = targetScrollTop - currentScrollTop;
            
            if (Math.abs(diff) > 0.5) {{
                const ease = Math.min(0.08, Math.max(0.02, Math.abs(diff) / 1000));
                currentScrollTop += diff * ease;
                viewport.scrollTop = currentScrollTop;
                animationFrame = requestAnimationFrame(animateScroll);
            }} else {{
                currentScrollTop = targetScrollTop;
                viewport.scrollTop = currentScrollTop;
                animationFrame = null;
            }}
        }}
        
        let currentOldTextLength = 0;
        let previousNewText = '';
"###,
        font_size = font_size,
        check_svg = crate::overlay::html_components::icons::get_icon_svg("check"),
        copy_svg = crate::overlay::html_components::icons::get_icon_svg("content_copy")
    )
}
</file>

<file path="src/overlay/html_components/mod.rs">
pub mod css_main;
pub mod css_modals;
pub mod font_manager;
pub mod grid_js;
pub mod icons;
pub mod js_logic;
pub mod js_main;
</file>

<file path="src/overlay/input_history.rs">
//! Persistent input history for text inputs
//! Supports arrow up/down navigation through previous inputs

use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;
use std::sync::Mutex;

/// Maximum number of history entries to keep
const MAX_HISTORY_SIZE: usize = 100;

lazy_static::lazy_static! {
    /// Global input history manager
    pub static ref INPUT_HISTORY: Mutex<InputHistory> = Mutex::new(InputHistory::load());
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InputHistory {
    /// List of previous inputs (newest first)
    entries: Vec<String>,

    /// Current navigation index (-1 means not navigating)
    #[serde(skip)]
    nav_index: i32,

    /// Temporary storage for current input when navigating
    #[serde(skip)]
    current_draft: String,
}

impl Default for InputHistory {
    fn default() -> Self {
        Self {
            entries: Vec::new(),
            nav_index: -1,
            current_draft: String::new(),
        }
    }
}

impl InputHistory {
    /// Get the path to the history file
    fn history_path() -> PathBuf {
        let config_dir = dirs::config_dir()
            .unwrap_or_default()
            .join("screen-goated-toolbox");
        let _ = fs::create_dir_all(&config_dir);
        config_dir.join("input_history.json")
    }

    /// Load history from disk
    pub fn load() -> Self {
        let path = Self::history_path();
        if path.exists() {
            if let Ok(data) = fs::read_to_string(&path) {
                if let Ok(history) = serde_json::from_str::<InputHistory>(&data) {
                    return history;
                }
            }
        }
        Self::default()
    }

    /// Save history to disk
    fn save(&self) {
        let path = Self::history_path();
        if let Ok(data) = serde_json::to_string_pretty(self) {
            let _ = fs::write(path, data);
        }
    }

    /// Add a new entry to history (called on submit)
    pub fn add_entry(&mut self, text: &str) {
        let text = text.trim().to_string();
        if text.is_empty() {
            return;
        }

        // Remove duplicate if exists (so we can move it to the end)
        self.entries.retain(|e| e != &text);

        // Add to end (Newest)
        self.entries.push(text);

        // Limit size (remove from front/Oldest)
        while self.entries.len() > MAX_HISTORY_SIZE {
            self.entries.remove(0);
        }

        // Reset navigation state
        self.reset_navigation();

        // Persist
        self.save();
    }

    /// Start navigation (called when arrow key pressed on empty navigation state)
    /// Returns the text to show, or None if no history
    pub fn navigate_up(&mut self, current_text: &str) -> Option<String> {
        if self.entries.is_empty() {
            return None;
        }

        // If not currently navigating, start at the end (Newest + 1)
        if self.nav_index == -1 {
            self.current_draft = current_text.to_string();
            self.nav_index = self.entries.len() as i32;
        }

        // Move up (towards older entries / index 0)
        if self.nav_index > 0 {
            self.nav_index -= 1;
        }

        // Return entry at current index
        if (self.nav_index as usize) < self.entries.len() {
            self.entries.get(self.nav_index as usize).cloned()
        } else {
            None
        }
    }

    /// Navigate down (towards newer entries or back to draft)
    /// Returns the text to show
    pub fn navigate_down(&mut self, _current_text: &str) -> Option<String> {
        if self.nav_index == -1 {
            return None;
        }

        // If we haven't started (at -1), we can't go down.
        // Logic handles nav_index = len() as "Draft".

        if (self.nav_index as usize) < self.entries.len() {
            self.nav_index += 1;
        }

        if (self.nav_index as usize) >= self.entries.len() {
            // Returned to draft
            let draft = self.current_draft.clone();
            self.reset_navigation();
            Some(draft)
        } else {
            self.entries.get(self.nav_index as usize).cloned()
        }
    }

    /// Reset navigation state (called when input is hidden or submitted)
    pub fn reset_navigation(&mut self) {
        self.nav_index = -1;
        self.current_draft.clear();
    }
}

/// Convenience function to add entry to global history
pub fn add_to_history(text: &str) {
    if let Ok(mut history) = INPUT_HISTORY.lock() {
        history.add_entry(text);
    }
}

/// Navigate up in history, returns text to show or None
pub fn navigate_history_up(current_text: &str) -> Option<String> {
    if let Ok(mut history) = INPUT_HISTORY.lock() {
        history.navigate_up(current_text)
    } else {
        None
    }
}

/// Navigate down in history, returns text to show or None
pub fn navigate_history_down(current_text: &str) -> Option<String> {
    if let Ok(mut history) = INPUT_HISTORY.lock() {
        history.navigate_down(current_text)
    } else {
        None
    }
}

/// Reset history navigation
pub fn reset_history_navigation() {
    if let Ok(mut history) = INPUT_HISTORY.lock() {
        history.reset_navigation();
    }
}
</file>

<file path="src/overlay/paint_utils.rs">
const CORNER_RADIUS: f32 = 12.0;

#[inline(always)]
pub fn hsv_to_rgb(h: f32, s: f32, v: f32) -> u32 {
    let c = v * s;
    let h_prime = (h % 360.0) / 60.0;
    let x = c * (1.0 - (h_prime % 2.0 - 1.0).abs());
    let m = v - c;

    let (r, g, b) = if h_prime < 1.0 { (c, x, 0.0) }
    else if h_prime < 2.0 { (x, c, 0.0) }
    else if h_prime < 3.0 { (0.0, c, x) }
    else if h_prime < 4.0 { (0.0, x, c) }
    else if h_prime < 5.0 { (x, 0.0, c) }
    else { (c, 0.0, x) };

    let r_u = ((r + m) * 255.0) as u32;
    let g_u = ((g + m) * 255.0) as u32;
    let b_u = ((b + m) * 255.0) as u32;

    (r_u << 16) | (g_u << 8) | b_u 
}

#[inline(always)]
pub fn sd_rounded_box(px: f32, py: f32, bx: f32, by: f32, r: f32) -> f32 {
    let qx = px.abs() - bx + r;
    let qy = py.abs() - by + r;
    let len_max_q = (qx.max(0.0).powi(2) + qy.max(0.0).powi(2)).sqrt();
    let min_max_q = qx.max(qy).min(0.0);
    len_max_q + min_max_q - r
}

// OPTIMIZED DRAWING: Writes directly to cached buffer
// Defers expensive atan2 until after visibility check
pub unsafe fn draw_direct_sdf_glow(
    pixels_ptr: *mut u32, 
    w: i32, 
    h: i32, 
    time_offset: f32,
    alpha_mult: f32,
    is_glowing: bool
) {
    if pixels_ptr.is_null() { return; }
    
    let pixels = std::slice::from_raw_parts_mut(pixels_ptr, (w * h) as usize);
    let bx = (w as f32) / 2.0;
    let by = (h as f32) / 2.0;
    let center_x = bx;
    let center_y = by;
    let eff_radius = CORNER_RADIUS.min(bx).min(by);

    // ADAPTIVE GLOW SCALING: Scale based on window size to keep center hollow
    // For small windows (e.g., 100px): scales to ~20px glow
    // For large windows (e.g., 600px+): scales to 60px glow
    let min_dim = (w as f32).min(h as f32);
    let dynamic_base_scale = (min_dim * 0.2).clamp(20.0, 60.0);

    // Optimization: Skip the middle of the box to save CPU
    // Increase margin slightly to ensure we don't process internal pixels
    let safe_margin = 85.0;
    let skip_min_x = center_x - bx + safe_margin;
    let skip_max_x = center_x + bx - safe_margin;
    let skip_min_y = center_y - by + safe_margin;
    let skip_max_y = center_y + by - safe_margin;
    
    // Pre-calculate constants outside loop
    let time_rad = time_offset.to_radians();
    let glow_threshold = -dynamic_base_scale * 1.5;

    for y in 0..h {
        let py = (y as f32) - center_y;
        let fy = y as f32;
        let is_y_safe = fy > skip_min_y && fy < skip_max_y;
        
        for x in 0..w {
            let idx = (y * w + x) as usize;
            
            // Fast Path: Clear middle pixels and skip math entirely
            if is_y_safe && (x as f32) > skip_min_x && (x as f32) < skip_max_x {
                pixels[idx] = 0;
                continue;
            }

            let px = (x as f32) - center_x;
            
            // Standard SDF Logic
            let qx = px.abs() - bx + eff_radius;
            let qy = py.abs() - by + eff_radius;
            let d = if qx > 0.0 && qy > 0.0 { 
                ((qx * qx + qy * qy).sqrt()) - eff_radius 
            } else { 
                qx.max(qy) - eff_radius 
            };

            if d > 0.0 {
                // Border Logic (Outer edge)
                // Use explicit bounds to avoid expensive clamp if outside
                if d > 2.0 {
                     pixels[idx] = 0;
                     continue;
                }
                
                let t = (d / 2.0).clamp(0.0, 1.0);
                let aa = 1.0 - t * t * (3.0 - 2.0 * t);
                
                if aa > 0.0 {
                     let a = (aa * 255.0 * alpha_mult) as u32;
                     pixels[idx] = (a << 24) | (a << 16) | (a << 8) | a;
                } else {
                     pixels[idx] = 0;
                }
            } else {
                // Inner Glow Logic
                if !is_glowing || d < glow_threshold {
                    pixels[idx] = 0;
                } else {
                    let dist_in = d.abs();
                    
                    // OPTIMIZATION: Lazy Math
                    // Only calculate atan2/sin/cos (Expensive!) if pixel is actually visible.
                    // Use rough intensity check first to skip pixels that are too faint.
                    
                    let t_rough = (dist_in / (dynamic_base_scale * 1.4)).clamp(0.0, 1.0);
                    let base_intensity_rough = (1.0 - t_rough).powi(3);
                    
                    if base_intensity_rough < 0.005 {
                        pixels[idx] = 0;
                        continue;
                    }

                    // Now perform expensive math only for visible pixels
                    let angle = py.atan2(px);
                    let noise = (angle * 4.0 + time_rad * 2.0).sin() * 0.5; 
                    let local_glow_width = dynamic_base_scale + (noise * (dynamic_base_scale * 0.4));
                    
                    let t = (dist_in / local_glow_width).clamp(0.0, 1.0);
                    let intensity = (1.0 - t).powi(3);
                    let final_alpha = if dist_in < 3.0 { 1.0 } else { intensity };
                    
                    if final_alpha > 0.005 {
                         let deg = angle.to_degrees() + 180.0;
                         let hue = (deg + time_offset) % 360.0;
                         
                         let rgb = if dist_in < 2.5 { 0x00FFFFFF } else { hsv_to_rgb(hue, 0.8, 1.0) };
                         
                         let a = (final_alpha * 255.0 * alpha_mult) as u32;
                         let r = ((rgb >> 16) & 0xFF) * a / 255;
                         let g = ((rgb >> 8) & 0xFF) * a / 255;
                         let b = (rgb & 0xFF) * a / 255;
                         
                         pixels[idx] = (a << 24) | (r << 16) | (g << 8) | b;
                    } else {
                        pixels[idx] = 0;
                    }
                }
            }
        }
    }
}

// === MINIMAL GRAPHICS MODE ===
// Super lightweight rendering for weak computers.
// Only draws: white border + bouncing green scan line.
// NO per-pixel SDF calculations, NO trigonometry, NO expensive math.
// This is inspired by the old working version that never crashed.
pub unsafe fn draw_minimal_glow(
    pixels_ptr: *mut u32, 
    w: i32, 
    h: i32, 
    time_offset: f32,
    _alpha_mult: f32,
    is_glowing: bool
) {
    if pixels_ptr.is_null() { return; }
    
    let pixels = std::slice::from_raw_parts_mut(pixels_ptr, (w * h) as usize);
    
    // Clear all pixels first (transparent)
    for pixel in pixels.iter_mut() {
        *pixel = 0;
    }
    
    // Draw white border (1 pixel thick)
    let white: u32 = 0xFFFFFFFF; // ARGB: fully opaque white
    
    // Top and bottom edges
    for x in 0..w {
        pixels[x as usize] = white; // Top row
        pixels[((h - 1) * w + x) as usize] = white; // Bottom row
    }
    // Left and right edges
    for y in 0..h {
        pixels[(y * w) as usize] = white; // Left column
        pixels[(y * w + w - 1) as usize] = white; // Right column
    }
    
    // Draw bouncing green scan line if glowing (processing)
    if is_glowing {
        // Use time_offset to calculate scan line position
        // The scan line bounces up and down between 2px from edges
        let cycle = (time_offset % 360.0) / 180.0; // 0.0 to 2.0
        let t = if cycle <= 1.0 { cycle } else { 2.0 - cycle }; // 0.0 to 1.0 (bounce)
        
        let margin = 3;
        let scan_range = h - (margin * 2);
        if scan_range > 0 {
            let scan_y = margin + ((t * scan_range as f32) as i32).clamp(0, scan_range - 1);
            
            // Draw 2px thick green line
            let green: u32 = 0xFF00FF00; // ARGB: fully opaque green
            for line_offset in 0..2 {
                let y = scan_y + line_offset;
                if y > 0 && y < h - 1 {
                    for x in margin..(w - margin) {
                        pixels[(y * w + x) as usize] = green;
                    }
                }
            }
        }
    }
}
</file>

<file path="src/overlay/preset_wheel/html.rs">
// Preset Wheel HTML - Apple Watch fisheye with center-out ripple animation

use crate::config::Preset;
use crate::gui::settings_ui::get_localized_preset_name;

pub fn escape_html(s: &str) -> String {
    s.replace('&', "&amp;")
        .replace('<', "&lt;")
        .replace('>', "&gt;")
        .replace('"', "&quot;")
        .replace('\'', "&#39;")
}

/// Calculate balanced row distribution using ratio-based "square-squeeze" algorithm
/// Pills are ~3x wider than tall, so we use sqrt(n/2) for columns to get more rows than columns
/// This creates visually square/rectangular clumps: 5→[3,2], 10→[4,3,3], 25→[5,5,5,5,5]
fn calculate_row_distribution(n: usize) -> Vec<usize> {
    if n == 0 {
        return vec![];
    }

    if n == 1 {
        return vec![1];
    }

    // Ratio-based: pills are ~130px wide, ~40px tall (ratio ~3:1)
    // For a visually square clump, use fewer columns than pure sqrt would give
    // cols = ceil(sqrt(n / squish_factor)) where squish_factor accounts for aspect ratio
    let squish_factor = 1.5; // Balance between rows and columns
    let cols = ((n as f64 / squish_factor).sqrt().ceil() as usize).max(1);

    // Calculate number of rows needed
    let num_rows = (n + cols - 1) / cols;

    // Calculate base items per row and remainder
    let base = n / num_rows;
    let remainder = n % num_rows;

    // Distribute evenly: first 'remainder' rows get base+1
    let mut rows = Vec::with_capacity(num_rows);
    for i in 0..num_rows {
        if i < remainder {
            rows.push(base + 1);
        } else {
            rows.push(base);
        }
    }

    rows
}

/// Helper to generate just the items HTML (used for dynamic updates)
/// Uses fixed row layout to prevent reflow during animations
pub fn generate_items_html(presets: &[(usize, Preset)], ui_lang: &str) -> String {
    let n = presets.len();
    let row_distribution = calculate_row_distribution(n);

    let mut html = String::new();
    let mut item_idx = 0;

    for (row_idx, &items_in_row) in row_distribution.iter().enumerate() {
        html.push_str(&format!(
            r#"<div class="preset-row" data-row="{}">"#,
            row_idx
        ));

        for _ in 0..items_in_row {
            if item_idx < presets.len() {
                let (idx, preset) = &presets[item_idx];
                let name = escape_html(&get_localized_preset_name(&preset.id, ui_lang));
                let color_class = format!("color-{}", item_idx % 12);
                html.push_str(&format!(
                    r#"<div class="preset-item {}" data-idx="{}" data-item="{}" onclick="select({})">{}</div>"#,
                    color_class, idx, item_idx, idx, name
                ));
                item_idx += 1;
            }
        }

        html.push_str("</div>");
    }

    html
}

/// Returns the static HTML skeleton with CSS and JS (loaded once)
pub fn get_wheel_template(is_dark: bool) -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();
    let css = generate_css(is_dark);
    let js = get_js();

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style id="font-style">
{font_css}
</style>
<style id="theme-style">
{css}
</style>
</head>
<body>
<div class="container">
    <div class="dismiss-btn" onclick="dismiss()">CANCEL</div>
    <div class="presets-grid" id="grid">
        <!-- Items will be injected here -->
    </div>
</div>
<script>
{js}
</script>
</body>
</html>"#
    )
}

/// Generate CSS for the wheel with light/dark theme support
pub fn generate_css(is_dark: bool) -> String {
    // Theme-specific colors
    let (
        text_color,
        dismiss_bg,
        dismiss_border,
        dismiss_color,
        dismiss_hover_bg,
        dismiss_hover_border,
        item_border,
        item_hover_border,
        item_shadow,
    ) = if is_dark {
        (
            "#ffffff",
            "rgba(20, 20, 25, 0.75)",
            "rgba(255, 255, 255, 0.12)",
            "rgba(255, 180, 180, 0.85)",
            "rgba(60, 30, 30, 0.85)",
            "rgba(255, 150, 150, 0.4)",
            "rgba(255, 255, 255, 0.15)",
            "rgba(255, 255, 255, 0.5)",
            "0 5px 18px rgba(0, 0, 0, 0.35)",
        )
    } else {
        // Light mode colors
        (
            "#222222",
            "rgba(255, 255, 255, 0.85)",
            "rgba(0, 0, 0, 0.1)",
            "rgba(180, 60, 60, 0.9)",
            "rgba(255, 220, 220, 0.95)",
            "rgba(200, 100, 100, 0.4)",
            "rgba(0, 0, 0, 0.12)",
            "rgba(0, 0, 0, 0.3)",
            "0 5px 18px rgba(0, 0, 0, 0.15)",
        )
    };

    // Color palettes for dark and light modes
    let color_palette = if is_dark {
        // Dark mode - Deep Glass (Rich, saturated, premium)
        r#"
.color-0  { background: rgba(30, 60, 110, 0.85); border-color: rgba(100, 150, 255, 0.3); } /* Deep Blue */
.color-1  { background: rgba(35, 80, 45, 0.85);  border-color: rgba(100, 255, 120, 0.3); } /* Deep Green */
.color-2  { background: rgba(90, 30, 35, 0.85);  border-color: rgba(255, 100, 110, 0.3); } /* Deep Red */
.color-3  { background: rgba(70, 35, 90, 0.85);  border-color: rgba(200, 120, 255, 0.3); } /* Deep Purple */
.color-4  { background: rgba(90, 60, 20, 0.85);  border-color: rgba(255, 180, 80, 0.3); }  /* Deep Orange */
.color-5  { background: rgba(20, 75, 85, 0.85);  border-color: rgba(80, 230, 255, 0.3); }  /* Deep Teal */
.color-6  { background: rgba(85, 30, 85, 0.85);  border-color: rgba(255, 100, 255, 0.3); } /* Deep Magenta */
.color-7  { background: rgba(30, 70, 100, 0.85); border-color: rgba(100, 200, 255, 0.3); } /* Deep Sky */
.color-8  { background: rgba(65, 80, 20, 0.85);  border-color: rgba(200, 255, 80, 0.3); }  /* Deep Lime */
.color-9  { background: rgba(90, 20, 60, 0.85);  border-color: rgba(255, 80, 150, 0.3); }  /* Deep Pink */
.color-10 { background: rgba(20, 80, 70, 0.85);  border-color: rgba(80, 255, 200, 0.3); }  /* Deep Cyan */
.color-11 { background: rgba(90, 50, 30, 0.85);  border-color: rgba(255, 140, 80, 0.3); }  /* Deep Amber */

.color-0.hovered  { background: rgba(50, 100, 180, 0.95); box-shadow: 0 0 15px rgba(60, 120, 255, 0.4); }
.color-1.hovered  { background: rgba(50, 140, 70, 0.95);  box-shadow: 0 0 15px rgba(80, 255, 100, 0.4); }
.color-2.hovered  { background: rgba(160, 50, 60, 0.95);  box-shadow: 0 0 15px rgba(255, 80, 90, 0.4); }
.color-3.hovered  { background: rgba(120, 60, 160, 0.95); box-shadow: 0 0 15px rgba(180, 100, 255, 0.4); }
.color-4.hovered  { background: rgba(160, 100, 40, 0.95); box-shadow: 0 0 15px rgba(255, 160, 60, 0.4); }
.color-5.hovered  { background: rgba(40, 130, 150, 0.95); box-shadow: 0 0 15px rgba(60, 220, 255, 0.4); }
.color-6.hovered  { background: rgba(150, 50, 150, 0.95); box-shadow: 0 0 15px rgba(255, 80, 255, 0.4); }
.color-7.hovered  { background: rgba(50, 120, 170, 0.95); box-shadow: 0 0 15px rgba(80, 180, 255, 0.4); }
.color-8.hovered  { background: rgba(110, 140, 40, 0.95); box-shadow: 0 0 15px rgba(180, 255, 60, 0.4); }
.color-9.hovered  { background: rgba(160, 40, 100, 0.95); box-shadow: 0 0 15px rgba(255, 60, 140, 0.4); }
.color-10.hovered { background: rgba(40, 140, 120, 0.95); box-shadow: 0 0 15px rgba(60, 255, 200, 0.4); }
.color-11.hovered { background: rgba(160, 80, 50, 0.95);  box-shadow: 0 0 15px rgba(255, 120, 60, 0.4); }"#
    } else {
        // Light mode - softer pastel colors
        r#"
.color-0  { background: rgba(200, 220, 255, 0.95); }
.color-1  { background: rgba(200, 235, 200, 0.95); }
.color-2  { background: rgba(255, 210, 210, 0.95); }
.color-3  { background: rgba(230, 210, 255, 0.95); }
.color-4  { background: rgba(255, 230, 200, 0.95); }
.color-5  { background: rgba(200, 240, 240, 0.95); }
.color-6  { background: rgba(240, 210, 245, 0.95); }
.color-7  { background: rgba(210, 230, 250, 0.95); }
.color-8  { background: rgba(235, 235, 200, 0.95); }
.color-9  { background: rgba(255, 210, 235, 0.95); }
.color-10 { background: rgba(200, 245, 240, 0.95); }
.color-11 { background: rgba(255, 225, 210, 0.95); }

.color-0.hovered  { background: rgba(130, 180, 255, 0.98); }
.color-1.hovered  { background: rgba(130, 200, 130, 0.98); }
.color-2.hovered  { background: rgba(255, 150, 150, 0.98); }
.color-3.hovered  { background: rgba(190, 150, 255, 0.98); }
.color-4.hovered  { background: rgba(255, 190, 120, 0.98); }
.color-5.hovered  { background: rgba(100, 220, 220, 0.98); }
.color-6.hovered  { background: rgba(220, 150, 230, 0.98); }
.color-7.hovered  { background: rgba(140, 190, 255, 0.98); }
.color-8.hovered  { background: rgba(200, 200, 120, 0.98); }
.color-9.hovered  { background: rgba(255, 150, 200, 0.98); }
.color-10.hovered { background: rgba(80, 210, 200, 0.98); }
.color-11.hovered { background: rgba(255, 170, 130, 0.98); }"#
    };

    format!(
        r#"
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
html, body {{
    width: 100%;
    height: 100%;
    overflow: hidden;
    background: transparent;
    font-family: 'Google Sans Flex', 'Segoe UI Variable Text', 'Segoe UI', system-ui, sans-serif;
    font-variation-settings: 'wght' 500, 'wdth' 100, 'ROND' 100;
    user-select: none;
    color: {text_color};
}}

.container {{
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    min-height: 100%;
    padding: 40px;
    gap: 10px;
}}

/* Cancel button - frosted glass, distinct from colorful presets */
.dismiss-btn {{
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 12px 36px;
    margin-bottom: 16px;
    background: {dismiss_bg};
    backdrop-filter: blur(16px);
    border: 1px solid {dismiss_border};
    border-radius: 24px;
    cursor: pointer;
    font-size: 14px;
    letter-spacing: 3px;
    text-transform: uppercase;
    font-variation-settings: 'wght' 600, 'wdth' 125, 'ROND' 100;
    color: {dismiss_color};
    
    opacity: 0;
    transform: scale(0.5);
    transition: 
        transform 0.2s cubic-bezier(0.22, 1, 0.36, 1),
        opacity 0.15s ease-out,
        background 0.1s ease,
        border-color 0.1s ease,
        box-shadow 0.1s ease,
        color 0.1s ease,
        font-variation-settings 0.15s ease;
}}

.dismiss-btn.visible {{
    opacity: 1;
    transform: scale(1);
}}

.dismiss-btn:hover {{
    background: {dismiss_hover_bg};
    border-color: {dismiss_hover_border};
    box-shadow: 0 4px 20px rgba(0, 0, 0, 0.2);
    color: {text_color};
    font-variation-settings: 'wght' 700, 'wdth' 105, 'ROND' 100;
}}

.dismiss-btn:active {{
    transform: scale(0.92) !important;
}}

/* Fixed row-based layout - prevents reflow during animations */
.presets-grid {{
    display: flex;
    flex-direction: column;
    align-items: center;
    justify-content: center;
    gap: 10px;
    padding: 20px;
}}

/* Each row is a flex container with fixed item count */
.preset-row {{
    display: flex;
    flex-direction: row;
    justify-content: center;
    align-items: center;
    gap: 10px;
    min-height: 40px;
}}

.preset-item {{
    display: inline-flex;
    align-items: center;
    justify-content: center;
    padding: 9px 14px;
    min-width: 85px;
    backdrop-filter: blur(12px);
    border: 1px solid {item_border};
    border-radius: 15px;
    cursor: pointer;
    font-size: 12px;
    white-space: nowrap;
    letter-spacing: 0;
    color: {text_color};
    
    opacity: 0;
    transform: scale(0.8);
    
    transition: 
        transform 0.15s cubic-bezier(0.22, 1, 0.36, 1),
        opacity 0.15s ease-out,
        background 0.1s ease,
        box-shadow 0.1s ease,
        border-color 0.1s ease,
        font-variation-settings 0.1s ease,
        letter-spacing 0.1s ease;
}}

.preset-item.visible {{
    opacity: 1;
    transform: scale(1);
}}

{color_palette}

.preset-item.hovered {{
    border-color: {item_hover_border};
    box-shadow: {item_shadow};
    font-variation-settings: 'wght' 650, 'wdth' 90, 'ROND' 100;
    letter-spacing: 0.5px;
}}

.preset-item:active {{
    transform: scale(0.88) !important;
    transition: transform 0.05s ease !important;
}}
"#,
        text_color = text_color,
        dismiss_bg = dismiss_bg,
        dismiss_border = dismiss_border,
        dismiss_color = dismiss_color,
        dismiss_hover_bg = dismiss_hover_bg,
        dismiss_hover_border = dismiss_hover_border,
        item_border = item_border,
        item_hover_border = item_hover_border,
        item_shadow = item_shadow,
        color_palette = color_palette
    )
}

fn get_js() -> &'static str {
    r#"
function select(idx) {
    window.ipc.postMessage('select:' + idx);
}

function dismiss() {
    window.ipc.postMessage('dismiss');
}

// === Apple Watch Fisheye Effect ===
const grid = document.getElementById('grid');
let items = []; // Will be updated on content load
const dismissBtn = document.querySelector('.dismiss-btn');

// Tuned constants - NO shrinking, only scale up hovered item
const MAX_SCALE = 1.10;
const MIN_SCALE = 1.0;
const EFFECT_RADIUS = 80;
const BASE_WEIGHT = 500;     
const MAX_WEIGHT = 650;      
const BASE_WIDTH = 100;      
const MAX_WIDTH = 104;       

let animationFrame = null;
let mouseX = -1000;
let mouseY = -1000;
let isMouseInGrid = false;

// Cache item positions to avoid getBoundingClientRect returning scaled positions
// This fixes the cursor position vs hover mismatch issue
let itemCenters = new Map();

function cacheItemPositions() {
    // Reset all items to scale(1) to get accurate positions
    items.forEach(item => {
        item.style.transform = 'scale(1)';
    });
    
    // Cache the original center positions (before any scaling)
    itemCenters.clear();
    items.forEach(item => {
        const rect = item.getBoundingClientRect();
        itemCenters.set(item, {
            x: rect.left + rect.width / 2,
            y: rect.top + rect.height / 2
        });
    });
}

function getItemCenter(item) {
    // Use cached position if available
    const cached = itemCenters.get(item);
    if (cached) return cached;
    
    // Fallback to live calculation
    const rect = item.getBoundingClientRect();
    return {
        x: rect.left + rect.width / 2,
        y: rect.top + rect.height / 2
    };
}

function isMouseInRect(rect) {
    return mouseX >= rect.left && mouseX <= rect.right && 
           mouseY >= rect.top && mouseY <= rect.bottom;
}

function updateFisheye() {
    items.forEach(item => {
        if (!item.classList.contains('visible')) return;
        
        // For fisheye scaling, use cached centers
        const center = getItemCenter(item);
        const dx = mouseX - center.x;
        const dy = mouseY - center.y;
        const distance = Math.sqrt(dx * dx + dy * dy);
        
        let influence = isMouseInGrid ? Math.max(0, 1 - distance / EFFECT_RADIUS) : 0;
        influence = influence * influence * (3 - 2 * influence); // smoothstep
        
        // Only scale UP - never below 1.0
        const scale = MIN_SCALE + (MAX_SCALE - MIN_SCALE) * influence;
        
        // For hover detection, check if mouse is actually inside this pill
        const rect = item.getBoundingClientRect();
        const isHovered = isMouseInGrid && isMouseInRect(rect);
        
        if (isHovered) {
            item.classList.add('hovered');
            // Let CSS handle font styling for hovered items
            item.style.fontVariationSettings = '';
            item.style.letterSpacing = '';
        } else {
            item.classList.remove('hovered');
            // Apply fisheye font effect for non-hovered items
            const weight = BASE_WEIGHT + (MAX_WEIGHT - BASE_WEIGHT) * influence;
            const width = BASE_WIDTH + (MAX_WIDTH - BASE_WIDTH) * influence;
            item.style.fontVariationSettings = `'wght' ${weight.toFixed(0)}, 'wdth' ${width.toFixed(0)}, 'ROND' 100`;
            item.style.letterSpacing = '0';
        }
        
        item.style.transform = `scale(${scale.toFixed(3)})`;
    });
}

function onMouseMove(e) {
    mouseX = e.clientX;
    mouseY = e.clientY;
    
    if (!animationFrame) {
        animationFrame = requestAnimationFrame(() => {
            updateFisheye();
            animationFrame = null;
        });
    }
}

function onMouseEnter() {
    isMouseInGrid = true;
}

function onMouseLeave() {
    isMouseInGrid = false;
    mouseX = -1000;
    mouseY = -1000;
    
    items.forEach(item => {
        item.style.transform = 'scale(1)';
        item.style.fontVariationSettings = `'wght' ${BASE_WEIGHT}, 'wdth' ${BASE_WIDTH}, 'ROND' 100`;
        item.classList.remove('hovered');
    });
}

grid.addEventListener('mousemove', onMouseMove);
grid.addEventListener('mouseenter', onMouseEnter);
grid.addEventListener('mouseleave', onMouseLeave);

document.querySelector('.container').addEventListener('mousemove', (e) => {
    const gridRect = grid.getBoundingClientRect();
    const padding = 35;
    if (e.clientX >= gridRect.left - padding && 
        e.clientX <= gridRect.right + padding &&
        e.clientY >= gridRect.top - padding && 
        e.clientY <= gridRect.bottom + padding) {
        onMouseMove(e);
    }
});

// === Animate in from CENTER outward (ripple effect) ===
function animateIn() {
    // Get window center (cursor should be near center when wheel opens)
    const windowCenterX = window.innerWidth / 2;
    const windowCenterY = window.innerHeight / 2;
    
    // Calculate distance of each item from center
    const itemsWithDistance = items.map(item => {
        const rect = item.getBoundingClientRect();
        const itemCenterX = rect.left + rect.width / 2;
        const itemCenterY = rect.top + rect.height / 2;
        const dx = itemCenterX - windowCenterX;
        const dy = itemCenterY - windowCenterY;
        const distance = Math.sqrt(dx * dx + dy * dy);
        return { item, distance };
    });
    
    // Sort by distance (closest to center first)
    itemsWithDistance.sort((a, b) => a.distance - b.distance);

    // Dismiss button first (it's at top center)
    setTimeout(() => dismissBtn.classList.add('visible'), 0);
    
    // Then items in ripple order from center out - fast stagger
    itemsWithDistance.forEach(({ item }, i) => {
        setTimeout(() => item.classList.add('visible'), i * 12);
    });
    
    // Cache positions AFTER animation completes (when items are at scale(1))
    // Wait for all items to animate in + some buffer
    const totalAnimationTime = itemsWithDistance.length * 12 + 150;
    setTimeout(() => cacheItemPositions(), totalAnimationTime);
}

// Function called by Rust to update content and trigger animation
window.updateContent = function(itemsHtml, dismissLabel) {
    grid.innerHTML = itemsHtml;
    dismissBtn.innerText = dismissLabel;
    
    // Re-query items - now nested in .preset-row divs
    items = Array.from(document.querySelectorAll('.preset-item'));
    
    // Clear cached positions
    itemCenters.clear();
    
    // Reset visibility state BEFORE window becomes visible
    dismissBtn.classList.remove('visible');
    items.forEach(item => item.classList.remove('visible'));
    
    // Notify Rust we are ready to be visible
    setTimeout(() => {
        window.ipc.postMessage('ready_to_show');
        // Start animation after a tiny delay to ensure window is shown
        setTimeout(() => requestAnimationFrame(animateIn), 16);
        
        // Fallback: force visible after 300ms if animation didn't work
        setTimeout(() => {
            dismissBtn.classList.add('visible');
            items.forEach(item => item.classList.add('visible'));
        }, 300);
    }, 0);
};

document.addEventListener('keydown', (e) => {
    if (e.key === 'Escape') dismiss();
});
    "#
}
</file>

<file path="src/overlay/preset_wheel/mod.rs">
// Preset Wheel Overlay - Modern WebView2 implementation
// Shows a beautiful wheel of preset options for MASTER presets

mod html;
mod window;

pub use window::{dismiss_wheel, is_wheel_active, show_preset_wheel, warmup};
</file>

<file path="src/overlay/process/mod.rs">
pub mod chain;
pub mod pipeline;
pub mod types;
pub mod window;

pub use pipeline::*;
</file>

<file path="src/overlay/process/pipeline.rs">
use crate::win_types::SendHwnd;
use image::{ImageBuffer, Rgba};
use std::sync::{atomic::AtomicBool, Arc, Mutex};
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::{
    GetMonitorInfoW, MonitorFromRect, MONITORINFO, MONITOR_DEFAULTTONEAREST,
};
use windows::Win32::UI::WindowsAndMessaging::*;

use crate::config::{Config, Preset};
use crate::model_config::model_is_non_llm;
use crate::overlay::preset_wheel;
use crate::overlay::result::{self, RefineContext};
use crate::overlay::text_input;

use super::chain::{execute_chain_pipeline, execute_chain_pipeline_with_token, run_chain_step};
use super::types::generate_chain_id;
use super::window::create_processing_window;

// Track last result window rect for continuous mode snaking
lazy_static::lazy_static! {
    static ref LAST_RESULT_RECT: Arc<Mutex<Option<RECT>>> = Arc::new(Mutex::new(None));
}

// --- ENTRY POINTS ---

pub fn start_text_processing(
    initial_text_content: String,
    screen_rect: RECT,
    config: Config,
    preset: Preset,
    localized_preset_name: String, // Already localized by caller
    cancel_hotkey_name: String,    // The actual hotkey name like "Ctrl+Shift+D"
) {
    if preset.text_input_mode == "type" {
        // Use blocks[0].prompt instead of legacy preset.prompt
        let first_block_prompt = preset
            .blocks
            .first()
            .map(|b| b.prompt.as_str())
            .unwrap_or("");

        // Also check if model is non-LLM (doesn't use prompts)
        let first_block_model = preset
            .blocks
            .first()
            .map(|b| b.model.as_str())
            .unwrap_or("");

        let guide_text = if first_block_prompt.is_empty() || model_is_non_llm(first_block_model) {
            localized_preset_name
        } else {
            format!("{}...", localized_preset_name)
        };

        let config_shared = Arc::new(config.clone());
        let preset_shared = Arc::new(preset.clone());
        let ui_lang = config.ui_language.clone();
        // For MASTER presets: always keep window open initially (continuous_mode=true)
        // We'll decide whether to close based on the SELECTED preset after wheel selection
        let continuous_mode = if preset.is_master {
            true
        } else {
            preset.continuous_input
        };

        // For continuous mode: store the previous chain's cancellation token so we can close old windows
        let last_cancel_token: Arc<Mutex<Option<std::sync::Arc<std::sync::atomic::AtomicBool>>>> =
            Arc::new(Mutex::new(None));
        let last_cancel_token_clone = last_cancel_token.clone();

        // Check if this is a MASTER preset
        let is_master = preset.is_master;

        // CRITICAL: For MASTER presets, store the selected preset index after first wheel selection.
        // Subsequent Enter presses will use this stored preset directly (no wheel).
        // The text input window "transfers" to the selected preset.
        let selected_preset_idx: Arc<Mutex<Option<usize>>> = Arc::new(Mutex::new(None));
        let selected_preset_idx_clone = selected_preset_idx.clone();

        // Reset snaking state for new session
        *LAST_RESULT_RECT.lock().unwrap() = None;

        text_input::show(
            guide_text,
            ui_lang,
            cancel_hotkey_name,
            continuous_mode,
            move |user_text, input_hwnd| {
                // Check if we already selected a preset from the wheel (subsequent submissions)
                let already_selected = selected_preset_idx_clone.lock().unwrap().clone();

                let (final_preset, final_config, is_continuous) = if let Some(preset_idx) =
                    already_selected
                {
                    // Already selected from wheel previously - use that preset directly (no wheel)
                    let app = crate::APP.lock().unwrap();
                    let p = app.config.presets[preset_idx].clone();
                    let c = app.config.clone();
                    let continuous = p.continuous_input;

                    // Update UI header just in case (e.g. if it reverted or missed an update)
                    let localized_name =
                        crate::gui::settings_ui::get_localized_preset_name(&p.id, &c.ui_language);
                    text_input::update_ui_text(localized_name);

                    (p, c, continuous)
                } else if is_master {
                    // First time MASTER preset - show the preset wheel
                    let mut cursor_pos = POINT::default();
                    unsafe {
                        let _ = GetCursorPos(&mut cursor_pos);
                    }

                    // Show preset wheel - this blocks until user makes selection
                    let selected =
                        preset_wheel::show_preset_wheel("text", Some("type"), cursor_pos);

                    if let Some(idx) = selected {
                        // Store the selected preset index for subsequent submissions
                        *selected_preset_idx_clone.lock().unwrap() = Some(idx);

                        // Refocus the text input window and editor after wheel closes
                        text_input::refocus_editor();

                        // Get the selected preset from config AND update active_preset_idx
                        let mut app = crate::APP.lock().unwrap();
                        // CRITICAL: Update active_preset_idx so auto_paste logic works!
                        app.config.active_preset_idx = idx;
                        let p = app.config.presets[idx].clone();
                        let c = app.config.clone();
                        let continuous = p.continuous_input;

                        // Update UI header with the new preset's name
                        let localized_name = crate::gui::settings_ui::get_localized_preset_name(
                            &p.id,
                            &c.ui_language,
                        );
                        // Find first hotkey name for this preset if available
                        let hk_name = p
                            .hotkeys
                            .first()
                            .map(|h| h.name.clone())
                            .unwrap_or_default();

                        let new_guide_text = if !hk_name.is_empty() {
                            format!("{} [{}]", localized_name, hk_name)
                        } else {
                            localized_name
                        };
                        text_input::update_ui_text(new_guide_text);

                        (p, c, continuous)
                    } else {
                        // User dismissed wheel - refocus and allow retry
                        text_input::refocus_editor();
                        return;
                    }
                } else {
                    // Normal non-MASTER preset
                    let is_continuous = (*preset_shared).continuous_input;
                    (
                        (*preset_shared).clone(),
                        (*config_shared).clone(),
                        is_continuous,
                    )
                };

                if !is_continuous {
                    // Normal mode: close input window
                    unsafe {
                        let _ = PostMessageW(Some(input_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                } else {
                    // Continuous mode: close previous result overlays before spawning new ones
                    if let Ok(token_guard) = last_cancel_token_clone.lock() {
                        if let Some(ref old_token) = *token_guard {
                            // Close windows from previous submission
                            result::close_windows_with_token(old_token);
                        }
                    }
                }

                let overlay_rect = if is_continuous {
                    if let Some(input_rect) = text_input::get_window_rect() {
                        // Calculate Ideal "Under Input" Position
                        // 1. Height: Same as input window
                        // 2. Width: 90% of input window
                        // 3. Position: Centered below input window
                        let input_w = input_rect.right - input_rect.left;
                        let input_h = input_rect.bottom - input_rect.top;

                        let shrink_total = input_w / 10; // 10% shrink
                        let new_w = input_w - shrink_total;

                        let center_x = input_rect.left + (input_w / 2);
                        let left = center_x - (new_w / 2);
                        let new_h = input_h;

                        let ideal_rect = RECT {
                            left,
                            top: input_rect.bottom + 10, // 10px gap below input window
                            right: left + new_w,
                            bottom: input_rect.bottom + 10 + new_h,
                        };

                        // Get monitor rect for boundary checking
                        let monitor_rect = unsafe {
                            let h_monitor = MonitorFromRect(&input_rect, MONITOR_DEFAULTTONEAREST);
                            let mut mi = MONITORINFO::default();
                            mi.cbSize = std::mem::size_of::<MONITORINFO>() as u32;
                            if GetMonitorInfoW(h_monitor, &mut mi).as_bool() {
                                mi.rcMonitor
                            } else {
                                // Fallback to primary screen metrics if monitor detection fails
                                RECT {
                                    left: 0,
                                    top: 0,
                                    right: GetSystemMetrics(SM_CXSCREEN),
                                    bottom: GetSystemMetrics(SM_CYSCREEN),
                                }
                            }
                        };

                        // First window: place at ideal_rect directly (under input)
                        // Subsequent windows: snake from last result window
                        let final_rect =
                            if let Some(last_rect) = LAST_RESULT_RECT.lock().unwrap().clone() {
                                // Second+ window: snake from previous result window
                                crate::overlay::result::layout::calculate_next_window_rect(
                                    last_rect,
                                    monitor_rect,
                                )
                            } else {
                                // First window: use ideal position directly
                                ideal_rect
                            };

                        // Store this rect as the last result window for next iteration
                        *LAST_RESULT_RECT.lock().unwrap() = Some(final_rect);

                        final_rect
                    } else {
                        screen_rect
                    }
                } else {
                    screen_rect
                };

                // Start processing and track the new cancellation token for continuous mode
                let config_clone = final_config;
                let preset_clone = final_preset;
                let last_token_update = last_cancel_token_clone.clone();

                // Reset last result rect for new submission (prevent stale rects from previous chain)
                // Reset last result rect is REMOVED to allow snaking in continuous mode
                // *LAST_RESULT_RECT.lock().unwrap() = None;

                let input_hwnd_send = SendHwnd(input_hwnd);
                std::thread::spawn(move || {
                    // Create a new cancellation token for this chain
                    let new_token = std::sync::Arc::new(std::sync::atomic::AtomicBool::new(false));

                    // Store it for later cleanup (in continuous mode)
                    if let Ok(mut token_guard) = last_token_update.lock() {
                        *token_guard = Some(new_token.clone());
                    }

                    // Execute the chain
                    execute_chain_pipeline_with_token(
                        user_text,
                        overlay_rect,
                        config_clone,
                        preset_clone,
                        RefineContext::None,
                        new_token,
                        Some(input_hwnd_send),
                    );
                });
            },
        );
    } else if preset.prompt_mode == "dynamic" {
        // Dynamic prompt mode for text selection: show WebView input for user to type command
        let ui_lang = config.ui_language.clone();
        // Header shows just the localized preset name (hotkey goes to footer via cancel_hotkey_name)
        let guide_text = localized_preset_name.clone();

        // Store for use in callback
        let initial_text = Arc::new(initial_text_content);
        let config = Arc::new(config);
        let preset = Arc::new(preset);

        text_input::show(
            guide_text,
            ui_lang,
            cancel_hotkey_name,
            false,
            move |user_prompt, input_hwnd| {
                // Close the input window
                unsafe {
                    let _ = PostMessageW(Some(input_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }

                // Clone preset and modify the first block's prompt with user's input
                let mut modified_preset = (*preset).clone();
                if let Some(block0) = modified_preset.blocks.get_mut(0) {
                    if block0.prompt.is_empty() {
                        block0.prompt = user_prompt.clone();
                    } else {
                        block0.prompt =
                            format!("{}\n\nUser request: {}", block0.prompt, user_prompt);
                    }
                }

                let config_clone = (*config).clone();
                let initial_text_clone = (*initial_text).clone();

                // Execute the chain with modified preset
                std::thread::spawn(move || {
                    execute_chain_pipeline(
                        initial_text_clone,
                        screen_rect,
                        config_clone,
                        modified_preset,
                        RefineContext::None,
                    );
                });
            },
        );
    } else {
        execute_chain_pipeline(
            initial_text_content,
            screen_rect,
            config,
            preset,
            RefineContext::None,
        );
    }
}

pub fn show_audio_result(
    preset: Preset,
    transcription_text: String,
    wav_data: Vec<u8>, // Audio data for input overlay
    rect: RECT,
    _unused_rect: Option<RECT>,
    recording_hwnd: HWND, // Recording overlay window - keep alive until first visible block
    is_streaming_result: bool, // Explicit flag: if true, we disable auto-paste (real-time typing assumed)
) {
    let config = {
        let app = crate::APP.lock().unwrap();
        app.config.clone()
    };

    // Audio processing already completed Block 0 (audio recording/transcription).
    // Start at block 0 with skip_execution=true so it can display its overlay (if configured),
    // then the chain naturally continues to block 1, 2, etc.
    //
    // Pass the recording_hwnd as processing_indicator_hwnd - it will keep animating
    // until the first visible block appears (same behavior as image pipeline).
    let processing_hwnd = if unsafe {
        windows::Win32::UI::WindowsAndMessaging::IsWindow(Some(recording_hwnd)).as_bool()
    } {
        Some(recording_hwnd)
    } else {
        None
    };

    // Generate unique chain ID for this processing chain
    let chain_id = generate_chain_id();

    run_chain_step(
        0,
        transcription_text,
        rect,
        preset.blocks.clone(),
        preset.block_connections.clone(), // Graph connections
        config,
        Arc::new(Mutex::new(None)),
        RefineContext::Audio(wav_data), // Pass audio data for input overlay
        true, // skip_execution: audio already done, just display and chain forward
        processing_hwnd.map(SendHwnd), // Pass recording overlay - will close when first visible block appears
        Arc::new(AtomicBool::new(false)), // New chains start with cancellation = false
        preset.id.clone(),
        // Check if we should disable auto-paste (e.g. for Gemini Live real-time typing)
        is_streaming_result,
        chain_id, // Per-chain position tracking
        None,     // No input refocus for audio results
    );
}

pub fn start_processing_pipeline(
    cropped_img: ImageBuffer<Rgba<u8>, Vec<u8>>,
    screen_rect: RECT,
    config: Config,
    preset: Preset,
) {
    // If dynamic prompt mode, use WebView-based text input
    if preset.prompt_mode == "dynamic" && !preset.blocks.is_empty() {
        // For dynamic mode, encode PNG first (user will type prompt)
        let mut png_data = Vec::new();
        let _ = cropped_img.write_to(
            &mut std::io::Cursor::new(&mut png_data),
            image::ImageFormat::Png,
        );

        // Get localized UI elements
        let ui_lang = config.ui_language.clone();
        let localized_name =
            crate::gui::settings_ui::get_localized_preset_name(&preset.id, &ui_lang);
        let guide_text = format!("{}...", localized_name);
        let cancel_hotkey = preset
            .hotkeys
            .first()
            .map(|h| h.name.clone())
            .unwrap_or_default();

        // Store for use in callback
        let png_data = Arc::new(png_data);
        let config = Arc::new(config);
        let preset = Arc::new(preset);

        // Use WebView-based text input
        text_input::show(
            guide_text,
            ui_lang,
            cancel_hotkey,
            false,
            move |user_prompt, input_hwnd| {
                // Close the input window
                unsafe {
                    let _ = PostMessageW(Some(input_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }

                // Clone preset and modify the first actual processing block's prompt with user's input
                let mut modified_preset = (*preset).clone();
                if let Some(target_block) = modified_preset
                    .blocks
                    .iter_mut()
                    .find(|b| b.block_type != "input_adapter")
                {
                    if target_block.prompt.is_empty() {
                        target_block.prompt = user_prompt.clone();
                    } else {
                        target_block.prompt =
                            format!("{}\n\nUser request: {}", target_block.prompt, user_prompt);
                    }
                }

                // Context with image data
                let context = RefineContext::Image((*png_data).clone());
                let config_clone = (*config).clone();
                let graphics_mode = config_clone.graphics_mode.clone();

                // Create processing window IMMEDIATELY
                let processing_hwnd =
                    unsafe { create_processing_window(screen_rect, graphics_mode) };
                unsafe {
                    let _ =
                        SendMessageW(processing_hwnd, WM_TIMER, Some(WPARAM(1)), Some(LPARAM(0)));
                }

                // Generate unique chain ID for this processing chain
                let chain_id = generate_chain_id();

                // Spawn chain execution - reusing existing run_chain_step!
                let blocks = modified_preset.blocks.clone();
                let connections = modified_preset.block_connections.clone();
                let preset_id = modified_preset.id.clone();

                let processing_hwnd_send = SendHwnd(processing_hwnd);
                std::thread::spawn(move || {
                    run_chain_step(
                        0,
                        String::new(),
                        screen_rect,
                        blocks,
                        connections,
                        config_clone,
                        Arc::new(Mutex::new(None)),
                        context,
                        false,
                        Some(processing_hwnd_send),
                        Arc::new(AtomicBool::new(false)),
                        preset_id,
                        false,    // disable_auto_paste
                        chain_id, // Per-chain position tracking
                        None,     // No input refocus
                    );
                });

                // Keep processing window alive until closed
                unsafe {
                    let mut msg = MSG::default();
                    while GetMessageW(&mut msg, None, 0, 0).into() {
                        let _ = TranslateMessage(&msg);
                        DispatchMessageW(&msg);
                        if !IsWindow(Some(processing_hwnd)).as_bool() {
                            break;
                        }
                    }
                }
            },
        );
        return;
    }

    // STANDARD PIPELINE: Create processing window IMMEDIATELY, then encode PNG in background
    // This eliminates the delay between selection and animation appearing

    // 1. Create Processing Window FIRST (instant, no delay)
    let graphics_mode = config.graphics_mode.clone();
    let processing_hwnd = unsafe { create_processing_window(screen_rect, graphics_mode) };
    unsafe {
        let _ = SendMessageW(processing_hwnd, WM_TIMER, Some(WPARAM(1)), Some(LPARAM(0)));
    }

    // 2. Spawn background thread to encode PNG and start chain execution
    let conf_clone = config.clone();
    let blocks = preset.blocks.clone();
    let connections = preset.block_connections.clone();
    let preset_id = preset.id.clone();

    let processing_hwnd_val = processing_hwnd.0 as usize;
    std::thread::spawn(move || {
        let processing_hwnd = HWND(processing_hwnd_val as *mut std::ffi::c_void);
        // Heavy work: PNG encoding happens here, while animation plays
        let mut png_data = Vec::new();
        let _ = cropped_img.write_to(
            &mut std::io::Cursor::new(&mut png_data),
            image::ImageFormat::Png,
        );
        let context = RefineContext::Image(png_data);

        // Generate unique chain ID for this processing chain
        let chain_id = generate_chain_id();

        // Start chain execution with the pre-created processing window
        run_chain_step(
            0,
            String::new(),
            screen_rect,
            blocks,
            connections, // Graph connections
            conf_clone,
            Arc::new(Mutex::new(None)),
            context,
            false,
            Some(SendHwnd(processing_hwnd)), // Pass the handle to be closed later
            Arc::new(AtomicBool::new(false)), // New chains start with cancellation = false
            preset_id,
            false,    // disable_auto_paste
            chain_id, // Per-chain position tracking
            None,     // No input refocus
        );
    });

    // 3. Keep the Processing Window alive on this thread until it is destroyed by the worker
    unsafe {
        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
            if !IsWindow(Some(processing_hwnd)).as_bool() {
                break;
            }
        }
    }
}

pub fn start_processing_pipeline_parallel(
    rx: std::sync::mpsc::Receiver<Option<(ImageBuffer<Rgba<u8>, Vec<u8>>, Vec<u8>)>>,
    screen_rect: RECT,
    config: Config,
    preset: Preset,
) {
    // Dynamic prompt mode optimization is complex due to text input dependency
    // Fallback to blocking wait for dynamic mode (usually user input is the bottleneck anyway)
    if preset.prompt_mode == "dynamic" {
        if let Ok(Some((img, _))) = rx.recv() {
            start_processing_pipeline(img, screen_rect, config, preset);
        }
        return;
    }

    // STANDARD PIPELINE PARALLEL
    // 1. Create Processing Window FIRST (instant, no delay)
    let graphics_mode = config.graphics_mode.clone();
    let processing_hwnd = unsafe { create_processing_window(screen_rect, graphics_mode) };
    unsafe {
        let _ = SendMessageW(processing_hwnd, WM_TIMER, Some(WPARAM(1)), Some(LPARAM(0)));
    }

    // 2. Spawn background thread to wait for data, encode PNG and start chain execution
    let conf_clone = config.clone();
    let blocks = preset.blocks.clone();
    let connections = preset.block_connections.clone();
    let preset_id = preset.id.clone();
    let processing_hwnd_val = processing_hwnd.0 as usize;

    std::thread::spawn(move || {
        let processing_hwnd = HWND(processing_hwnd_val as *mut std::ffi::c_void);

        // WAIT FOR DATA - delays here won't freeze UI!
        if let Ok(Some((_cropped_img, original_bytes))) = rx.recv() {
            // Use original bytes directly (Zero-Copy/Zero-Encode)
            // This preserves JPEG format if input was JPEG
            let context = RefineContext::Image(original_bytes);

            // Generate unique chain ID for this processing chain
            let chain_id = generate_chain_id();

            // Start chain execution with the pre-created processing window
            run_chain_step(
                0,
                String::new(),
                screen_rect,
                blocks,
                connections,
                conf_clone,
                Arc::new(Mutex::new(None)),
                context,
                false,
                Some(SendHwnd(processing_hwnd)), // Pass the handle to be closed later
                Arc::new(AtomicBool::new(false)),
                preset_id,
                false,    // disable_auto_paste
                chain_id, // Per-chain position tracking
                None,     // No input refocus
            );
        } else {
            // Load failed or cancelled -> Close window immediately
            unsafe {
                let _ = PostMessageW(Some(processing_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
    });

    // 3. Keep the Processing Window alive on this thread until it is destroyed by the worker
    unsafe {
        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
            if !IsWindow(Some(processing_hwnd)).as_bool() {
                break;
            }
        }
    }
}
</file>

<file path="src/overlay/process/types.rs">
use crate::overlay::result::layout::calculate_next_window_rect;
use std::collections::HashMap;
use std::sync::Mutex;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::UI::WindowsAndMessaging::*;

pub const MAX_GLOW_BUFFER_DIM: i32 = 1280;

pub struct ProcessingState {
    pub animation_offset: f32,
    pub is_fading_out: bool,
    pub alpha: u8,
    pub cache_hbm: HBITMAP,
    pub cache_bits: *mut core::ffi::c_void,
    pub scaled_w: i32,
    pub scaled_h: i32,
    pub timer_killed: bool,
    pub graphics_mode: String,
}

unsafe impl Send for ProcessingState {}
unsafe impl Sync for ProcessingState {}

impl ProcessingState {
    pub fn new(graphics_mode: String) -> Self {
        Self {
            animation_offset: 0.0,
            is_fading_out: false,
            alpha: 255,
            cache_hbm: HBITMAP::default(),
            cache_bits: std::ptr::null_mut(),
            scaled_w: 0,
            scaled_h: 0,
            timer_killed: false,
            graphics_mode,
        }
    }

    pub fn cleanup(&mut self) {
        if !self.cache_hbm.is_invalid() {
            unsafe {
                let _ = DeleteObject(self.cache_hbm.into());
            }
            self.cache_hbm = HBITMAP::default();
            self.cache_bits = std::ptr::null_mut();
        }
    }
}

lazy_static::lazy_static! {
    // Per-chain window position tracking - ensures snake pattern only applies within the same chain
    // Key: chain_id (UUID string), Value: last window RECT for that chain
    static ref CHAIN_WINDOW_POSITIONS: Mutex<HashMap<String, RECT>> = Mutex::new(HashMap::new());
}

/// Generate a new unique chain ID for a processing chain
pub fn generate_chain_id() -> String {
    use std::sync::atomic::{AtomicU64, Ordering};
    use std::time::{SystemTime, UNIX_EPOCH};

    static COUNTER: AtomicU64 = AtomicU64::new(0);

    let timestamp = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_nanos() as u64;
    let count = COUNTER.fetch_add(1, Ordering::Relaxed);

    format!("chain-{}-{}", timestamp, count)
}

/// Get the next window position using snake algorithm (first-come-first-serve)
/// This is mutex-protected so parallel branches within the SAME chain get sequential positions
/// Different chains (different chain_id) are completely independent
pub fn get_next_window_position_for_chain(chain_id: &str, initial_rect: RECT) -> RECT {
    let mut positions = CHAIN_WINDOW_POSITIONS.lock().unwrap();

    let monitor_rect = unsafe {
        let h_monitor = MonitorFromRect(&initial_rect, MONITOR_DEFAULTTONEAREST);
        let mut mi = MONITORINFO::default();
        mi.cbSize = std::mem::size_of::<MONITORINFO>() as u32;
        if GetMonitorInfoW(h_monitor, &mut mi).as_bool() {
            mi.rcMonitor
        } else {
            RECT {
                left: 0,
                top: 0,
                right: GetSystemMetrics(SM_CXSCREEN),
                bottom: GetSystemMetrics(SM_CYSCREEN),
            }
        }
    };

    let next_rect = match positions.get(chain_id) {
        None => {
            // First window in this chain: use initial rect
            initial_rect
        }
        Some(&prev) => {
            // Subsequent windows in this chain: use snake algorithm from last position
            calculate_next_window_rect(prev, monitor_rect)
        }
    };

    // Update last position for this chain
    positions.insert(chain_id.to_string(), next_rect);

    next_rect
}
</file>

<file path="src/overlay/process/window.rs">
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::core::*;
use std::sync::{Mutex, Once};
use std::collections::HashMap;

use super::types::{ProcessingState, MAX_GLOW_BUFFER_DIM};

// --- PROCESSING WINDOW STATIC STATE ---
static REGISTER_PROC_CLASS: Once = Once::new();

lazy_static::lazy_static! {
    static ref PROC_STATES: Mutex<HashMap<isize, ProcessingState>> = Mutex::new(HashMap::new());
}

// --- WINDOW PROC FOR OVERLAY ---
pub unsafe fn create_processing_window(rect: RECT, graphics_mode: String) -> HWND {
    let instance = GetModuleHandleW(None).unwrap();
    let class_name = w!("SGTProcessingOverlay");

    REGISTER_PROC_CLASS.call_once(|| {
        let mut wc = WNDCLASSW::default();
        wc.lpfnWndProc = Some(processing_wnd_proc);
        wc.hInstance = instance.into();
        wc.hCursor = LoadCursorW(None, IDC_WAIT).unwrap();
        wc.lpszClassName = class_name;
        wc.style = CS_HREDRAW | CS_VREDRAW;
        wc.hbrBackground = HBRUSH(std::ptr::null_mut()); 
        RegisterClassW(&wc);
    });

    let w = (rect.right - rect.left).abs();
    let h = (rect.bottom - rect.top).abs();
    let pixels = (w as i64) * (h as i64);
    let timer_interval = if pixels > 5_000_000 { 50 } else if pixels > 2_000_000 { 32 } else { 16 };

    let hwnd = CreateWindowExW(
        WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_TRANSPARENT | WS_EX_NOACTIVATE, 
        class_name, w!("Processing"), WS_POPUP, rect.left, rect.top, w, h, None, None, Some(instance.into()), None
    ).unwrap_or_default();
    let mut states = PROC_STATES.lock().unwrap();
    states.insert(hwnd.0 as isize, ProcessingState::new(graphics_mode));
    drop(states);
    SetTimer(Some(hwnd), 1, timer_interval, None);
    let _ = ShowWindow(hwnd, SW_SHOWNOACTIVATE);
    hwnd
}

unsafe extern "system" fn processing_wnd_proc(hwnd: HWND, msg: u32, wparam: WPARAM, lparam: LPARAM) -> LRESULT {
    match msg {
        WM_CLOSE => {
            let mut states = PROC_STATES.lock().unwrap();
            let state = states.entry(hwnd.0 as isize).or_insert(ProcessingState::new("standard".to_string()));
            if !state.is_fading_out {
                state.is_fading_out = true;
                if !state.timer_killed {
                    let _ = KillTimer(Some(hwnd), 1); state.timer_killed = true;
                    SetTimer(Some(hwnd), 2, 25, None);
                }
            }
            LRESULT(0)
        }
        WM_TIMER => {
            let (should_destroy, anim_offset, alpha, is_fading) = {
                let mut states = PROC_STATES.lock().unwrap();
                let state = states.entry(hwnd.0 as isize).or_insert(ProcessingState::new("standard".to_string()));
                let mut destroy_flag = false;
                if state.is_fading_out {
                    if state.alpha > 20 { state.alpha -= 20; } else { state.alpha = 0; destroy_flag = true; }
                } else {
                    state.animation_offset += 5.0; if state.animation_offset > 360.0 { state.animation_offset -= 360.0; }
                }
                (destroy_flag, state.animation_offset, state.alpha, state.is_fading_out)
            };
            if should_destroy { 
                let _ = KillTimer(Some(hwnd), 1); let _ = KillTimer(Some(hwnd), 2); 
                let _ = DestroyWindow(hwnd); 
                return LRESULT(0); 
            }
            
            let mut rect = RECT::default(); let _ = GetWindowRect(hwnd, &mut rect);
            let w = (rect.right - rect.left).abs(); let h = (rect.bottom - rect.top).abs();
            if w > 0 && h > 0 {
                let mut states = PROC_STATES.lock().unwrap();
                let state = states.get_mut(&(hwnd.0 as isize)).unwrap();
                let scale_factor = if w > MAX_GLOW_BUFFER_DIM || h > MAX_GLOW_BUFFER_DIM {
                    (MAX_GLOW_BUFFER_DIM as f32 / w as f32).min(MAX_GLOW_BUFFER_DIM as f32 / h as f32).min(1.0)
                } else { 1.0 };
                let buf_w = ((w as f32) * scale_factor).ceil() as i32;
                let buf_h = ((h as f32) * scale_factor).ceil() as i32;
                if state.cache_hbm.is_invalid() || state.scaled_w != buf_w || state.scaled_h != buf_h {
                    state.cleanup();
                    let screen_dc = GetDC(None);
                    let bmi = BITMAPINFO { bmiHeader: BITMAPINFOHEADER { biSize: std::mem::size_of::<BITMAPINFOHEADER>() as u32, biWidth: buf_w, biHeight: -buf_h, biPlanes: 1, biBitCount: 32, biCompression: BI_RGB.0 as u32, ..Default::default() }, ..Default::default() };
                    let res = CreateDIBSection(Some(screen_dc), &bmi, DIB_RGB_COLORS, &mut state.cache_bits, None, 0);
                    ReleaseDC(None, screen_dc);
                    if let Ok(hbm) = res { if !hbm.is_invalid() && !state.cache_bits.is_null() { state.cache_hbm = hbm; state.scaled_w = buf_w; state.scaled_h = buf_h; } else { return LRESULT(0); } } else { return LRESULT(0); }
                }
                if !is_fading && !state.cache_bits.is_null() {
                    if state.graphics_mode == "minimal" { crate::overlay::paint_utils::draw_minimal_glow(state.cache_bits as *mut u32, state.scaled_w, state.scaled_h, anim_offset, 1.0, true); }
                    else { crate::overlay::paint_utils::draw_direct_sdf_glow(state.cache_bits as *mut u32, state.scaled_w, state.scaled_h, anim_offset, 1.0, true); }
                }
                let screen_dc = GetDC(None);
                let needs_scaling = state.scaled_w != w || state.scaled_h != h;
                let (final_hbm, final_w, final_h) = if needs_scaling {
                    let scaled_dc = CreateCompatibleDC(Some(screen_dc)); SelectObject(scaled_dc, state.cache_hbm.into());
                    let dest_bmi = BITMAPINFO { bmiHeader: BITMAPINFOHEADER { biSize: std::mem::size_of::<BITMAPINFOHEADER>() as u32, biWidth: w, biHeight: -h, biPlanes: 1, biBitCount: 32, biCompression: BI_RGB.0 as u32, ..Default::default() }, ..Default::default() };
                    let mut dest_bits: *mut core::ffi::c_void = std::ptr::null_mut();
                    let dest_hbm = CreateDIBSection(Some(screen_dc), &dest_bmi, DIB_RGB_COLORS, &mut dest_bits, None, 0);
                    if let Ok(hbm) = dest_hbm {
                        if !hbm.is_invalid() {
                            let dest_dc = CreateCompatibleDC(Some(screen_dc)); SelectObject(dest_dc, hbm.into());
                            SetStretchBltMode(dest_dc, HALFTONE); let _ = StretchBlt(dest_dc, 0, 0, w, h, Some(scaled_dc), 0, 0, state.scaled_w, state.scaled_h, SRCCOPY);
                            let _ = DeleteDC(scaled_dc); (Some((dest_dc, hbm)), w, h)
                        } else { let _ = DeleteDC(scaled_dc); (None, state.scaled_w, state.scaled_h) }
                    } else { let _ = DeleteDC(scaled_dc); (None, state.scaled_w, state.scaled_h) }
                } else { (None, w, h) };
                
                let (mem_dc, old_hbm, temp_res) = if let Some((dc, hbm)) = final_hbm { (dc, HGDIOBJ::default(), Some(hbm)) } else { let dc = CreateCompatibleDC(Some(screen_dc)); let old = SelectObject(dc, state.cache_hbm.into()); (dc, old, None) };
                let pt_src = POINT { x: 0, y: 0 }; let size = SIZE { cx: final_w, cy: final_h };
                let mut blend = BLENDFUNCTION::default(); blend.BlendOp = AC_SRC_OVER as u8; blend.SourceConstantAlpha = alpha; blend.AlphaFormat = AC_SRC_ALPHA as u8;
                let _ = UpdateLayeredWindow(hwnd, None, None, Some(&size), Some(mem_dc), Some(&pt_src), COLORREF(0), Some(&blend), ULW_ALPHA);
                
                if temp_res.is_some() { let _ = DeleteDC(mem_dc); if let Some(hbm) = temp_res { let _ = DeleteObject(hbm.into()); } } else { SelectObject(mem_dc, old_hbm); let _ = DeleteDC(mem_dc); }
                ReleaseDC(None, screen_dc);
            }
            LRESULT(0)
        }
        WM_PAINT => { let mut ps = PAINTSTRUCT::default(); BeginPaint(hwnd, &mut ps); let _ = EndPaint(hwnd, &mut ps); LRESULT(0) }
        WM_DESTROY => { let mut states = PROC_STATES.lock().unwrap(); if let Some(mut state) = states.remove(&(hwnd.0 as isize)) { state.cleanup(); } LRESULT(0) }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/realtime_egui.rs">
use crate::api::realtime_audio::{start_realtime_transcription, RealtimeState};
use crate::overlay::realtime_webview::state::*;
use crate::APP;
use eframe::egui;
use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
use std::sync::Mutex;

lazy_static::lazy_static! {
    pub static ref MINIMAL_ACTIVE: AtomicBool = AtomicBool::new(false);
    pub static ref MINIMAL_PRESET_IDX: AtomicUsize = AtomicUsize::new(0);
    static ref UI_STATE: Mutex<RealtimeUiState> = Mutex::new(RealtimeUiState::default());
    static ref USER_REQUESTED_CLOSE: AtomicBool = AtomicBool::new(false);
}

struct RealtimeUiState {
    font_size: f32,
    apps_list: Vec<(u32, String)>,
    show_transcription: bool,
    show_translation: bool,
    last_spoken_len: usize,
    show_app_picker: bool,
    show_tts_panel: bool,
    last_committed_len: usize,
    prev_window_size: egui::Vec2,
    prev_has_content: bool,
    committed_segments: Vec<String>,
}

impl Default for RealtimeUiState {
    fn default() -> Self {
        Self {
            font_size: 24.0,
            apps_list: Vec::new(),
            show_transcription: true,
            show_translation: true,
            last_spoken_len: 0,
            show_app_picker: false,
            show_tts_panel: false,
            last_committed_len: 0,
            prev_window_size: egui::Vec2::ZERO,
            prev_has_content: false,
            committed_segments: Vec::new(),
        }
    }
}

pub fn show_realtime_egui_overlay(preset_idx: usize) {
    if MINIMAL_ACTIVE.load(Ordering::SeqCst) || unsafe { IS_ACTIVE } {
        return;
    }

    unsafe {
        IS_ACTIVE = true;
        REALTIME_STOP_SIGNAL.store(false, Ordering::SeqCst);
        MIC_VISIBLE.store(true, Ordering::SeqCst);
        TRANS_VISIBLE.store(true, Ordering::SeqCst);
        AUDIO_SOURCE_CHANGE.store(false, Ordering::SeqCst);
        LANGUAGE_CHANGE.store(false, Ordering::SeqCst);
        TRANSLATION_MODEL_CHANGE.store(false, Ordering::SeqCst);

        {
            let mut state = REALTIME_STATE.lock().unwrap();
            *state = RealtimeState::new();
        }
    }
    
    LAST_SPOKEN_LENGTH.store(0, Ordering::SeqCst);
    REALTIME_TTS_ENABLED.store(false, Ordering::SeqCst);
    SELECTED_APP_PID.store(0, Ordering::SeqCst);
    if let Ok(mut name) = SELECTED_APP_NAME.lock() { name.clear(); }
    if let Ok(mut queue) = COMMITTED_TRANSLATION_QUEUE.lock() { queue.clear(); }
    USER_REQUESTED_CLOSE.store(false, Ordering::SeqCst);

    MINIMAL_ACTIVE.store(true, Ordering::SeqCst);
    MINIMAL_PRESET_IDX.store(preset_idx, Ordering::SeqCst);
    
    let app = APP.lock().unwrap();
    let preset = app.config.presets[preset_idx].clone();
    let font_size = app.config.realtime_font_size as f32;
    let config_language = app.config.realtime_target_language.clone();
    let config_audio_source = app.config.realtime_audio_source.clone();
    drop(app);
    
    let is_device_saved = config_audio_source == "device";
    
    if let Ok(mut ui_state) = UI_STATE.lock() {
        ui_state.font_size = font_size;
        ui_state.apps_list.clear();
        ui_state.show_transcription = true;
        ui_state.show_translation = true;
        ui_state.last_spoken_len = 0;
        ui_state.last_committed_len = 0;
        ui_state.show_app_picker = is_device_saved;
        ui_state.show_tts_panel = false;
        ui_state.prev_window_size = egui::Vec2::ZERO;
        ui_state.prev_has_content = false;
        ui_state.committed_segments.clear();
        // Don't lazy load apps here to avoid blocking
    }
    
    let effective_source = if config_audio_source.is_empty() { "device".to_string() } else { config_audio_source };
    
    if let Ok(mut new_source) = NEW_AUDIO_SOURCE.lock() {
        *new_source = effective_source.clone();
    }
    
    if !config_language.is_empty() {
        if let Ok(mut new_lang) = NEW_TARGET_LANGUAGE.lock() {
            *new_lang = config_language.clone();
        }
        LANGUAGE_CHANGE.store(true, Ordering::SeqCst);
    }

    let mut final_preset = preset.clone();
    final_preset.audio_source = effective_source;

    start_realtime_transcription(
        final_preset,
        REALTIME_STOP_SIGNAL.clone(),
        windows::Win32::Foundation::HWND::default(),
        Some(windows::Win32::Foundation::HWND::default()), 
        REALTIME_STATE.clone(),
    );

    if let Ok(guard) = crate::gui::GUI_CONTEXT.lock() {
        if let Some(ctx) = guard.as_ref() {
            ctx.request_repaint();
        }
    }
}

pub fn render_minimal_overlay(ctx: &egui::Context) {
    if !MINIMAL_ACTIVE.load(Ordering::SeqCst) {
        return;
    }
    
    if USER_REQUESTED_CLOSE.load(Ordering::SeqCst) {
        MINIMAL_ACTIVE.store(false, Ordering::SeqCst);
        unsafe { IS_ACTIVE = false; }
        REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);
        crate::api::tts::TTS_MANAGER.stop();
        USER_REQUESTED_CLOSE.store(false, Ordering::SeqCst);
        return;
    }
    
    let mut ui_state = UI_STATE.lock().unwrap();
    let ui_language = APP.lock().map(|a| a.config.ui_language.clone()).unwrap_or_else(|_| "en".to_string());
    let title = crate::gui::settings_ui::get_localized_preset_name("preset_realtime_audio_translate", &ui_language);

    ctx.show_viewport_immediate(
        egui::ViewportId::from_hash_of("minimal_realtime_overlay"),
        egui::ViewportBuilder::default()
            .with_inner_size([700.0, 200.0])  
            .with_title(title)
            .with_always_on_top(),
        |ctx, _class| {
             if ctx.input(|i| i.viewport().close_requested()) {
                 USER_REQUESTED_CLOSE.store(true, Ordering::SeqCst);
             }
             
             egui::CentralPanel::default().show(ctx, |ui| {
                  render_main_ui(ui, &mut ui_state);
             });
        }
    );
}

fn render_main_ui(ui: &mut egui::Ui, state: &mut RealtimeUiState) {
    let current_source = NEW_AUDIO_SOURCE.lock().map(|s| s.clone()).unwrap_or_else(|_| "mic".to_string());
    let is_device_mode = current_source == "device";
    let app_pid = SELECTED_APP_PID.load(Ordering::SeqCst);
    let tts_enabled = REALTIME_TTS_ENABLED.load(Ordering::SeqCst);
    let ui_language = APP.lock().map(|a| a.config.ui_language.clone()).unwrap_or_else(|_| "en".to_string());
    let locale = crate::gui::locale::LocaleText::get(&ui_language);
    
    // ===== HEADER BAR =====
    ui.horizontal(|ui| {
        // Warning Logic REPLACES Title
        if is_device_mode && app_pid == 0 && !state.show_app_picker {
             ui.label(egui::RichText::new(locale.device_mode_warning)
                .color(egui::Color32::from_rgb(255, 180, 100)).size(11.0));
             if ui.small_button(locale.select_app_btn).clicked() {
                state.show_app_picker = true;
                if state.apps_list.is_empty() {
                    state.apps_list = crate::overlay::realtime_webview::app_selection::enumerate_audio_apps();
                }
             }
        }
        
        ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
            // Visibility toggles
            if ui.selectable_label(state.show_translation, "🌐").on_hover_text(locale.toggle_translation_tooltip).clicked() {
                state.show_translation = !state.show_translation;
                TRANS_VISIBLE.store(state.show_translation, Ordering::SeqCst);
                if !state.show_translation {
                    crate::api::tts::TTS_MANAGER.stop();
                }
                if !state.show_transcription && !state.show_translation {
                    USER_REQUESTED_CLOSE.store(true, Ordering::SeqCst);
                }
            }
            
            if ui.selectable_label(state.show_transcription, "📝").on_hover_text(locale.toggle_transcription_tooltip).clicked() {
                state.show_transcription = !state.show_transcription;
                MIC_VISIBLE.store(state.show_transcription, Ordering::SeqCst);
                if !state.show_transcription && !state.show_translation {
                    USER_REQUESTED_CLOSE.store(true, Ordering::SeqCst);
                }
            }
            
            ui.separator();
            
            // Font controls
            if ui.small_button("➖").on_hover_text(locale.font_minus_tooltip).clicked() {
                state.font_size = (state.font_size - 2.0).max(10.0);
                if let Ok(mut app) = APP.lock() {
                    app.config.realtime_font_size = state.font_size as u32;
                }
            }
            if ui.small_button("➕").on_hover_text(locale.font_plus_tooltip).clicked() {
                state.font_size = (state.font_size + 2.0).min(40.0);
                if let Ok(mut app) = APP.lock() {
                    app.config.realtime_font_size = state.font_size as u32;
                }
            }
            
            ui.separator();
            
            // TTS button
            if state.show_translation {
                let tts_label = if tts_enabled { "🔊" } else { "🔇" };
                if ui.small_button(tts_label).on_hover_text(locale.tts_settings_title).clicked() {
                    state.show_tts_panel = !state.show_tts_panel;
                }
                
                // Model toggle
                let current_model = APP.lock().map(|a| a.config.realtime_translation_model.clone()).unwrap_or_default();
                let model_label = match current_model.as_str() {
                    "google-gemma" => "✨",
                    "google-gtx" => "🌍",
                    _ => "🔥"
                };
                
                ui.menu_button(model_label, |ui| {
                    if ui.selectable_label(current_model == "cerebras-oss", "🔥 Cerebras").clicked() {
                        if let Ok(mut m) = NEW_TRANSLATION_MODEL.lock() { *m = "cerebras-oss".to_string(); }
                        TRANSLATION_MODEL_CHANGE.store(true, Ordering::SeqCst);
                        if let Ok(mut app) = APP.lock() { app.config.realtime_translation_model = "cerebras-oss".to_string(); }
                        ui.close();
                    }
                    if ui.selectable_label(current_model == "google-gemma", "✨ Gemma").clicked() {
                        if let Ok(mut m) = NEW_TRANSLATION_MODEL.lock() { *m = "google-gemma".to_string(); }
                        TRANSLATION_MODEL_CHANGE.store(true, Ordering::SeqCst);
                        if let Ok(mut app) = APP.lock() { app.config.realtime_translation_model = "google-gemma".to_string(); }
                        ui.close();
                    }
                    if ui.selectable_label(current_model == "google-gtx", format!("🌍 {}", locale.google_gtx_label)).clicked() {
                        if let Ok(mut m) = NEW_TRANSLATION_MODEL.lock() { *m = "google-gtx".to_string(); }
                        TRANSLATION_MODEL_CHANGE.store(true, Ordering::SeqCst);
                        if let Ok(mut app) = APP.lock() { app.config.realtime_translation_model = "google-gtx".to_string(); }
                        ui.close();
                    }
                });
                
                // Language selector
                let current_lang = NEW_TARGET_LANGUAGE.lock().map(|l| if l.is_empty() { "English".to_string() } else { l.clone() }).unwrap_or_else(|_| "English".to_string());
                let lang_code = isolang::Language::from_name(&current_lang)
                    .and_then(|l| l.to_639_1())
                    .map(|c| c.to_uppercase())
                    .unwrap_or_else(|| current_lang.chars().take(2).collect::<String>().to_uppercase());
                
                let btn_resp = ui.button(&lang_code);
                if btn_resp.clicked() {
                    egui::Popup::toggle_id(ui.ctx(), btn_resp.id);
                }
                let popup_id = btn_resp.id;
                
                egui::Popup::from_toggle_button_response(&btn_resp)
                    .close_behavior(egui::PopupCloseBehavior::CloseOnClickOutside)
                    .show(|ui| {
                        ui.set_min_width(120.0);
                        let search_id = egui::Id::new("realtime_lang_search");
                        let mut search_text: String = ui.data_mut(|d| d.get_temp(search_id).unwrap_or_default());
                        
                        let response = ui.add(egui::TextEdit::singleline(&mut search_text).hint_text("Search...").desired_width(120.0));
                        if response.changed() {
                            ui.data_mut(|d| d.insert_temp(search_id, search_text.clone()));
                        }
                        if response.clicked() {
                            response.request_focus();
                        }

                        ui.separator();

                        egui::ScrollArea::vertical().max_height(250.0).show(ui, |ui| {
                            for lang in crate::config::get_all_languages() {
                                let matches = search_text.is_empty() || lang.to_lowercase().contains(&search_text.to_lowercase());
                                if matches {
                                    if ui.selectable_label(current_lang == *lang, lang).clicked() {
                                        if let Ok(mut l) = NEW_TARGET_LANGUAGE.lock() { *l = lang.to_string(); }
                                        LANGUAGE_CHANGE.store(true, Ordering::SeqCst);
                                        if let Ok(mut app) = APP.lock() { app.config.realtime_target_language = lang.to_string(); }
                                        ui.data_mut(|d| d.remove_temp::<String>(search_id));
                                        
                                        egui::Popup::toggle_id(ui.ctx(), popup_id);
                                    }
                                }
                            }
                        });
                    });
            }
            
            ui.separator();
            
            // Audio source toggle
            if ui.selectable_label(!is_device_mode, "🎤").on_hover_text(locale.audio_src_mic).clicked() {
                if let Ok(mut s) = NEW_AUDIO_SOURCE.lock() { *s = "mic".to_string(); }
                SELECTED_APP_PID.store(0, Ordering::SeqCst);
                if let Ok(mut name) = SELECTED_APP_NAME.lock() { name.clear(); }
                AUDIO_SOURCE_CHANGE.store(true, Ordering::SeqCst);
                if let Ok(mut app) = APP.lock() { app.config.realtime_audio_source = "mic".to_string(); }
                state.show_app_picker = false;
            }
            
            if ui.selectable_label(is_device_mode, "🔊").on_hover_text(locale.audio_src_device).clicked() {
                state.show_app_picker = true;
                if state.apps_list.is_empty() {
                    state.apps_list = crate::overlay::realtime_webview::app_selection::enumerate_audio_apps();
                }
            }
        });
    });
    
    // ===== TTS PANEL =====
    if state.show_tts_panel && state.show_translation {
        ui.horizontal(|ui| {
            let can_enable_tts = !is_device_mode || app_pid > 0;
            let mut tts_on = tts_enabled;
            
            ui.add_enabled_ui(can_enable_tts, |ui| {
                if ui.checkbox(&mut tts_on, "TTS").changed() {
                    if tts_on {
                        REALTIME_TTS_ENABLED.store(true, Ordering::SeqCst);
                        if is_device_mode && app_pid == 0 {
                            state.show_app_picker = true;
                            if state.apps_list.is_empty() {
                                state.apps_list = crate::overlay::realtime_webview::app_selection::enumerate_audio_apps();
                            }
                        }
                    } else {
                        REALTIME_TTS_ENABLED.store(false, Ordering::SeqCst);
                        crate::api::tts::TTS_MANAGER.stop();
                        LAST_SPOKEN_LENGTH.store(0, Ordering::SeqCst);
                        state.last_spoken_len = 0;
                        if let Ok(mut queue) = COMMITTED_TRANSLATION_QUEUE.lock() { queue.clear(); }
                    }
                }
            });
            
            let current_speed = CURRENT_TTS_SPEED.load(Ordering::Relaxed);
            let base_speed = REALTIME_TTS_SPEED.load(Ordering::Relaxed);
            let auto_speed = REALTIME_TTS_AUTO_SPEED.load(Ordering::Relaxed);
            
            ui.label(format!("{:.1}x", current_speed as f32 / 100.0));
            
            let mut speed_val = base_speed as i32;
            if ui.add(egui::Slider::new(&mut speed_val, 50..=200).show_value(false)).changed() {
                REALTIME_TTS_SPEED.store(speed_val as u32, Ordering::SeqCst);
                REALTIME_TTS_AUTO_SPEED.store(false, Ordering::SeqCst);
            }
            
            let mut auto_on = auto_speed;
            if ui.checkbox(&mut auto_on, locale.realtime_tts_auto).changed() {
                REALTIME_TTS_AUTO_SPEED.store(auto_on, Ordering::SeqCst);
            }
        });
    }
    
    // ===== APP PICKER PANEL =====
    if state.show_app_picker {
        ui.horizontal(|ui| {
            ui.label(egui::RichText::new(locale.app_select_title).strong().size(11.0));
            if ui.small_button("🔄").clicked() {
                state.apps_list = crate::overlay::realtime_webview::app_selection::enumerate_audio_apps();
            }
            if ui.small_button("✖").clicked() {
                state.show_app_picker = false;
            }
            let selected_name = SELECTED_APP_NAME.lock().map(|n| n.clone()).unwrap_or_default();
            if !selected_name.is_empty() {
                ui.label(egui::RichText::new(format!("✓ {}", selected_name)).color(egui::Color32::GREEN).size(10.0));
            }
        });
        
        if state.apps_list.is_empty() {
            state.apps_list = crate::overlay::realtime_webview::app_selection::enumerate_audio_apps();
        }
        
        egui::ScrollArea::vertical().max_height(80.0).id_salt("app_list").show(ui, |ui| {
            for (pid, name) in state.apps_list.clone() {
                let is_selected = app_pid == pid;
                let display = if name.chars().count() > 40 { 
                    format!("{}...", name.chars().take(37).collect::<String>()) 
                } else { 
                    name.clone() 
                };
                
                if ui.selectable_label(is_selected, &display).clicked() {
                    SELECTED_APP_PID.store(pid, Ordering::SeqCst);
                    if let Ok(mut app_name) = SELECTED_APP_NAME.lock() {
                        *app_name = name.clone();
                    }
                    // REALTIME_TTS_ENABLED.store(true, Ordering::SeqCst); // User requested removal
                    if let Ok(mut new_source) = NEW_AUDIO_SOURCE.lock() {
                        *new_source = "device".to_string();
                    }
                    AUDIO_SOURCE_CHANGE.store(true, Ordering::SeqCst);
                    state.show_app_picker = false;
                }
            }
        });
    }
    
    // ===== CONTENT AREA =====
    let state_data = REALTIME_STATE.lock().unwrap();
    let font = egui::FontId::new(state.font_size, egui::FontFamily::Proportional);

    // TTS Logic
    if state.show_translation && TRANS_VISIBLE.load(Ordering::SeqCst) {
        let committed = &state_data.committed_translation;
        let old_len = committed.len();
        
        let is_mic_mode = current_source.is_empty() || current_source == "mic";
        let tts_allowed = is_mic_mode || app_pid > 0;
        
        // Re-read enabled state in case it changed in this frame
        let current_tts_enabled = REALTIME_TTS_ENABLED.load(Ordering::SeqCst);
        
        if current_tts_enabled && tts_allowed && !committed.is_empty() {
            if state.last_spoken_len == 0 && old_len > 50 {
                let text = committed.trim_end();
                let search_limit = text.len().saturating_sub(1);
                if search_limit > 0 {
                    if let Some(idx) = text[..search_limit].rfind(|c| c == '.' || c == '?' || c == '!' || c == '\n') {
                        state.last_spoken_len = idx + 1;
                    }
                }
            }

            if old_len > state.last_spoken_len {
                let new_committed = committed[state.last_spoken_len..].to_string();
                if !new_committed.trim().is_empty() {
                    if let Ok(mut queue) = COMMITTED_TRANSLATION_QUEUE.lock() {
                        queue.push_back(new_committed.clone());
                    }
                    let text_to_speak = new_committed;
                    std::thread::spawn(move || {
                        crate::api::tts::TTS_MANAGER.speak_realtime(&text_to_speak, 0);
                    });
                }
                state.last_spoken_len = old_len;
            }
        }
    }

    let (full_transcript, last_committed_pos, committed_translation, uncommitted_translation) = (
        state_data.full_transcript.clone(),
        state_data.last_committed_pos,
        state_data.committed_translation.clone(),
        state_data.uncommitted_translation.clone(),
    );
    drop(state_data);

    let available_height = ui.available_height();
    let rect = ui.ctx().input(|i| i.viewport().inner_rect);
    let current_window_size = rect.map(|r| r.size()).unwrap_or(egui::Vec2::ZERO);
    
    // logic: trigger scroll if committed text grows OR window resized OR content just appeared
    // logic: trigger scroll if committed text grows OR window resized OR content just appeared
    let current_len = committed_translation.len();
    
    if current_len < state.last_committed_len {
        // Reset detected (e.g. language switch or clear)
        state.committed_segments.clear();
        state.last_committed_len = 0;
    }
    
    let committed_grew = current_len > state.last_committed_len;
    
    if committed_grew {
        let new_segment = committed_translation[state.last_committed_len..].to_string();
        state.committed_segments.push(new_segment);
        state.last_committed_len = current_len;
    } else {
        // Ensure sync (should be equal)
        state.last_committed_len = current_len;
    }
    
    let window_resized = (current_window_size - state.prev_window_size).length() > 1.0;
    if window_resized {
        state.prev_window_size = current_window_size;
    }
    
    let has_content = !committed_translation.is_empty() || !uncommitted_translation.is_empty();
    let content_appeared = has_content && !state.prev_has_content;
    if has_content != state.prev_has_content {
        state.prev_has_content = has_content;
    }
    
    let should_scroll_trans = committed_grew || window_resized || content_appeared;

    // Render content
    if state.show_transcription && state.show_translation {
        let available_width = ui.available_width();
        // Prevent negative width when window is very narrow
        let col_width = ((available_width - 10.0) / 2.0).max(1.0);
        let content_height = available_height.max(50.0);
        
        ui.horizontal(|ui| {
            ui.vertical(|ui| {
                ui.set_width(col_width);
                ui.set_min_height(content_height);
                egui::ScrollArea::vertical()
                    .id_salt("trans_scroll")
                    .auto_shrink([false, false])
                    .stick_to_bottom(true)
                    .show(ui, |ui| {
                        render_transcript(ui, &full_transcript, last_committed_pos, &font);
                    });
            });
            
            ui.separator();

            ui.vertical(|ui| {
                ui.set_width(col_width);
                ui.set_min_height(content_height);
                egui::ScrollArea::vertical()
                    .id_salt("transl_scroll")
                    .auto_shrink([false, false])
                    .show(ui, |ui| {
                        render_translation(ui, &state.committed_segments, &uncommitted_translation, &font);
                        if should_scroll_trans {
                            ui.scroll_to_cursor(Some(egui::Align::BOTTOM));
                        }
                    });
            });
        });
    } else if state.show_transcription {
        egui::ScrollArea::vertical()
            .id_salt("trans_full")
            .auto_shrink([false, false])
            .stick_to_bottom(true)
            .show(ui, |ui| {
                render_transcript(ui, &full_transcript, last_committed_pos, &font);
            });
    } else if state.show_translation {
        egui::ScrollArea::vertical()
            .id_salt("transl_full")
            .auto_shrink([false, false])
            .show(ui, |ui| {
                 render_translation(ui, &state.committed_segments, &uncommitted_translation, &font);
                 if should_scroll_trans {
                     ui.scroll_to_cursor(Some(egui::Align::BOTTOM));
                 }
            });
    }
}

fn render_transcript(ui: &mut egui::Ui, full: &str, split_pos: usize, font: &egui::FontId) {
    let split_idx = split_pos.min(full.len());
    let split_idx = if full.is_char_boundary(split_idx) { split_idx } else {
        full.char_indices().take_while(|(i, _)| *i < split_idx).last().map(|(i, c)| i + c.len_utf8()).unwrap_or(0)
    };
    
    let committed = full[..split_idx].trim_end();
    let uncommitted = full[split_idx..].trim_start();
    let dark_mode = ui.visuals().dark_mode;
    
    ui.horizontal_wrapped(|ui| {
        ui.spacing_mut().item_spacing.x = 0.0;
        if !committed.is_empty() {
             ui.label(egui::RichText::new(committed).font(font.clone()).color(get_text_color(true, dark_mode)));
        }
        if !uncommitted.is_empty() {
            if !committed.is_empty() { ui.label(" "); }
            let color = if dark_mode { egui::Color32::WHITE } else { egui::Color32::BLACK };
            ui.label(egui::RichText::new(uncommitted).font(font.clone()).color(color).italics());
        }
    });
}

fn render_translation(ui: &mut egui::Ui, segments: &[String], uncommitted: &str, font: &egui::FontId) {
    let uncommitted = uncommitted.trim_start();
    let dark_mode = ui.visuals().dark_mode;
    
    ui.horizontal_wrapped(|ui| {
        ui.spacing_mut().item_spacing.x = 0.0;
        
        for (i, segment) in segments.iter().enumerate() {
            let color = get_segment_color(i, dark_mode);
            ui.label(egui::RichText::new(segment).font(font.clone()).color(color));
        }
        
        if !uncommitted.is_empty() {
            // Uncommitted text color
            let color = if dark_mode { egui::Color32::YELLOW } else { egui::Color32::from_rgb(200, 100, 0) }; // Dark Orange for light mode
            ui.label(egui::RichText::new(uncommitted).font(font.clone()).color(color).italics());
        }
    });
}

// Helpers
#[allow(dead_code)]
fn tr(key: &str, lang: &str) -> String {
    match lang {
         "vi" => match key {
             "device_mode_warning" => "⚠ Đã chọn âm thanh thiết bị nhưng chưa chọn ứng dụng".to_string(),
             "select_app" => "Chọn ứng dụng".to_string(),
             "toggle_translation" => "Tắt/Mở dịch".to_string(),
             "toggle_transcription" => "Tắt/Mở phụ đề".to_string(),
             "font_minus" => "Giảm cỡ chữ".to_string(),
             "font_plus" => "Tăng cỡ chữ".to_string(),
             "tts_settings" => "Cài đặt đọc văn bản (TTS)".to_string(),
             "microphone" => "Microphone".to_string(),
             "system_audio" => "Âm thanh hệ thống".to_string(),
             "select_app_title" => "🎧 Chọn ứng dụng để thu âm".to_string(),
             "auto" => "Tự động".to_string(),
             _ => key.to_string(),
         },
         _ => match key {
             "device_mode_warning" => "⚠ Device audio selected but no app chosen".to_string(),
             "select_app" => "Select App".to_string(),
             "toggle_translation" => "Toggle Translation".to_string(),
             "toggle_transcription" => "Toggle Transcription".to_string(),
             "font_minus" => "Font -".to_string(),
             "font_plus" => "Font +".to_string(),
             "tts_settings" => "TTS Settings".to_string(),
             "microphone" => "Microphone".to_string(),
             "system_audio" => "System Audio".to_string(),
             "select_app_title" => "🎧 Select App to Record".to_string(),
             "auto" => "Auto".to_string(),
             _ => key.to_string(),
         }
    }
}

fn get_segment_color(index: usize, dark_mode: bool) -> egui::Color32 {
    if dark_mode {
        if index % 2 == 0 {
            egui::Color32::from_gray(230)
        } else {
            egui::Color32::from_rgb(180, 210, 255) // Light Blue
        }
    } else {
        if index % 2 == 0 {
            egui::Color32::from_gray(30) // Dark Gray (almost black) for readability
        } else {
            egui::Color32::from_rgb(0, 80, 200) // Deep Blue
        }
    }
}

fn get_text_color(is_committed: bool, dark_mode: bool) -> egui::Color32 {
    if dark_mode {
        if is_committed { egui::Color32::from_gray(200) } else { egui::Color32::WHITE }
    } else {
        if is_committed { egui::Color32::from_gray(60) } else { egui::Color32::BLACK }
    }
}
</file>

<file path="src/overlay/realtime_html.rs">
use crate::gui::locale::LocaleText;

pub fn get_realtime_html(
    is_translation: bool,
    audio_source: &str,
    languages: &[String],
    current_language: &str,
    translation_model: &str,
    transcription_model: &str,
    font_size: u32,
    text: &LocaleText,
    is_dark: bool,
) -> String {
    let _title_icon = if is_translation {
        "translate"
    } else {
        "graphic_eq"
    };
    let title_text = if is_translation {
        text.realtime_translation
    } else {
        text.realtime_listening
    };
    let glow_color = if is_translation { "#ff9633" } else { "#00c8ff" };

    // Title content: volume bars for transcription, text for translation
    let title_content = if is_translation {
        format!("{}", title_text)
    } else {
        // Canvas-based volume visualizer for smooth 60fps animation
        r#"<canvas id="volume-canvas" width="90" height="24"></canvas>"#.to_string()
    };

    let _mic_text = text.realtime_mic;
    let _device_text = text.realtime_device;
    let placeholder_text = text.realtime_waiting;

    // Build language options HTML - show full name in dropdown, but store code for display
    let lang_options: String = languages
        .iter()
        .map(|lang| {
            let selected = if lang == current_language {
                "selected"
            } else {
                ""
            };
            // Get 2-letter ISO 639-1 code
            let lang_code = isolang::Language::from_name(lang)
                .and_then(|l| l.to_639_1())
                .map(|c| c.to_uppercase())
                .unwrap_or_else(|| lang.chars().take(2).collect::<String>().to_uppercase());
            // Option shows full name, but we store code as data attribute for selected display
            format!(
                r#"<option value="{}" data-code="{}" {}>{}</option>"#,
                lang, lang_code, selected, lang
            )
        })
        .collect::<Vec<_>>()
        .join("\n");

    // Audio source selector (only for transcription window) - simple mic/device toggle
    let audio_selector = if !is_translation {
        let is_device = audio_source == "device";
        let gemini_active = if transcription_model == "gemini" {
            "active"
        } else {
            ""
        };
        let parakeet_active = if transcription_model == "parakeet" {
            "active"
        } else {
            ""
        };

        format!(
            r#"
            <div class="btn-group">
                <span class="material-symbols-rounded audio-icon {mic_active}" id="mic-btn" data-value="mic" title="Microphone Input">{mic_svg}</span>
                <span class="material-symbols-rounded audio-icon {device_active}" id="device-btn" data-value="device" title="Device Audio">{device_svg}</span>
            </div>
            <div class="btn-group">
                <span class="material-symbols-rounded trans-model-icon {gemini_active}" data-value="gemini" title="Gemini Live (Cloud)">{auto_awesome_svg}</span>
                <span class="material-symbols-rounded trans-model-icon {parakeet_active}" data-value="parakeet" title="Parakeet (Local)">{bolt_en_svg}</span>
            </div>
        "#,
            mic_active = if !is_device { "active" } else { "" },
            device_active = if is_device { "active" } else { "" },
            gemini_active = gemini_active,
            parakeet_active = parakeet_active,
            mic_svg = crate::overlay::html_components::icons::get_icon_svg("mic"),
            device_svg = crate::overlay::html_components::icons::get_icon_svg("speaker_group"),
            auto_awesome_svg = crate::overlay::html_components::icons::get_icon_svg("auto_awesome"),
            bolt_en_svg = crate::overlay::html_components::icons::get_icon_svg("bolt_en")
        )
    } else {
        // Language selector and model toggle for translation window
        let gemma_active = if translation_model == "google-gemma" {
            "active"
        } else {
            ""
        };
        let cerebras_active = if translation_model == "cerebras-oss" {
            "active"
        } else {
            ""
        };
        let gtx_active = if translation_model == "google-gtx" {
            "active"
        } else {
            ""
        };

        format!(
            r#"
            <span class="ctrl-btn speak-btn" id="speak-btn" title="Text-to-Speech Settings"><span class="material-symbols-rounded">{volume_up_svg}</span></span>
            <div class="btn-group">
                <span class="material-symbols-rounded model-icon {gemma_active}" data-value="google-gemma" title="AI Translation (Gemma)">{auto_awesome_svg}</span>
                <span class="material-symbols-rounded model-icon {cerebras_active}" data-value="cerebras-oss" title="Instant AI (Cerebras)">{speed_svg}</span>
                <span class="material-symbols-rounded model-icon {gtx_active}" data-value="google-gtx" title="Unlimited Translation (Google)">{language_svg}</span>
            </div>
            <select id="language-select" title="Target Language">
                {lang_options}
            </select>
        "#,
            lang_options = lang_options,
            gemma_active = gemma_active,
            cerebras_active = cerebras_active,
            gtx_active = gtx_active,
            volume_up_svg = crate::overlay::html_components::icons::get_icon_svg("volume_up"),
            auto_awesome_svg = crate::overlay::html_components::icons::get_icon_svg("auto_awesome"),
            speed_svg = crate::overlay::html_components::icons::get_icon_svg("speed"),
            language_svg = crate::overlay::html_components::icons::get_icon_svg("language")
        )
    };

    let loading_icon = if is_translation {
        r##"<svg class="loading-svg" viewBox="0 -6 24 36" fill="none" stroke="#ff9633" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"><g class="trans-part-1"><path d="m5 8 6 6"></path><path d="m4 14 6-6 2-3"></path><path d="M2 5h12"></path><path d="M7 2h1"></path></g><g class="trans-part-2"><path d="m22 22-5-10-5 10"></path><path d="M14 18h6"></path></g></svg>"##
    } else {
        r##"<svg class="loading-svg" viewBox="0 -12 24 48" fill="none" stroke="#00c8ff" stroke-width="4" stroke-linecap="round" stroke-linejoin="round"><line class="wave-line delay-1" x1="4" y1="8" x2="4" y2="16"></line><line class="wave-line delay-2" x1="9" y1="4" x2="9" y2="20"></line><line class="wave-line delay-3" x1="14" y1="6" x2="14" y2="18"></line><line class="wave-line delay-4" x1="19" y1="8" x2="19" y2="16"></line></svg>"##
    };

    // Construct CSS and JS from components
    let css = format!(
        "{}{}",
        crate::overlay::html_components::css_main::get(glow_color, font_size, is_dark),
        crate::overlay::html_components::css_modals::get(is_dark)
    );
    let js = format!(
        "{}{}",
        crate::overlay::html_components::js_main::get(font_size),
        crate::overlay::html_components::js_logic::get(placeholder_text)
    );

    // Get local font CSS (cached fonts, no network loading)
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>{font_css}</style>
    <style id="main-style">
        {css_content}
    </style>
</head>
<body>
    <div id="loading-overlay">{loading_icon}</div>
    <div id="container">
        <div id="header">
            <div id="title">{title_content}</div>
            <div id="controls">
                {audio_selector}
                <span class="ctrl-btn" id="copy-btn" title="Copy text"><span class="material-symbols-rounded">{content_copy_svg}</span></span>
                <div class="pill-group">
                    <span class="ctrl-btn" id="font-decrease" title="Decrease font size"><span class="material-symbols-rounded">{remove_svg}</span></span>
                    <span class="ctrl-btn" id="font-increase" title="Increase font size"><span class="material-symbols-rounded">{add_svg}</span></span>
                </div>
                <div class="btn-group">
                    <span class="vis-btn mic active" id="toggle-mic" title="Toggle Transcription"><span class="material-symbols-rounded">{subtitles_svg}</span></span>
                    <span class="vis-btn trans active" id="toggle-trans" title="Toggle Translation"><span class="material-symbols-rounded">{translate_svg}</span></span>
                </div>
            </div>
        </div>
        <div id="header-toggle" title="Toggle header"><span class="material-symbols-rounded">{expand_less_svg}</span></div>
        <div id="viewport">
            <div id="content">
                <span class="placeholder">{placeholder_text}</span>
            </div>
        </div>
        <div id="resize-hint"><span class="material-symbols-rounded" style="font-size: 20px;">{pip_svg}</span></div>
    </div>
    <!-- Download Modal -->
    <div id="download-modal-overlay"></div>
    <div id="download-modal">
        <div class="download-modal-title">
            <span class="material-symbols-rounded">{download_svg}</span>
            <span id="download-title">Downloading Model</span>
        </div>
        <div class="download-modal-msg" id="download-msg">Please wait...</div>
        <div class="download-progress-bar">
            <div class="download-progress-fill" id="download-fill" style="width: 0%;"></div>
        </div>
        <div class="download-modal-footnote">{supports_english}</div>
        <button class="download-cancel-btn" id="download-cancel-btn" title="Cancel download and return to Gemini Live">
            <span class="material-symbols-rounded">{close_svg}</span>
            {cancel_text}
        </button>
    </div>
    <!-- TTS Settings Modal -->
    <div id="tts-modal-overlay"></div>
    <div id="tts-modal">
        <div class="tts-modal-title">
            <span class="material-symbols-rounded">{volume_up_svg}</span>
            {tts_title}
            <div class="toggle-switch" id="tts-toggle" style="margin-left: auto;"></div>
        </div>
        <div class="tts-modal-row">
            <span class="tts-modal-label">{tts_speed}</span>
            <div class="speed-slider-container">
                <input type="range" class="speed-slider" id="speed-slider" min="50" max="200" value="100" step="10">
                <span class="speed-value" id="speed-value">1.0x</span>
                <button class="auto-toggle on" id="auto-speed-toggle" title="Auto-adjust speed to catch up">{tts_auto}</button>
            </div>
    </div>
            </div>
        </div>
    </div>
    <!-- App Selection Modal -->
    <div id="app-modal-overlay"></div>
    <div id="app-modal">
        <div class="app-modal-title">
            <span class="material-symbols-rounded">{apps_svg}</span>
            {app_select_title}
        </div>
        <div class="app-modal-hint">{app_select_hint}</div>
        <div id="app-list" class="app-list">
            <div class="app-loading">Loading...</div>
        </div>
    </div>
    <script>
        {js_content}
    </script>
</body>
</html>"#,
        css_content = css,
        js_content = js,
        loading_icon = loading_icon,
        title_content = title_content,
        audio_selector = audio_selector,
        placeholder_text = placeholder_text,
        tts_title = text.realtime_tts_title,
        tts_speed = text.realtime_tts_speed,
        tts_auto = text.realtime_tts_auto,
        app_select_title = text.app_select_title,
        app_select_hint = text.app_select_hint,
        content_copy_svg = crate::overlay::html_components::icons::get_icon_svg("content_copy"),
        remove_svg = crate::overlay::html_components::icons::get_icon_svg("remove"),
        add_svg = crate::overlay::html_components::icons::get_icon_svg("add"),
        subtitles_svg = crate::overlay::html_components::icons::get_icon_svg("subtitles"),
        translate_svg = crate::overlay::html_components::icons::get_icon_svg("translate"),
        expand_less_svg = crate::overlay::html_components::icons::get_icon_svg("expand_less"),
        pip_svg = crate::overlay::html_components::icons::get_icon_svg("picture_in_picture_small"),
        volume_up_svg = crate::overlay::html_components::icons::get_icon_svg("volume_up"),
        apps_svg = crate::overlay::html_components::icons::get_icon_svg("apps"),
        download_svg = crate::overlay::html_components::icons::get_icon_svg("download"),
        close_svg = crate::overlay::html_components::icons::get_icon_svg("close"),
        cancel_text = text.cancel_label,
        supports_english = text.parakeet_supports_english_only
    )
}
</file>

<file path="src/overlay/realtime_webview/wndproc.rs">
//! Window procedures for realtime overlay windows

use super::state::*;
use super::webview::{update_webview_text, update_webview_theme};
use crate::api::realtime_audio::{
    REALTIME_RMS, WM_COPY_TEXT, WM_DOWNLOAD_PROGRESS, WM_EXEC_SCRIPT, WM_MODEL_SWITCH,
    WM_REALTIME_UPDATE, WM_START_DRAG, WM_THEME_UPDATE, WM_TOGGLE_MIC, WM_TOGGLE_TRANS,
    WM_TRANSLATION_UPDATE, WM_UPDATE_TTS_SPEED, WM_VOLUME_UPDATE,
};
use std::sync::atomic::Ordering;
use windows::Win32::Foundation::*;
use windows::Win32::UI::Input::KeyboardAndMouse::ReleaseCapture;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::Rect;
pub unsafe extern "system" fn realtime_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_START_DRAG => {
            let _ = ReleaseCapture();
            let _ = SendMessageW(
                hwnd,
                WM_NCLBUTTONDOWN,
                Some(WPARAM(HTCAPTION as usize)),
                Some(LPARAM(0)),
            );
            LRESULT(0)
        }
        WM_TOGGLE_MIC => {
            let val = wparam.0 != 0;
            MIC_VISIBLE.store(val, Ordering::SeqCst);
            LRESULT(0)
        }
        WM_TOGGLE_TRANS => {
            let val = wparam.0 != 0;
            TRANS_VISIBLE.store(val, Ordering::SeqCst);
            LRESULT(0)
        }
        WM_COPY_TEXT => {
            let ptr = lparam.0 as *mut String;
            if !ptr.is_null() {
                let text = Box::from_raw(ptr);
                crate::overlay::utils::copy_to_clipboard(&text, hwnd);
            }
            LRESULT(0)
        }
        WM_EXEC_SCRIPT => {
            let ptr = lparam.0 as *mut String;
            if !ptr.is_null() {
                let script_box = Box::from_raw(ptr);
                let script = *script_box;
                let hwnd_key = hwnd.0 as isize;
                REALTIME_WEBVIEWS.with(|wvs| {
                    if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                        let _ = webview.evaluate_script(&script);
                    }
                });
            }
            LRESULT(0)
        }
        WM_REALTIME_UPDATE => {
            // Check if we need to close the modal (flag set by app selection)
            if CLOSE_TTS_MODAL_REQUEST.load(Ordering::SeqCst) {
                if CLOSE_TTS_MODAL_REQUEST.swap(false, Ordering::SeqCst) {
                    let hwnd_key = hwnd.0 as isize;
                    let script = "var m = document.getElementById('tts-modal'); if(m) m.classList.remove('show'); var o = document.getElementById('tts-modal-overlay'); if(o) o.classList.remove('show');";
                    REALTIME_WEBVIEWS.with(|wvs| {
                        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                            let _ = webview.evaluate_script(script);
                        }
                    });
                }
            }

            // Get old (committed) and new (current sentence) text from state
            let (old_text, new_text) = {
                if let Ok(state) = REALTIME_STATE.lock() {
                    // Everything before last_committed_pos is "old"
                    // Everything after is "new" (current sentence)
                    let full = &state.full_transcript;
                    let pos = state.last_committed_pos.min(full.len());
                    let old_raw = &full[..pos];
                    let new_raw = &full[pos..];

                    let old = old_raw.trim_end();
                    let new = new_raw.trim_start();
                    if !old.is_empty() && !new.is_empty() {
                        (old.to_string(), format!(" {}", new))
                    } else {
                        (old.to_string(), new.to_string())
                    }
                } else {
                    (String::new(), String::new())
                }
            };
            update_webview_text(hwnd, &old_text, &new_text);
            LRESULT(0)
        }
        WM_DOWNLOAD_PROGRESS => {
            let (is_downloading, title, message, progress) = {
                if let Ok(state) = REALTIME_STATE.lock() {
                    (
                        state.is_downloading,
                        state.download_title.clone(),
                        state.download_message.clone(),
                        state.download_progress,
                    )
                } else {
                    (false, String::new(), String::new(), 0.0)
                }
            };

            if is_downloading {
                let script = format!(
                    "if(window.showDownloadModal) window.showDownloadModal('{}', '{}', {});",
                    title.replace("'", "\\'"),
                    message.replace("'", "\\'"),
                    progress
                );
                let hwnd_key = hwnd.0 as isize;
                REALTIME_WEBVIEWS.with(|wvs| {
                    if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                        let _ = webview.evaluate_script(&script);
                    }
                });
            } else {
                let script = "if(window.hideDownloadModal) window.hideDownloadModal();";
                let hwnd_key = hwnd.0 as isize;
                REALTIME_WEBVIEWS.with(|wvs| {
                    if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                        let _ = webview.evaluate_script(&script);
                    }
                });
            }

            LRESULT(0)
        }
        WM_VOLUME_UPDATE => {
            // Read RMS from shared atomic and update visualizer
            let rms_bits = REALTIME_RMS.load(Ordering::Relaxed);
            let rms = f32::from_bits(rms_bits);

            let hwnd_key = hwnd.0 as isize;
            let script = format!("if(window.updateVolume) window.updateVolume({});", rms);

            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.evaluate_script(&script);
                }
            });
            LRESULT(0)
        }
        WM_UPDATE_TTS_SPEED => {
            let speed = wparam.0 as u32;
            let hwnd_key = hwnd.0 as isize;
            let script = format!(
                "if(window.updateTtsSpeed) window.updateTtsSpeed({});",
                speed
            );

            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.evaluate_script(&script);
                }
            });
            LRESULT(0)
        }
        WM_THEME_UPDATE => {
            update_webview_theme(hwnd);
            LRESULT(0)
        }
        WM_SIZE => {
            // Resize WebView to match window size
            let width = (lparam.0 & 0xFFFF) as u32;
            let height = ((lparam.0 >> 16) & 0xFFFF) as u32;
            let hwnd_key = hwnd.0 as isize;
            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                            0, 0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(width, height)),
                    });
                }
            });
            LRESULT(0)
        }
        WM_CLOSE => {
            let _ = PostMessageW(Some(hwnd), WM_APP_REALTIME_HIDE, WPARAM(0), LPARAM(0));
            LRESULT(0)
        }
        WM_APP_REALTIME_HIDE => {
            // Check if download modal is active - if so, user wants to cancel and revert to Gemini
            let is_downloading = {
                if let Ok(state) = REALTIME_STATE.lock() {
                    state.is_downloading
                } else {
                    false
                }
            };

            if is_downloading {
                // Cancel download and revert to Gemini
                crate::api::realtime_audio::cancel_download_and_revert_to_gemini();
            }

            // Stop transcription and TTS
            REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);
            crate::api::tts::TTS_MANAGER.stop();

            // Hide windows
            let _ = ShowWindow(hwnd, SW_HIDE);
            if !std::ptr::addr_of!(TRANSLATION_HWND).read().is_invalid() {
                let _ = ShowWindow(TRANSLATION_HWND, SW_HIDE);
            }

            // Reset active state so it can be shown again
            IS_ACTIVE = false;

            LRESULT(0)
        }

        WM_DESTROY => {
            let _ = DestroyWindow(hwnd);
            if !std::ptr::addr_of!(TRANSLATION_HWND).read().is_invalid() {
                let _ = DestroyWindow(TRANSLATION_HWND);
            }
            PostQuitMessage(0);
            LRESULT(0)
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

pub unsafe extern "system" fn translation_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_COPY_TEXT => {
            let ptr = lparam.0 as *mut String;
            if !ptr.is_null() {
                let text = Box::from_raw(ptr);
                crate::overlay::utils::copy_to_clipboard(&text, hwnd);
            }
            LRESULT(0)
        }
        WM_TRANSLATION_UPDATE => {
            // Check if we need to close the modal (flag set by app selection)
            if CLOSE_TTS_MODAL_REQUEST.load(Ordering::SeqCst) {
                if CLOSE_TTS_MODAL_REQUEST.swap(false, Ordering::SeqCst) {
                    let hwnd_key = hwnd.0 as isize;
                    let script = "var m = document.getElementById('tts-modal'); if(m) m.classList.remove('show'); var o = document.getElementById('tts-modal-overlay'); if(o) o.classList.remove('show');";
                    REALTIME_WEBVIEWS.with(|wvs| {
                        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                            let _ = webview.evaluate_script(script);
                        }
                    });
                }
            }

            // Get old (committed) and new (uncommitted) translation from state
            let (old_text, new_text): (String, String) = {
                if let Ok(state) = REALTIME_STATE.lock() {
                    let old = state.committed_translation.trim_end();
                    let new = state.uncommitted_translation.trim_start();
                    if !old.is_empty() && !new.is_empty() {
                        (old.to_string(), format!(" {}", new))
                    } else {
                        (old.to_string(), new.to_string())
                    }
                } else {
                    (String::new(), String::new())
                }
            };

            // TTS: Check if we have new committed text to speak
            // For Mic mode: TTS always works (no feedback loop concern)
            // For Device mode: Only speak if an app is selected (per-app capture isolates TTS from loopback)
            let app_selected = SELECTED_APP_PID.load(Ordering::SeqCst) > 0;
            let is_mic_mode = NEW_AUDIO_SOURCE
                .lock()
                .map(|s| s.is_empty() || s.as_str() == "mic")
                .unwrap_or(true);
            let tts_allowed = is_mic_mode || app_selected;
            if REALTIME_TTS_ENABLED.load(Ordering::SeqCst) && tts_allowed && !old_text.is_empty() {
                let old_len = old_text.len();

                // Smart catch-up: If starting fresh (0) with existing text, skip to last sentence
                // This prevents reading the entire history when toggling TTS on
                if LAST_SPOKEN_LENGTH.load(Ordering::SeqCst) == 0 && old_len > 50 {
                    let text = old_text.trim_end();
                    // Ignore the very last char if it's punctuation, to find the PREVIOUS sentence boundary
                    let search_limit = text.len().saturating_sub(1);
                    if search_limit > 0 {
                        // Find last sentence terminator (. ? ! or newline)
                        let last_boundary = text[..search_limit]
                            .rfind(|c| c == '.' || c == '?' || c == '!' || c == '\n');

                        if let Some(idx) = last_boundary {
                            // Mark everything up to (and including) this punctuation as "spoken"
                            // So we only read what follows
                            LAST_SPOKEN_LENGTH.store(idx + 1, Ordering::SeqCst);
                        }
                    }
                }

                let last_spoken = LAST_SPOKEN_LENGTH.load(Ordering::SeqCst);

                if old_len > last_spoken {
                    // We have new committed text since last spoken
                    let new_committed = old_text[last_spoken..].to_string();

                    // Only queue non-empty, non-whitespace segments
                    if !new_committed.trim().is_empty() {
                        // Queue this text for TTS
                        if let Ok(mut queue) = COMMITTED_TRANSLATION_QUEUE.lock() {
                            queue.push_back(new_committed.clone());
                        }

                        // Speak using TTS manager (non-blocking)
                        // This uses the existing parallel TTS infrastructure
                        let hwnd_val = hwnd.0 as isize;
                        std::thread::spawn(move || {
                            crate::api::tts::TTS_MANAGER.speak_realtime(&new_committed, hwnd_val);
                        });
                    }

                    LAST_SPOKEN_LENGTH.store(old_len, Ordering::SeqCst);
                }
            }

            update_webview_text(hwnd, &old_text, &new_text);
            LRESULT(0)
        }
        WM_MODEL_SWITCH => {
            // Animate the model switch in the UI
            // WPARAM: 0 = groq-llama, 1 = google-gemma, 2 = google-gtx
            let model_name = match wparam.0 {
                1 => "google-gemma",
                2 => "google-gtx",
                _ => "groq-llama",
            };
            let hwnd_key = hwnd.0 as isize;
            let script = format!(
                "if(window.switchModel) window.switchModel('{}');",
                model_name
            );

            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.evaluate_script(&script);
                }
            });
            LRESULT(0)
        }
        WM_UPDATE_TTS_SPEED => {
            let speed = wparam.0 as u32;
            let hwnd_key = hwnd.0 as isize;
            let script = format!(
                "if(window.updateTtsSpeed) window.updateTtsSpeed({});",
                speed
            );

            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.evaluate_script(&script);
                }
            });
            LRESULT(0)
        }
        WM_THEME_UPDATE => {
            update_webview_theme(hwnd);
            LRESULT(0)
        }
        WM_SIZE => {
            // Resize WebView to match window size
            let width = (lparam.0 & 0xFFFF) as u32;
            let height = ((lparam.0 >> 16) & 0xFFFF) as u32;
            let hwnd_key = hwnd.0 as isize;
            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                            0, 0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(width, height)),
                    });
                }
            });
            LRESULT(0)
        }

        WM_CLOSE => {
            let _ = PostMessageW(
                Some(REALTIME_HWND),
                WM_APP_REALTIME_HIDE,
                WPARAM(0),
                LPARAM(0),
            );
            LRESULT(0)
        }
        WM_APP_REALTIME_HIDE => {
            let _ = ShowWindow(hwnd, SW_HIDE);
            LRESULT(0)
        }
        WM_DESTROY => LRESULT(0),
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/result/logic.rs">
use super::state::{AnimationMode, DustParticle, WINDOW_STATES};
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::UI::WindowsAndMessaging::*;

fn rand_float(min: f32, max: f32) -> f32 {
    static mut SEED: u32 = 12345;
    unsafe {
        SEED = SEED.wrapping_mul(1103515245).wrapping_add(12345);
        let norm = (SEED as f32) / (u32::MAX as f32);
        min + norm * (max - min)
    }
}

pub fn handle_timer(hwnd: HWND, wparam: WPARAM) {
    unsafe {
        if wparam.0 == 3 {
            // 60 FPS Physics Loop
            let should_close = false;

            {
                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                    let p = &mut state.physics;

                    // --- 1. MOUSE PHYSICS (Spring System) ---
                    // Hooke's Law for Handle Tilt:
                    // Force = -k * x - c * v
                    // k = stiffness, c = damping

                    // Natural wobble rest point is 0.0
                    let spring_stiffness = 0.15;
                    let damping = 0.85;

                    p.tilt_velocity += (0.0 - p.current_tilt) * spring_stiffness;
                    p.tilt_velocity *= damping;
                    p.current_tilt += p.tilt_velocity;

                    // Bristle bend follows tilt but lags slightly
                    p.bristle_bend = p.bristle_bend * 0.8 + (p.current_tilt / 10.0) * 0.2;

                    // --- 2. ANIMATION STATE MACHINE ---
                    match p.mode {
                        AnimationMode::Idle => {
                            p.squish_factor = p.squish_factor * 0.9 + 1.0 * 0.1;
                            // Return to 1.0
                        }
                    }

                    // --- 3. PARTICLE PHYSICS ---
                    let mut keep = Vec::new();
                    for mut pt in p.particles.drain(..) {
                        pt.x += pt.vx;
                        pt.y += pt.vy;
                        pt.vy += 0.5; // Gravity
                        pt.vx *= 0.92; // Air resistance
                        pt.life -= 0.03;
                        if pt.life > 0.0 {
                            keep.push(pt);
                        }
                    }
                    p.particles = keep;

                    // --- 4. RESIZE DEBOUNCE CHECK ---
                    // After resize stops for 100ms, trigger font recalculation
                    if state.last_resize_time != 0 && !state.is_markdown_mode {
                        let now = std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .map(|d| d.as_millis() as u32)
                            .unwrap_or(0);
                        let time_since_resize = now.wrapping_sub(state.last_resize_time);
                        if time_since_resize > 100 && time_since_resize < 200 {
                            // Just crossed the 100ms threshold, trigger font recalculation
                            state.font_cache_dirty = true;
                        }
                    }

                    // PERFORMANCE FIX: Skip repaints during DragOut EXCEPT for the cleanup repaint
                    // The cleanup repaint clears the broom/particles from the visual
                    let skip_repaint = false;
                    if p.needs_cleanup_repaint {
                        p.needs_cleanup_repaint = false; // Consume the flag
                    }
                    if !skip_repaint {
                        // CARET FIX: When editing, only invalidate areas OUTSIDE the edit control
                        // This prevents the constant timer from killing the caret blink
                        if state.is_editing {
                            let mut client_rect = RECT::default();
                            let _ = GetClientRect(hwnd, &mut client_rect);

                            // Edit control is at (10, 10) with width = client_w - 20, height = 40
                            // Invalidate: bottom region (below edit), left margin, right margin
                            let edit_bottom = 10 + 40 + 5; // Edit Y + Height + padding

                            // Bottom region (main content area)
                            let bottom_region = RECT {
                                left: 0,
                                top: edit_bottom,
                                right: client_rect.right,
                                bottom: client_rect.bottom,
                            };
                            let _ = InvalidateRect(Some(hwnd), Some(&bottom_region), false);

                            // Left margin
                            let left_margin = RECT {
                                left: 0,
                                top: 0,
                                right: 10,
                                bottom: edit_bottom,
                            };
                            let _ = InvalidateRect(Some(hwnd), Some(&left_margin), false);

                            // Right margin
                            let right_margin = RECT {
                                left: client_rect.right - 10,
                                top: 0,
                                right: client_rect.right,
                                bottom: edit_bottom,
                            };
                            let _ = InvalidateRect(Some(hwnd), Some(&right_margin), false);
                        } else {
                            let _ = InvalidateRect(Some(hwnd), None, false);
                        }
                    }
                }
            }

            if should_close {
                // CRITICAL: Set alpha to 0 BEFORE closing to prevent last frame freeze
                let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 0, LWA_ALPHA);

                let linked_hwnd = {
                    let states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get(&(hwnd.0 as isize)) {
                        state.linked_window
                    } else {
                        None
                    }
                };
                if let Some(linked) = linked_hwnd {
                    let linked = crate::win_types::SendHwnd(linked).0;
                    if IsWindow(Some(linked)).as_bool() {
                        // Also set linked window to invisible
                        let _ = SetLayeredWindowAttributes(linked, COLORREF(0), 0, LWA_ALPHA);
                        let _ = PostMessageW(Some(linked), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                }
                let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        } else if wparam.0 == 1 {
            // Revert Copy Icon
            let _ = KillTimer(Some(hwnd), 1);
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                state.copy_success = false;

                // Spawn sparkles for success
                let cx = state.physics.x;
                let cy = state.physics.y;
                for _ in 0..8 {
                    state.physics.particles.push(DustParticle {
                        x: cx + rand_float(-10.0, 10.0),
                        y: cy,
                        vx: rand_float(-2.0, 2.0),
                        vy: rand_float(-2.0, -5.0),
                        life: 1.0,
                        size: rand_float(1.0, 3.0),
                        color: 0xFF00FF00, // Green sparkles
                    });
                }
            }
            let _ = InvalidateRect(Some(hwnd), None, false);
        }
    }
}
</file>

<file path="src/overlay/result/paint.rs">
use super::layout::should_show_buttons;
use super::state::{ResizeEdge, WINDOW_STATES};
use crate::overlay::broom_assets::{render_procedural_broom, BroomRenderParams, BROOM_H, BROOM_W};
use crate::overlay::paint_utils::{hsv_to_rgb, sd_rounded_box};
use std::mem::size_of;
use windows::core::w;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::UI::WindowsAndMessaging::*;

// Helper: Measure text dimensions (Height AND Width)
unsafe fn measure_text_bounds(
    hdc: windows::Win32::Graphics::Gdi::HDC,
    text: &mut [u16],
    font_size: i32,
    max_width: i32,
) -> (i32, i32) {
    let hfont = CreateFontW(
        font_size,
        0,
        0,
        0,
        FW_MEDIUM.0 as i32,
        0,
        0,
        0,
        DEFAULT_CHARSET,
        OUT_DEFAULT_PRECIS,
        CLIP_DEFAULT_PRECIS,
        CLEARTYPE_QUALITY,
        (VARIABLE_PITCH.0 | FF_SWISS.0) as u32,
        w!("Google Sans Flex"),
    );
    let old_font = SelectObject(hdc, hfont.into());

    // We start with the max width constraint.
    // DT_CALCRECT will expand the 'right' value if a single word is wider than max_width (unless we handle it),
    // or wrap lines which increases 'bottom'.
    let mut calc_rect = RECT {
        left: 0,
        top: 0,
        right: max_width,
        bottom: 0,
    };

    // DT_EDITCONTROL helps simulate multiline text box behavior
    DrawTextW(
        hdc,
        text,
        &mut calc_rect,
        DT_CALCRECT | DT_WORDBREAK | DT_EDITCONTROL,
    );

    SelectObject(hdc, old_font);
    let _ = DeleteObject(hfont.into());

    // Return (Height, Width)
    (calc_rect.bottom, calc_rect.right)
}

pub fn create_bitmap_from_pixels(pixels: &[u32], w: i32, h: i32) -> HBITMAP {
    unsafe {
        let hdc = GetDC(None);
        let bmi = BITMAPINFO {
            bmiHeader: BITMAPINFOHEADER {
                biSize: size_of::<BITMAPINFOHEADER>() as u32,
                biWidth: w,
                biHeight: -h,
                biPlanes: 1,
                biBitCount: 32,
                biCompression: BI_RGB.0 as u32,
                ..Default::default()
            },
            ..Default::default()
        };
        let mut bits: *mut core::ffi::c_void = std::ptr::null_mut();
        let hbm = CreateDIBSection(Some(hdc), &bmi, DIB_RGB_COLORS, &mut bits, None, 0).unwrap();
        if !bits.is_null() {
            std::ptr::copy_nonoverlapping(
                pixels.as_ptr() as *const u8,
                bits as *mut u8,
                pixels.len() * 4,
            );
        }
        ReleaseDC(None, hdc);
        hbm
    }
}

// --- MATH HELPERS FOR SDF ICONS ---
fn dist_segment(px: f32, py: f32, ax: f32, ay: f32, bx: f32, by: f32) -> f32 {
    let pax = px - ax;
    let pay = py - ay;
    let bax = bx - ax;
    let bay = by - ay;
    let h = (pax * bax + pay * bay) / (bax * bax + bay * bay).max(0.001);
    let h = h.clamp(0.0, 1.0);
    let dx = pax - bax * h;
    let dy = pay - bay * h;
    (dx * dx + dy * dy).sqrt()
}

fn sd_box(px: f32, py: f32, cx: f32, cy: f32, w: f32, h: f32) -> f32 {
    let dx = (px - cx).abs() - w;
    let dy = (py - cy).abs() - h;
    (dx.max(0.0).powi(2) + dy.max(0.0).powi(2)).sqrt() + dx.max(dy).min(0.0)
}

pub fn paint_window(hwnd: HWND) {
    unsafe {
        let mut ps = PAINTSTRUCT::default();
        let hdc = BeginPaint(hwnd, &mut ps);
        let mut rect = RECT::default();
        let _ = GetClientRect(hwnd, &mut rect);
        let width = rect.right - rect.left;
        let height = rect.bottom - rect.top;

        // --- PHASE 1: STATE SNAPSHOT & CACHE MANAGEMENT ---
        let (
            bg_color_u32,
            is_hovered,
            on_copy_btn,
            copy_success,
            on_edit_btn,
            on_undo_btn,
            on_redo_btn,
            on_markdown_btn,
            is_markdown_mode,
            is_browsing,
            on_back_btn,
            on_forward_btn,
            on_download_btn,
            on_speaker_btn,
            is_speaking,
            tts_loading,
            broom_data,
            particles,
            mut cached_text_bm,
            _cached_font_size,
            cache_dirty,
            cached_bg_bm,
            is_refining,
            is_streaming_active,
            anim_offset,
            history_count,
            redo_count,
            navigation_depth,
            max_navigation_depth,
            graphics_mode,
            preset_prompt,
            input_text,
        ) = {
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                // 1.1 Update Background Cache if needed
                if state.bg_bitmap.is_invalid() || state.bg_w != width || state.bg_h != height {
                    if !state.bg_bitmap.is_invalid() {
                        let _ = DeleteObject(state.bg_bitmap.into());
                    }

                    let bmi = BITMAPINFO {
                        bmiHeader: BITMAPINFOHEADER {
                            biSize: size_of::<BITMAPINFOHEADER>() as u32,
                            biWidth: width,
                            biHeight: -height,
                            biPlanes: 1,
                            biBitCount: 32,
                            biCompression: BI_RGB.0 as u32,
                            ..Default::default()
                        },
                        ..Default::default()
                    };

                    let mut p_bg_bits: *mut core::ffi::c_void = std::ptr::null_mut();
                    let hbm_bg =
                        CreateDIBSection(Some(hdc), &bmi, DIB_RGB_COLORS, &mut p_bg_bits, None, 0)
                            .unwrap();

                    if !p_bg_bits.is_null() {
                        let pixels = std::slice::from_raw_parts_mut(
                            p_bg_bits as *mut u32,
                            (width * height) as usize,
                        );
                        let r = (state.bg_color >> 16) & 0xFF;
                        let g = (state.bg_color >> 8) & 0xFF;
                        let b = state.bg_color & 0xFF;
                        let col = (255 << 24) | (r << 16) | (g << 8) | b;
                        pixels.fill(col);
                    }
                    state.bg_bitmap = hbm_bg;
                    state.bg_w = width;
                    state.bg_h = height;
                }

                if state.last_w != width || state.last_h != height {
                    // Record resize time for debouncing
                    let now = std::time::SystemTime::now()
                        .duration_since(std::time::UNIX_EPOCH)
                        .map(|d| d.as_millis() as u32)
                        .unwrap_or(0);

                    // RESIZE DEBOUNCE: Only recalculate font after resize stops for 100ms
                    // This prevents expensive DrawTextW calls during active resize of large text
                    let time_since_last_resize = now.wrapping_sub(state.last_resize_time);
                    if time_since_last_resize > 100 || state.last_resize_time == 0 {
                        state.font_cache_dirty = true;
                    }
                    // Always update resize time and dimensions
                    state.last_resize_time = now;
                    state.last_w = width;
                    state.last_h = height;
                }

                let particles_vec: Vec<(f32, f32, f32, f32, u32)> = state
                    .physics
                    .particles
                    .iter()
                    .map(|p| (p.x, p.y, p.life, p.size, p.color))
                    .collect();

                // AGGRESSIVE FIX: Don't render broom during ANY closing animation (Smashing OR DragOut)
                // This completely eliminates the "frozen frame" issue during fade
                // The broom is only shown on hover, not during click-to-close
                let is_closing = false;

                let show_broom = !is_closing
                    && !state.is_markdown_mode
                    && (state.is_hovered
                        && !state.on_copy_btn
                        && !state.on_edit_btn
                        && !state.on_undo_btn
                        && !state.on_redo_btn
                        && !state.on_markdown_btn
                        && !state.on_back_btn
                        && !state.on_forward_btn
                        && !state.on_download_btn
                        && !state.on_speaker_btn
                        && state.current_resize_edge == ResizeEdge::None);

                let broom_info = if show_broom {
                    Some((
                        state.physics.x,
                        state.physics.y,
                        BroomRenderParams {
                            tilt_angle: state.physics.current_tilt,
                            squish: state.physics.squish_factor,
                            bend: state.physics.bristle_bend,
                            opacity: 1.0,
                        },
                    ))
                } else {
                    None
                };

                // Check if TTS is currently speaking for this window
                let is_speaking = state.tts_request_id != 0
                    && crate::api::tts::TTS_MANAGER.is_speaking(state.tts_request_id);

                (
                    state.bg_color,
                    state.is_hovered,
                    state.on_copy_btn,
                    state.copy_success,
                    state.on_edit_btn,
                    state.on_undo_btn,
                    state.on_redo_btn,
                    state.on_markdown_btn,
                    state.is_markdown_mode,
                    state.is_browsing,
                    state.on_back_btn,
                    state.on_forward_btn,
                    state.on_download_btn,
                    state.on_speaker_btn,
                    is_speaking,
                    state.tts_loading,
                    broom_info,
                    particles_vec,
                    state.content_bitmap,
                    state.cached_font_size as i32,
                    state.font_cache_dirty,
                    state.bg_bitmap,
                    state.is_refining,
                    state.is_streaming_active,
                    state.animation_offset,
                    state.text_history.len(),
                    state.redo_history.len(),
                    state.navigation_depth,
                    state.max_navigation_depth,
                    state.graphics_mode.clone(),
                    state.preset_prompt.clone(),
                    state.input_text.clone(),
                )
            } else {
                (
                    0,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    false,
                    None,
                    Vec::new(),
                    HBITMAP::default(),
                    72,
                    true,
                    HBITMAP::default(),
                    false,
                    false,
                    0.0,
                    0,
                    0,
                    0,
                    0,
                    "standard".to_string(),
                    String::new(),
                    String::new(),
                )
            }
        };

        // --- PHASE 2: COMPOSITOR SETUP ---
        let mem_dc = CreateCompatibleDC(Some(hdc));

        let bmi_scratch = BITMAPINFO {
            bmiHeader: BITMAPINFOHEADER {
                biSize: size_of::<BITMAPINFOHEADER>() as u32,
                biWidth: width,
                biHeight: -height,
                biPlanes: 1,
                biBitCount: 32,
                biCompression: BI_RGB.0 as u32,
                ..Default::default()
            },
            ..Default::default()
        };
        let mut scratch_bits: *mut core::ffi::c_void = std::ptr::null_mut();
        let scratch_bitmap = CreateDIBSection(
            Some(hdc),
            &bmi_scratch,
            DIB_RGB_COLORS,
            &mut scratch_bits,
            None,
            0,
        )
        .unwrap();
        let old_scratch = SelectObject(mem_dc, scratch_bitmap.into());

        // 2.1 Copy Background
        if !cached_bg_bm.is_invalid() {
            let cache_dc = CreateCompatibleDC(Some(hdc));
            let old_cbm = SelectObject(cache_dc, cached_bg_bm.into());
            let _ = BitBlt(mem_dc, 0, 0, width, height, Some(cache_dc), 0, 0, SRCCOPY).ok();
            SelectObject(cache_dc, old_cbm);
            let _ = DeleteDC(cache_dc);
        }

        if !is_markdown_mode {
            if cache_dirty || cached_text_bm.is_invalid() {
                if !cached_text_bm.is_invalid() {
                    let _ = DeleteObject(cached_text_bm.into());
                }

                cached_text_bm = CreateCompatibleBitmap(hdc, width, height);
                let cache_dc = CreateCompatibleDC(Some(hdc));
                let old_cache_bm = SelectObject(cache_dc, cached_text_bm.into());

                let dark_brush = CreateSolidBrush(COLORREF(bg_color_u32));
                let fill_rect = RECT {
                    left: 0,
                    top: 0,
                    right: width,
                    bottom: height,
                };
                FillRect(cache_dc, &fill_rect, dark_brush);
                let _ = DeleteObject(dark_brush.into());

                SetBkMode(cache_dc, TRANSPARENT);
                // Auto-contrast text color based on background luminance
                let bg_r = (bg_color_u32 >> 16) & 0xFF;
                let bg_g = (bg_color_u32 >> 8) & 0xFF;
                let bg_b = bg_color_u32 & 0xFF;
                let luminance =
                    (0.299 * bg_r as f32) + (0.587 * bg_g as f32) + (0.114 * bg_b as f32);
                let text_col = if luminance > 140.0 {
                    0x00000000 // Black text for light background
                } else {
                    0x00FFFFFF // White text for dark background
                };
                SetTextColor(cache_dc, COLORREF(text_col));

                let mut buf = if is_refining {
                    if !crate::overlay::utils::SHOW_REFINING_CONTEXT_QUOTE {
                        vec![0u16; 1] // Return empty buffer
                    } else {
                        let combined = if input_text.is_empty() {
                            preset_prompt.clone()
                        } else {
                            format!("{}\n\n{}", preset_prompt, input_text)
                        };
                        let quote = crate::overlay::utils::get_context_quote(&combined);
                        quote.encode_utf16().collect::<Vec<u16>>()
                    }
                } else {
                    let text_len = GetWindowTextLengthW(hwnd);
                    let mut b = vec![0u16; text_len as usize + 1];
                    let actual_len = GetWindowTextW(hwnd, &mut b);
                    b.truncate(actual_len as usize);
                    b
                };

                let h_padding = if is_refining { 20 } else { 2 };
                let available_w = (width - (h_padding * 2)).max(1);
                let v_safety_margin = 0;
                let available_h = (height - v_safety_margin).max(1);

                let mut low = if is_refining { 8 } else { 2 };
                let max_possible = if is_refining {
                    18.min(available_h)
                } else {
                    available_h.max(2).min(150)
                };
                let mut high = max_possible;
                let mut best_fit = low;

                if high < low {
                    best_fit = low;
                } else {
                    while low <= high {
                        let mid = (low + high) / 2;
                        let (h, w) = measure_text_bounds(cache_dc, &mut buf, mid, available_w);
                        if h <= available_h && w <= available_w {
                            best_fit = mid;
                            low = mid + 1;
                        } else {
                            high = mid - 1;
                        }
                    }
                }
                let font_size_val = best_fit;

                let font_weight = if is_refining { FW_NORMAL } else { FW_MEDIUM };
                let hfont = CreateFontW(
                    font_size_val,
                    0,
                    0,
                    0,
                    font_weight.0 as i32,
                    0,
                    0,
                    0,
                    DEFAULT_CHARSET,
                    OUT_DEFAULT_PRECIS,
                    CLIP_DEFAULT_PRECIS,
                    CLEARTYPE_QUALITY,
                    (VARIABLE_PITCH.0 | FF_SWISS.0) as u32,
                    w!("Google Sans Flex"),
                );
                let old_font = SelectObject(cache_dc, hfont.into());

                let mut measure_rect = RECT {
                    left: 0,
                    top: 0,
                    right: available_w,
                    bottom: 0,
                };
                DrawTextW(
                    cache_dc,
                    &mut buf,
                    &mut measure_rect,
                    DT_CALCRECT | DT_WORDBREAK | DT_EDITCONTROL,
                );
                let text_h = measure_rect.bottom;

                let offset_y = ((height - text_h) / 2).max(0);
                let mut draw_rect = RECT {
                    left: h_padding,
                    top: offset_y,
                    right: width - h_padding,
                    bottom: height,
                };

                let draw_flags = if is_refining {
                    DT_CENTER | DT_WORDBREAK | DT_EDITCONTROL
                } else {
                    DT_LEFT | DT_WORDBREAK | DT_EDITCONTROL
                };
                DrawTextW(cache_dc, &mut buf, &mut draw_rect as *mut _, draw_flags);

                SelectObject(cache_dc, old_font);
                let _ = DeleteObject(hfont.into());
                SelectObject(cache_dc, old_cache_bm);
                let _ = DeleteDC(cache_dc);

                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                    state.content_bitmap = cached_text_bm;
                    state.cached_font_size = font_size_val;
                    state.font_cache_dirty = false;
                }
            }

            if !cached_text_bm.is_invalid() {
                let cache_dc = CreateCompatibleDC(Some(hdc));
                let old_cbm = SelectObject(cache_dc, cached_text_bm.into());
                let _ = BitBlt(mem_dc, 0, 0, width, height, Some(cache_dc), 0, 0, SRCCOPY).ok();
                SelectObject(cache_dc, old_cbm);
                let _ = DeleteDC(cache_dc);
            }
        }

        // --- PHASE 4: PIXEL MANIPULATION ---
        if !scratch_bits.is_null() {
            let raw_pixels =
                std::slice::from_raw_parts_mut(scratch_bits as *mut u32, (width * height) as usize);

            // 4.0 REFINEMENT GLOW
            if is_refining {
                let is_minimal = graphics_mode == "minimal";

                if is_minimal {
                    // MINIMAL MODE: Bouncing orange scan line (exactly like green laser but orange)
                    // Simple, lightweight, no per-pixel calculation

                    // Calculate scan line position (bounces up and down)
                    // Use abs() because anim_offset can be negative
                    let cycle = (anim_offset.abs() % 360.0) / 180.0; // 0.0 to 2.0
                    let t = if cycle <= 1.0 { cycle } else { 2.0 - cycle }; // 0.0 to 1.0 (bounce)

                    let margin = 3;
                    let scan_range = height - (margin * 2);
                    if scan_range > 0 {
                        let scan_y =
                            margin + ((t * scan_range as f32) as i32).clamp(0, scan_range - 1);

                        // Draw 2px thick orange line
                        for line_offset in 0..2 {
                            let y = scan_y + line_offset;
                            if y > 0 && y < height - 1 {
                                for x in margin..(width - margin) {
                                    let idx = (y * width + x) as usize;
                                    if idx < raw_pixels.len() {
                                        // Blend orange with background
                                        let bg_px = raw_pixels[idx];
                                        let bg_b = (bg_px & 0xFF) as f32;
                                        let bg_g = ((bg_px >> 8) & 0xFF) as f32;
                                        let bg_r = ((bg_px >> 16) & 0xFF) as f32;

                                        let intensity = 0.9; // Strong but not fully opaque
                                        let out_r =
                                            (255.0 * intensity + bg_r * (1.0 - intensity)) as u32;
                                        let out_g =
                                            (140.0 * intensity + bg_g * (1.0 - intensity)) as u32;
                                        let out_b =
                                            (0.0 * intensity + bg_b * (1.0 - intensity)) as u32;
                                        raw_pixels[idx] =
                                            (255 << 24) | (out_r << 16) | (out_g << 8) | out_b;
                                    }
                                }
                            }
                        }
                    }
                } else {
                    // STANDARD MODE: Rainbow edge glow (full per-pixel calculation)
                    let bx = width as f32 / 2.0;
                    let by = height as f32 / 2.0;
                    let center_x = bx;
                    let center_y = by;
                    let time_rad = anim_offset.to_radians();

                    for y in 0..height {
                        for x in 0..width {
                            let idx = (y * width + x) as usize;
                            let px = x as f32 - center_x;
                            let py = y as f32 - center_y;
                            let d = sd_rounded_box(px, py, bx, by, 12.0);

                            if d <= 0.0 {
                                let dist = d.abs();
                                if dist < 20.0 {
                                    let angle = py.atan2(px);
                                    let noise = (angle * 12.0 - time_rad * 2.0).sin() * 0.5;
                                    let glow_width = 14.0;
                                    let t = (dist / glow_width).clamp(0.0, 1.0);
                                    let base_intensity = (1.0 - t).powi(3);

                                    if base_intensity > 0.01 {
                                        let noise_mod = (1.0 + noise * 0.3).clamp(0.0, 2.0);
                                        let final_intensity =
                                            (base_intensity * noise_mod).clamp(0.0, 1.0);
                                        if final_intensity > 0.01 {
                                            let deg = angle.to_degrees() + (anim_offset * 2.0);
                                            let hue = (deg % 360.0 + 360.0) % 360.0;
                                            let rgb = hsv_to_rgb(hue, 0.85, 1.0);
                                            let bg_px = raw_pixels[idx];
                                            let bg_b = (bg_px & 0xFF) as f32;
                                            let bg_g = ((bg_px >> 8) & 0xFF) as f32;
                                            let bg_r = ((bg_px >> 16) & 0xFF) as f32;
                                            let fg_r = ((rgb >> 16) & 0xFF) as f32;
                                            let fg_g = ((rgb >> 8) & 0xFF) as f32;
                                            let fg_b = (rgb & 0xFF) as f32;

                                            let out_r = (fg_r * final_intensity
                                                + bg_r * (1.0 - final_intensity))
                                                as u32;
                                            let out_g = (fg_g * final_intensity
                                                + bg_g * (1.0 - final_intensity))
                                                as u32;
                                            let out_b = (fg_b * final_intensity
                                                + bg_b * (1.0 - final_intensity))
                                                as u32;
                                            raw_pixels[idx] =
                                                (255 << 24) | (out_r << 16) | (out_g << 8) | out_b;
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }

            // 4.1 Particles
            for (d_x, d_y, life, size, col) in particles {
                if life <= 0.0 {
                    continue;
                }
                let radius = size * life;
                if radius < 0.5 {
                    continue;
                }

                let p_r = ((col >> 16) & 0xFF) as f32;
                let p_g = ((col >> 8) & 0xFF) as f32;
                let p_b = (col & 0xFF) as f32;
                let p_max_alpha = 255.0 * life;

                let min_x = (d_x - radius - 1.0).floor() as i32;
                let max_x = (d_x + radius + 1.0).ceil() as i32;
                let min_y = (d_y - radius - 1.0).floor() as i32;
                let max_y = (d_y + radius + 1.0).ceil() as i32;

                let start_x = min_x.max(0);
                let end_x = max_x.min(width - 1);
                let start_y = min_y.max(0);
                let end_y = max_y.min(height - 1);

                for y in start_y..=end_y {
                    for x in start_x..=end_x {
                        let dx = x as f32 - d_x;
                        let dy = y as f32 - d_y;
                        let dist = (dx * dx + dy * dy).sqrt();
                        let aa_edge = (radius + 0.5 - dist).clamp(0.0, 1.0);

                        if aa_edge > 0.0 {
                            let idx = (y * width + x) as usize;
                            let bg_px = raw_pixels[idx];
                            let bg_b = (bg_px & 0xFF) as f32;
                            let bg_g = ((bg_px >> 8) & 0xFF) as f32;
                            let bg_r = ((bg_px >> 16) & 0xFF) as f32;

                            let final_alpha_norm = (p_max_alpha * aa_edge) / 255.0;
                            let inv_alpha = 1.0 - final_alpha_norm;

                            let out_r = (p_r * final_alpha_norm + bg_r * inv_alpha) as u32;
                            let out_g = (p_g * final_alpha_norm + bg_g * inv_alpha) as u32;
                            let out_b = (p_b * final_alpha_norm + bg_b * inv_alpha) as u32;

                            raw_pixels[idx] = (255 << 24) | (out_r << 16) | (out_g << 8) | out_b;
                        }
                    }
                }
            }

            // 4.2 Buttons - hide during refining, streaming, or when overlay is too small
            if is_hovered
                && !is_refining
                && !is_streaming_active
                && should_show_buttons(width, height)
            {
                let btn_size = 28;
                let margin = 12;
                let threshold_h = btn_size + (margin * 2);
                let cy = if height < threshold_h {
                    (height as f32) / 2.0
                } else {
                    (height - margin - btn_size / 2) as f32
                };

                // Button positions - used differently based on browsing mode
                let cx_back = (margin + btn_size / 2) as f32;
                let cx_forward = (width - margin - btn_size / 2) as f32; // Forward on right when browsing

                // Result UI button positions (only used when not browsing)
                // Order from right to left: Copy -> Speaker -> Edit -> Markdown -> Download -> Undo -> Redo
                let cx_copy = (width - margin - btn_size / 2) as f32;
                let cx_speaker = cx_copy - (btn_size as f32) - 8.0;
                let cx_edit = cx_speaker - (btn_size as f32) - 8.0;
                let cx_md = cx_edit - (btn_size as f32) - 8.0;
                let cx_dl = cx_md - (btn_size as f32) - 8.0;
                let cx_undo = cx_dl - (btn_size as f32) - 8.0;
                let cx_redo = cx_undo - (btn_size as f32) - 8.0;

                let radius = 13.0;

                // Color configuration
                let (tr_c, tg_c, tb_c) = if copy_success {
                    (30.0, 180.0, 30.0)
                } else if on_copy_btn {
                    (128.0, 128.0, 128.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_e, tg_e, tb_e) = if on_edit_btn {
                    (128.0, 128.0, 128.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_u, tg_u, tb_u) = if on_undo_btn {
                    (128.0, 128.0, 128.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_rd, tg_rd, tb_rd) = if on_redo_btn {
                    (128.0, 128.0, 128.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_m, tg_m, tb_m) = if is_markdown_mode {
                    (60.0, 180.0, 200.0)
                } else if on_markdown_btn {
                    (100.0, 140.0, 180.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_b, tg_b, tb_b) = if on_back_btn {
                    (128.0, 128.0, 128.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_f, tg_f, tb_f) = if on_forward_btn {
                    (128.0, 128.0, 128.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                let (tr_dl, tg_dl, tb_dl) = if on_download_btn {
                    (100.0, 180.0, 100.0)
                } else {
                    (80.0, 80.0, 80.0)
                };
                // Speaker button: orange when loading, blue when speaking, gray when idle
                let (tr_sp, tg_sp, tb_sp) = if tts_loading {
                    (255.0, 180.0, 50.0) // Orange/yellow for loading
                } else if is_speaking {
                    (80.0, 150.0, 220.0) // Blue for speaking
                } else if on_speaker_btn {
                    (128.0, 128.0, 128.0) // Highlight on hover
                } else {
                    (80.0, 80.0, 80.0) // Default gray
                };

                let b_start_y = (cy - radius - 4.0) as i32;
                let b_end_y = (cy + radius + 4.0) as i32;
                let show_undo = history_count > 0 && !is_browsing;
                let show_redo = redo_count > 0 && !is_browsing;
                let show_forward = is_browsing && navigation_depth < max_navigation_depth;
                let show_speaker = !is_browsing; // Always show speaker when not browsing
                let border_inner_radius = radius - 1.5;

                for y in b_start_y.max(0)..b_end_y.min(height) {
                    for x in 0..width {
                        let fx = x as f32;
                        let fy = y as f32;
                        let dy = (fy - cy).abs();

                        let mut hit = false;
                        let mut t_r = 0.0;
                        let mut t_g = 0.0;
                        let mut t_b = 0.0;
                        let mut alpha = 0.0;
                        let mut border_alpha = 0.0;
                        let mut icon_alpha = 0.0;

                        if is_browsing {
                            // BROWSING MODE: Only show Back (left) and Forward (right) buttons

                            // BACK BUTTON (Left side)
                            if x < width / 2 {
                                let dx = (fx - cx_back).abs();
                                let dist = (dx * dx + dy * dy).sqrt();
                                let aa = (radius + 0.5 - dist).clamp(0.0, 1.0);
                                if aa > 0.0 {
                                    hit = true;
                                    alpha = aa;
                                    t_r = tr_b;
                                    t_g = tg_b;
                                    t_b = tb_b;
                                    border_alpha = ((radius + 0.5 - dist).clamp(0.0, 1.0)
                                        * ((dist - (border_inner_radius - 0.5)).clamp(0.0, 1.0)))
                                        * 0.6;

                                    // Back Arrow (Left Arrow)
                                    let tip_x = cx_back - 3.5;
                                    let tail_x = cx_back + 3.5;
                                    let d_shaft = dist_segment(fx, fy, tip_x, cy, tail_x, cy);
                                    let d_wing1 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x + 3.0, cy - 3.0);
                                    let d_wing2 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x + 3.0, cy + 3.0);
                                    let d_arrow = d_shaft.min(d_wing1).min(d_wing2);
                                    icon_alpha = (1.3 - d_arrow).clamp(0.0, 1.0);
                                }
                            }

                            // FORWARD BUTTON (Right side)
                            if !hit && show_forward && x > width / 2 {
                                let dx = (fx - cx_forward).abs();
                                let dist = (dx * dx + dy * dy).sqrt();
                                let aa = (radius + 0.5 - dist).clamp(0.0, 1.0);
                                if aa > 0.0 {
                                    hit = true;
                                    alpha = aa;
                                    t_r = tr_f;
                                    t_g = tg_f;
                                    t_b = tb_f;
                                    border_alpha = ((radius + 0.5 - dist).clamp(0.0, 1.0)
                                        * ((dist - (border_inner_radius - 0.5)).clamp(0.0, 1.0)))
                                        * 0.6;

                                    // Forward Arrow (Right Arrow)
                                    let tip_x = cx_forward + 3.5;
                                    let tail_x = cx_forward - 3.5;
                                    let d_shaft = dist_segment(fx, fy, tail_x, cy, tip_x, cy);
                                    let d_wing1 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x - 3.0, cy - 3.0);
                                    let d_wing2 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x - 3.0, cy + 3.0);
                                    let d_arrow = d_shaft.min(d_wing1).min(d_wing2);
                                    icon_alpha = (1.3 - d_arrow).clamp(0.0, 1.0);
                                }
                            }
                        } else {
                            // RESULT MODE: Show all result UI buttons on the right side

                            // COPY
                            let dx_c = (fx - cx_copy).abs();
                            let dist_c = (dx_c * dx_c + dy * dy).sqrt();
                            let aa_c = (radius + 0.5 - dist_c).clamp(0.0, 1.0);
                            if aa_c > 0.0 {
                                hit = true;
                                alpha = aa_c;
                                t_r = tr_c;
                                t_g = tg_c;
                                t_b = tb_c;
                                border_alpha = ((radius + 0.5 - dist_c).clamp(0.0, 1.0)
                                    * ((dist_c - (border_inner_radius - 0.5)).clamp(0.0, 1.0)))
                                    * 0.6;
                                if copy_success {
                                    let d1 = dist_segment(
                                        fx,
                                        fy,
                                        cx_copy - 4.0,
                                        cy,
                                        cx_copy - 1.0,
                                        cy + 3.0,
                                    );
                                    let d2 = dist_segment(
                                        fx,
                                        fy,
                                        cx_copy - 1.0,
                                        cy + 3.0,
                                        cx_copy + 4.0,
                                        cy - 4.0,
                                    );
                                    icon_alpha = (1.8 - d1.min(d2)).clamp(0.0, 1.0);
                                } else {
                                    let back_d = sd_box(fx, fy, cx_copy - 2.0, cy - 2.0, 3.0, 4.0);
                                    let back_outline = (1.25 - back_d.abs()).clamp(0.0, 1.0);
                                    let front_d = sd_box(fx, fy, cx_copy + 2.0, cy + 2.0, 3.0, 4.0);
                                    let front_fill = (0.8 - front_d).clamp(0.0, 1.0);
                                    let mask_d = sd_box(fx, fy, cx_copy + 2.0, cy + 2.0, 4.5, 5.5);
                                    icon_alpha = (front_fill
                                        + back_outline * mask_d.clamp(0.0, 1.0))
                                    .clamp(0.0, 1.0);
                                }
                            }

                            // EDIT
                            if !hit {
                                let dx_e = (fx - cx_edit).abs();
                                let dist_e = (dx_e * dx_e + dy * dy).sqrt();
                                let aa_e = (radius + 0.5 - dist_e).clamp(0.0, 1.0);
                                if aa_e > 0.0 {
                                    hit = true;
                                    alpha = aa_e;
                                    t_r = tr_e;
                                    t_g = tg_e;
                                    t_b = tb_e;
                                    border_alpha = ((radius + 0.5 - dist_e).clamp(0.0, 1.0)
                                        * ((dist_e - (border_inner_radius - 0.5)).clamp(0.0, 1.0)))
                                        * 0.6;
                                    let sx = (fx - cx_edit).abs();
                                    let sy = (fy - cy).abs();
                                    let star_dist =
                                        (sx.powf(0.6) + sy.powf(0.6)).powf(1.0 / 0.6) - 4.5;
                                    let mut ia = (1.2 - star_dist).clamp(0.0, 1.0);
                                    let sx2 = (fx - (cx_edit + 4.5)).abs();
                                    let sy2 = (fy - (cy - 3.5)).abs();
                                    let star2_dist =
                                        (sx2.powf(0.6) + sy2.powf(0.6)).powf(1.0 / 0.6) - 2.2;
                                    ia = ia.max((1.2 - star2_dist).clamp(0.0, 1.0));
                                    icon_alpha = ia;
                                }
                            }

                            // MARKDOWN
                            if !hit {
                                let dx_m = (fx - cx_md).abs();
                                let dist_m = (dx_m * dx_m + dy * dy).sqrt();
                                let aa_m = (radius + 0.5 - dist_m).clamp(0.0, 1.0);
                                if aa_m > 0.0 {
                                    hit = true;
                                    alpha = aa_m;
                                    t_r = tr_m;
                                    t_g = tg_m;
                                    t_b = tb_m;
                                    border_alpha = ((radius + 0.5 - dist_m).clamp(0.0, 1.0)
                                        * ((dist_m - (border_inner_radius - 0.5)).clamp(0.0, 1.0)))
                                        * 0.6;
                                    let d_m1 = dist_segment(
                                        fx,
                                        fy,
                                        cx_md - 4.0,
                                        cy + 4.0,
                                        cx_md - 4.0,
                                        cy - 4.0,
                                    );
                                    let d_m2 = dist_segment(
                                        fx,
                                        fy,
                                        cx_md - 4.0,
                                        cy - 4.0,
                                        cx_md,
                                        cy + 1.0,
                                    );
                                    let d_m3 = dist_segment(
                                        fx,
                                        fy,
                                        cx_md,
                                        cy + 1.0,
                                        cx_md + 4.0,
                                        cy - 4.0,
                                    );
                                    let d_m4 = dist_segment(
                                        fx,
                                        fy,
                                        cx_md + 4.0,
                                        cy - 4.0,
                                        cx_md + 4.0,
                                        cy + 4.0,
                                    );
                                    let d_m = d_m1.min(d_m2).min(d_m3).min(d_m4);
                                    icon_alpha = (1.5 - d_m).clamp(0.0, 1.0);
                                }
                            }

                            // DOWNLOAD
                            if !hit {
                                let dx_dl = (fx - cx_dl).abs();
                                let dist_dl = (dx_dl * dx_dl + dy * dy).sqrt();
                                let aa_dl = (radius + 0.5 - dist_dl).clamp(0.0, 1.0);
                                if aa_dl > 0.0 {
                                    hit = true;
                                    alpha = aa_dl;
                                    t_r = tr_dl;
                                    t_g = tg_dl;
                                    t_b = tb_dl;
                                    border_alpha = ((radius + 0.5 - dist_dl).clamp(0.0, 1.0)
                                        * ((dist_dl - (border_inner_radius - 0.5))
                                            .clamp(0.0, 1.0)))
                                        * 0.6;
                                    let d_line =
                                        dist_segment(fx, fy, cx_dl, cy - 4.0, cx_dl, cy + 2.0);
                                    let d_arrow1 = dist_segment(
                                        fx,
                                        fy,
                                        cx_dl - 3.5,
                                        cy - 0.5,
                                        cx_dl,
                                        cy + 3.5,
                                    );
                                    let d_arrow2 = dist_segment(
                                        fx,
                                        fy,
                                        cx_dl + 3.5,
                                        cy - 0.5,
                                        cx_dl,
                                        cy + 3.5,
                                    );
                                    let d_tray = dist_segment(
                                        fx,
                                        fy,
                                        cx_dl - 4.0,
                                        cy + 4.5,
                                        cx_dl + 4.0,
                                        cy + 4.5,
                                    );
                                    let d_icon = d_line.min(d_arrow1).min(d_arrow2).min(d_tray);
                                    icon_alpha = (1.5 - d_icon).clamp(0.0, 1.0);
                                }
                            }

                            // UNDO
                            if !hit && show_undo {
                                let dx_u = (fx - cx_undo).abs();
                                let dist_u = (dx_u * dx_u + dy * dy).sqrt();
                                let aa_u = (radius + 0.5 - dist_u).clamp(0.0, 1.0);
                                if aa_u > 0.0 {
                                    hit = true;
                                    alpha = aa_u;
                                    t_r = tr_u;
                                    t_g = tg_u;
                                    t_b = tb_u;
                                    border_alpha = ((radius + 0.5 - dist_u).clamp(0.0, 1.0)
                                        * ((dist_u - (border_inner_radius - 0.5)).clamp(0.0, 1.0)))
                                        * 0.6;
                                    let tip_x = cx_undo - 3.5;
                                    let tail_x = cx_undo + 3.5;
                                    let d_shaft = dist_segment(fx, fy, tip_x, cy, tail_x, cy);
                                    let d_wing1 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x + 3.0, cy - 3.0);
                                    let d_wing2 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x + 3.0, cy + 3.0);
                                    let d_arrow = d_shaft.min(d_wing1).min(d_wing2);
                                    icon_alpha = (1.3 - d_arrow).clamp(0.0, 1.0);
                                }
                            }

                            // REDO
                            if !hit && show_redo {
                                let dx_rd = (fx - cx_redo).abs();
                                let dist_rd = (dx_rd * dx_rd + dy * dy).sqrt();
                                let aa_rd = (radius + 0.5 - dist_rd).clamp(0.0, 1.0);
                                if aa_rd > 0.0 {
                                    hit = true;
                                    alpha = aa_rd;
                                    t_r = tr_rd;
                                    t_g = tg_rd;
                                    t_b = tb_rd;
                                    border_alpha = ((radius + 0.5 - dist_rd).clamp(0.0, 1.0)
                                        * ((dist_rd - (border_inner_radius - 0.5))
                                            .clamp(0.0, 1.0)))
                                        * 0.6;
                                    let tip_x = cx_redo + 3.5;
                                    let tail_x = cx_redo - 3.5;
                                    let d_shaft = dist_segment(fx, fy, tail_x, cy, tip_x, cy);
                                    let d_wing1 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x - 3.0, cy - 3.0);
                                    let d_wing2 =
                                        dist_segment(fx, fy, tip_x, cy, tip_x - 3.0, cy + 3.0);
                                    let d_arrow = d_shaft.min(d_wing1).min(d_wing2);
                                    icon_alpha = (1.3 - d_arrow).clamp(0.0, 1.0);
                                }
                            }

                            // SPEAKER (TTS)
                            if !hit && show_speaker {
                                let dx_sp = (fx - cx_speaker).abs();
                                let dist_sp = (dx_sp * dx_sp + dy * dy).sqrt();
                                let aa_sp = (radius + 0.5 - dist_sp).clamp(0.0, 1.0);
                                if aa_sp > 0.0 {
                                    hit = true;
                                    alpha = aa_sp;
                                    t_r = tr_sp;
                                    t_g = tg_sp;
                                    t_b = tb_sp;
                                    border_alpha = ((radius + 0.5 - dist_sp).clamp(0.0, 1.0)
                                        * ((dist_sp - (border_inner_radius - 0.5))
                                            .clamp(0.0, 1.0)))
                                        * 0.6;

                                    // Speaker icon: cone + sound waves
                                    // Speaker cone (left side)
                                    let cone_l = cx_speaker - 4.0;
                                    let cone_r = cx_speaker - 1.0;
                                    let cone_t = cy - 2.0;
                                    let cone_b = cy + 2.0;
                                    let d_cone = sd_box(
                                        fx,
                                        fy,
                                        (cone_l + cone_r) / 2.0,
                                        cy,
                                        (cone_r - cone_l) / 2.0,
                                        (cone_b - cone_t) / 2.0,
                                    );

                                    // Speaker "bell" (trapezoid-ish, made with lines)
                                    let d_bell1 = dist_segment(
                                        fx,
                                        fy,
                                        cone_r,
                                        cone_t,
                                        cone_r + 2.5,
                                        cy - 4.0,
                                    );
                                    let d_bell2 = dist_segment(
                                        fx,
                                        fy,
                                        cone_r + 2.5,
                                        cy - 4.0,
                                        cone_r + 2.5,
                                        cy + 4.0,
                                    );
                                    let d_bell3 = dist_segment(
                                        fx,
                                        fy,
                                        cone_r + 2.5,
                                        cy + 4.0,
                                        cone_r,
                                        cone_b,
                                    );
                                    let d_bell = d_bell1.min(d_bell2).min(d_bell3);

                                    // Sound waves (arcs to the right)
                                    let wave_cx = cx_speaker + 2.0;
                                    let px = fx - wave_cx;
                                    let py_wave = fy - cy;
                                    let angle = py_wave.atan2(px);

                                    // Only draw waves on the right side (facing direction)
                                    let mut d_wave = 100.0f32;
                                    if px > 0.0 && angle.abs() < std::f32::consts::FRAC_PI_3 {
                                        let dist_from_center = (px * px + py_wave * py_wave).sqrt();
                                        // Two wave arcs at different distances
                                        let d_wave1 = (dist_from_center - 3.5).abs() - 0.8;
                                        let d_wave2 = (dist_from_center - 6.0).abs() - 0.8;
                                        d_wave = d_wave1.min(d_wave2);
                                    }

                                    let d_speaker = d_cone.min(d_bell).min(d_wave);
                                    icon_alpha = (1.5 - d_speaker).clamp(0.0, 1.0);
                                }
                            }
                        }

                        if hit {
                            let idx = (y * width + x) as usize;
                            let bg = raw_pixels[idx];
                            let bg_b = (bg & 0xFF) as f32;
                            let bg_g = ((bg >> 8) & 0xFF) as f32;
                            let bg_r = ((bg >> 16) & 0xFF) as f32;

                            let mut final_r = bg_r;
                            let mut final_g = bg_g;
                            let mut final_b = bg_b;

                            if alpha > 0.0 {
                                let a = 0.9 * alpha;
                                final_r = t_r * a + final_r * (1.0 - a);
                                final_g = t_g * a + final_g * (1.0 - a);
                                final_b = t_b * a + final_b * (1.0 - a);
                            }
                            if border_alpha > 0.0 {
                                final_r += 255.0 * border_alpha;
                                final_g += 255.0 * border_alpha;
                                final_b += 255.0 * border_alpha;
                            }
                            if icon_alpha > 0.0 {
                                final_r = 255.0 * icon_alpha + final_r * (1.0 - icon_alpha);
                                final_g = 255.0 * icon_alpha + final_g * (1.0 - icon_alpha);
                                final_b = 255.0 * icon_alpha + final_b * (1.0 - icon_alpha);
                            }

                            raw_pixels[idx] = (255 << 24)
                                | ((final_r.min(255.0) as u32) << 16)
                                | ((final_g.min(255.0) as u32) << 8)
                                | (final_b.min(255.0) as u32);
                        }
                    }
                }
            }
        }

        // --- PHASE 5: DYNAMIC BROOM ---
        let broom_bitmap_data = if let Some((bx, by, params)) = broom_data {
            let pixels = render_procedural_broom(params);
            let hbm = create_bitmap_from_pixels(&pixels, BROOM_W, BROOM_H);
            Some((bx, by, hbm))
        } else {
            None
        };

        if let Some((px, py, hbm)) = broom_bitmap_data {
            if !hbm.is_invalid() {
                let broom_dc = CreateCompatibleDC(Some(hdc));
                let old_hbm_broom = SelectObject(broom_dc, hbm.into());
                let mut bf = BLENDFUNCTION::default();
                bf.BlendOp = AC_SRC_OVER as u8;
                bf.SourceConstantAlpha = 255;
                bf.AlphaFormat = AC_SRC_ALPHA as u8;
                let draw_x = px as i32 - (BROOM_W / 2);
                let draw_y = py as i32 - (BROOM_H as f32 * 0.65) as i32;
                let _ = GdiAlphaBlend(
                    mem_dc, draw_x, draw_y, BROOM_W, BROOM_H, broom_dc, 0, 0, BROOM_W, BROOM_H, bf,
                );
                SelectObject(broom_dc, old_hbm_broom);
                let _ = DeleteDC(broom_dc);
                let _ = DeleteObject(hbm.into());
            }
        }

        // --- PHASE 6: FINAL BLIT ---
        let _ = BitBlt(hdc, 0, 0, width, height, Some(mem_dc), 0, 0, SRCCOPY).ok();

        SelectObject(mem_dc, old_scratch);
        let _ = DeleteObject(scratch_bitmap.into());
        let _ = DeleteDC(mem_dc);

        let _ = EndPaint(hwnd, &mut ps);
    }
}
</file>

<file path="src/overlay/screen_record/native_export.rs">
use image::imageops::{resize, FilterType};
use image::{ImageBuffer, Rgba};
use serde::Deserialize;
use std::io::Write;
use std::path::PathBuf;
use std::process::{Command, Stdio};

use crate::overlay::screen_record::engine::VIDEO_PATH;

// --- Structs for JSON Deserialization ---

#[derive(Deserialize, Debug, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ExportConfig {
    pub width: u32,
    pub height: u32,
    pub framerate: u32,
    pub audio_path: String,
    pub trim_start: f64,
    pub duration: f64,
    pub speed: f64,
    pub segment: VideoSegment,
    pub background_config: BackgroundConfig,
    pub mouse_positions: Vec<MousePosition>,
}

#[derive(Deserialize, Debug, Clone)]
#[serde(rename_all = "camelCase")]
pub struct VideoSegment {
    pub trim_start: f64,
    pub trim_end: f64,
    pub zoom_keyframes: Vec<ZoomKeyframe>,
    pub smooth_motion_path: Option<Vec<MotionPoint>>,
    pub crop: Option<CropRect>,
}

#[derive(Deserialize, Debug, Clone)]
pub struct CropRect {
    pub x: f64,
    pub y: f64,
    pub width: f64,
    pub height: f64,
}

#[derive(Deserialize, Debug, Clone)]
#[serde(rename_all = "camelCase")]
pub struct ZoomKeyframe {
    pub time: f64,
    pub zoom_factor: f64,
    pub position_x: f64,
    pub position_y: f64,
}

#[derive(Deserialize, Debug, Clone)]
pub struct MotionPoint {
    pub time: f64,
    pub x: f64,
    pub y: f64,
    pub zoom: f64,
}

#[derive(Deserialize, Debug, Clone)]
#[serde(rename_all = "camelCase")]
pub struct BackgroundConfig {
    pub scale: f64,
    pub border_radius: f64,
    pub background_type: String,
    pub custom_background: Option<String>,
    pub shadow: f64,
    pub cursor_scale: f64,
}

#[derive(Deserialize, Debug, Clone)]
pub struct MousePosition {
    pub x: i32,
    pub y: i32,
    pub timestamp: f64,
    #[serde(rename = "isClicked")]
    pub is_clicked: bool,
    pub cursor_type: String,
}

// --- CURSOR LOADING (Programmatic / SVG) ---
lazy_static::lazy_static! {
    static ref CURSOR_ARROW: ImageBuffer<Rgba<u8>, Vec<u8>> = draw_default_cursor();
    static ref CURSOR_TEXT: ImageBuffer<Rgba<u8>, Vec<u8>> = draw_text_cursor();
    static ref CURSOR_HAND: ImageBuffer<Rgba<u8>, Vec<u8>> = load_svg_cursor(include_bytes!("../../../screen-record/public/pointer.svg"));
}

fn load_svg_cursor(svg_bytes: &[u8]) -> ImageBuffer<Rgba<u8>, Vec<u8>> {
    let opt = resvg::usvg::Options::default();
    let tree = resvg::usvg::Tree::from_data(svg_bytes, &opt).expect("Failed to parse cursor SVG");

    let size = tree.size();
    let width = size.width() as u32;
    let height = size.height() as u32;

    let mut pixmap = tiny_skia::Pixmap::new(width, height).unwrap();
    resvg::render(&tree, tiny_skia::Transform::default(), &mut pixmap.as_mut());

    ImageBuffer::from_raw(width, height, pixmap.data().to_vec()).unwrap()
}

fn draw_default_cursor() -> ImageBuffer<Rgba<u8>, Vec<u8>> {
    let mut pixmap = tiny_skia::Pixmap::new(32, 32).unwrap();
    let transform = tiny_skia::Transform::from_translate(4.0, 4.0);

    let mut path_builder = tiny_skia::PathBuilder::new();
    // M 8.2 4.9 L 19.8 16.5 L 13 16.5 L 12.6 16.6 L 8.2 20.9 Z
    path_builder.move_to(8.2, 4.9);
    path_builder.line_to(19.8, 16.5);
    path_builder.line_to(13.0, 16.5);
    path_builder.line_to(12.6, 16.6);
    path_builder.line_to(8.2, 20.9);
    path_builder.close();

    // M 17.3 21.6 L 13.7 23.1 L 9 12 L 12.7 10.5 Z
    path_builder.move_to(17.3, 21.6);
    path_builder.line_to(13.7, 23.1);
    path_builder.line_to(9.0, 12.0);
    path_builder.line_to(12.7, 10.5);
    path_builder.close();
    let path = path_builder.finish().unwrap();

    let mut paint = tiny_skia::Paint::default();
    paint.set_color_rgba8(0, 0, 0, 255);
    paint.anti_alias = true;

    let mut white_paint = tiny_skia::Paint::default();
    white_paint.set_color_rgba8(255, 255, 255, 255);
    white_paint.anti_alias = true;

    let mut stroke = tiny_skia::Stroke::default();
    stroke.width = 1.5;

    pixmap.stroke_path(&path, &white_paint, &stroke, transform, None);
    pixmap.fill_path(&path, &paint, tiny_skia::FillRule::Winding, transform, None);

    ImageBuffer::from_raw(32, 32, pixmap.data().to_vec()).unwrap()
}

fn draw_text_cursor() -> ImageBuffer<Rgba<u8>, Vec<u8>> {
    let mut pixmap = tiny_skia::Pixmap::new(32, 32).unwrap();
    let transform = tiny_skia::Transform::from_translate(10.0, 8.0);

    let mut path_builder = tiny_skia::PathBuilder::new();
    // Path matched from videoRenderer.ts
    // M 2 0 L 10 0 L 10 2 L 7 2 L 7 14 L 10 14 L 10 16 L 2 16 L 2 14 L 5 14 L 5 2 L 2 2 Z
    path_builder.move_to(2.0, 0.0);
    path_builder.line_to(10.0, 0.0);
    path_builder.line_to(10.0, 2.0);
    path_builder.line_to(7.0, 2.0);
    path_builder.line_to(7.0, 14.0);
    path_builder.line_to(10.0, 14.0);
    path_builder.line_to(10.0, 16.0);
    path_builder.line_to(2.0, 16.0);
    path_builder.line_to(2.0, 14.0);
    path_builder.line_to(5.0, 14.0);
    path_builder.line_to(5.0, 2.0);
    path_builder.line_to(2.0, 2.0);
    path_builder.close();
    let path = path_builder.finish().unwrap();

    let mut paint = tiny_skia::Paint::default();
    paint.set_color_rgba8(0, 0, 0, 255);
    paint.anti_alias = true;

    let mut white_paint = tiny_skia::Paint::default();
    white_paint.set_color_rgba8(255, 255, 255, 255);
    white_paint.anti_alias = true;

    let mut stroke = tiny_skia::Stroke::default();
    stroke.width = 1.5;

    pixmap.stroke_path(&path, &white_paint, &stroke, transform, None);
    pixmap.fill_path(&path, &paint, tiny_skia::FillRule::Winding, transform, None);

    ImageBuffer::from_raw(32, 32, pixmap.data().to_vec()).unwrap()
}

// --- HELPER: Interpolation ---
fn interpolate_zoom(
    current_time: f64,
    segment: &VideoSegment,
    source_w: u32,
    source_h: u32,
) -> (f64, f64, f64) {
    // 1. Check for smooth motion path first
    if let Some(path) = &segment.smooth_motion_path {
        if !path.is_empty() {
            // Find segment in path
            let idx = path
                .iter()
                .position(|p| p.time >= current_time)
                .unwrap_or(path.len().saturating_sub(1));

            if idx == 0 {
                let p = &path[0];
                return (p.x, p.y, p.zoom);
            }

            let p2 = &path[idx];
            let p1 = &path[idx - 1];

            let t = (current_time - p1.time) / (p2.time - p1.time).max(0.001);
            let x = p1.x + (p2.x - p1.x) * t;
            let y = p1.y + (p2.y - p1.y) * t;
            let zoom = p1.zoom + (p2.zoom - p1.zoom) * t;

            return (x, y, zoom);
        }
    }

    // 2. Fallback to Keyframes
    let kfs = &segment.zoom_keyframes;
    if kfs.is_empty() {
        return (source_w as f64 / 2.0, source_h as f64 / 2.0, 1.0);
    }

    // Find keyframes surrounding current time
    // Sort logic should be handled by frontend ideally, but we assume sorted here or sort if needed?
    // Assuming sorted for speed.

    // Find next keyframe
    let next_idx = kfs.iter().position(|k| k.time > current_time);

    if let Some(idx) = next_idx {
        if idx == 0 {
            let k = &kfs[0];
            return (
                k.position_x * source_w as f64,
                k.position_y * source_h as f64,
                k.zoom_factor,
            );
        }

        let k2 = &kfs[idx];
        let k1 = &kfs[idx - 1];

        // Check transition window (1.0s)
        let diff = k2.time - current_time;
        if diff <= 1.0 {
            let t = 1.0 - diff; // 0 to 1
                                // Ease out cubic
            let et = 1.0 - (1.0 - t).powi(3);

            let z = k1.zoom_factor + (k2.zoom_factor - k1.zoom_factor) * et;
            let x = (k1.position_x + (k2.position_x - k1.position_x) * et) * source_w as f64;
            let y = (k1.position_y + (k2.position_y - k1.position_y) * et) * source_h as f64;
            return (x, y, z);
        } else {
            // Static at K1
            return (
                k1.position_x * source_w as f64,
                k1.position_y * source_h as f64,
                k1.zoom_factor,
            );
        }
    } else {
        // Past last keyframe
        let k = kfs.last().unwrap();
        return (
            k.position_x * source_w as f64,
            k.position_y * source_h as f64,
            k.zoom_factor,
        );
    }
}

fn interpolate_mouse(time: f64, positions: &[MousePosition]) -> Option<(i32, i32, bool, String)> {
    if positions.is_empty() {
        return None;
    }

    // Binary search for position
    let idx = positions.partition_point(|p| p.timestamp < time);

    if idx == 0 {
        let p = &positions[0];
        return Some((p.x, p.y, p.is_clicked, p.cursor_type.clone()));
    }
    if idx >= positions.len() {
        let p = positions.last().unwrap();
        return Some((p.x, p.y, p.is_clicked, p.cursor_type.clone()));
    }

    let p1 = &positions[idx - 1];
    let p2 = &positions[idx];

    let dt = p2.timestamp - p1.timestamp;
    if dt <= 0.0 {
        return Some((p1.x, p1.y, p1.is_clicked, p1.cursor_type.clone()));
    }

    let t = (time - p1.timestamp) / dt;

    let x = (p1.x as f64 + (p2.x as f64 - p1.x as f64) * t) as i32;
    let y = (p1.y as f64 + (p2.y as f64 - p1.y as f64) * t) as i32;

    // Click state logic (persist for short duration)
    let is_clicked = p1.is_clicked || p2.is_clicked;

    Some((x, y, is_clicked, p2.cursor_type.clone()))
}

// --- MAIN EXPORT FUNCTION ---

pub fn start_native_export(args: serde_json::Value) -> Result<serde_json::Value, String> {
    let config: ExportConfig = serde_json::from_value(args).map_err(|e| e.to_string())?;

    let output_path = dirs::download_dir()
        .unwrap_or(PathBuf::from("."))
        .join(format!(
            "SGT_Export_{}.mp4",
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_secs()
        ));

    // 1. Get FFmpeg Path
    let ffmpeg_path = super::get_ffmpeg_path();
    if !ffmpeg_path.exists() {
        return Err("FFmpeg not found. Please install via Download Manager.".to_string());
    }

    // 2. Get Source Video Path
    let source_video = unsafe { VIDEO_PATH.clone() }.ok_or("No source video found")?;

    // 3. Setup Decoding Process (Read raw video)
    // We trim using -ss and -t here to avoid processing unnecessary frames
    let mut decoder = Command::new(&ffmpeg_path)
        .args(&[
            "-ss",
            &config.trim_start.to_string(),
            "-t",
            &config.duration.to_string(),
            "-i",
            &source_video,
            "-f",
            "image2pipe",
            "-pix_fmt",
            "rgba",
            "-vcodec",
            "rawvideo",
            "-",
        ])
        .stdout(Stdio::piped())
        .stderr(Stdio::null())
        .spawn()
        .map_err(|e| format!("Failed to start decoder: {}", e))?;

    let mut decoder_stdout = decoder
        .stdout
        .take()
        .ok_or("Failed to open decoder stdout")?;

    // 4. Setup Encoding Process
    // Audio filter: trim + speed
    let audio_filter = format!(
        "[0:a]atrim=start={}:duration={},asetpts=PTS-STARTPTS,atempo={}[aout]",
        config.trim_start, config.duration, config.speed
    );

    // Calculate actual output resolution (ensure even)
    let out_w = config.width - (config.width % 2);
    let out_h = config.height - (config.height % 2);

    let mut encoder = Command::new(&ffmpeg_path)
        .args(&[
            "-y",
            "-f",
            "rawvideo",
            "-pixel_format",
            "rgba",
            "-video_size",
            &format!("{}x{}", out_w, out_h),
            "-framerate",
            &config.framerate.to_string(),
            "-i",
            "-", // Video from pipe
            "-i",
            &config.audio_path, // Audio file
            "-filter_complex",
            &audio_filter,
            "-map",
            "0:v",
            "-map",
            "[aout]",
            "-c:v",
            "libx264", // Hardware accel can be added here if detected (h264_nvenc)
            "-preset",
            "fast",
            "-crf",
            "20",
            "-pix_fmt",
            "yuv420p",
            "-c:a",
            "aac",
            "-b:a",
            "192k",
            "-shortest",
            output_path.to_str().unwrap(),
        ])
        .stdin(Stdio::piped())
        .stdout(Stdio::inherit())
        .stderr(Stdio::inherit())
        .spawn()
        .map_err(|e| format!("Failed to start encoder: {}", e))?;

    let mut encoder_stdin = encoder.stdin.take().ok_or("Failed to open encoder stdin")?;

    // 5. Processing Loop
    // Use Rayon to process a buffer of frames?
    // Video decoding is sequential, so we iterate one by one.
    // However, we can use Rayon inside the loop for the heavy image ops (resize/composite)
    // if we process blocks of frames?
    // For simplicity and low latency, single thread logic is usually bottlenecked by FFmpeg decode/encode anyway.
    // We will stick to sequential loop but optimize the image ops.

    // Get source dimensions from metadata? Or assume 1920x1080?
    // We can probe or just hardcode if we know.
    // Let's assume standard full HD capture for now, or fetch via probe.
    // Actually, `capture_handler` set VIDEO_PATH. We can run ffprobe.

    let probe = Command::new(&ffmpeg_path)
        .args(&[
            "-v",
            "error",
            "-select_streams",
            "v:0",
            "-show_entries",
            "stream=width,height",
            "-of",
            "csv=s=x:p=0",
            &source_video,
        ])
        .output()
        .map_err(|e| format!("Probe failed: {}", e))?;

    let dim_str = String::from_utf8_lossy(&probe.stdout);
    let dims: Vec<&str> = dim_str.trim().split('x').collect();
    let src_w: u32 = dims[0].parse().unwrap_or(1920);
    let src_h: u32 = dims[1].parse().unwrap_or(1080);

    let frame_size = (src_w * src_h * 4) as usize;
    let mut buffer = vec![0u8; frame_size];

    // Time tracking
    let dt = 1.0 / config.framerate as f64;
    let mut current_time = config.trim_start;
    let end_time = config.trim_start + config.duration;
    // Speed factor: if speed is 2.0, we step time by dt * 2.0
    let step = dt * config.speed;

    // Determine background color
    let bg_color = match config.background_config.background_type.as_str() {
        "gradient1" => Rgba([37, 99, 235, 255]), // Blue-Violet approximation
        "gradient2" => Rgba([251, 113, 133, 255]), // Rose-Orange approximation
        "gradient3" => Rgba([16, 185, 129, 255]), // Emerald-Teal approximation
        _ => Rgba([10, 10, 10, 255]),            // Solid dark
    };

    while current_time < end_time {
        // Read frame from decoder
        // Read frame from decoder
        if std::io::Read::read_exact(&mut decoder_stdout, &mut buffer).is_err() {
            break;
        }

        // --- PROCESSING ---
        // 1. Create ImageBuffer and wrap in DynamicImage for easier trait satisfaction
        let src_img =
            ImageBuffer::<Rgba<u8>, Vec<u8>>::from_raw(src_w, src_h, buffer.clone()).unwrap();
        let dyn_img = image::DynamicImage::ImageRgba8(src_img);

        // 2. Calculate Zoom State
        let (cam_x, cam_y, zoom) = interpolate_zoom(current_time, &config.segment, src_w, src_h);

        // 3. Handle Crop (if exists)
        // The crop logic was removed from the provided snippet, but the original code had it.
        // Assuming it's meant to be removed or handled differently based on the new snippet.
        // The new snippet doesn't use crop_x, crop_y, crop_w, crop_h.
        // If crop is needed, it should be applied before calculating view_x, view_y, view_w, view_h.

        // 4. Transform Logic
        // Calculate viewport
        let view_w = (out_w as f64 / zoom) as u32;
        let view_h = (out_h as f64 / zoom) as u32;

        let view_x = (cam_x - view_w as f64 / 2.0).clamp(0.0, (src_w - view_w) as f64) as u32;
        let view_y = (cam_y - view_h as f64 / 2.0).clamp(0.0, (src_h - view_h) as f64) as u32;

        // Extract View using DynamicImage's crop_imm
        let view = dyn_img.crop_imm(view_x, view_y, view_w, view_h);

        // Resize to Output (Background Logic)
        // Check "scale" config (padding)
        let scale_factor = config.background_config.scale / 100.0;

        let final_video_w = (out_w as f64 * scale_factor) as u32;
        let final_video_h = (out_h as f64 * scale_factor) as u32;

        // Resize video content
        let resized_video = resize(&view, final_video_w, final_video_h, FilterType::Triangle);

        // Create Final Frame
        let mut final_frame = ImageBuffer::from_pixel(out_w, out_h, bg_color);

        // Composite Video on Background (Centered)
        let offset_x = (out_w - final_video_w) / 2;
        let offset_y = (out_h - final_video_h) / 2;

        image::imageops::overlay(
            &mut final_frame,
            &resized_video,
            offset_x.into(),
            offset_y.into(),
        );

        // 5. Draw Cursor
        if let Some((mx, my, _is_clicked, c_type)) =
            interpolate_mouse(current_time, &config.mouse_positions)
        {
            // Map mouse to final frame coords
            // Mouse is in Source Coords (0..src_w)

            // Adjust for Viewport offset
            let rel_x = mx as f64 - view_x as f64;
            let rel_y = my as f64 - view_y as f64;

            // Scale to Resized Video
            let scale_x = final_video_w as f64 / view_w as f64;
            let scale_y = final_video_h as f64 / view_h as f64;

            let final_mx = offset_x as f64 + (rel_x * scale_x);
            let final_my = offset_y as f64 + (rel_y * scale_y);

            // Determine cursor sprite
            let cursor_sprite = match c_type.as_str() {
                "text" => &*CURSOR_TEXT,
                "pointer" => &*CURSOR_HAND,
                _ => &*CURSOR_ARROW,
            };

            // Draw Cursor
            if final_mx >= 0.0
                && final_mx < out_w as f64
                && final_my >= 0.0
                && final_my < out_h as f64
            {
                image::imageops::overlay(
                    &mut final_frame,
                    cursor_sprite,
                    final_mx as i64,
                    final_my as i64,
                );
            }
        }

        // Write to Encoder
        encoder_stdin
            .write_all(&final_frame)
            .map_err(|e| e.to_string())?;

        current_time += step;
    }

    // Flush
    drop(encoder_stdin);
    let _ = encoder.wait().map_err(|e| e.to_string())?;

    Ok(serde_json::json!({
        "status": "success",
        "path": output_path.to_string_lossy()
    }))
}
</file>

<file path="src/overlay/text_selection_webview/html.rs">
pub fn get_html(is_dark: bool, initial_text: &str) -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    let (bg_color, text_color, glow_base, glow_active) = if is_dark {
        (
            "rgba(26, 26, 26, 0.95)", // Slightly more opaque
            "#ffffff",
            "#00c8ff",
            "#ff9633",
        )
    } else {
        ("rgba(255, 255, 255, 0.95)", "#202124", "#00c8ff", "#ff9633")
    };

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        {font_css}
        * {{
            margin: 0;
            padding: 0;
            user-select: none;
            cursor: default;
        }}
        body {{
            background: transparent;
            overflow: hidden;
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            width: 100vw;
            font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
            font-weight: 500;
        }}
        
        /* Container for the gradient border */
        .badge-container {{
            position: relative;
            padding: 2px; /* Border thickness */
            border-radius: 22px;
            overflow: hidden;
            /* Entrance Animation */
            opacity: 0;
            transform: translateY(10px);
            animation: fadeIn 0.3s cubic-bezier(0.2, 0, 0, 1) forwards;
            /* Shadow for depth */
            box-shadow: 0 4px 12px rgba(0,0,0,0.15);
        }}

        /* The spinning gradient background (visible via padding) */
        .badge-glow {{
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: conic-gradient(
                from 0deg, 
                transparent 0deg, 
                var(--glow-color) 60deg, 
                transparent 120deg,
                transparent 180deg, 
                var(--glow-color) 240deg, 
                transparent 300deg
            );
            animation: spin 3s linear infinite;
            z-index: 1;
        }}

        /* The inner content badge */
        .badge-inner {{
            position: relative;
            background: {bg_color};
            color: {text_color};
            padding: 8px 16px;
            border-radius: 20px;
            font-size: 14px;
            white-space: nowrap;
            z-index: 2;
            display: flex;
            align-items: center;
            gap: 8px;
        }}

        @keyframes fadeIn {{
            to {{ opacity: 1; transform: translateY(0); }}
        }}

        @keyframes spin {{
            from {{ transform: rotate(0deg); }}
            to {{ transform: rotate(360deg); }}
        }}

        /* State: Selecting (Active) */
        body.selecting .badge-glow {{
            --glow-color: {glow_active};
            animation-duration: 1s; /* Faster spin */
            opacity: 1;
        }}
        
        /* State: Idle */
        body:not(.selecting) .badge-glow {{
            --glow-color: {glow_base};
            opacity: 0.6; /* Subtler glow when idle */
        }}

    </style>
</head>
<body>
    <div class="badge-container">
        <div class="badge-glow"></div>
        <div class="badge-inner">
            <span id="text">{text}</span>
        </div>
    </div>

    <script>
        function updateState(isSelecting, newText) {{
            if (isSelecting) {{
                document.body.classList.add('selecting');
            }} else {{
                document.body.classList.remove('selecting');
            }}
            document.getElementById('text').innerText = newText;
        }}
    </script>
</body>
</html>"#,
        font_css = font_css,
        bg_color = bg_color,
        text_color = text_color,
        glow_base = glow_base,
        glow_active = glow_active,
        text = initial_text
    )
}
</file>

<file path="src/win_types.rs">
// Windows 0.62+ type wrappers for thread safety
// HWND, HANDLE, HHOOK etc. are now *mut c_void which don't implement Send/Sync

use windows::Win32::Foundation::{HWND, HANDLE};
use windows::Win32::UI::WindowsAndMessaging::HHOOK;
use windows::Win32::Graphics::Gdi::HBITMAP;

/// Thread-safe wrapper for HWND
#[derive(Clone, Copy, Debug)]
pub struct SendHwnd(pub HWND);
unsafe impl Send for SendHwnd {}
unsafe impl Sync for SendHwnd {}

impl Default for SendHwnd {
    fn default() -> Self {
        SendHwnd(HWND::default())
    }
}

impl SendHwnd {
    pub fn is_invalid(&self) -> bool {
        self.0.is_invalid()
    }
    
    pub fn as_isize(&self) -> isize {
        self.0.0 as isize
    }
    
    pub fn from_isize(val: isize) -> Self {
        SendHwnd(HWND(val as *mut std::ffi::c_void))
    }
}

/// Thread-safe wrapper for HANDLE  
#[derive(Clone, Copy, Debug)]
pub struct SendHandle(pub HANDLE);
unsafe impl Send for SendHandle {}
unsafe impl Sync for SendHandle {}

impl SendHandle {
    pub fn is_invalid(&self) -> bool {
        self.0.is_invalid()
    }
}

/// Thread-safe wrapper for HHOOK
#[derive(Clone, Copy, Debug)]  
pub struct SendHhook(pub HHOOK);
unsafe impl Send for SendHhook {}
unsafe impl Sync for SendHhook {}

impl Default for SendHhook {
    fn default() -> Self {
        SendHhook(HHOOK::default())
    }
}

/// Thread-safe wrapper for HBITMAP
#[derive(Clone, Copy, Debug)]
pub struct SendHbitmap(pub HBITMAP);
unsafe impl Send for SendHbitmap {}
unsafe impl Sync for SendHbitmap {}

impl Default for SendHbitmap {
    fn default() -> Self {
        SendHbitmap(HBITMAP::default())
    }
}

impl SendHbitmap {
    pub fn is_invalid(&self) -> bool {
        self.0.is_invalid()
    }
}
</file>

<file path=".cargo/config.toml">
[build]
# Optimize compilation
rustflags = [
    "-Z", "location-detail=none",
    "-C", "target-cpu=native",
    "-C", "target-feature=+crt-static"
]

[target.x86_64-pc-windows-msvc]
rustflags = [
    "-C", "target-feature=+crt-static"
]
</file>

<file path=".gitignore">
/target
Cargo.lock
.env
.DS_Store
*.swp
*.swo
tools/

# Cursor build artifacts
build_cursor.exe
cursor_data.txt
broom.cur
screen-goated-toolbox-*.exe

# Patched dependencies (cloned by scripts/setup-egui-snarl.ps1)
libs/egui-snarl/

# PromptDJ artifacts
src/overlay/prompt_dj/dist/

# Agent specific files
.agent/

# General web artifacts
node_modules/
dist/

# Screen Record artifacts
src/overlay/screen_record/dist/
</file>

<file path="build.ps1">
# Re-patch egui-snarl to ensure custom scroll-to-zoom is applied
Write-Host "Setting up patched egui-snarl..." -ForegroundColor Cyan
$snarlDir = Join-Path $PSScriptRoot "libs\egui-snarl"
if (Test-Path $snarlDir) {
    Remove-Item $snarlDir -Recurse -Force
}
& (Join-Path $PSScriptRoot "scripts\setup-egui-snarl.ps1")

# --- Build PromptDJ Frontend ---
Write-Host "Building PromptDJ Frontend..." -ForegroundColor Cyan
$pdjDir = Join-Path $PSScriptRoot "promptdj-midi"
$pdjDist = Join-Path $pdjDir "dist"
$pdjTargetDist = Join-Path $PSScriptRoot "src\overlay\prompt_dj\dist"

Push-Location $pdjDir
try {
    npm run build
}
finally {
    Pop-Location
}

if (Test-Path $pdjDist) {
    if (-not (Test-Path $pdjTargetDist)) {
        New-Item -ItemType Directory -Path $pdjTargetDist -Force | Out-Null
    }
    Copy-Item -Path "$pdjDist\*" -Destination $pdjTargetDist -Recurse -Force
    Write-Host "PromptDJ assets synchronized." -ForegroundColor Green
}
else {
    Write-Host "FAILED: PromptDJ build did not produce dist folder." -ForegroundColor Red
    exit 1
}

# --- Continue Main Build ---
# Extract version from Cargo.toml
$cargoContent = Get-Content "Cargo.toml" -Raw
if ($cargoContent -match 'version\s*=\s*"([^"]+)"') {
    $version = $matches[1]
}
else {
    Write-Host "Failed to extract version from Cargo.toml" -ForegroundColor Red
    exit 1
}

# Output paths
$outputExeName = "ScreenGoatedToolbox_v$version.exe"
$outputPath = "target/release/$outputExeName"
$exePathRelease = "target/release/screen-goated-toolbox.exe"

# =============================================================================
# Build Release version (LTO optimized + stripped)
# =============================================================================
Write-Host ""
Write-Host "=== Building ScreenGoatedToolbox v$version ===" -ForegroundColor Cyan
Write-Host "Using 'release' profile (LTO + stripped)..." -ForegroundColor Gray
cargo build --release

if (Test-Path $exePathRelease) {
    if (Test-Path $outputPath) {
        Remove-Item $outputPath
    }
    Move-Item $exePathRelease $outputPath
    $size = (Get-Item $outputPath).Length / 1MB
    Write-Host "  -> Created: $outputExeName ($([Math]::Round($size, 2)) MB)" -ForegroundColor Green
}
else {
    Write-Host "  -> FAILED: release build did not produce exe" -ForegroundColor Red
    exit 1
}

# =============================================================================
# SUMMARY
# =============================================================================
Write-Host ""
Write-Host "=======================================" -ForegroundColor White
Write-Host "         BUILD COMPLETE v$version" -ForegroundColor White
Write-Host "=======================================" -ForegroundColor White
Write-Host ""
Write-Host "  $outputExeName" -ForegroundColor Green
Write-Host "  Size: $([Math]::Round($size, 2)) MB" -ForegroundColor Gray
Write-Host ""
</file>

<file path="build.rs">
use std::fs;
use std::io::{Cursor, Write};
use std::path::Path;

fn main() {
    let manifest_dir = std::env::var("CARGO_MANIFEST_DIR").unwrap();

    // Declare the custom configuration 'nopack' to avoid warnings
    println!("cargo::rustc-check-cfg=cfg(nopack)");

    // Ensure assets directory exists
    let assets_dir = Path::new(&manifest_dir).join("assets");
    let _ = fs::create_dir_all(&assets_dir);

    // Optimize Tray Icon (32x32 is standard for tray)
    let tray_source = Path::new(&manifest_dir)
        .join("assets")
        .join("tray-icon.png");
    if tray_source.exists() {
        let tray_icon_path = assets_dir.join("tray_icon.png");
        if let Ok(img) = image::open(&tray_source) {
            let resized = img.resize(32, 32, image::imageops::FilterType::Lanczos3);
            let _ = resized.save_with_format(&tray_icon_path, image::ImageFormat::Png);
        }
    }

    // Optimize App Icon for embedding (256x256 max)
    let app_icon_path = assets_dir.join("app-icon-small.png");
    let app_icon_small_path = assets_dir.join("app-icon-small.png");

    if app_icon_path.exists() {
        if let Ok(img) = image::open(&app_icon_path) {
            let resized = img.resize(256, 256, image::imageops::FilterType::Lanczos3);
            let _ = resized.save(&app_icon_small_path);
        }
    }

    // Generate multi-size ICO from the optimized small icon
    if app_icon_small_path.exists() {
        let ico_path = assets_dir.join("app.ico");
        create_multi_size_ico(&app_icon_small_path, &ico_path);
    }

    // Embed icon in Windows executable using manual windres compilation
    #[cfg(target_os = "windows")]
    {
        let ico_path = Path::new(&manifest_dir).join("assets").join("app.ico");
        let rc_path = Path::new(&manifest_dir).join("app.rc");

        if ico_path.exists() && rc_path.exists() {
            // Define output path for the object file in the OUT_DIR
            let out_dir = std::env::var("OUT_DIR").unwrap();
            let res_path = Path::new(&out_dir).join("resources.o");

            // Run windres manually
            // windres app.rc -o resources.o
            let status = std::process::Command::new("windres")
                .arg(&rc_path)
                .arg("-o")
                .arg(&res_path)
                .status();

            match status {
                Ok(s) if s.success() => {
                    // Tell Cargo to pass the object file to the linker
                    println!("cargo:rustc-link-arg={}", res_path.display());
                }
                Ok(s) => {
                    panic!("windres failed with exit code: {}", s);
                }
                Err(e) => {
                    panic!("Failed to execute windres: {}", e);
                }
            }
        }
    }

    println!("cargo:rerun-if-changed=assets/app-icon-small.png");
    println!("cargo:rerun-if-changed=icon.png");
    println!("cargo:rerun-if-changed=app.rc");
    println!("cargo:rerun-if-changed=build.rs");
}

fn create_multi_size_ico(png_path: &Path, ico_path: &Path) {
    let img = match image::open(png_path) {
        Ok(i) => i,
        Err(e) => {
            println!("cargo:warning=Failed to open PNG for ICO creation: {}", e);
            return;
        }
    };
    let mut file = match fs::File::create(ico_path) {
        Ok(f) => f,
        Err(e) => {
            println!("cargo:warning=Failed to create ICO file: {}", e);
            return;
        }
    };

    // Reduced sizes to save space: 16, 32, 48, 256 (Removed 64)
    let sizes = [16, 32, 48, 256];
    let num_images = sizes.len() as u16;

    // ICO Header
    file.write_all(&[0, 0]).unwrap(); // Reserved
    file.write_all(&[1, 0]).unwrap(); // Type 1 (Icon)
    file.write_all(&num_images.to_le_bytes()).unwrap();

    let mut offset = 6 + (16 * num_images as u32);

    // Prepare image data
    let mut images_data: Vec<Vec<u8>> = Vec::new();

    for &size in &sizes {
        let mut data = Vec::new();

        if size == 256 {
            // Use PNG format for 256x256 (Vista+)
            let resized = img.resize(size, size, image::imageops::FilterType::Lanczos3);
            let mut buffer = Cursor::new(Vec::new());
            resized
                .write_to(&mut buffer, image::ImageFormat::Png)
                .unwrap();
            data = buffer.into_inner();
        } else {
            // BMP format for smaller sizes
            let resized = img.resize(size, size, image::imageops::FilterType::Lanczos3);
            let rgba = resized.to_rgba8();

            // BMP Header (40 bytes)
            data.extend_from_slice(&40u32.to_le_bytes());
            data.extend_from_slice(&(size as i32).to_le_bytes());
            data.extend_from_slice(&(size as i32 * 2).to_le_bytes()); // Height * 2
            data.extend_from_slice(&[1, 0]); // Planes
            data.extend_from_slice(&[32, 0]); // BPP
            data.extend_from_slice(&[0, 0, 0, 0]); // Compression
            data.extend_from_slice(&[0, 0, 0, 0]); // ImageSize
            data.extend_from_slice(&[0, 0, 0, 0]); // Xppm
            data.extend_from_slice(&[0, 0, 0, 0]); // Yppm
            data.extend_from_slice(&[0, 0, 0, 0]); // ColorsUsed
            data.extend_from_slice(&[0, 0, 0, 0]); // ColorsImportant

            // Pixel Data (BGRA, bottom-up)
            for row in (0..rgba.height()).rev() {
                for col in 0..rgba.width() {
                    let pixel = rgba.get_pixel(col, row);
                    data.push(pixel[2]); // B
                    data.push(pixel[1]); // G
                    data.push(pixel[0]); // R
                    data.push(pixel[3]); // A
                }
            }

            // AND Mask (1 bit per pixel, padded to 32 bits)
            // All zeros (transparent) since we use alpha channel
            let row_bytes = ((size + 31) / 32) * 4;
            for _ in 0..size {
                for _ in 0..row_bytes {
                    data.push(0);
                }
            }
        }
        images_data.push(data);
    }

    // Write Directory Entries
    for (i, size) in sizes.iter().enumerate() {
        let width = if *size == 256 { 0 } else { *size as u8 };
        let height = if *size == 256 { 0 } else { *size as u8 };
        let data_size = images_data[i].len() as u32;

        file.write_all(&[width]).unwrap();
        file.write_all(&[height]).unwrap();
        file.write_all(&[0]).unwrap(); // Colors
        file.write_all(&[0]).unwrap(); // Reserved
        file.write_all(&[1, 0]).unwrap(); // Planes
        file.write_all(&[32, 0]).unwrap(); // BPP
        file.write_all(&data_size.to_le_bytes()).unwrap();
        file.write_all(&offset.to_le_bytes()).unwrap();

        offset += data_size;
    }

    // Write Image Data
    for data in images_data {
        file.write_all(&data).unwrap();
    }
}
</file>

<file path="README.md">
# Screen Goated Toolbox (SGT)

**The Ultimate AI Productivity Automation Tool for Windows.**

Screen Goated Toolbox (SGT) is a native Windows utility that bridges your screen, system audio, and microphone with the world's most powerful AI models. It allows you to create custom AI workflows using a visual node graph to automate tasks like OCR, translation, meeting transcription, generative audio, and text analysis.

## Key Features

### 🧠 Multi-Modal AI Support

* **Cloud Providers:** Native integration with **Groq** (Llama 3, Whisper), **Google Gemini** (Flash, Pro, Gemma), and **OpenRouter** (Claude, GPT-4, DeepSeek).
* **Local AI:** Full support for **Ollama** to run private, local vision and text models without internet.

### ⛓️ Node Graph Workflow

Create complex presets using a visual editor. Connect blocks to define logic:

* **Input:** Screen Region (Snipping), Microphone, System Audio Loopback, Text Selection, or File Drag-and-Drop.
* **Process:** Chain multiple models (e.g., *Speech to Text* -> *Translate* -> *Summarize*).
* **Output:** Streaming Overlay, Markdown View, Text-to-Speech, or Clipboard.

### 🎙️ Audio Intelligence

* **Real-time "Cabin" Mode:** Live, low-latency transcription and translation overlay. Works with **System Audio** (Zoom/Youtube/Games) or **Microphone**.
* **Per-App Capture:** Target audio from specific running applications.
* **PromptDJ:** A dedicated MIDI-controlled interface for generative music and audio control.

### 🛠️ Productivity Tools

* **Smart Overlays:**
  * **Result Overlay:** Interactive window with streaming text, markdown rendering, and "Refine" chat.
  * **Preset Wheel:** A circular menu (`Win+Shift+S` style) to quickly select tools at cursor position.
  * **Favorite Bubble:** A floating dock for instant access to common presets.
* **Text-to-Speech:** High-quality reading using Edge TTS, Gemini Live, or Google Translate.
* **History Gallery:** Auto-saves captures, transcriptions, and generated audio in a searchable database.

## Installation

### Option 1: Download Release

Download the latest `.exe` from the [Releases](https://github.com/nganlinh4/screen-goated-toolbox/releases) page.

* **Standard:** `ScreenGoatedToolbox_v4.0.0.exe` (Compressed, smaller).
* **NoPack:** `..._nopack.exe` (Use this if Windows Defender triggers a false positive).

### Option 2: Build from Source

**Prerequisites:**

* [Rust](https://www.rust-lang.org/) (Nightly toolchain required).
* [Node.js](https://nodejs.org/) (Required for building the PromptDJ frontend).
* **Visual Studio Build Tools 2022** with "Desktop development with C++" workload.

```bash
git clone https://github.com/nganlinh4/screen-goated-toolbox
cd screen-goated-toolbox

# 1. Setup dependencies and patch libraries
powershell -ExecutionPolicy Bypass -File scripts/setup-egui-snarl.ps1

# 2. Build the application (Script handles Frontend build + Rust build + UPX)
powershell -ExecutionPolicy Bypass -File build.ps1
```

The executable will be located in `target/release/`.

### Quick Development Build

To rebuild and run during development (builds PromptDJ frontend, then runs the app):

```powershell
cd promptdj-midi; npm install; npm run build; cd ..; New-Item -ItemType Directory -Path src\overlay\prompt_dj\dist -Force | Out-Null; Copy-Item promptdj-midi\dist\* -Destination src\overlay\prompt_dj\dist -Recurse -Force; cargo run
```

### Quick Screen Record Build

To rebuild and run during development (builds Screen Record frontend, then runs the app):

```powershell
cd screen-record; npm install; npm run build; cd ..; New-Item -ItemType Directory -Path src\overlay\screen_record\dist -Force | Out-Null; Copy-Item screen-record\dist\* -Destination src\overlay\screen_record\dist -Recurse -Force; cargo run
```

## Getting Started

1. **Launch SGT:** Run the executable.
2. **Global Settings:**
    * Click the **Settings** icon in the sidebar.
    * Enter API Keys for the providers you wish to use (Groq, Gemini, OpenRouter).
    * *(Optional)* Enable **Ollama** if you have it installed locally.
3. **Select a Preset:**
    * Use the sidebar to choose a built-in preset (e.g., "Translate Region", "Transcribe Speech").
    * Assign a **Global Hotkey** (e.g., `Alt+Q`) to the preset.
4. **Usage:**
    * Press your hotkey.
    * **For Image Presets:** Drag to select a screen area.
    * **For Audio Presets:** Recording starts automatically (or opens the Realtime overlay).

## Advanced Configuration

### The Node Graph

SGT v4 uses a node-based system for Presets.

1. **Create Preset:** Click `+` in the sidebar.
2. **Input Node:** Choose "Image", "Audio", or "Text".
3. **Process Node:** Select your AI Model and enter a System Prompt (e.g., "Translate this to Vietnamese").
4. **Connect:** Drag wires between nodes to define the data flow.
5. **Variables:** Use `{language1}` in your prompt to allow dynamic language selection via the UI.

### Real-time Translation (Cabin Mode)

1. Select/Create an **Audio** preset.
2. Set **Processing Mode** to **Realtime (Live)**.
3. Set **Source** to **Device** (System Audio) or **Mic**.
4. Launch the preset. A minimalist overlay will appear showing live subtitles.
5. *Tip:* You can toggle Transcription, Translation, and TTS directly from the overlay.

### Using Local AI (Ollama)

1. Install [Ollama](https://ollama.com/).
2. Pull models: `ollama pull llama3` (text) or `ollama pull moondream` (vision).
3. In SGT **Global Settings**, enable Ollama and set the URL (default: `http://localhost:11434`).
4. In your Preset's **Process Node**, select the model from the "Local" section.

## Troubleshooting

**"NO_API_KEY" Error**

* Go to Global Settings and ensure you have pasted a valid key for the model provider selected in your preset (Groq vs Google vs OpenRouter).

**WebView2 / Blank UI**

* SGT uses Microsoft Edge WebView2 for complex rendering (Markdown, Charts, PromptDJ). Ensure the [WebView2 Runtime](https://developer.microsoft.com/en-us/microsoft-edge/webview2/) is installed on your Windows machine.

**Audio Recording is Silent**

* **Device Audio:** Ensure audio is actually playing through your default output device.
* **Permissions:** Check Windows Privacy settings to ensure the app has access to the Microphone.

**PromptDJ / MIDI Not Working**

* Ensure your MIDI controller is connected *before* launching SGT.
* Click "Refresh Devices" inside the PromptDJ interface.

## License

MIT License — See [LICENSE](LICENSE) file.

## Credits

Developed by **nganlinh4**.

* **UI Framework:** [egui](https://github.com/emilk/egui) & [wry](https://github.com/tauri-apps/wry).
* **Audio:** [cpal](https://github.com/RustAudio/cpal) & [symphonia](https://github.com/pdeljanov/Symphonia).
* **AI Providers:** Groq, Google DeepMind, OpenRouter.
</file>

<file path="screen-record/.gitignore">
# Logs
logs
*.log
npm-debug.log*
yarn-debug.log*
yarn-error.log*
pnpm-debug.log*
lerna-debug.log*

node_modules
dist
dist-ssr
*.local

# Editor directories and files
.vscode/*
!.vscode/extensions.json
.idea
.DS_Store
*.suo
*.ntvs*
*.njsproj
*.sln
*.sw?
.tauri/
</file>

<file path="screen-record/components.json">
{
  "$schema": "https://ui.shadcn.com/schema.json",
  "style": "new-york",
  "rsc": false,
  "tsx": true,
  "tailwind": {
    "config": "tailwind.config.js",
    "css": "src/App.css",
    "baseColor": "neutral",
    "cssVariables": true,
    "prefix": ""
  },
  "aliases": {
    "components": "@/components",
    "utils": "@/lib/utils",
    "ui": "@/components/ui",
    "lib": "@/lib",
    "hooks": "@/hooks"
  },
  "iconLibrary": "lucide"
}
</file>

<file path="screen-record/index.html">
<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <link rel="icon" type="image/svg+xml" href="/vite.svg" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Tauri + React + Typescript</title>
  </head>

  <body>
    <div id="root"></div>
    <script type="module" src="/src/main.tsx"></script>
  </body>
</html>
</file>

<file path="screen-record/package.json">
{
  "name": "screen-demo",
  "private": true,
  "version": "0.1.4",
  "type": "module",
  "scripts": {
    "dev": "vite",
    "build": "tsc && vite build",
    "preview": "vite preview",
    "tauri": "tauri"
  },
  "dependencies": {
    "@radix-ui/react-slot": "^1.1.0",
    "@tauri-apps/api": "^2.1.1",
    "@tauri-apps/plugin-shell": "^2",
    "@tauri-apps/plugin-updater": "^2.5.0",
    "@types/gif.js": "^0.2.5",
    "class-variance-authority": "^0.7.1",
    "clsx": "^2.1.1",
    "gif.js": "^0.2.0",
    "html2canvas": "^1.4.1",
    "lucide-react": "^0.468.0",
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "tailwind-merge": "^2.5.5",
    "tailwindcss-animate": "^1.0.7"
  },
  "devDependencies": {
    "@tauri-apps/cli": "^2",
    "@types/node": "^22.10.1",
    "@types/react": "^18.2.15",
    "@types/react-dom": "^18.2.7",
    "@vitejs/plugin-react": "^4.2.1",
    "autoprefixer": "^10.4.20",
    "postcss": "^8.4.49",
    "tailwindcss": "^3.4.16",
    "typescript": "^5.2.2",
    "vite": "^5.3.1"
  }
}
</file>

<file path="screen-record/postcss.config.js">
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
</file>

<file path="screen-record/public/pointer.svg">
<?xml version="1.0" encoding="utf-8"?>
<!-- Generator: Adobe Illustrator 18.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->
<!DOCTYPE svg PUBLIC "-//W3C//DTD SVG 1.1//EN" "http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd">
<svg version="1.1" id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px"
	 viewBox="0 0 32 32" width="48px" height="48px" enable-background="new 0 0 32 32" xml:space="preserve">
<g transform="scale(0.75)">
	<defs>
		<rect id="SVGID_1_" width="32" height="32"/>
	</defs>
	<clipPath id="SVGID_2_">
		<use xlink:href="#SVGID_1_"  overflow="visible"/>
	</clipPath>
	<path clip-path="url(#SVGID_2_)" fill="#FFFFFF" d="M11.3,20.4c-0.3-0.4-0.6-1.1-1.2-2c-0.3-0.5-1.2-1.5-1.5-1.9
		c-0.2-0.4-0.2-0.6-0.1-1c0.1-0.6,0.7-1.1,1.4-1.1c0.5,0,1,0.4,1.4,0.7c0.2,0.2,0.5,0.6,0.7,0.8c0.2,0.2,0.2,0.3,0.4,0.5
		c0.2,0.3,0.3,0.5,0.2,0.1c-0.1-0.5-0.2-1.3-0.4-2.1c-0.1-0.6-0.2-0.7-0.3-1.1c-0.1-0.5-0.2-0.8-0.3-1.3c-0.1-0.3-0.2-1.1-0.3-1.5
		c-0.1-0.5-0.1-1.4,0.3-1.8c0.3-0.3,0.9-0.4,1.3-0.2c0.5,0.3,0.8,1,0.9,1.3c0.2,0.5,0.4,1.2,0.5,2c0.2,1,0.5,2.5,0.5,2.8
		c0-0.4-0.1-1.1,0-1.5c0.1-0.3,0.3-0.7,0.7-0.8c0.3-0.1,0.6-0.1,0.9-0.1c0.3,0.1,0.6,0.3,0.8,0.5c0.4,0.6,0.4,1.9,0.4,1.8
		c0.1-0.4,0.1-1.2,0.3-1.6c0.1-0.2,0.5-0.4,0.7-0.5c0.3-0.1,0.7-0.1,1,0c0.2,0,0.6,0.3,0.7,0.5c0.2,0.3,0.3,1.3,0.4,1.7
		c0,0.1,0.1-0.4,0.3-0.7c0.4-0.6,1.8-0.8,1.9,0.6c0,0.7,0,0.6,0,1.1c0,0.5,0,0.8,0,1.2c0,0.4-0.1,1.3-0.2,1.7
		c-0.1,0.3-0.4,1-0.7,1.4c0,0-1.1,1.2-1.2,1.8c-0.1,0.6-0.1,0.6-0.1,1c0,0.4,0.1,0.9,0.1,0.9s-0.8,0.1-1.2,0c-0.4-0.1-0.9-0.8-1-1.1
		c-0.2-0.3-0.5-0.3-0.7,0c-0.2,0.4-0.7,1.1-1.1,1.1c-0.7,0.1-2.1,0-3.1,0c0,0,0.2-1-0.2-1.4c-0.3-0.3-0.8-0.8-1.1-1.1L11.3,20.4z"/>
	
		<path clip-path="url(#SVGID_2_)" fill="none" stroke="#000000" stroke-width="0.75" stroke-linecap="round" stroke-linejoin="round" d="
		M11.3,20.4c-0.3-0.4-0.6-1.1-1.2-2c-0.3-0.5-1.2-1.5-1.5-1.9c-0.2-0.4-0.2-0.6-0.1-1c0.1-0.6,0.7-1.1,1.4-1.1c0.5,0,1,0.4,1.4,0.7
		c0.2,0.2,0.5,0.6,0.7,0.8c0.2,0.2,0.2,0.3,0.4,0.5c0.2,0.3,0.3,0.5,0.2,0.1c-0.1-0.5-0.2-1.3-0.4-2.1c-0.1-0.6-0.2-0.7-0.3-1.1
		c-0.1-0.5-0.2-0.8-0.3-1.3c-0.1-0.3-0.2-1.1-0.3-1.5c-0.1-0.5-0.1-1.4,0.3-1.8c0.3-0.3,0.9-0.4,1.3-0.2c0.5,0.3,0.8,1,0.9,1.3
		c0.2,0.5,0.4,1.2,0.5,2c0.2,1,0.5,2.5,0.5,2.8c0-0.4-0.1-1.1,0-1.5c0.1-0.3,0.3-0.7,0.7-0.8c0.3-0.1,0.6-0.1,0.9-0.1
		c0.3,0.1,0.6,0.3,0.8,0.5c0.4,0.6,0.4,1.9,0.4,1.8c0.1-0.4,0.1-1.2,0.3-1.6c0.1-0.2,0.5-0.4,0.7-0.5c0.3-0.1,0.7-0.1,1,0
		c0.2,0,0.6,0.3,0.7,0.5c0.2,0.3,0.3,1.3,0.4,1.7c0,0.1,0.1-0.4,0.3-0.7c0.4-0.6,1.8-0.8,1.9,0.6c0,0.7,0,0.6,0,1.1
		c0,0.5,0,0.8,0,1.2c0,0.4-0.1,1.3-0.2,1.7c-0.1,0.3-0.4,1-0.7,1.4c0,0-1.1,1.2-1.2,1.8c-0.1,0.6-0.1,0.6-0.1,1
		c0,0.4,0.1,0.9,0.1,0.9s-0.8,0.1-1.2,0c-0.4-0.1-0.9-0.8-1-1.1c-0.2-0.3-0.5-0.3-0.7,0c-0.2,0.4-0.7,1.1-1.1,1.1
		c-0.7,0.1-2.1,0-3.1,0c0,0,0.2-1-0.2-1.4c-0.3-0.3-0.8-0.8-1.1-1.1L11.3,20.4z"/>
	
		<line clip-path="url(#SVGID_2_)" fill="none" stroke="#000000" stroke-width="0.75" stroke-linecap="round" x1="19.6" y1="20.7" x2="19.6" y2="17.3"/>
	
		<line clip-path="url(#SVGID_2_)" fill="none" stroke="#000000" stroke-width="0.75" stroke-linecap="round" x1="17.6" y1="20.7" x2="17.5" y2="17.3"/>
	
		<line clip-path="url(#SVGID_2_)" fill="none" stroke="#000000" stroke-width="0.75" stroke-linecap="round" x1="15.6" y1="17.3" x2="15.6" y2="20.7"/>
</g>
</svg>
</file>

<file path="screen-record/public/tauri.svg">
<svg width="206" height="231" viewBox="0 0 206 231" fill="none" xmlns="http://www.w3.org/2000/svg">
<path d="M143.143 84C143.143 96.1503 133.293 106 121.143 106C108.992 106 99.1426 96.1503 99.1426 84C99.1426 71.8497 108.992 62 121.143 62C133.293 62 143.143 71.8497 143.143 84Z" fill="#FFC131"/>
<ellipse cx="84.1426" cy="147" rx="22" ry="22" transform="rotate(180 84.1426 147)" fill="#24C8DB"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M166.738 154.548C157.86 160.286 148.023 164.269 137.757 166.341C139.858 160.282 141 153.774 141 147C141 144.543 140.85 142.121 140.558 139.743C144.975 138.204 149.215 136.139 153.183 133.575C162.73 127.404 170.292 118.608 174.961 108.244C179.63 97.8797 181.207 86.3876 179.502 75.1487C177.798 63.9098 172.884 53.4021 165.352 44.8883C157.82 36.3744 147.99 30.2165 137.042 27.1546C126.095 24.0926 114.496 24.2568 103.64 27.6274C92.7839 30.998 83.1319 37.4317 75.8437 46.1553C74.9102 47.2727 74.0206 48.4216 73.176 49.5993C61.9292 50.8488 51.0363 54.0318 40.9629 58.9556C44.2417 48.4586 49.5653 38.6591 56.679 30.1442C67.0505 17.7298 80.7861 8.57426 96.2354 3.77762C111.685 -1.01901 128.19 -1.25267 143.769 3.10474C159.348 7.46215 173.337 16.2252 184.056 28.3411C194.775 40.457 201.767 55.4101 204.193 71.404C206.619 87.3978 204.374 103.752 197.73 118.501C191.086 133.25 180.324 145.767 166.738 154.548ZM41.9631 74.275L62.5557 76.8042C63.0459 72.813 63.9401 68.9018 65.2138 65.1274C57.0465 67.0016 49.2088 70.087 41.9631 74.275Z" fill="#FFC131"/>
<path fill-rule="evenodd" clip-rule="evenodd" d="M38.4045 76.4519C47.3493 70.6709 57.2677 66.6712 67.6171 64.6132C65.2774 70.9669 64 77.8343 64 85.0001C64 87.1434 64.1143 89.26 64.3371 91.3442C60.0093 92.8732 55.8533 94.9092 51.9599 97.4256C42.4128 103.596 34.8505 112.392 30.1816 122.756C25.5126 133.12 23.9357 144.612 25.6403 155.851C27.3449 167.09 32.2584 177.598 39.7906 186.112C47.3227 194.626 57.153 200.784 68.1003 203.846C79.0476 206.907 90.6462 206.743 101.502 203.373C112.359 200.002 122.011 193.568 129.299 184.845C130.237 183.722 131.131 182.567 131.979 181.383C143.235 180.114 154.132 176.91 164.205 171.962C160.929 182.49 155.596 192.319 148.464 200.856C138.092 213.27 124.357 222.426 108.907 227.222C93.458 232.019 76.9524 232.253 61.3736 227.895C45.7948 223.538 31.8055 214.775 21.0867 202.659C10.3679 190.543 3.37557 175.59 0.949823 159.596C-1.47592 143.602 0.768139 127.248 7.41237 112.499C14.0566 97.7497 24.8183 85.2327 38.4045 76.4519ZM163.062 156.711L163.062 156.711C162.954 156.773 162.846 156.835 162.738 156.897C162.846 156.835 162.954 156.773 163.062 156.711Z" fill="#24C8DB"/>
</svg>
</file>

<file path="screen-record/public/vite.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="31.88" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 257"><defs><linearGradient id="IconifyId1813088fe1fbc01fb466" x1="-.828%" x2="57.636%" y1="7.652%" y2="78.411%"><stop offset="0%" stop-color="#41D1FF"></stop><stop offset="100%" stop-color="#BD34FE"></stop></linearGradient><linearGradient id="IconifyId1813088fe1fbc01fb467" x1="43.376%" x2="50.316%" y1="2.242%" y2="89.03%"><stop offset="0%" stop-color="#FFEA83"></stop><stop offset="8.333%" stop-color="#FFDD35"></stop><stop offset="100%" stop-color="#FFA800"></stop></linearGradient></defs><path fill="url(#IconifyId1813088fe1fbc01fb466)" d="M255.153 37.938L134.897 252.976c-2.483 4.44-8.862 4.466-11.382.048L.875 37.958c-2.746-4.814 1.371-10.646 6.827-9.67l120.385 21.517a6.537 6.537 0 0 0 2.322-.004l117.867-21.483c5.438-.991 9.574 4.796 6.877 9.62Z"></path><path fill="url(#IconifyId1813088fe1fbc01fb467)" d="M185.432.063L96.44 17.501a3.268 3.268 0 0 0-2.634 3.014l-5.474 92.456a3.268 3.268 0 0 0 3.997 3.378l24.777-5.718c2.318-.535 4.413 1.507 3.936 3.838l-7.361 36.047c-.495 2.426 1.782 4.5 4.151 3.78l15.304-4.649c2.372-.72 4.652 1.36 4.15 3.788l-11.698 56.621c-.732 3.542 3.979 5.473 5.943 2.437l1.313-2.028l72.516-144.72c1.215-2.423-.88-5.186-3.54-4.672l-25.505 4.922c-2.396.462-4.435-1.77-3.759-4.114l16.646-57.705c.677-2.35-1.37-4.583-3.769-4.113Z"></path></svg>
</file>

<file path="screen-record/README.md">
<div align="center">
  <img src="src/assets/logo.svg" alt="Screen Demo Logo" width="120" height="120" />
  <h1>Screen Demo</h1>
  <p>An open-source screen recording and editing tool with zoom animation capabilities.<br/>A lightweight open-source alternative to Screen.studio.</p>
</div>

![Demo Screenshot](public/screenshot.png)
## Download

<div align="center">
  <h3>
    <a href="https://github.com/njraladdin/screen-demo/releases">Download for Windows →</a>
  </h3>
</div>

## Features

- **Screen Recording**
  - Record any monitor
  - Capture mouse movements and clicks
  - Multi-monitor support

- **Video Effects**
  - Add smooth zoom animations
  - Customize background styles and gradients
  - Enhanced cursor visualization
  - Adjust video scale and borders

- **Simple to Use**
  - Easy trim and edit
  - Quick export
  - No account needed

## Installation

1. Download the latest release for your platform from the [Releases](https://github.com/njraladdin/screen-demo/releases) page

2. Or build from source:
```bash
# Install dependencies
npm install

# Run in development
npm run tauri dev

# Build
npm run tauri build
```

## Usage

1. Click "Start Recording" and select your monitor
2. Record your screen
3. Stop recording when done
4. Add zoom animations by clicking "Add Zoom at Playhead" 
5. Adjust zoom level, position and timing
6. Export the final video

## Development

Built with Tauri, React, and TypeScript.

Requirements:
- Node.js 16+
- Rust toolchain
- Windows 10+

## License

This project is licensed under the MIT License
</file>

<file path="screen-record/src/assets/logo.svg">
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100">
  <defs>
    <linearGradient id="primaryGradient" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#FF26BE" />
      <stop offset="100%" style="stop-color:#9C17FF" />
    </linearGradient>
  </defs>

  <!-- Clean rounded square background -->
  <rect x="10" y="10" width="80" height="80" rx="12" fill="url(#primaryGradient)" />
  
  <!-- Screen recording frame symbol -->
  <g fill="none" stroke="white" stroke-width="8" stroke-linejoin="round">
    <!-- Outer frame representing screen -->
    <rect x="30" y="28" width="40" height="44" rx="4" />
    <!-- Recording indicator dot -->
    <circle cx="50" cy="50" r="6" fill="white" stroke="none" />
  </g>
</svg>
</file>

<file path="screen-record/src/assets/react.svg">
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" aria-hidden="true" role="img" class="iconify iconify--logos" width="35.93" height="32" preserveAspectRatio="xMidYMid meet" viewBox="0 0 256 228"><path fill="#00D8FF" d="M210.483 73.824a171.49 171.49 0 0 0-8.24-2.597c.465-1.9.893-3.777 1.273-5.621c6.238-30.281 2.16-54.676-11.769-62.708c-13.355-7.7-35.196.329-57.254 19.526a171.23 171.23 0 0 0-6.375 5.848a155.866 155.866 0 0 0-4.241-3.917C100.759 3.829 77.587-4.822 63.673 3.233C50.33 10.957 46.379 33.89 51.995 62.588a170.974 170.974 0 0 0 1.892 8.48c-3.28.932-6.445 1.924-9.474 2.98C17.309 83.498 0 98.307 0 113.668c0 15.865 18.582 31.778 46.812 41.427a145.52 145.52 0 0 0 6.921 2.165a167.467 167.467 0 0 0-2.01 9.138c-5.354 28.2-1.173 50.591 12.134 58.266c13.744 7.926 36.812-.22 59.273-19.855a145.567 145.567 0 0 0 5.342-4.923a168.064 168.064 0 0 0 6.92 6.314c21.758 18.722 43.246 26.282 56.54 18.586c13.731-7.949 18.194-32.003 12.4-61.268a145.016 145.016 0 0 0-1.535-6.842c1.62-.48 3.21-.974 4.76-1.488c29.348-9.723 48.443-25.443 48.443-41.52c0-15.417-17.868-30.326-45.517-39.844Zm-6.365 70.984c-1.4.463-2.836.91-4.3 1.345c-3.24-10.257-7.612-21.163-12.963-32.432c5.106-11 9.31-21.767 12.459-31.957c2.619.758 5.16 1.557 7.61 2.4c23.69 8.156 38.14 20.213 38.14 29.504c0 9.896-15.606 22.743-40.946 31.14Zm-10.514 20.834c2.562 12.94 2.927 24.64 1.23 33.787c-1.524 8.219-4.59 13.698-8.382 15.893c-8.067 4.67-25.32-1.4-43.927-17.412a156.726 156.726 0 0 1-6.437-5.87c7.214-7.889 14.423-17.06 21.459-27.246c12.376-1.098 24.068-2.894 34.671-5.345a134.17 134.17 0 0 1 1.386 6.193ZM87.276 214.515c-7.882 2.783-14.16 2.863-17.955.675c-8.075-4.657-11.432-22.636-6.853-46.752a156.923 156.923 0 0 1 1.869-8.499c10.486 2.32 22.093 3.988 34.498 4.994c7.084 9.967 14.501 19.128 21.976 27.15a134.668 134.668 0 0 1-4.877 4.492c-9.933 8.682-19.886 14.842-28.658 17.94ZM50.35 144.747c-12.483-4.267-22.792-9.812-29.858-15.863c-6.35-5.437-9.555-10.836-9.555-15.216c0-9.322 13.897-21.212 37.076-29.293c2.813-.98 5.757-1.905 8.812-2.773c3.204 10.42 7.406 21.315 12.477 32.332c-5.137 11.18-9.399 22.249-12.634 32.792a134.718 134.718 0 0 1-6.318-1.979Zm12.378-84.26c-4.811-24.587-1.616-43.134 6.425-47.789c8.564-4.958 27.502 2.111 47.463 19.835a144.318 144.318 0 0 1 3.841 3.545c-7.438 7.987-14.787 17.08-21.808 26.988c-12.04 1.116-23.565 2.908-34.161 5.309a160.342 160.342 0 0 1-1.76-7.887Zm110.427 27.268a347.8 347.8 0 0 0-7.785-12.803c8.168 1.033 15.994 2.404 23.343 4.08c-2.206 7.072-4.956 14.465-8.193 22.045a381.151 381.151 0 0 0-7.365-13.322Zm-45.032-43.861c5.044 5.465 10.096 11.566 15.065 18.186a322.04 322.04 0 0 0-30.257-.006c4.974-6.559 10.069-12.652 15.192-18.18ZM82.802 87.83a323.167 323.167 0 0 0-7.227 13.238c-3.184-7.553-5.909-14.98-8.134-22.152c7.304-1.634 15.093-2.97 23.209-3.984a321.524 321.524 0 0 0-7.848 12.897Zm8.081 65.352c-8.385-.936-16.291-2.203-23.593-3.793c2.26-7.3 5.045-14.885 8.298-22.6a321.187 321.187 0 0 0 7.257 13.246c2.594 4.48 5.28 8.868 8.038 13.147Zm37.542 31.03c-5.184-5.592-10.354-11.779-15.403-18.433c4.902.192 9.899.29 14.978.29c5.218 0 10.376-.117 15.453-.343c-4.985 6.774-10.018 12.97-15.028 18.486Zm52.198-57.817c3.422 7.8 6.306 15.345 8.596 22.52c-7.422 1.694-15.436 3.058-23.88 4.071a382.417 382.417 0 0 0 7.859-13.026a347.403 347.403 0 0 0 7.425-13.565Zm-16.898 8.101a358.557 358.557 0 0 1-12.281 19.815a329.4 329.4 0 0 1-23.444.823c-7.967 0-15.716-.248-23.178-.732a310.202 310.202 0 0 1-12.513-19.846h.001a307.41 307.41 0 0 1-10.923-20.627a310.278 310.278 0 0 1 10.89-20.637l-.001.001a307.318 307.318 0 0 1 12.413-19.761c7.613-.576 15.42-.876 23.31-.876H128c7.926 0 15.743.303 23.354.883a329.357 329.357 0 0 1 12.335 19.695a358.489 358.489 0 0 1 11.036 20.54a329.472 329.472 0 0 1-11 20.722Zm22.56-122.124c8.572 4.944 11.906 24.881 6.52 51.026c-.344 1.668-.73 3.367-1.15 5.09c-10.622-2.452-22.155-4.275-34.23-5.408c-7.034-10.017-14.323-19.124-21.64-27.008a160.789 160.789 0 0 1 5.888-5.4c18.9-16.447 36.564-22.941 44.612-18.3ZM128 90.808c12.625 0 22.86 10.235 22.86 22.86s-10.235 22.86-22.86 22.86s-22.86-10.235-22.86-22.86s10.235-22.86 22.86-22.86Z"></path></svg>
</file>

<file path="screen-record/src/components/ui/button.tsx">
import * as React from "react"
import { Slot } from "@radix-ui/react-slot"
import { cva, type VariantProps } from "class-variance-authority"

import { cn } from "@/lib/utils"

const buttonVariants = cva(
  "inline-flex items-center justify-center gap-2 whitespace-nowrap rounded-md text-sm font-medium transition-colors focus-visible:outline-none focus-visible:ring-1 focus-visible:ring-ring disabled:pointer-events-none disabled:opacity-50 [&_svg]:pointer-events-none [&_svg]:size-4 [&_svg]:shrink-0",
  {
    variants: {
      variant: {
        default:
          "bg-primary text-primary-foreground shadow hover:bg-primary/90",
        destructive:
          "bg-destructive text-destructive-foreground shadow-sm hover:bg-destructive/90",
        outline:
          "border border-input bg-background shadow-sm hover:bg-accent hover:text-accent-foreground",
        secondary:
          "bg-secondary text-secondary-foreground shadow-sm hover:bg-secondary/80",
        ghost: "hover:bg-accent hover:text-accent-foreground",
        link: "text-primary underline-offset-4 hover:underline",
      },
      size: {
        default: "h-9 px-4 py-2",
        sm: "h-8 rounded-md px-3 text-xs",
        lg: "h-10 rounded-md px-8",
        icon: "h-9 w-9",
      },
    },
    defaultVariants: {
      variant: "default",
      size: "default",
    },
  }
)

export interface ButtonProps
  extends React.ButtonHTMLAttributes<HTMLButtonElement>,
    VariantProps<typeof buttonVariants> {
  asChild?: boolean
}

const Button = React.forwardRef<HTMLButtonElement, ButtonProps>(
  ({ className, variant, size, asChild = false, ...props }, ref) => {
    const Comp = asChild ? Slot : "button"
    return (
      <Comp
        className={cn(buttonVariants({ variant, size, className }))}
        ref={ref}
        {...props}
      />
    )
  }
)
Button.displayName = "Button"

export { Button, buttonVariants }
</file>

<file path="screen-record/src/hooks/useUndoRedo.ts">
import { useState, useCallback, useRef } from 'react';

// A simple hook to manage undo/redo history
export function useUndoRedo<T>(initialState: T, maxHistory: number = 20) {
    const [present, setPresent] = useState<T>(initialState);
    const [past, setPast] = useState<T[]>([]);
    const [future, setFuture] = useState<T[]>([]);

    // We need refs to access latest state in callbacks without re-creating them
    const presentRef = useRef(present);
    presentRef.current = present;

    const set = useCallback((newState: T | ((prev: T) => T), withHistory: boolean = true) => {
        // If newState is a function, evaluate it
        const computedState = newState instanceof Function ? newState(presentRef.current) : newState;

        // Don't save if state hasn't changed (deep comparison/shallow expected?)
        // Basic strict equality for now.
        if (computedState === presentRef.current) return;

        if (withHistory) {
            setPast((prev) => {
                const newPast = [...prev, presentRef.current];
                if (newPast.length > maxHistory) newPast.shift();
                return newPast;
            });
            setFuture([]);
        }
        setPresent(computedState);
    }, [maxHistory]);

    const undo = useCallback(() => {
        if (past.length === 0) return;

        const previous = past[past.length - 1];
        const newPast = past.slice(0, past.length - 1);

        setFuture((prev) => [presentRef.current, ...prev]);
        setPresent(previous);
        setPast(newPast);
    }, [past]);

    const redo = useCallback(() => {
        if (future.length === 0) return;

        const next = future[0];
        const newFuture = future.slice(1);

        setPast((prev) => [...prev, presentRef.current]);
        setPresent(next);
        setFuture(newFuture);
    }, [future]);

    return {
        state: present,
        setState: set,
        undo,
        redo,
        canUndo: past.length > 0,
        canRedo: future.length > 0
    };
}
</file>

<file path="screen-record/src/lib/thumbnailGenerator.ts">
export class ThumbnailGenerator {
  private canvas: HTMLCanvasElement;
  private video: HTMLVideoElement;

  constructor() {
    this.canvas = document.createElement('canvas');
    this.video = document.createElement('video');
    this.video.muted = true;
  }

  async generateThumbnails(
    videoUrl: string, 
    numThumbnails: number = 20,
    options?: {
      width?: number;
      height?: number;
      quality?: number;
      trimStart?: number;
      trimEnd?: number;
    }
  ): Promise<string[]> {
    this.video.src = videoUrl;
    await new Promise(r => this.video.addEventListener('loadeddata', r, { once: true }));

    // Set canvas size
    this.canvas.width = options?.width || 160;
    this.canvas.height = options?.height || 90;

    const ctx = this.canvas.getContext('2d');
    if (!ctx) throw new Error('Could not get canvas context');

    const start = options?.trimStart || 0;
    const end = options?.trimEnd || this.video.duration;
    const duration = end - start;
    const interval = duration / numThumbnails;
    const thumbnails: string[] = [];

    for (let i = 0; i < numThumbnails; i++) {
      const time = start + (i * interval);
      this.video.currentTime = time;
      await new Promise(r => this.video.addEventListener('seeked', r, { once: true }));
      
      ctx.drawImage(this.video, 0, 0, this.canvas.width, this.canvas.height);
      thumbnails.push(this.canvas.toDataURL('image/jpeg', options?.quality || 0.5));
    }

    // Cleanup
    this.video.src = '';
    return thumbnails;
  }

  destroy() {
    this.video.src = '';
    this.video = null!;
    this.canvas = null!;
  }
}

export const thumbnailGenerator = new ThumbnailGenerator();
</file>

<file path="screen-record/src/lib/utils.ts">
import { clsx, type ClassValue } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}
</file>

<file path="screen-record/src/main.tsx">
import React from "react";
import ReactDOM from "react-dom/client";
import App from "./App";

ReactDOM.createRoot(document.getElementById("root") as HTMLElement).render(
  <React.StrictMode>
    <App />
  </React.StrictMode>,
);
</file>

<file path="screen-record/src/vite-env.d.ts">
/// <reference types="vite/client" />
</file>

<file path="screen-record/tailwind.config.js">
/** @type {import('tailwindcss').Config} */
module.exports = {
    darkMode: ["class"],
    content: ["./index.html", "./src/**/*.{ts,tsx,js,jsx}"],
  theme: {
  	extend: {
  		borderRadius: {
  			lg: 'var(--radius)',
  			md: 'calc(var(--radius) - 2px)',
  			sm: 'calc(var(--radius) - 4px)'
  		},
  		colors: {
  			background: 'hsl(var(--background))',
  			foreground: 'hsl(var(--foreground))',
  			card: {
  				DEFAULT: 'hsl(var(--card))',
  				foreground: 'hsl(var(--card-foreground))'
  			},
  			popover: {
  				DEFAULT: 'hsl(var(--popover))',
  				foreground: 'hsl(var(--popover-foreground))'
  			},
  			primary: {
  				DEFAULT: 'hsl(var(--primary))',
  				foreground: 'hsl(var(--primary-foreground))'
  			},
  			secondary: {
  				DEFAULT: 'hsl(var(--secondary))',
  				foreground: 'hsl(var(--secondary-foreground))'
  			},
  			muted: {
  				DEFAULT: 'hsl(var(--muted))',
  				foreground: 'hsl(var(--muted-foreground))'
  			},
  			accent: {
  				DEFAULT: 'hsl(var(--accent))',
  				foreground: 'hsl(var(--accent-foreground))'
  			},
  			destructive: {
  				DEFAULT: 'hsl(var(--destructive))',
  				foreground: 'hsl(var(--destructive-foreground))'
  			},
  			border: 'hsl(var(--border))',
  			input: 'hsl(var(--input))',
  			ring: 'hsl(var(--ring))',
  			chart: {
  				'1': 'hsl(var(--chart-1))',
  				'2': 'hsl(var(--chart-2))',
  				'3': 'hsl(var(--chart-3))',
  				'4': 'hsl(var(--chart-4))',
  				'5': 'hsl(var(--chart-5))'
  			}
  		}
  	}
  },
  plugins: [require("tailwindcss-animate")],
}
</file>

<file path="screen-record/tsconfig.json">
{
  "compilerOptions": {
    "target": "ES2020",
    "useDefineForClassFields": true,
    "lib": ["ES2020", "DOM", "DOM.Iterable"],
    "module": "ESNext",
    "skipLibCheck": true,

    /* Bundler mode */
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "resolveJsonModule": true,
    "isolatedModules": true,
    "noEmit": true,
    "jsx": "react-jsx",

    /* Linting */
    "strict": true,
    "noUnusedLocals": true,
    "noUnusedParameters": true,
    "noFallthroughCasesInSwitch": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    },
    "types": [
      "@tauri-apps/api"
    ]
  },
  "include": ["src"],
  "references": [{ "path": "./tsconfig.node.json" }]
}
</file>

<file path="screen-record/tsconfig.node.json">
{
  "compilerOptions": {
    "composite": true,
    "skipLibCheck": true,
    "module": "ESNext", 
    "moduleResolution": "bundler",
    "allowSyntheticDefaultImports": true,
    "baseUrl": ".",
    "paths": {
      "@/*": ["./src/*"]
    }
  },
  "include": ["vite.config.ts"]
}
</file>

<file path="screen-record/vite.config.ts">
import path from "path";
import react from "@vitejs/plugin-react";
import { defineConfig } from "vite";

// @ts-expect-error process is a nodejs global
const host = process.env.TAURI_DEV_HOST;

// https://vitejs.dev/config/
export default defineConfig(async () => ({
  plugins: [react()],
  resolve: {
    alias: {
      "@": path.resolve(__dirname, "./src"),
    },
  },
  // Vite options tailored for Tauri development and only applied in `tauri dev` or `tauri build`
  //
  // 1. prevent vite from obscuring rust errors
  clearScreen: false,
  // 2. tauri expects a fixed port, fail if that port is not available
  server: {
    port: 1420,
    strictPort: true,
    host: host || false,
    hmr: host
      ? {
        protocol: "ws",
        host,
        port: 1421,
      }
      : undefined,
    watch: {
      // 3. tell vite to ignore watching `src-tauri`
      ignored: ["**/src-tauri/**"],
    },
  },
  build: {
    rollupOptions: {
      output: {
        entryFileNames: `assets/[name].js`,
        chunkFileNames: `assets/[name].js`,
        assetFileNames: `assets/[name].[ext]`
      }
    }
  },
}));
</file>

<file path="src/api/gemini_live/manager.rs">
//! Manager for Gemini Live LLM connection pool

use super::types::{LiveEvent, LiveInputContent, LiveRequest, QueuedLiveRequest};
use std::collections::VecDeque;
use std::sync::mpsc;
use std::sync::{
    atomic::{AtomicBool, AtomicU64, Ordering},
    Condvar, Mutex,
};

static REQUEST_ID_COUNTER: AtomicU64 = AtomicU64::new(1);

/// Manager for the Gemini Live LLM connection pool
/// Similar architecture to TtsManager for consistency
pub struct GeminiLiveManager {
    /// Queue for workers: requests waiting to be processed
    pub work_queue: Mutex<VecDeque<QueuedLiveRequest>>,
    /// Signal for workers to wake up
    pub work_signal: Condvar,

    /// Generation counter for interrupts
    pub interrupt_generation: AtomicU64,

    /// Shutdown flag
    pub shutdown: AtomicBool,
}

impl GeminiLiveManager {
    pub fn new() -> Self {
        Self {
            work_queue: Mutex::new(VecDeque::new()),
            work_signal: Condvar::new(),
            interrupt_generation: AtomicU64::new(0),
            shutdown: AtomicBool::new(false),
        }
    }

    /// Send a request to the Gemini Live LLM and get a receiver for events
    /// Returns (request_id, event_receiver)
    pub fn request(
        &self,
        content: LiveInputContent,
        instruction: String,
        show_thinking: bool,
    ) -> (u64, mpsc::Receiver<LiveEvent>) {
        let id = REQUEST_ID_COUNTER.fetch_add(1, Ordering::SeqCst);
        let current_gen = self.interrupt_generation.load(Ordering::SeqCst);

        let (tx, rx) = mpsc::channel();

        let req = LiveRequest {
            content,
            instruction,
            show_thinking,
        };

        {
            let mut queue = self.work_queue.lock().unwrap();
            queue.push_back(QueuedLiveRequest {
                req,
                generation: current_gen,
                response_tx: tx,
            });
        }
        self.work_signal.notify_one();

        (id, rx)
    }

    /// Interrupt all pending requests (increment generation, clear queue)
    #[allow(dead_code)]
    pub fn interrupt(&self) {
        self.interrupt_generation.fetch_add(1, Ordering::SeqCst);

        {
            let mut queue = self.work_queue.lock().unwrap();
            // Send error to all pending requests before clearing
            for req in queue.drain(..) {
                let _ = req
                    .response_tx
                    .send(LiveEvent::Error("Interrupted".to_string()));
            }
        }

        self.work_signal.notify_all();
    }

    /// Check if a request's generation is still valid
    pub fn is_generation_valid(&self, generation: u64) -> bool {
        generation >= self.interrupt_generation.load(Ordering::SeqCst)
    }

    /// Shutdown the manager
    #[allow(dead_code)]
    pub fn shutdown(&self) {
        self.shutdown.store(true, Ordering::SeqCst);
        self.interrupt();
    }
}

impl Default for GeminiLiveManager {
    fn default() -> Self {
        Self::new()
    }
}
</file>

<file path="src/api/gemini_live/types.rs">
//! Types for Gemini Live LLM API

use std::sync::mpsc;

/// Model for Gemini Live LLM (same as TTS/STT for consistency)
pub const GEMINI_LIVE_MODEL: &str = "gemini-2.5-flash-native-audio-preview-12-2025";

/// Events sent from worker to caller
#[derive(Debug)]
pub enum LiveEvent {
    /// Text chunk received from the model
    TextChunk(String),
    /// Model is thinking (for models with thinking support)
    Thinking,
    /// Turn is complete
    TurnComplete,
    /// Error occurred
    Error(String),
}

/// Input content types for Gemini Live
#[derive(Clone, Debug)]
pub enum LiveInputContent {
    /// Text-only input
    Text(String),
    /// Text with image (base64 encoded)
    TextWithImage {
        text: String,
        image_data: Vec<u8>,
        mime_type: String,
    },
    /// Text with audio (PCM 16-bit mono 16kHz)
    TextWithAudio { text: String, audio_data: Vec<u8> },
    /// Audio-only input (for audio presets)
    AudioOnly(Vec<u8>),
}

/// A request to the Gemini Live LLM
#[derive(Clone)]
pub struct LiveRequest {
    /// The input content
    pub content: LiveInputContent,
    /// System instruction (prompt)
    pub instruction: String,
    /// Whether to enable thinking display
    pub show_thinking: bool,
}

/// Queued request with generation tracking for interrupts
pub struct QueuedLiveRequest {
    pub req: LiveRequest,
    pub generation: u64,
    pub response_tx: mpsc::Sender<LiveEvent>,
}
</file>

<file path="src/api/realtime_audio/mod.rs">
//! Real-time audio transcription using Gemini Live API
//!
//! This module handles streaming audio to Gemini's native audio model
//! and receives real-time transcriptions via WebSocket.
//!
//! Translation is handled separately via Cerebras' gpt-oss-120b model
//! every 2 seconds for new sentence chunks.

mod capture;
pub mod model_loader;
pub mod parakeet;
mod state;
mod transcription;
mod translation;
mod utils;
pub mod websocket;

use windows::Win32::UI::WindowsAndMessaging::WM_APP;

// Re-export public items
pub use state::{RealtimeState, SharedRealtimeState};
pub use transcription::start_realtime_transcription;
pub use translation::translate_with_google_gtx;

/// Interval for triggering translation (milliseconds)
pub const TRANSLATION_INTERVAL_MS: u64 = 1500;

/// Model for realtime audio transcription
pub const REALTIME_MODEL: &str = "gemini-2.5-flash-native-audio-preview-12-2025";

/// Custom message for updating overlay text
pub const WM_REALTIME_UPDATE: u32 = WM_APP + 200;
pub const WM_TRANSLATION_UPDATE: u32 = WM_APP + 201;
pub const WM_VOLUME_UPDATE: u32 = WM_APP + 202;
pub const WM_MODEL_SWITCH: u32 = WM_APP + 203;
pub const WM_DOWNLOAD_PROGRESS: u32 = WM_APP + 204;
pub const WM_START_DRAG: u32 = WM_APP + 205;
pub const WM_TOGGLE_MIC: u32 = WM_APP + 206;
pub const WM_TOGGLE_TRANS: u32 = WM_APP + 207;
pub const WM_COPY_TEXT: u32 = WM_APP + 208;
pub const WM_EXEC_SCRIPT: u32 = WM_APP + 209;
pub const WM_UPDATE_TTS_SPEED: u32 = WM_APP + 210;
pub const WM_THEME_UPDATE: u32 = WM_APP + 212;

// Shared RMS value for volume visualization
pub static REALTIME_RMS: std::sync::atomic::AtomicU32 = std::sync::atomic::AtomicU32::new(0);

/// Cancel Parakeet download and revert to Gemini Live mode
pub fn cancel_download_and_revert_to_gemini() {
    use crate::overlay::realtime_webview::state::{
        NEW_TRANSCRIPTION_MODEL, REALTIME_HWND, REALTIME_STATE, REALTIME_WEBVIEWS,
        TRANSCRIPTION_MODEL_CHANGE,
    };
    use std::sync::atomic::Ordering;

    // 1. Set stop signal to cancel download
    crate::overlay::realtime_webview::state::REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);

    // 2. Clear the download state
    if let Ok(mut state) = REALTIME_STATE.lock() {
        state.is_downloading = false;
    }

    // 3. Revert transcription model to gemini in config
    {
        let mut app = crate::APP.lock().unwrap();
        app.config.realtime_transcription_model = "gemini".to_string();
        crate::config::save_config(&app.config);
    }

    // 4. Signal model change to restart with gemini
    if let Ok(mut model) = NEW_TRANSCRIPTION_MODEL.lock() {
        *model = "gemini".to_string();
    }
    TRANSCRIPTION_MODEL_CHANGE.store(true, Ordering::SeqCst);

    // 5. Update WebView UI to show Gemini icon as active and hide download modal
    unsafe {
        let hwnd = std::ptr::addr_of!(REALTIME_HWND).read();
        if !hwnd.is_invalid() {
            let hwnd_key = hwnd.0 as isize;
            // Hide download modal and update transcription model selection
            let script = r#"
                if(window.hideDownloadModal) window.hideDownloadModal();
                document.querySelectorAll('.trans-model-icon').forEach(icon => {
                    icon.classList.toggle('active', icon.getAttribute('data-value') === 'gemini');
                });
            "#;
            REALTIME_WEBVIEWS.with(|wvs| {
                if let Some(webview) = wvs.borrow().get(&hwnd_key) {
                    let _ = webview.evaluate_script(script);
                }
            });
        }
    }

    println!("Parakeet download cancelled, reverting to Gemini Live");
}
</file>

<file path="src/api/tts/manager.rs">
use super::types::{AudioEvent, QueuedRequest, TtsRequest};
use super::utils;
use std::collections::VecDeque;
use std::sync::mpsc;
use std::sync::{
    atomic::{AtomicBool, AtomicU64, Ordering},
    Condvar, Mutex,
};

static REQUEST_ID_COUNTER: AtomicU64 = AtomicU64::new(1);

/// Manages the persistent TTS WebSocket connection
pub struct TtsManager {
    /// Flag to indicate if the connection is ready
    _is_ready: AtomicBool,

    /// Queue for Socket Workers: (Request + Generation, Output Channel)
    pub work_queue: Mutex<VecDeque<(QueuedRequest, mpsc::Sender<AudioEvent>)>>,
    /// Signal for Socket Workers
    pub work_signal: Condvar,

    /// Queue for Player: (Input Channel, Window Handle, Request ID, Generation ID, IsRealtime)
    pub playback_queue: Mutex<VecDeque<(mpsc::Receiver<AudioEvent>, isize, u64, u64, bool)>>,
    /// Signal for Player
    pub playback_signal: Condvar,

    /// Generation counter for interrupts (incrementing this invalidates old jobs)
    pub interrupt_generation: AtomicU64,

    /// Flag to indicate if audio is currently playing (set by player thread)
    pub is_playing: AtomicBool,

    /// Flag to shutdown the manager
    pub shutdown: AtomicBool,
}

impl TtsManager {
    pub fn new() -> Self {
        Self {
            _is_ready: AtomicBool::new(false),
            work_queue: Mutex::new(VecDeque::new()),
            work_signal: Condvar::new(),
            playback_queue: Mutex::new(VecDeque::new()),
            playback_signal: Condvar::new(),
            interrupt_generation: AtomicU64::new(0),
            is_playing: AtomicBool::new(false),
            shutdown: AtomicBool::new(false),
        }
    }

    /// Check if TTS is ready to accept requests
    pub fn _is_ready(&self) -> bool {
        self._is_ready.load(Ordering::SeqCst)
    }

    /// Request TTS for the given text. Appends to queue (sequential playback).
    /// Returns the request ID.
    pub fn speak(&self, text: &str, hwnd: isize) -> u64 {
        self.speak_internal(text, hwnd, false)
    }

    /// Request TTS for realtime translation. Uses REALTIME_TTS_SPEED and auto-catchup.
    /// Returns the request ID.
    pub fn speak_realtime(&self, text: &str, hwnd: isize) -> u64 {
        self.speak_internal(text, hwnd, true)
    }

    /// Internal speak implementation
    fn speak_internal(&self, text: &str, hwnd: isize, is_realtime: bool) -> u64 {
        let id = REQUEST_ID_COUNTER.fetch_add(1, Ordering::SeqCst);
        let current_gen = self.interrupt_generation.load(Ordering::SeqCst);

        let (tx, rx) = mpsc::channel();

        // Add to queues
        {
            let mut wq = self.work_queue.lock().unwrap();
            wq.push_back((
                QueuedRequest {
                    req: TtsRequest {
                        _id: id,
                        text: text.to_string(),
                        hwnd,
                        is_realtime,
                    },
                    generation: current_gen,
                },
                tx,
            ));
        }
        self.work_signal.notify_one();

        {
            let mut pq = self.playback_queue.lock().unwrap();
            pq.push_back((rx, hwnd, id, current_gen, is_realtime));
        }
        self.playback_signal.notify_one();

        id
    }

    /// Request TTS for the given text, interrupting any current speech.
    /// Clears the queue and stops current playback immediately.
    pub fn speak_interrupt(&self, text: &str, hwnd: isize) -> u64 {
        // Increment generation to invalidate all currently running/queued work
        let new_gen = self.interrupt_generation.fetch_add(1, Ordering::SeqCst) + 1;
        let id = REQUEST_ID_COUNTER.fetch_add(1, Ordering::SeqCst);

        // Clear all queues
        {
            let mut wq = self.work_queue.lock().unwrap();
            wq.clear();
        }
        {
            let mut pq = self.playback_queue.lock().unwrap();
            pq.clear(); // Drops receivers, causing senders to error and workers to reset
        }

        // Push new request
        let (tx, rx) = mpsc::channel();

        {
            let mut wq = self.work_queue.lock().unwrap();
            wq.push_back((
                QueuedRequest {
                    req: TtsRequest {
                        _id: id,
                        text: text.to_string(),
                        hwnd,
                        is_realtime: false,
                    },
                    generation: new_gen,
                },
                tx,
            ));
        }
        self.work_signal.notify_one();

        {
            let mut pq = self.playback_queue.lock().unwrap();
            pq.push_back((rx, hwnd, id, new_gen, false));
        }
        // Force notify player to wake up and check generation/queue
        self.playback_signal.notify_one();

        id
    }

    /// Stop the current speech or cancel pending request
    pub fn stop(&self) {
        self.interrupt_generation.fetch_add(1, Ordering::SeqCst);

        // Clear queues
        {
            let mut wq = self.work_queue.lock().unwrap();
            wq.clear();
        }
        {
            let mut pq = self.playback_queue.lock().unwrap();
            pq.clear();
        }

        // Wake up player to realize it should stop
        self.playback_signal.notify_all();
    }

    /// Stop speech for a specific request ID (only if it's the current one)
    pub fn stop_if_active(&self, _request_id: u64) {
        // Simplified to just stop
        self.stop();
    }

    /// Check if this request ID is currently active
    pub fn is_speaking(&self, _request_id: u64) -> bool {
        self.has_pending_audio()
    }

    /// Check if there's any pending TTS audio (in work queue, playback queue, or currently playing)
    pub fn has_pending_audio(&self) -> bool {
        // Check if actively playing first (most common case when user wants to stop)
        if self.is_playing.load(Ordering::SeqCst) {
            return true;
        }
        let wq_has = self
            .work_queue
            .lock()
            .map(|q| !q.is_empty())
            .unwrap_or(false);
        let pq_has = self
            .playback_queue
            .lock()
            .map(|q| !q.is_empty())
            .unwrap_or(false);
        wq_has || pq_has
    }

    /// Shutdown the TTS manager
    pub fn _shutdown(&self) {
        self.shutdown.store(true, Ordering::SeqCst);
        self.interrupt_generation.fetch_add(1, Ordering::SeqCst);
        self.work_signal.notify_all();
        self.playback_signal.notify_all();
    }

    /// List available audio output devices (ID, Name)
    pub fn get_output_devices() -> Vec<(String, String)> {
        utils::get_output_devices()
    }
}
</file>

<file path="src/api/tts/utils.rs">
use windows::Win32::Foundation::HWND;
use windows::Win32::Graphics::Gdi::InvalidateRect;
use windows::Win32::Media::Audio::*;
use windows::Win32::System::Com::*;

use crate::overlay::result::state::WINDOW_STATES;

/// Clear the TTS loading state for a window and trigger repaint
pub fn clear_tts_loading_state(hwnd: isize) {
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd) {
            state.tts_loading = false;
        }
    }

    // Trigger repaint to update button appearance
    unsafe {
        let _ = InvalidateRect(Some(HWND(hwnd as *mut std::ffi::c_void)), None, false);
    }

    // Notify button canvas that state has changed
    crate::overlay::result::button_canvas::update_canvas();
}

/// Clear TTS state completely when speech ends
pub fn clear_tts_state(hwnd: isize) {
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd) {
            state.tts_loading = false;
            state.tts_request_id = 0;
        }
    }

    // Trigger repaint to update button appearance
    unsafe {
        let _ = InvalidateRect(Some(HWND(hwnd as *mut std::ffi::c_void)), None, false);
    }

    // Notify button canvas that state has changed
    crate::overlay::result::button_canvas::update_canvas();
}

/// Detect language of text and get matching TTS instruction from config conditions
pub fn get_language_instruction_for_text(
    text: &str,
    conditions: &[crate::config::TtsLanguageCondition],
) -> Option<String> {
    // Use whatlang for fast language detection (70 languages supported)
    // Returns None if text is too short or language is unclear
    let detected = whatlang::detect_lang(text)?;
    let detected_code = detected.code(); // ISO 639-3 code (e.g., "vie", "kor", "eng")

    // Find matching condition
    for condition in conditions {
        if condition.language_code.eq_ignore_ascii_case(detected_code) {
            return Some(condition.instruction.clone());
        }
    }
    None
}

/// List available audio output devices (ID, Name)
pub fn get_output_devices() -> Vec<(String, String)> {
    let mut devices = Vec::new();
    unsafe {
        let _ = CoInitializeEx(None, COINIT_MULTITHREADED);
        if let Ok(enumerator) =
            CoCreateInstance::<_, IMMDeviceEnumerator>(&MMDeviceEnumerator, None, CLSCTX_ALL)
        {
            if let Ok(collection) = enumerator.EnumAudioEndpoints(eRender, DEVICE_STATE_ACTIVE) {
                if let Ok(count) = collection.GetCount() {
                    for i in 0..count {
                        if let Ok(device) = collection.Item(i) {
                            if let Ok(id) = device.GetId() {
                                let id_str = id.to_string().unwrap_or_default();
                                // Try to get friendly name
                                let name = if let Ok(_props) = device.OpenPropertyStore(STGM_READ) {
                                    // PKEY_Device_FriendlyName would be ideal but requires property key definition
                                    // For now, let's just use the ID or partial ID if needed,
                                    // but usually we rely on the ID.
                                    // If we really need the name, we would need to implement property getters.
                                    // Given the original code had this logic, we keep it simple or reuse if possible.
                                    // The original code comment said: "In windows 0.62, PropVariant access is verbose."
                                    // and "Let's rely on the ID matching...".
                                    id_str.clone()
                                } else {
                                    id_str.clone()
                                };
                                devices.push((id_str, name));
                            }
                        }
                    }
                }
            }
        }
    }
    devices
}
</file>

<file path="src/api/tts/worker.rs">
use minimp3::{Decoder, Frame};
use std::io::{Cursor, Read};
use std::sync::{atomic::Ordering, Arc};
use std::time::{Duration, Instant};
use tungstenite::{client, Message};

use super::manager::TtsManager;
use super::types::AudioEvent;
use super::utils::{clear_tts_loading_state, clear_tts_state, get_language_instruction_for_text};
use super::websocket::{
    connect_tts_websocket, is_turn_complete, parse_audio_data, send_tts_setup, send_tts_text,
};
use crate::api::client::UREQ_AGENT;

use crate::APP;
use isolang::Language;

/// Socket Worker thread - fetches audio data and pipes it to the player
pub fn run_socket_worker(manager: Arc<TtsManager>) {
    // Delay start slightly to stagger connections if multiple workers start at once
    std::thread::sleep(Duration::from_millis(100));

    loop {
        if manager.shutdown.load(Ordering::SeqCst) {
            break;
        }

        // Wait for a request
        let (request, tx) = {
            let mut queue = manager.work_queue.lock().unwrap();
            while queue.is_empty() && !manager.shutdown.load(Ordering::SeqCst) {
                let result = manager.work_signal.wait(queue).unwrap();
                queue = result;
            }
            if manager.shutdown.load(Ordering::SeqCst) {
                return;
            }
            queue.pop_front().unwrap()
        };

        // Check if this request is stale
        if request.generation < manager.interrupt_generation.load(Ordering::SeqCst) {
            let _ = tx.send(AudioEvent::End);
            continue;
        }

        // Check TTS Method - route to alternative handlers if not Gemini
        let tts_method = {
            match APP.lock() {
                Ok(app) => app.config.tts_method.clone(),
                Err(_) => {
                    let _ = tx.send(AudioEvent::End);
                    continue;
                }
            }
        };

        if tts_method == crate::config::TtsMethod::GoogleTranslate {
            handle_google_tts(manager.clone(), request, tx);
            continue;
        }

        if tts_method == crate::config::TtsMethod::EdgeTTS {
            handle_edge_tts(manager.clone(), request, tx);
            continue;
        }

        // Get API key
        let api_key = {
            match APP.lock() {
                Ok(app) => app.config.gemini_api_key.clone(),
                Err(_) => {
                    let _ = tx.send(AudioEvent::End);
                    std::thread::sleep(Duration::from_secs(1));
                    continue;
                }
            }
        };

        if api_key.trim().is_empty() {
            eprintln!("TTS: No Gemini API key configured");
            let _ = tx.send(AudioEvent::End);
            clear_tts_loading_state(request.req.hwnd);
            clear_tts_state(request.req.hwnd);
            std::thread::sleep(Duration::from_secs(5));
            continue;
        }

        // Attempt to connect
        let socket_result = connect_tts_websocket(&api_key);
        let mut socket = match socket_result {
            Ok(s) => s,
            Err(e) => {
                eprintln!("TTS: Failed to connect: {}", e);
                let _ = tx.send(AudioEvent::End);
                clear_tts_loading_state(request.req.hwnd);
                clear_tts_state(request.req.hwnd);
                std::thread::sleep(Duration::from_secs(3));
                continue;
            }
        };

        // Read config for setup
        let (current_voice, current_speed, language_instruction) = {
            let app = APP.lock().unwrap();
            let voice = app.config.tts_voice.clone();
            let conditions = app.config.tts_language_conditions.clone();

            let instruction = get_language_instruction_for_text(&request.req.text, &conditions);

            if request.req.is_realtime {
                (voice, "Normal".to_string(), instruction)
            } else {
                (voice, app.config.tts_speed.clone(), instruction)
            }
        };

        // Send setup
        if let Err(e) = send_tts_setup(
            &mut socket,
            &current_voice,
            &current_speed,
            language_instruction.as_deref(),
        ) {
            eprintln!("TTS: Failed to send setup: {}", e);
            let _ = socket.close(None);
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            std::thread::sleep(Duration::from_secs(2));
            continue;
        }

        // Wait for setup acknowledgment
        let setup_start = Instant::now();
        let mut setup_complete = false;
        loop {
            if request.generation < manager.interrupt_generation.load(Ordering::SeqCst)
                || manager.shutdown.load(Ordering::SeqCst)
            {
                let _ = socket.close(None);
                let _ = tx.send(AudioEvent::End);
                break;
            }

            match socket.read() {
                Ok(Message::Text(msg)) => {
                    let msg = msg.as_str();
                    if msg.contains("setupComplete") {
                        setup_complete = true;
                        break;
                    }
                    if msg.contains("error") || msg.contains("Error") {
                        eprintln!("TTS: Setup error: {}", msg);
                        break;
                    }
                }
                Ok(Message::Close(_)) => {
                    break;
                }
                Ok(Message::Binary(data)) => {
                    if let Ok(text) = String::from_utf8(data.to_vec()) {
                        if text.contains("setupComplete") {
                            setup_complete = true;
                            break;
                        }
                    }
                }
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock =>
                {
                    if setup_start.elapsed() > Duration::from_secs(10) {
                        break;
                    }
                    std::thread::sleep(Duration::from_millis(50));
                }
                Err(_) => {
                    break;
                }
            }
        }

        if manager.shutdown.load(Ordering::SeqCst) {
            return;
        }

        if !setup_complete {
            let _ = socket.close(None);
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            continue;
        }

        // Send request text
        if let Err(e) = send_tts_text(&mut socket, &request.req.text) {
            eprintln!("TTS: Failed to send text: {}", e);
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            let _ = socket.close(None);
            continue;
        }

        // Read loop
        loop {
            if request.generation < manager.interrupt_generation.load(Ordering::SeqCst)
                || manager.shutdown.load(Ordering::SeqCst)
            {
                let _ = socket.close(None);
                let _ = tx.send(AudioEvent::End);
                break;
            }

            match socket.read() {
                Ok(Message::Text(msg)) => {
                    let msg = msg.as_str();
                    if let Some(audio_data) = parse_audio_data(msg) {
                        let _ = tx.send(AudioEvent::Data(audio_data));
                    }
                    if is_turn_complete(msg) {
                        let _ = tx.send(AudioEvent::End);
                        break;
                    }
                }
                Ok(Message::Binary(data)) => {
                    if let Ok(text) = String::from_utf8(data.to_vec()) {
                        if let Some(audio_data) = parse_audio_data(&text) {
                            let _ = tx.send(AudioEvent::Data(audio_data));
                        }
                        if is_turn_complete(&text) {
                            let _ = tx.send(AudioEvent::End);
                            break;
                        }
                    }
                }
                Ok(Message::Close(_)) => {
                    let _ = tx.send(AudioEvent::End);
                    break;
                }
                Ok(_) => {}
                Err(tungstenite::Error::Io(ref e))
                    if e.kind() == std::io::ErrorKind::WouldBlock =>
                {
                    std::thread::sleep(Duration::from_millis(5));
                }
                Err(e) => {
                    eprintln!("TTS: Read error: {}", e);
                    let _ = tx.send(AudioEvent::End);
                    clear_tts_state(request.req.hwnd);
                    break;
                }
            }
        }

        let _ = socket.close(None);
    }
}

/// Google Translate TTS integrated with the existing audio pipeline
/// Downloads MP3, decodes to PCM, sends via AudioEvent channel for WSOLA speed control
fn handle_google_tts(
    manager: Arc<TtsManager>,
    request: super::types::QueuedRequest,
    tx: std::sync::mpsc::Sender<AudioEvent>,
) {
    let text = request.req.text.clone();

    // Detect language for Google TTS TL parameter
    let lang_code = whatlang::detect_lang(&text).unwrap_or(whatlang::Lang::Eng);

    // Convert whatlang Lang to ISO 639-1 (best effort)
    // Convert whatlang Lang to ISO 639-1 via isolang for Google TTS
    let tl = Language::from_639_3(lang_code.code())
        .and_then(|l| l.to_639_1())
        .unwrap_or("en");

    // Google TTS URL
    let url = format!(
        "https://translate.google.com/translate_tts?ie=UTF-8&q={}&tl={}&client=tw-ob",
        urlencoding::encode(&text),
        tl
    );

    // Download audio (blocking)
    let resp = match UREQ_AGENT.get(&url).call() {
        Ok(r) => r,
        Err(_) => {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }
    };

    let mut mp3_data = Vec::new();
    if resp
        .into_body()
        .into_reader()
        .read_to_end(&mut mp3_data)
        .is_err()
    {
        let _ = tx.send(AudioEvent::End);
        clear_tts_state(request.req.hwnd);
        return;
    }

    // Decode MP3 to PCM
    let mut decoder = Decoder::new(Cursor::new(mp3_data));
    let mut source_sample_rate = 24000u32;
    let mut all_samples: Vec<i16> = Vec::new();

    loop {
        // Check interrupt
        if request.generation < manager.interrupt_generation.load(Ordering::SeqCst) {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }

        match decoder.next_frame() {
            Ok(Frame {
                data,
                sample_rate,
                channels,
                ..
            }) => {
                source_sample_rate = sample_rate as u32;
                // If stereo, mix to mono
                if channels == 2 {
                    for chunk in data.chunks(2) {
                        let sample = ((chunk[0] as i32 + chunk[1] as i32) / 2) as i16;
                        all_samples.push(sample);
                    }
                } else {
                    all_samples.extend_from_slice(&data);
                }
            }
            Err(minimp3::Error::Eof) => break,
            Err(_) => break,
        }
    }

    if all_samples.is_empty() {
        let _ = tx.send(AudioEvent::End);
        clear_tts_state(request.req.hwnd);
        return;
    }

    // Clear loading state as soon as we have audio
    clear_tts_loading_state(request.req.hwnd);

    // Resample if needed to 24kHz (Gemini standard for our pipeline)
    let audio_bytes = if source_sample_rate != 24000 {
        let resampled = resample_audio(&all_samples, source_sample_rate, 24000);
        let mut bytes = Vec::with_capacity(resampled.len() * 2);
        for sample in resampled {
            bytes.extend_from_slice(&sample.to_le_bytes());
        }
        bytes
    } else {
        let mut bytes = Vec::with_capacity(all_samples.len() * 2);
        for sample in all_samples {
            bytes.extend_from_slice(&sample.to_le_bytes());
        }
        bytes
    };

    // Send in chunks
    let chunk_size = 24000;
    for chunk in audio_bytes.chunks(chunk_size) {
        if request.generation < manager.interrupt_generation.load(Ordering::SeqCst) {
            break;
        }
        let _ = tx.send(AudioEvent::Data(chunk.to_vec()));
    }

    let _ = tx.send(AudioEvent::End);
    clear_tts_state(request.req.hwnd);
}

fn handle_edge_tts(
    manager: Arc<TtsManager>,
    request: super::types::QueuedRequest,
    tx: std::sync::mpsc::Sender<AudioEvent>,
) {
    let text = request.req.text.clone();
    let generation = request.generation;
    let manager_clone = manager.clone();

    // Get Settings
    let (voice_name, pitch, rate) = {
        let app = APP.lock().unwrap();
        let settings = &app.config.edge_tts_settings;

        let lang_detect = whatlang::detect(&text);

        let mut voice = "en-US-AriaNeural".to_string();

        // Convert detected language to ISO 639-1 (2-letter) code for config lookup
        let code_2 = lang_detect
            .and_then(|info| Language::from_639_3(info.lang().code()))
            .and_then(|l| l.to_639_1())
            .unwrap_or("en");

        for config in &settings.voice_configs {
            if config.language_code == code_2 {
                voice = config.voice_name.clone();
                break;
            }
        }

        (voice, settings.pitch, settings.rate)
    };

    // Edge TTS WebSocket constants
    let trusted_token = "6A5AA1D4EAFF4E9FB37E23D68491D6F4";
    let connection_id = format!(
        "{:032x}",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos()
    );
    let wss_url = format!(
        "wss://speech.platform.bing.com/consumer/speech/synthesize/readaloud/edge/v1?TrustedClientToken={}&ConnectionId={}",
        trusted_token, connection_id
    );

    let connector = match native_tls::TlsConnector::new() {
        Ok(c) => c,
        Err(_) => {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }
    };

    let host = "speech.platform.bing.com";
    let stream = match std::net::TcpStream::connect(format!("{}:443", host)) {
        Ok(s) => s,
        Err(_) => {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }
    };

    let tls_stream = match connector.connect(host, stream) {
        Ok(s) => s,
        Err(_) => {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }
    };

    let (mut socket, _) = match client(&wss_url, tls_stream) {
        Ok(s) => s,
        Err(_) => {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }
    };

    let request_id = format!(
        "{:032x}",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos()
    );

    let config_msg = format!(
        "X-Timestamp:{}\r\nContent-Type:application/json; charset=utf-8\r\nPath:speech.config\r\n\r\n{{\"context\":{{\"synthesis\":{{\"audio\":{{\"metadataoptions\":{{\"sentenceBoundaryEnabled\":\"false\",\"wordBoundaryEnabled\":\"false\"}},\"outputFormat\":\"audio-24khz-48kbitrate-mono-mp3\"}}}}}}}}",
        chrono::Utc::now().format("%a %b %d %Y %H:%M:%S GMT+0000 (Coordinated Universal Time)")
    );

    if socket.send(Message::Text(config_msg.into())).is_err() {
        let _ = tx.send(AudioEvent::End);
        clear_tts_state(request.req.hwnd);
        return;
    }

    let pitch_str = if pitch >= 0 {
        format!("+{}Hz", pitch)
    } else {
        format!("{}Hz", pitch)
    };
    let rate_str = if rate >= 0 {
        format!("+{}%", rate)
    } else {
        format!("{}%", rate)
    };

    let escaped_text = text
        .replace('&', "&amp;")
        .replace('<', "&lt;")
        .replace('>', "&gt;")
        .replace('"', "&quot;")
        .replace('\'', "&apos;");

    let ssml = format!(
        "<speak version='1.0' xmlns='http://www.w3.org/2001/10/synthesis' xml:lang='en-US'>\
        <voice name='{}'>\
        <prosody pitch='{}' rate='{}' volume='+0%'>{}</prosody>\
        </voice></speak>",
        voice_name, pitch_str, rate_str, escaped_text
    );

    let ssml_msg = format!(
        "X-RequestId:{}\r\nContent-Type:application/ssml+xml\r\nX-Timestamp:{}Z\r\nPath:ssml\r\n\r\n{}",
        request_id,
        chrono::Utc::now().format("%Y-%m-%dT%H:%M:%S%.3f"),
        ssml
    );

    if socket.send(Message::Text(ssml_msg.into())).is_err() {
        let _ = tx.send(AudioEvent::End);
        clear_tts_state(request.req.hwnd);
        return;
    }

    clear_tts_loading_state(request.req.hwnd);

    let mut mp3_data: Vec<u8> = Vec::new();

    loop {
        if generation < manager_clone.interrupt_generation.load(Ordering::SeqCst) {
            break;
        }

        match socket.read() {
            Ok(Message::Binary(data)) => {
                if data.len() >= 2 {
                    let header_len = u16::from_be_bytes([data[0], data[1]]) as usize;
                    let audio_start = 2 + header_len;
                    if data.len() > audio_start {
                        let header = &data[2..audio_start];
                        if header.windows(11).any(|w| w == b"Path:audio\r") {
                            mp3_data.extend_from_slice(&data[audio_start..]);
                        }
                    }
                }
            }
            Ok(Message::Text(text)) => {
                let text = text.as_str();
                if text.contains("Path:turn.end") {
                    break;
                }
            }
            Ok(Message::Close(_)) => break,
            Err(tungstenite::Error::Io(ref e)) if e.kind() == std::io::ErrorKind::WouldBlock => {
                std::thread::sleep(Duration::from_millis(5));
            }
            Err(_) => break,
            _ => {}
        }
    }

    let _ = socket.close(None);

    if mp3_data.is_empty() {
        let _ = tx.send(AudioEvent::End);
        clear_tts_state(request.req.hwnd);
        return;
    }

    let mut decoder = Decoder::new(Cursor::new(mp3_data));
    let mut all_samples: Vec<i16> = Vec::new();
    let mut source_sample_rate = 24000u32;

    loop {
        if generation < manager_clone.interrupt_generation.load(Ordering::SeqCst) {
            let _ = tx.send(AudioEvent::End);
            clear_tts_state(request.req.hwnd);
            return;
        }
        match decoder.next_frame() {
            Ok(Frame {
                data,
                sample_rate,
                channels,
                ..
            }) => {
                source_sample_rate = sample_rate as u32;
                if channels == 2 {
                    for chunk in data.chunks(2) {
                        let sample = ((chunk[0] as i32 + chunk[1] as i32) / 2) as i16;
                        all_samples.push(sample);
                    }
                } else {
                    all_samples.extend_from_slice(&data);
                }
            }
            Err(minimp3::Error::Eof) => break,
            Err(_) => break,
        }
    }

    let audio_bytes = if source_sample_rate != 24000 {
        let resampled = resample_audio(&all_samples, source_sample_rate, 24000);
        let mut bytes = Vec::with_capacity(resampled.len() * 2);
        for sample in resampled {
            bytes.extend_from_slice(&sample.to_le_bytes());
        }
        bytes
    } else {
        let mut bytes = Vec::with_capacity(all_samples.len() * 2);
        for sample in all_samples {
            bytes.extend_from_slice(&sample.to_le_bytes());
        }
        bytes
    };

    let chunk_size = 24000;
    for chunk in audio_bytes.chunks(chunk_size) {
        if generation < manager_clone.interrupt_generation.load(Ordering::SeqCst) {
            break;
        }
        let _ = tx.send(AudioEvent::Data(chunk.to_vec()));
    }

    let _ = tx.send(AudioEvent::End);
    clear_tts_state(request.req.hwnd);
}

fn resample_audio(samples: &[i16], from_rate: u32, to_rate: u32) -> Vec<i16> {
    if from_rate == to_rate {
        return samples.to_vec();
    }

    let ratio = to_rate as f32 / from_rate as f32;
    let new_len = (samples.len() as f32 * ratio) as usize;
    let mut result = Vec::with_capacity(new_len);

    for i in 0..new_len {
        let src_idx_f = i as f32 / ratio;
        let src_idx = src_idx_f as usize;

        if src_idx >= samples.len() - 1 {
            result.push(samples[src_idx.min(samples.len() - 1)]);
        } else {
            let t = src_idx_f - src_idx as f32;
            let s1 = samples[src_idx] as f32;
            let s2 = samples[src_idx + 1] as f32;
            let val = s1 + t * (s2 - s1);
            result.push(val as i16);
        }
    }

    result
}
</file>

<file path="src/assets.rs">
pub static GOOGLE_SANS_FLEX: &[u8] =
    include_bytes!("../assets/GoogleSansFlex-VariableFont_GRAD,ROND,opsz,slnt,wdth,wght.ttf");
</file>

<file path="src/config/preset/defaults/mod.rs">
//! Default presets module.
//!
//! This module provides all built-in presets in a single ordered list.
//! The order here determines the default display order in the UI.

mod audio;
mod image;
mod master;
mod text;

use crate::config::preset::Preset;

pub use audio::create_audio_presets;
pub use image::create_image_presets;
pub use master::create_master_presets;
pub use text::create_text_presets;

/// Get all default presets in the correct display order.
///
/// The order is organized by columns in the sidebar:
/// - Column 1: Image presets, ending with Image MASTER
/// - Column 2: Text-Select presets, Text-Type presets, with MASTERs at section ends
/// - Column 3: Mic presets, Device Audio presets, with MASTERs at section ends
pub fn get_default_presets() -> Vec<Preset> {
    let image = create_image_presets();
    let text = create_text_presets();
    let audio = create_audio_presets();
    let masters = create_master_presets();

    // Helper to find preset by ID
    let find = |presets: &[Preset], id: &str| -> Preset {
        presets.iter().find(|p| p.id == id).cloned().unwrap()
    };

    vec![
        // =====================================================================
        // COLUMN 1: IMAGE PRESETS
        // =====================================================================
        find(&image, "preset_translate"),
        find(&image, "preset_extract_retranslate"),
        find(&image, "preset_translate_auto_paste"),
        find(&image, "preset_extract_table"),
        find(&image, "preset_translate_retranslate"),
        find(&image, "preset_extract_retrans_retrans"),
        find(&image, "preset_ocr"),
        find(&image, "preset_ocr_read"),
        find(&image, "preset_quick_screenshot"),
        find(&image, "preset_qr_scanner"),
        find(&image, "preset_summarize"),
        find(&image, "preset_desc"),
        find(&image, "preset_ask_image"),
        find(&image, "preset_fact_check"),
        find(&image, "preset_omniscient_god"),
        find(&image, "preset_hang_image"),
        find(&masters, "preset_image_master"),
        // =====================================================================
        // COLUMN 2: TEXT PRESETS
        // =====================================================================
        // Text-Select section
        find(&text, "preset_read_aloud"),
        find(&text, "preset_translate_select"),
        find(&text, "preset_translate_arena"),
        find(&text, "preset_trans_retrans_select"),
        find(&text, "preset_select_translate_replace"),
        find(&text, "preset_fix_grammar"),
        find(&text, "preset_rephrase"),
        find(&text, "preset_make_formal"),
        find(&text, "preset_explain"),
        find(&text, "preset_ask_text"),
        find(&text, "preset_edit_as_follows"),
        find(&text, "preset_101_on_this"),
        find(&text, "preset_hang_text"),
        find(&masters, "preset_text_select_master"),
        // Text-Type section
        find(&text, "preset_trans_retrans_typing"),
        find(&text, "preset_ask_ai"),
        find(&text, "preset_internet_search"),
        find(&text, "preset_make_game"),
        find(&text, "preset_quick_note"),
        find(&masters, "preset_text_type_master"),
        // =====================================================================
        // COLUMN 3: AUDIO PRESETS
        // =====================================================================
        // Mic section
        find(&audio, "preset_transcribe"),
        find(&audio, "preset_continuous_writing_online"),
        find(&audio, "preset_fix_pronunciation"),
        find(&audio, "preset_transcribe_retranslate"),
        find(&audio, "preset_quicker_foreigner_reply"),
        find(&audio, "preset_quick_ai_question"),
        find(&audio, "preset_voice_search"),
        find(&audio, "preset_quick_record"),
        find(&masters, "preset_audio_mic_master"),
        // Device audio section
        find(&audio, "preset_study_language"),
        find(&audio, "preset_record_device"),
        find(&audio, "preset_transcribe_english_offline"),
        find(&masters, "preset_audio_device_master"),
        find(&audio, "preset_realtime_audio_translate"),
    ]
}
</file>

<file path="src/config/types/enums.rs">
//! Core enums and constants for configuration.

use serde::{Deserialize, Serialize};

// ============================================================================
// CONSTANTS
// ============================================================================

pub const DEFAULT_HISTORY_LIMIT: usize = 50;
pub const DEFAULT_PROJECTS_LIMIT: usize = 50;

// ============================================================================
// THEME MODE
// ============================================================================

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Default)]
pub enum ThemeMode {
    #[default]
    System,
    Dark,
    Light,
}

// ============================================================================
// BLOCK TYPE - Used by ProcessingBlock for type checking
// ============================================================================

#[derive(Serialize, Deserialize, Clone, Debug, PartialEq, Default)]
#[serde(rename_all = "snake_case")]
pub enum BlockType {
    InputAdapter, // Pass-through node for input
    Image,
    #[default]
    Text,
    Audio,
}

impl BlockType {
    pub fn from_str(s: &str) -> Self {
        match s {
            "input_adapter" => BlockType::InputAdapter,
            "image" => BlockType::Image,
            "audio" => BlockType::Audio,
            _ => BlockType::Text,
        }
    }
}

// ============================================================================
// UTILITY FUNCTIONS
// ============================================================================

/// Get system UI language (vi, ko, or en)
pub fn get_system_ui_language() -> String {
    let sys_locale = sys_locale::get_locale().unwrap_or_default();
    let lang_code = sys_locale.split('-').next().unwrap_or("en").to_lowercase();

    match lang_code.as_str() {
        "vi" => "vi".to_string(),
        "ko" => "ko".to_string(),
        "ja" => "ja".to_string(),
        "zh" => "zh".to_string(),
        _ => "en".to_string(),
    }
}
</file>

<file path="src/config/types/mod.rs">
//! Configuration types module.
//!
//! This module organizes all configuration-related types into logical groups:
//! - `enums`: Core enums (ThemeMode, BlockType)
//! - `hotkey`: Hotkey binding type
//! - `tts`: TTS-related types (TtsMethod, EdgeTtsSettings, etc.)

mod enums;
mod hotkey;
mod tts;

// Re-export all types for easy access
pub use enums::{
    get_system_ui_language, BlockType, ThemeMode, DEFAULT_HISTORY_LIMIT, DEFAULT_PROJECTS_LIMIT,
};

pub use hotkey::Hotkey;

pub use tts::{
    default_tts_language_conditions, EdgeTtsSettings, EdgeTtsVoiceConfig, TtsLanguageCondition,
    TtsMethod,
};
</file>

<file path="src/debug_log.rs">
use chrono::Local;
use std::fs::OpenOptions;
use std::io::Write;
use std::path::PathBuf;

lazy_static::lazy_static! {
    static ref LOG_MUTEX: std::sync::Mutex<()> = std::sync::Mutex::new(());
}

pub fn log_debug(msg: &str) {
    let _lock = LOG_MUTEX.lock().unwrap();
    let mut path = dirs::data_local_dir().unwrap_or_else(|| PathBuf::from("."));
    path.push("SGT");
    path.push("logs");
    let _ = std::fs::create_dir_all(&path);
    path.push("session.log");

    if let Ok(mut file) = OpenOptions::new().create(true).append(true).open(path) {
        let timestamp = Local::now().format("%Y-%m-%d %H:%M:%S%.3f");
        let _ = writeln!(file, "[{}] {}", timestamp, msg);
    }
}

#[macro_export]
macro_rules! log_info {
    ($($arg:tt)*) => {
        {
            let msg = format!($($arg)*);
            println!("{}", msg);
            $crate::debug_log::log_debug(&msg);
        }
    };
}
</file>

<file path="src/gui/app/input_handler.rs">
// Input Handler - Drag-and-Drop and Paste handling for the main app UI
//
// When files/images are dropped or pasted (Ctrl+V), this module:
// 1. Detects the content type (image, text, or audio)
// 2. Shows the appropriate preset wheel
// 3. Triggers the processing pipeline with the selected preset

use crate::APP;
use crate::overlay::preset_wheel::show_preset_wheel;
use crate::overlay::process::pipeline::{
    start_processing_pipeline, start_processing_pipeline_parallel, start_text_processing,
};
use crate::overlay::utils::get_clipboard_image_bytes;
use eframe::egui;
use image::{ImageBuffer, Rgba};
use std::io::Cursor;
use std::path::Path;
use std::sync::mpsc;
use windows::Win32::Foundation::{POINT, RECT};
use windows::Win32::UI::WindowsAndMessaging::GetCursorPos;

/// Image file extensions we support
const IMAGE_EXTENSIONS: &[&str] = &[
    "png", "jpg", "jpeg", "gif", "bmp", "webp", "ico", "tiff", "tif",
];

/// Audio file extensions we support (decoded via symphonia)
const AUDIO_EXTENSIONS: &[&str] = &[
    "wav", "mp3", "flac", "ogg", "m4a", "aac", "alac", "aiff", "aif", "wma", "opus",
];

/// Check if a file extension is an image type
fn is_image_extension(ext: &str) -> bool {
    IMAGE_EXTENSIONS.contains(&ext.to_lowercase().as_str())
}

/// Check if a file extension is an audio type
fn is_audio_extension(ext: &str) -> bool {
    AUDIO_EXTENSIONS.contains(&ext.to_lowercase().as_str())
}

/// Load a text file content
fn load_text_file(path: &Path) -> Option<String> {
    std::fs::read_to_string(path).ok()
}

/// Load an audio file and convert to WAV format using symphonia
/// Supports: WAV, MP3, FLAC, OGG, AAC, ALAC, AIFF, etc.
fn load_audio_file(path: &Path) -> Option<Vec<u8>> {
    use symphonia::core::audio::SampleBuffer;
    use symphonia::core::codecs::DecoderOptions;
    use symphonia::core::formats::FormatOptions;
    use symphonia::core::io::MediaSourceStream;
    use symphonia::core::meta::MetadataOptions;
    use symphonia::core::probe::Hint;

    // Open the file
    let file = std::fs::File::open(path).ok()?;
    let mss = MediaSourceStream::new(Box::new(file), Default::default());

    // Create a hint using the file extension
    let mut hint = Hint::new();
    if let Some(ext) = path.extension().and_then(|e| e.to_str()) {
        hint.with_extension(ext);
    }

    // Probe the media source
    let probed = symphonia::default::get_probe()
        .format(
            &hint,
            mss,
            &FormatOptions::default(),
            &MetadataOptions::default(),
        )
        .ok()?;

    let mut format = probed.format;

    // Find the first audio track
    let track = format
        .tracks()
        .iter()
        .find(|t| t.codec_params.codec != symphonia::core::codecs::CODEC_TYPE_NULL)?;
    let track_id = track.id;
    let codec_params = track.codec_params.clone();

    // Get sample rate and channels
    let sample_rate = codec_params.sample_rate.unwrap_or(44100);
    let channels = codec_params.channels.map(|c| c.count()).unwrap_or(2) as u16;

    // Create decoder
    let mut decoder = symphonia::default::get_codecs()
        .make(&codec_params, &DecoderOptions::default())
        .ok()?;

    // Decode all samples
    let mut all_samples: Vec<i16> = Vec::new();

    loop {
        let packet = match format.next_packet() {
            Ok(p) => p,
            Err(symphonia::core::errors::Error::IoError(ref e))
                if e.kind() == std::io::ErrorKind::UnexpectedEof =>
            {
                break;
            }
            Err(_) => break,
        };

        if packet.track_id() != track_id {
            continue;
        }

        let decoded = match decoder.decode(&packet) {
            Ok(d) => d,
            Err(_) => continue,
        };

        // Convert to interleaved i16 samples
        let spec = *decoded.spec();
        let duration = decoded.capacity() as u64;
        let mut sample_buf = SampleBuffer::<i16>::new(duration, spec);
        sample_buf.copy_interleaved_ref(decoded);
        all_samples.extend(sample_buf.samples());
    }

    if all_samples.is_empty() {
        return None;
    }

    // Write to WAV format in memory
    let spec = hound::WavSpec {
        channels,
        sample_rate,
        bits_per_sample: 16,
        sample_format: hound::SampleFormat::Int,
    };

    let mut wav_cursor = Cursor::new(Vec::new());
    {
        let mut writer = hound::WavWriter::new(&mut wav_cursor, spec).ok()?;
        for sample in &all_samples {
            writer.write_sample(*sample).ok()?;
        }
        writer.finalize().ok()?;
    }

    Some(wav_cursor.into_inner())
}

/// Get cursor position for wheel placement
fn get_cursor_pos() -> POINT {
    let mut pos = POINT::default();
    unsafe {
        let _ = GetCursorPos(&mut pos);
    }
    pos
}

/// Get screen rect centered around cursor for result window placement
fn get_screen_rect_at_cursor() -> RECT {
    let pos = get_cursor_pos();
    RECT {
        left: pos.x - 200,
        top: pos.y - 100,
        right: pos.x + 200,
        bottom: pos.y + 100,
    }
}

/// Process dropped/pasted image content
fn process_image_content(img: ImageBuffer<Rgba<u8>, Vec<u8>>) {
    let cursor_pos = get_cursor_pos();

    // Show image preset wheel (no filter_mode = all image presets)
    let selected = show_preset_wheel("image", None, cursor_pos);

    if let Some(preset_idx) = selected {
        let (config, preset) = {
            let mut app = APP.lock().unwrap();
            // Update active preset for auto-paste to work correctly
            app.config.active_preset_idx = preset_idx;
            (app.config.clone(), app.config.presets[preset_idx].clone())
        };

        let rect = get_screen_rect_at_cursor();

        // Spawn processing in background thread
        std::thread::spawn(move || {
            start_processing_pipeline(img, rect, config, preset);
        });
    }
}

/// Process dropped/pasted text content
fn process_text_content(text: String) {
    let cursor_pos = get_cursor_pos();

    // Show text preset wheel without mode filter (shows both select and type presets)
    let selected = show_preset_wheel("text", None, cursor_pos);

    if let Some(preset_idx) = selected {
        let (config, preset) = {
            let mut app = APP.lock().unwrap();
            // Update active preset for auto-paste to work correctly
            app.config.active_preset_idx = preset_idx;
            (app.config.clone(), app.config.presets[preset_idx].clone())
        };

        let rect = get_screen_rect_at_cursor();
        let ui_lang = config.ui_language.clone();
        let localized_name =
            crate::gui::settings_ui::get_localized_preset_name(&preset.id, &ui_lang);
        let cancel_hotkey = preset
            .hotkeys
            .first()
            .map(|h| h.name.clone())
            .unwrap_or_default();

        // Spawn processing in background thread
        std::thread::spawn(move || {
            start_text_processing(text, rect, config, preset, localized_name, cancel_hotkey);
        });
    }
}

/// Process image content in parallel (show wheel immediately, wait for load)
fn process_image_parallel(rx: mpsc::Receiver<Option<(ImageBuffer<Rgba<u8>, Vec<u8>>, Vec<u8>)>>) {
    let cursor_pos = get_cursor_pos();
    let selected = show_preset_wheel("image", None, cursor_pos);

    if let Some(preset_idx) = selected {
        crate::log_info!("Image preset selected: {}", preset_idx);
        let (config, preset) = {
            let mut app = APP.lock().unwrap();
            app.config.active_preset_idx = preset_idx;
            (app.config.clone(), app.config.presets[preset_idx].clone())
        };
        let rect = get_screen_rect_at_cursor();

        // Use parallel pipeline to show window immediately while waiting for data
        start_processing_pipeline_parallel(rx, rect, config, preset);
    }
}

/// Process text content in parallel
fn process_text_parallel(rx: mpsc::Receiver<Option<String>>) {
    let cursor_pos = get_cursor_pos();
    let selected = show_preset_wheel("text", None, cursor_pos);

    if let Some(preset_idx) = selected {
        crate::log_info!("Text preset selected: {}", preset_idx);
        let (config, preset) = {
            let mut app = APP.lock().unwrap();
            app.config.active_preset_idx = preset_idx;
            (app.config.clone(), app.config.presets[preset_idx].clone())
        };

        let rect = get_screen_rect_at_cursor();
        let ui_lang = config.ui_language.clone();
        let localized_name =
            crate::gui::settings_ui::get_localized_preset_name(&preset.id, &ui_lang);
        let cancel_hotkey = preset
            .hotkeys
            .first()
            .map(|h| h.name.clone())
            .unwrap_or_default();

        std::thread::spawn(move || {
            if let Ok(Some(text)) = rx.recv() {
                start_text_processing(text, rect, config, preset, localized_name, cancel_hotkey);
            }
        });
    }
}

/// Process audio content in parallel
fn process_audio_parallel(rx: mpsc::Receiver<Option<Vec<u8>>>) {
    let cursor_pos = get_cursor_pos();
    let selected = show_preset_wheel("audio", None, cursor_pos);

    if let Some(preset_idx) = selected {
        let preset = {
            let mut app = APP.lock().unwrap();
            app.config.active_preset_idx = preset_idx;
            app.config.presets[preset_idx].clone()
        };

        std::thread::spawn(move || {
            if let Ok(Some(wav_data)) = rx.recv() {
                crate::api::audio::process_audio_file_request(preset, wav_data);
            }
        });
    }
}

/// Process a single file path (public for context menu usage)
pub fn process_file_path(path: &Path) {
    crate::log_info!("Processing file path: {:?}", path);
    let path_clone = path.to_path_buf();

    // Determine type by extension for immediate feedback
    let ext = path.extension().and_then(|e| e.to_str()).unwrap_or("");
    crate::log_info!("Detected extension: '{}'", ext);

    if is_image_extension(ext) {
        crate::log_info!("Type detected: IMAGE");
        let (tx, rx) = mpsc::channel();
        std::thread::spawn(move || {
            // Read file bytes directly (preserves original format e.g. JPEG)
            if let Ok(bytes) = std::fs::read(&path_clone) {
                if let Ok(img) = image::load_from_memory(&bytes) {
                    let _ = tx.send(Some((img.to_rgba8(), bytes)));
                    return;
                }
            }
            let _ = tx.send(None);
        });
        process_image_parallel(rx);
    } else if is_audio_extension(ext) {
        crate::log_info!("Type detected: AUDIO");
        let (tx, rx) = mpsc::channel();
        std::thread::spawn(move || {
            let _ = tx.send(load_audio_file(&path_clone));
        });
        process_audio_parallel(rx);
    } else {
        crate::log_info!("Type detected: TEXT (Default)");
        // Default to Text (covers text files and unknown extensions)
        let (tx, rx) = mpsc::channel();
        std::thread::spawn(move || {
            let _ = tx.send(load_text_file(&path_clone));
        });
        process_text_parallel(rx);
    }
}

/// Handle dropped files from egui
pub fn handle_dropped_files(ctx: &egui::Context) -> bool {
    let dropped_files = ctx.input(|i| i.raw.dropped_files.clone());

    if dropped_files.is_empty() {
        return false;
    }

    // Process the first dropped file
    if let Some(file) = dropped_files.first() {
        if let Some(path) = &file.path {
            crate::log_info!("Handling dropped file: {:?}", path);
            process_file_path(path);
            return true;
        }
        // If path is not available, use existing byte handling (already threaded but serial load->process)
        else if let Some(bytes) = &file.bytes {
            let bytes_clone = bytes.clone();
            std::thread::spawn(move || {
                // Try to interpret as image first
                if let Ok(img) = image::load_from_memory(&bytes_clone) {
                    let rgba = img.to_rgba8();
                    // For direct bytes drop, we also pass the bytes as "original"
                    process_image_content(rgba); // Fallback to serial for bytes-drop or update process_image_content?
                // NOTE: process_image_content expects just ImageBuffer.
                // To support zero-copy for bytes-drop too, we would need to update process_image_content.
                // But user specifically asked for "dragging job" (files).
                // Leaving bytes-drop as-is for now (it uses process_image_content, not parallel pipeline yet? No wait, process_image_content spawns thread).
                }
                // Try as text
                else if let Ok(text) = String::from_utf8(bytes_clone.to_vec()) {
                    process_text_content(text);
                }
            });
            return true;
        }
    }

    false
}

/// Check if files are currently being dragged over the window (not yet dropped)
pub fn is_files_hovered(ctx: &egui::Context) -> bool {
    ctx.input(|i| !i.raw.hovered_files.is_empty())
}

/// Get text from Windows clipboard
fn get_clipboard_text() -> Option<String> {
    use windows::Win32::Foundation::HGLOBAL;
    use windows::Win32::System::DataExchange::{CloseClipboard, GetClipboardData, OpenClipboard};
    use windows::Win32::System::Memory::{GlobalLock, GlobalUnlock};

    unsafe {
        // Try to open clipboard
        for _attempt in 0..5 {
            if OpenClipboard(None).is_ok() {
                // CF_UNICODETEXT = 13
                if let Ok(h_data) = GetClipboardData(13) {
                    let ptr = GlobalLock(HGLOBAL(h_data.0));
                    if !ptr.is_null() {
                        // Read as wide string
                        let wide_ptr = ptr as *const u16;
                        let mut len = 0;
                        while *wide_ptr.add(len) != 0 {
                            len += 1;
                        }
                        let slice = std::slice::from_raw_parts(wide_ptr, len);
                        let text = String::from_utf16_lossy(slice);

                        let _ = GlobalUnlock(HGLOBAL(h_data.0));
                        let _ = CloseClipboard();

                        if !text.is_empty() {
                            return Some(text);
                        }
                        return None;
                    }
                }
                let _ = CloseClipboard();
                return None;
            }
            std::thread::sleep(std::time::Duration::from_millis(10));
        }
        None
    }
}

/// Handle Ctrl+V paste - uses Windows API for keyboard detection
pub fn handle_paste(ctx: &egui::Context) -> bool {
    use std::sync::atomic::{AtomicBool, Ordering};
    use windows::Win32::UI::Input::KeyboardAndMouse::{GetAsyncKeyState, VK_CONTROL, VK_V};

    // Skip paste handling if help assistant modal is open
    // This allows normal Ctrl+V paste into the text input field
    if crate::gui::settings_ui::help_assistant::is_modal_open() {
        return false;
    }

    // Only process if our window has focus
    let has_focus = ctx.input(|i| i.focused);
    if !has_focus {
        return false;
    }

    // skip paste handling if any of the api key fields are focused
    // this prevents the wheel from appearing when the user paste their api key
    let focused_id = ctx.memory(|mem| mem.focused());
    if let Some(id) = focused_id {
        let api_key_ids = [
            egui::Id::new("settings_api_key_groq"),
            egui::Id::new("settings_api_key_cerebras"),
            egui::Id::new("settings_api_key_gemini"),
            egui::Id::new("settings_api_key_openrouter"),
            egui::Id::new("settings_api_key_ollama_url"),
        ];
        if api_key_ids.contains(&id) {
            return false;
        }
    }

    // Debounce: prevent multiple triggers per key press
    static LAST_V_STATE: AtomicBool = AtomicBool::new(false);

    // Check keyboard state using Windows API
    let ctrl_down = unsafe { (GetAsyncKeyState(VK_CONTROL.0 as i32) as u16 & 0x8000) != 0 };
    let v_down = unsafe { (GetAsyncKeyState(VK_V.0 as i32) as u16 & 0x8000) != 0 };
    let v_was_down = LAST_V_STATE.swap(v_down, Ordering::SeqCst);

    // Trigger on V key press (not release)
    let ctrl_v_just_pressed = ctrl_down && v_down && !v_was_down;

    // Also check egui events as fallback
    let paste_event = ctx.input(|i| {
        i.raw
            .events
            .iter()
            .any(|e| matches!(e, egui::Event::Paste(_)))
    });

    if !ctrl_v_just_pressed && !paste_event {
        return false;
    }

    // First try to get image from clipboard (images take priority)
    if let Some(img_bytes) = get_clipboard_image_bytes() {
        if let Ok(img) = image::load_from_memory(&img_bytes) {
            let rgba = img.to_rgba8();
            std::thread::spawn(move || {
                process_image_content(rgba);
            });
            return true;
        }
    }

    // Try to get text from clipboard via Windows API
    if let Some(text) = get_clipboard_text() {
        if !text.is_empty() {
            std::thread::spawn(move || {
                process_text_content(text);
            });
            return true;
        }
    }

    false
}
</file>

<file path="src/gui/mod.rs">
pub mod app;
pub mod icons;
mod key_mapping;
pub mod locale;
pub mod settings_ui;
pub mod splash;
pub mod utils;

pub use app::SettingsApp;
pub use app::signal_restore_window;
pub use utils::configure_fonts;

lazy_static::lazy_static! {
    pub static ref GUI_CONTEXT: std::sync::Mutex<Option<eframe::egui::Context>> = std::sync::Mutex::new(None);
}
</file>

<file path="src/gui/settings_ui/help_assistant.rs">
//! Help Assistant - Ask questions about SGT and get AI-powered answers
//! Uses the TextInput overlay for input and markdown_view for displaying responses

use crate::api::client::UREQ_AGENT;
use std::sync::atomic::{AtomicBool, Ordering};

/// Static flag to track if help input is active
static HELP_INPUT_ACTIVE: AtomicBool = AtomicBool::new(false);

/// Check if the help assistant input is currently active
pub fn is_modal_open() -> bool {
    HELP_INPUT_ACTIVE.load(Ordering::SeqCst)
}

/// Fetch the repomix XML from GitHub
fn fetch_repomix_xml() -> Result<String, String> {
    let url =
        "https://raw.githubusercontent.com/nganlinh4/screen-goated-toolbox/main/repomix-output.xml";

    match UREQ_AGENT.get(url).call() {
        Ok(response) => response
            .into_body()
            .read_to_string()
            .map_err(|e| format!("Failed to read response: {}", e)),
        Err(e) => Err(format!("Failed to fetch XML: {}", e)),
    }
}

/// Ask Gemini a question about SGT
fn ask_gemini(gemini_api_key: &str, question: &str, context_xml: &str) -> Result<String, String> {
    if gemini_api_key.trim().is_empty() {
        return Err("Gemini API key not configured. Please set it in Global Settings.".to_string());
    }

    let url = format!(
        "https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent?key={}",
        gemini_api_key
    );

    let system_prompt = r#"
Answer the user in a helpful, concise and easy to understand way in the question's language, no made up infomation, only the true infomation. Go straight to the point, dont mention thing like "Based on the source code", if answer needs to mention the UI, be sure to use correct i18n locale terms matching the question's language. Format your response in Markdown."#;

    let user_message = format!(
        "{}\n\n---\nSource Code Context:\n{}\n---\n\nUser Question: {}",
        system_prompt, context_xml, question
    );

    let body = serde_json::json!({
        "contents": [{
            "parts": [{
                "text": user_message
            }]
        }],
        "generationConfig": {
            "maxOutputTokens": 2048,
            "temperature": 0.7
        }
    });

    let response = UREQ_AGENT
        .post(&url)
        .header("Content-Type", "application/json")
        .send(&body.to_string())
        .map_err(|e| format!("API request failed: {}", e))?;

    let json: serde_json::Value = response
        .into_body()
        .read_json()
        .map_err(|e| format!("Failed to parse response: {}", e))?;

    // Extract text from response
    json["candidates"][0]["content"]["parts"][0]["text"]
        .as_str()
        .map(|s| s.to_string())
        .ok_or_else(|| "Failed to extract response text".to_string())
}

/// Show the help assistant input using TextInput overlay
/// When user submits, query Gemini and show result in markdown_view
pub fn show_help_input() {
    HELP_INPUT_ACTIVE.store(true, Ordering::SeqCst);

    // Get config and API key
    let (gemini_api_key, ui_language) = {
        let app = crate::APP.lock().unwrap();
        (
            app.config.gemini_api_key.clone(),
            app.config.ui_language.clone(),
        )
    };

    // Get localized placeholder text
    let placeholder = match ui_language.as_str() {
        "vi" => "Hỏi gì về SGT? (VD: Làm sao để dịch vùng màn hình?)",
        "ko" => "SGT에 대해 무엇을 물어볼까요?",
        _ => "Ask anything about SGT (e.g., How do I translate a screen region?)",
    };

    // Show the text input overlay
    crate::overlay::text_input::show(
        placeholder.to_string(),
        ui_language.clone(),
        String::new(), // No cancel hotkey
        false,         // Not continuous mode
        move |question, _hwnd| {
            // User submitted a question
            let question = question.trim().to_string();
            if question.is_empty() {
                HELP_INPUT_ACTIVE.store(false, Ordering::SeqCst);
                return;
            }

            let gemini_key = gemini_api_key.clone();
            let lang = ui_language.clone();

            // Process in a dedicated thread (runs message loop for results)
            std::thread::spawn(move || {
                // Show loading state
                let loading_msg = match lang.as_str() {
                    "vi" => "⏳ Đang gọi cho tác giả nganlinh4 ... Kkk đùa thôi, đợi tí nha",
                    "ko" => "⏳ 작가 nganlinh4에게 전화 중... ㅋㅋ 농담이고, 잠깐만 기다려",
                    _ => "⏳ Calling author nganlinh4 ... Kkk joke, wait a bit",
                };

                // Initialize COM for WebView2
                unsafe {
                    use windows::Win32::System::Com::{CoInitializeEx, COINIT_APARTMENTTHREADED};
                    let _ = CoInitializeEx(None, COINIT_APARTMENTTHREADED);
                }

                // Get screen center for result display
                use windows::Win32::UI::WindowsAndMessaging::{
                    DispatchMessageW, GetMessageW, GetSystemMetrics, SetForegroundWindow,
                    ShowWindow, TranslateMessage, MSG, SM_CXSCREEN, SM_CYSCREEN, SW_SHOW,
                };

                let (screen_w, screen_h) =
                    unsafe { (GetSystemMetrics(SM_CXSCREEN), GetSystemMetrics(SM_CYSCREEN)) };

                let center_rect = windows::Win32::Foundation::RECT {
                    left: screen_w / 2 - 300,
                    top: screen_h / 2 - 200,
                    right: screen_w / 2 + 300,
                    bottom: screen_h / 2 + 200,
                };

                // 1. Create the Result Window (Loading State)
                // This must happen on the thread that runs the message loop
                let result_hwnd = crate::overlay::result::create_result_window(
                    center_rect,
                    crate::overlay::result::WindowType::Primary,
                    crate::overlay::result::RefineContext::None,
                    "gemini-2.5-flash".to_string(),
                    "google".to_string(),
                    false,
                    false,
                    "Ask SGT".to_string(),
                    crate::overlay::result::get_chain_color(0),
                    "markdown",
                    loading_msg.to_string(),
                );

                // Show the window (create_result_window creates it hidden by default)
                unsafe {
                    let _ = ShowWindow(result_hwnd, SW_SHOW);
                    let _ = SetForegroundWindow(result_hwnd);
                }

                // 2. Spawn a background worker for the API call (so we don't block the message loop)
                // HWND is not Send, so cast to isize to pass across threads
                let api_hwnd_val = result_hwnd.0 as isize;
                std::thread::spawn(move || {
                    let api_hwnd =
                        windows::Win32::Foundation::HWND(api_hwnd_val as *mut std::ffi::c_void);
                    // Fetch context and ask Gemini
                    let result = match fetch_repomix_xml() {
                        Ok(xml) => ask_gemini(&gemini_key, &question, &xml),
                        Err(e) => Err(format!("Failed to fetch context: {}", e)),
                    };

                    // Format the response
                    let response = match result {
                        Ok(answer) => format!("## ❓ {}\n\n{}", question, answer),
                        Err(e) => format!("## ❌ Error\n\n{}", e),
                    };

                    // Update the window text (thead-safe update via global state + InvalidateRect)
                    crate::overlay::result::update_window_text(api_hwnd, &response);
                });

                // 3. Run the Message Loop for the Result Window
                // This keeps the window alive and handling events (paint, mouse, webview, etc.)
                unsafe {
                    let mut msg = MSG::default();
                    while GetMessageW(&mut msg, None, 0, 0).as_bool() {
                        let _ = TranslateMessage(&msg);
                        DispatchMessageW(&msg);
                    }
                }

                // Loop ends when PostQuitMessage is called (e.g. on window close)
                HELP_INPUT_ACTIVE.store(false, Ordering::SeqCst);
            });
        },
    );
}
</file>

<file path="src/gui/settings_ui/mod.rs">
pub mod download_manager;
mod footer;
mod global;
pub mod help_assistant;
mod history;
pub mod node_graph;
mod preset;
mod sidebar;

pub use footer::render_footer;
pub use global::render_global_settings;
pub use history::render_history_panel;
pub use preset::render_preset_editor;
pub use sidebar::get_localized_preset_name;
pub use sidebar::render_sidebar;

#[derive(PartialEq, Clone, Copy)]
pub enum ViewMode {
    Global,
    History,
    Preset(usize),
}
</file>

<file path="src/gui/settings_ui/node_graph/body.rs">
use super::node::ChainNode;
use super::utils::{insert_next_language_tag, model_supports_search, show_language_vars};
use super::viewer::ChainViewer;
use crate::gui::icons::{icon_button, Icon};
use crate::model_config::{
    get_all_models_with_ollama, get_model_by_id, is_ollama_scan_in_progress, model_is_non_llm,
    trigger_ollama_model_scan, ModelType,
};
use eframe::egui;
use egui_snarl::{NodeId, Snarl};

pub fn show_body(
    viewer: &mut ChainViewer,
    node_id: NodeId,
    ui: &mut egui::Ui,
    snarl: &mut Snarl<ChainNode>,
) {
    #[allow(deprecated)]
    {
        let mut auto_copy_triggered = false;
        let current_node_uuid = snarl
            .get_node(node_id)
            .map(|n| n.id().to_string())
            .unwrap_or_default();

        // Render Node UI
        {
            let node = snarl.get_node_mut(node_id).unwrap();

            ui.vertical(|ui| {
                ui.set_max_width(320.0);

                match node {
                    ChainNode::Input {
                        block_type,
                        auto_copy,
                        auto_speak,
                        show_overlay,
                        render_mode,
                        ..
                    } => {
                        ui.set_min_width(173.0);
                        // Input settings (Simplified) - Label removed to avoid duplication with header
                        // ui.separator() removed for compact look

                        // Determine actual input type
                        let actual_type = if block_type == "input_adapter" {
                            viewer.preset_type.as_str()
                        } else {
                            block_type.as_str()
                        };

                        // Eye button + Display mode row for Input nodes
                        ui.horizontal(|ui| {
                            // Eye icon toggle
                            let icon = if *show_overlay {
                                Icon::EyeOpen
                            } else {
                                Icon::EyeClosed
                            };
                            if icon_button(ui, icon).clicked() {
                                *show_overlay = !*show_overlay;
                                viewer.changed = true;

                                // When turning ON, auto-set render_mode based on input type
                                // Image/Audio: "markdown" (đẹp), Text: "plain" (thường)
                                if *show_overlay {
                                    *render_mode = if actual_type == "text" {
                                        "plain".to_string()
                                    } else {
                                        "markdown".to_string()
                                    };
                                }
                            }

                            if *show_overlay {
                                // Render Mode Dropdown for input display
                                // Text: Normal only (no streaming for input)
                                // Image/Audio: Normal or Markdown (đẹp)
                                let current_mode_label = if render_mode == "markdown"
                                    || render_mode == "markdown_stream"
                                {
                                    // Normalize markdown_stream to markdown for Input nodes (they don't stream)
                                    if render_mode == "markdown_stream" {
                                        *render_mode = "markdown".to_string();
                                    }
                                    match viewer.ui_language.as_str() {
                                        "vi" => "Đẹp",
                                        "ko" => "마크다운",
                                        _ => "Markdown",
                                    }
                                } else {
                                    // Normalize stream to plain for Input nodes
                                    if render_mode == "stream" {
                                        *render_mode = "plain".to_string();
                                    }
                                    match viewer.ui_language.as_str() {
                                        "vi" => "Thường",
                                        "ko" => "일반",
                                        _ => "Normal",
                                    }
                                };

                                let popup_id = ui.make_persistent_id(format!(
                                    "input_render_mode_popup_{:?}",
                                    node_id
                                ));
                                let btn_bg = if ui.visuals().dark_mode {
                                    egui::Color32::from_rgba_unmultiplied(80, 80, 80, 180)
                                } else {
                                    egui::Color32::from_rgba_unmultiplied(220, 220, 220, 200)
                                };
                                let btn = ui.add(
                                    egui::Button::new(current_mode_label)
                                        .fill(btn_bg)
                                        .corner_radius(4.0),
                                );
                                if btn.clicked() {
                                    ui.memory_mut(|mem| mem.toggle_popup(popup_id));
                                }
                                egui::popup_below_widget(
                                    ui,
                                    popup_id,
                                    &btn,
                                    egui::PopupCloseBehavior::CloseOnClickOutside,
                                    |ui| {
                                        ui.set_min_width(60.0);
                                        let (lbl_norm, lbl_md) = match viewer.ui_language.as_str() {
                                            "vi" => ("Thường", "Đẹp"),
                                            "ko" => ("일반", "마크다운"),
                                            _ => ("Normal", "Markdown"),
                                        };

                                        if ui
                                            .selectable_label(render_mode == "plain", lbl_norm)
                                            .clicked()
                                        {
                                            *render_mode = "plain".to_string();
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(render_mode == "markdown", lbl_md)
                                            .clicked()
                                        {
                                            *render_mode = "markdown".to_string();
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                    },
                                );
                            }
                        });

                        // Copy/Speak toggles for Input - Conditional based on Type
                        ui.horizontal(|ui| {
                            // Logic:
                            // Text Input: Show Both
                            // Image Input: Show Copy, Hide Speak
                            // Audio Input: Hide Both

                            let show_copy = actual_type != "audio"; // Hide for audio
                            let show_speak = actual_type == "text"; // Show only for text

                            if show_copy {
                                let is_text_input = actual_type == "text";

                                if is_text_input {
                                    // Enforce Auto-Copy ON for Text Input
                                    // Required for text extraction mechanism
                                    if !*auto_copy {
                                        *auto_copy = true;
                                        viewer.changed = true;
                                    }

                                    // Render as active Copy Icon, but ignore clicks (locked ON)
                                    // We don't disable the UI, so it looks full color/active.
                                    // We just don't react to .clicked() to toggle it off.
                                    let _ = icon_button(ui, Icon::Copy)
                                        .on_hover_text(viewer.text.input_auto_copy_tooltip);
                                } else {
                                    // Copy icon toggle for other inputs (Image, Audio, etc.)
                                    let copy_icon = if *auto_copy {
                                        Icon::Copy
                                    } else {
                                        Icon::CopyDisabled
                                    };
                                    if icon_button(ui, copy_icon)
                                        .on_hover_text(viewer.text.input_auto_copy_tooltip)
                                        .clicked()
                                    {
                                        *auto_copy = !*auto_copy;
                                        viewer.changed = true;
                                        if *auto_copy {
                                            auto_copy_triggered = true;
                                        }
                                    }
                                }
                            }

                            if show_speak {
                                // Speak icon toggle
                                let speak_icon = if *auto_speak {
                                    Icon::Speaker
                                } else {
                                    Icon::SpeakerDisabled
                                };
                                if icon_button(ui, speak_icon)
                                    .on_hover_text(viewer.text.input_auto_speak_tooltip)
                                    .clicked()
                                {
                                    *auto_speak = !*auto_speak;
                                    viewer.changed = true;
                                }
                            }
                        });
                    }
                    ChainNode::Special {
                        model,
                        prompt,
                        language_vars,
                        show_overlay,
                        streaming_enabled,
                        render_mode,
                        auto_copy,
                        auto_speak,
                        ..
                    } => {
                        // Special nodes use different model types based on preset type
                        let target_model_type = match viewer.preset_type.as_str() {
                            "image" => ModelType::Vision,
                            "audio" => ModelType::Audio,
                            _ => ModelType::Text,
                        };

                        // Row 1: Model
                        let model_label = match viewer.ui_language.as_str() {
                            "vi" => "Mô hình:",
                            "ko" => "모델:",
                            _ => "Model:",
                        };
                        ui.horizontal(|ui| {
                            ui.label(model_label);
                            let model_def = get_model_by_id(model);
                            let display_name = model_def
                                .as_ref()
                                .map(|m| match viewer.ui_language.as_str() {
                                    "vi" => m.name_vi.as_str(),
                                    "ko" => m.name_ko.as_str(),
                                    _ => m.name_en.as_str(),
                                })
                                .unwrap_or(model.as_str());

                            // Model selector button with manual popup for tight width

                            let button_response = ui.button(display_name);
                            if button_response.clicked() {
                                egui::Popup::toggle_id(ui.ctx(), button_response.id);
                                // Trigger background scan when popup opens
                                if viewer.use_ollama {
                                    trigger_ollama_model_scan();
                                }
                            }
                            let popup_layer_id = button_response.id;
                            egui::Popup::from_toggle_button_response(&button_response).show(|ui| {
                                ui.style_mut().wrap_mode = Some(egui::TextWrapMode::Extend); // No text wrapping, auto width

                                // Show Ollama loading indicator if scanning
                                if viewer.use_ollama && is_ollama_scan_in_progress() {
                                    let loading_text = match viewer.ui_language.as_str() {
                                        "vi" => "⏳ Đang quét các model local...",
                                        "ko" => "⏳ 로컬 모델 스캔 중...",
                                        _ => "⏳ Scanning local models...",
                                    };
                                    ui.label(egui::RichText::new(loading_text).weak().italics());
                                    ui.separator();
                                }

                                for m in get_all_models_with_ollama() {
                                    if m.enabled
                                        && m.model_type == target_model_type
                                        && viewer.is_provider_enabled(&m.provider)
                                    {
                                        let name = match viewer.ui_language.as_str() {
                                            "vi" => &m.name_vi,
                                            "ko" => &m.name_ko,
                                            _ => &m.name_en,
                                        };
                                        let quota = match viewer.ui_language.as_str() {
                                            "vi" => &m.quota_limit_vi,
                                            "ko" => &m.quota_limit_ko,
                                            _ => &m.quota_limit_en,
                                        };
                                        let provider_icon = match m.provider.as_str() {
                                            "google" | "gemini-live" => "✨ ",
                                            "google-gtx" => "🌍 ",
                                            "groq" => "⚡ ",
                                            "cerebras" => "🔥 ",
                                            "openrouter" => "🌐 ",
                                            "ollama" => "🏠 ",
                                            "qrserver" => "🔳 ",
                                            "parakeet" => "🐦 ",
                                            _ => "⚙️ ",
                                        };
                                        let search_suffix = if model_supports_search(&m.id) {
                                            " 🔍"
                                        } else {
                                            ""
                                        };
                                        let label = format!(
                                            "{}{} - {} - {}{}",
                                            provider_icon, name, m.full_name, quota, search_suffix
                                        );
                                        let is_selected = *model == m.id;

                                        if ui.selectable_label(is_selected, label).clicked() {
                                            *model = m.id.clone();
                                            viewer.changed = true;
                                            egui::Popup::toggle_id(ui.ctx(), popup_layer_id);
                                        }
                                    }
                                }
                            });
                        });

                        // Only show prompt UI for LLM models (not QR scanner, GTX, Whisper, etc.)
                        if !model_is_non_llm(model) {
                            // Row 2: Prompt Label + Add Tag Button
                            ui.horizontal(|ui| {
                                let prompt_label = match viewer.ui_language.as_str() {
                                    "vi" => "Lệnh:",
                                    "ko" => "프롬프트:",
                                    _ => "Prompt:",
                                };
                                ui.label(prompt_label);

                                let btn_label = match viewer.ui_language.as_str() {
                                    "vi" => "+ Ngôn ngữ",
                                    "ko" => "+ 언어",
                                    _ => "+ Language",
                                };
                                let is_dark = ui.visuals().dark_mode;
                                let lang_btn_bg = if is_dark {
                                    egui::Color32::from_rgb(50, 100, 110)
                                } else {
                                    egui::Color32::from_rgb(100, 160, 170)
                                };
                                if ui
                                    .add(
                                        egui::Button::new(
                                            egui::RichText::new(btn_label)
                                                .small()
                                                .color(egui::Color32::WHITE),
                                        )
                                        .fill(lang_btn_bg)
                                        .corner_radius(8.0),
                                    )
                                    .clicked()
                                {
                                    insert_next_language_tag(prompt, language_vars);
                                    viewer.changed = true;
                                }
                            });

                            // Row 3: Prompt TextEdit
                            if ui
                                .add(
                                    egui::TextEdit::multiline(prompt)
                                        .desired_width(152.0)
                                        .desired_rows(2),
                                )
                                .changed()
                            {
                                viewer.changed = true;
                            }

                            // Row 4+: Language Variables
                            show_language_vars(
                                ui,
                                &viewer.ui_language,
                                prompt,
                                language_vars,
                                &mut viewer.changed,
                                &mut viewer.language_search,
                            );
                        }

                        // Bottom Row: Settings
                        ui.horizontal(|ui| {
                            let icon = if *show_overlay {
                                Icon::EyeOpen
                            } else {
                                Icon::EyeClosed
                            };
                            if icon_button(ui, icon).clicked() {
                                *show_overlay = !*show_overlay;
                                viewer.changed = true;
                            }

                            if *show_overlay {
                                // Render Mode Dropdown (Normal, Stream, Markdown, Markdown+Stream) - using button+popup
                                let current_mode_label =
                                    match (render_mode.as_str(), *streaming_enabled) {
                                        ("markdown_stream", _) => match viewer.ui_language.as_str()
                                        {
                                            "vi" => "Đẹp+Str",
                                            "ko" => "마크다운+스트림",
                                            _ => "MD+Stream",
                                        },
                                        ("markdown", _) => match viewer.ui_language.as_str() {
                                            "vi" => "Đẹp",
                                            "ko" => "마크다운",
                                            _ => "Markdown",
                                        },
                                        (_, true) => match viewer.ui_language.as_str() {
                                            "vi" => "Stream",
                                            "ko" => "스트림",
                                            _ => "Stream",
                                        },
                                        (_, false) => match viewer.ui_language.as_str() {
                                            "vi" => "Thường",
                                            "ko" => "일반",
                                            _ => "Normal",
                                        },
                                    };

                                let popup_id = ui
                                    .make_persistent_id(format!("render_mode_popup_{:?}", node_id));
                                let btn_bg = if ui.visuals().dark_mode {
                                    egui::Color32::from_rgba_unmultiplied(80, 80, 80, 180)
                                } else {
                                    egui::Color32::from_rgba_unmultiplied(220, 220, 220, 200)
                                };
                                let btn = ui.add(
                                    egui::Button::new(current_mode_label)
                                        .fill(btn_bg)
                                        .corner_radius(4.0),
                                );
                                if btn.clicked() {
                                    ui.memory_mut(|mem| mem.toggle_popup(popup_id));
                                }
                                egui::popup_below_widget(
                                    ui,
                                    popup_id,
                                    &btn,
                                    egui::PopupCloseBehavior::CloseOnClickOutside,
                                    |ui| {
                                        ui.set_min_width(80.0);
                                        let (lbl_norm, lbl_stm, lbl_md, lbl_md_stm) = match viewer
                                            .ui_language
                                            .as_str()
                                        {
                                            "vi" => ("Thường", "Stream", "Đẹp", "Đẹp+Str"),
                                            "ko" => {
                                                ("일반", "스트림", "마크다운", "마크다운+스트림")
                                            }
                                            _ => ("Normal", "Stream", "Markdown", "MD+Stream"),
                                        };

                                        if ui
                                            .selectable_label(
                                                render_mode == "plain" && !*streaming_enabled,
                                                lbl_norm,
                                            )
                                            .clicked()
                                        {
                                            *render_mode = "plain".to_string();
                                            *streaming_enabled = false;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(
                                                (render_mode == "stream" || render_mode == "plain")
                                                    && *streaming_enabled,
                                                lbl_stm,
                                            )
                                            .clicked()
                                        {
                                            *render_mode = "stream".to_string();
                                            *streaming_enabled = true;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(render_mode == "markdown", lbl_md)
                                            .clicked()
                                        {
                                            *render_mode = "markdown".to_string();
                                            *streaming_enabled = false;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(
                                                render_mode == "markdown_stream",
                                                lbl_md_stm,
                                            )
                                            .clicked()
                                        {
                                            *render_mode = "markdown_stream".to_string();
                                            *streaming_enabled = true;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                    },
                                );
                            }

                            let show_copy = true;
                            let show_speak = true;

                            // Copy icon toggle
                            if show_copy {
                                // Copy icon toggle
                                let copy_icon = if *auto_copy {
                                    Icon::Copy
                                } else {
                                    Icon::CopyDisabled
                                };
                                if icon_button(ui, copy_icon)
                                    .on_hover_text(viewer.text.input_auto_copy_tooltip)
                                    .clicked()
                                {
                                    *auto_copy = !*auto_copy;
                                    viewer.changed = true;
                                    if *auto_copy {
                                        auto_copy_triggered = true;
                                    }
                                }
                            }

                            if show_speak {
                                // Speak icon toggle
                                let speak_icon = if *auto_speak {
                                    Icon::Speaker
                                } else {
                                    Icon::SpeakerDisabled
                                };
                                if icon_button(ui, speak_icon)
                                    .on_hover_text(viewer.text.input_auto_speak_tooltip)
                                    .clicked()
                                {
                                    *auto_speak = !*auto_speak;
                                    viewer.changed = true;
                                }
                            }
                        });
                    }
                    ChainNode::Process {
                        model,
                        prompt,
                        language_vars,
                        show_overlay,
                        streaming_enabled,
                        render_mode,
                        auto_copy,
                        auto_speak,
                        ..
                    } => {
                        // Process nodes always use Text models (text-to-text transformation)
                        let target_model_type = ModelType::Text;

                        // Row 1: Model
                        let model_label = match viewer.ui_language.as_str() {
                            "vi" => "Mô hình:",
                            "ko" => "모델:",
                            _ => "Model:",
                        };
                        ui.horizontal(|ui| {
                            ui.label(model_label);
                            let model_def = get_model_by_id(model);
                            let display_name = model_def
                                .as_ref()
                                .map(|m| match viewer.ui_language.as_str() {
                                    "vi" => m.name_vi.as_str(),
                                    "ko" => m.name_ko.as_str(),
                                    _ => m.name_en.as_str(),
                                })
                                .unwrap_or(model.as_str());

                            let button_response = ui.button(display_name);
                            if button_response.clicked() {
                                egui::Popup::toggle_id(ui.ctx(), button_response.id);
                                if viewer.use_ollama {
                                    trigger_ollama_model_scan();
                                }
                            }
                            let popup_layer_id = button_response.id;
                            egui::Popup::from_toggle_button_response(&button_response).show(|ui| {
                                ui.style_mut().wrap_mode = Some(egui::TextWrapMode::Extend);

                                if viewer.use_ollama && is_ollama_scan_in_progress() {
                                    let loading_text = match viewer.ui_language.as_str() {
                                        "vi" => "⏳ Đang quét các model local...",
                                        "ko" => "⏳ 로컬 모델 스캔 중...",
                                        _ => "⏳ Scanning local models...",
                                    };
                                    ui.label(egui::RichText::new(loading_text).weak().italics());
                                    ui.separator();
                                }

                                for m in get_all_models_with_ollama() {
                                    if m.enabled
                                        && m.model_type == target_model_type
                                        && viewer.is_provider_enabled(&m.provider)
                                    {
                                        let name = match viewer.ui_language.as_str() {
                                            "vi" => &m.name_vi,
                                            "ko" => &m.name_ko,
                                            _ => &m.name_en,
                                        };
                                        let quota = match viewer.ui_language.as_str() {
                                            "vi" => &m.quota_limit_vi,
                                            "ko" => &m.quota_limit_ko,
                                            _ => &m.quota_limit_en,
                                        };
                                        let provider_icon = match m.provider.as_str() {
                                            "google" | "gemini-live" => "✨ ",
                                            "google-gtx" => "🌍 ",
                                            "groq" => "⚡ ",
                                            "cerebras" => "🔥 ",
                                            "openrouter" => "🌐 ",
                                            "ollama" => "🏠 ",
                                            "qrserver" => "🔳 ",
                                            "parakeet" => "🐦 ",
                                            _ => "⚙️ ",
                                        };
                                        let search_suffix = if model_supports_search(&m.id) {
                                            " 🔍"
                                        } else {
                                            ""
                                        };
                                        let label = format!(
                                            "{}{} - {} - {}{}",
                                            provider_icon, name, m.full_name, quota, search_suffix
                                        );
                                        let is_selected = *model == m.id;

                                        if ui.selectable_label(is_selected, label).clicked() {
                                            *model = m.id.clone();
                                            viewer.changed = true;
                                            egui::Popup::toggle_id(ui.ctx(), popup_layer_id);
                                        }
                                    }
                                }
                            });
                        });

                        // Only show prompt UI for LLM models (not GTX, etc.)
                        if !model_is_non_llm(model) {
                            // Row 2: Prompt Label + Add Tag Button
                            ui.horizontal(|ui| {
                                let prompt_label = match viewer.ui_language.as_str() {
                                    "vi" => "Lệnh:",
                                    "ko" => "프롬프트:",
                                    _ => "Prompt:",
                                };
                                ui.label(prompt_label);

                                let btn_label = match viewer.ui_language.as_str() {
                                    "vi" => "+ Ngôn ngữ",
                                    "ko" => "+ 언어",
                                    _ => "+ Language",
                                };
                                let is_dark = ui.visuals().dark_mode;
                                let lang_btn_bg = if is_dark {
                                    egui::Color32::from_rgb(50, 100, 110)
                                } else {
                                    egui::Color32::from_rgb(100, 160, 170)
                                };
                                if ui
                                    .add(
                                        egui::Button::new(
                                            egui::RichText::new(btn_label)
                                                .small()
                                                .color(egui::Color32::WHITE),
                                        )
                                        .fill(lang_btn_bg)
                                        .corner_radius(8.0),
                                    )
                                    .clicked()
                                {
                                    insert_next_language_tag(prompt, language_vars);
                                    viewer.changed = true;
                                }
                            });

                            // Row 3: Prompt TextEdit
                            if ui
                                .add(
                                    egui::TextEdit::multiline(prompt)
                                        .desired_width(152.0)
                                        .desired_rows(2),
                                )
                                .changed()
                            {
                                viewer.changed = true;
                            }

                            // Row 4+: Language Variables
                            show_language_vars(
                                ui,
                                &viewer.ui_language,
                                prompt,
                                language_vars,
                                &mut viewer.changed,
                                &mut viewer.language_search,
                            );
                        }

                        // Bottom Row: Settings
                        ui.horizontal(|ui| {
                            let icon = if *show_overlay {
                                Icon::EyeOpen
                            } else {
                                Icon::EyeClosed
                            };
                            if icon_button(ui, icon).clicked() {
                                *show_overlay = !*show_overlay;
                                viewer.changed = true;
                            }

                            if *show_overlay {
                                // Render Mode Dropdown (Normal, Stream, Markdown, Markdown+Stream) - using button+popup
                                let current_mode_label =
                                    match (render_mode.as_str(), *streaming_enabled) {
                                        ("markdown_stream", _) => match viewer.ui_language.as_str()
                                        {
                                            "vi" => "Đẹp+Str",
                                            "ko" => "마크다운+스트림",
                                            _ => "MD+Stream",
                                        },
                                        ("markdown", _) => match viewer.ui_language.as_str() {
                                            "vi" => "Đẹp",
                                            "ko" => "마크다운",
                                            _ => "Markdown",
                                        },
                                        (_, true) => match viewer.ui_language.as_str() {
                                            "vi" => "Stream",
                                            "ko" => "스트림",
                                            _ => "Stream",
                                        },
                                        (_, false) => match viewer.ui_language.as_str() {
                                            "vi" => "Thường",
                                            "ko" => "일반",
                                            _ => "Normal",
                                        },
                                    };

                                let popup_id = ui
                                    .make_persistent_id(format!("render_mode_popup_{:?}", node_id));
                                let btn_bg = if ui.visuals().dark_mode {
                                    egui::Color32::from_rgba_unmultiplied(80, 80, 80, 180)
                                } else {
                                    egui::Color32::from_rgba_unmultiplied(220, 220, 220, 200)
                                };
                                let btn = ui.add(
                                    egui::Button::new(current_mode_label)
                                        .fill(btn_bg)
                                        .corner_radius(4.0),
                                );
                                if btn.clicked() {
                                    ui.memory_mut(|mem| mem.toggle_popup(popup_id));
                                }
                                egui::popup_below_widget(
                                    ui,
                                    popup_id,
                                    &btn,
                                    egui::PopupCloseBehavior::CloseOnClickOutside,
                                    |ui| {
                                        ui.set_min_width(80.0);
                                        let (lbl_norm, lbl_stm, lbl_md, lbl_md_stm) = match viewer
                                            .ui_language
                                            .as_str()
                                        {
                                            "vi" => ("Thường", "Stream", "Đẹp", "Đẹp+Str"),
                                            "ko" => {
                                                ("일반", "스트림", "마크다운", "마크다운+스트림")
                                            }
                                            _ => ("Normal", "Stream", "Markdown", "MD+Stream"),
                                        };

                                        if ui
                                            .selectable_label(
                                                render_mode == "plain" && !*streaming_enabled,
                                                lbl_norm,
                                            )
                                            .clicked()
                                        {
                                            *render_mode = "plain".to_string();
                                            *streaming_enabled = false;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(
                                                (render_mode == "stream" || render_mode == "plain")
                                                    && *streaming_enabled,
                                                lbl_stm,
                                            )
                                            .clicked()
                                        {
                                            *render_mode = "stream".to_string();
                                            *streaming_enabled = true;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(render_mode == "markdown", lbl_md)
                                            .clicked()
                                        {
                                            *render_mode = "markdown".to_string();
                                            *streaming_enabled = false;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                        if ui
                                            .selectable_label(
                                                render_mode == "markdown_stream",
                                                lbl_md_stm,
                                            )
                                            .clicked()
                                        {
                                            *render_mode = "markdown_stream".to_string();
                                            *streaming_enabled = true;
                                            viewer.changed = true;
                                            ui.memory_mut(|mem| mem.close_popup(popup_id));
                                        }
                                    },
                                );
                            }

                            let show_copy = true;
                            let show_speak = true;

                            if show_copy {
                                let copy_icon = if *auto_copy {
                                    Icon::Copy
                                } else {
                                    Icon::CopyDisabled
                                };
                                if icon_button(ui, copy_icon)
                                    .on_hover_text(viewer.text.input_auto_copy_tooltip)
                                    .clicked()
                                {
                                    *auto_copy = !*auto_copy;
                                    viewer.changed = true;
                                    if *auto_copy {
                                        auto_copy_triggered = true;
                                    }
                                }
                            }

                            if show_speak {
                                let speak_icon = if *auto_speak {
                                    Icon::Speaker
                                } else {
                                    Icon::SpeakerDisabled
                                };
                                if icon_button(ui, speak_icon)
                                    .on_hover_text(viewer.text.input_auto_speak_tooltip)
                                    .clicked()
                                {
                                    *auto_speak = !*auto_speak;
                                    viewer.changed = true;
                                }
                            }
                        });
                    }
                }
            });
        }

        // Enforce auto-copy exclusivity
        if auto_copy_triggered {
            for node in snarl.nodes_mut() {
                if node.id() != current_node_uuid {
                    node.set_auto_copy(false);
                }
            }
        }
    }
}
</file>

<file path="src/gui/settings_ui/node_graph/node.rs">
use crate::config::ProcessingBlock;
use std::collections::HashMap;

/// Node type for the processing chain
#[derive(Clone, serde::Serialize, serde::Deserialize)]
pub enum ChainNode {
    /// Input node (audio/image/text source)
    Input {
        id: String,
        block_type: String, // "audio", "image", "text", "input_adapter"
        auto_copy: bool,
        auto_speak: bool,
        show_overlay: bool,
        render_mode: String,
    },
    /// Special Processing Node (First level processor, Presets)
    Special {
        id: String,
        block_type: String,
        model: String,
        prompt: String,
        language_vars: HashMap<String, String>,
        show_overlay: bool,
        streaming_enabled: bool,
        render_mode: String,
        auto_copy: bool,
        auto_speak: bool,
    },
    /// Processing node (transforms text)
    Process {
        id: String,
        block_type: String,
        model: String,
        prompt: String,
        language_vars: HashMap<String, String>,
        show_overlay: bool,
        streaming_enabled: bool,
        render_mode: String,
        auto_copy: bool,
        auto_speak: bool,
    },
}

impl Default for ChainNode {
    fn default() -> Self {
        ChainNode::Process {
            id: format!(
                "{:x}",
                std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap()
                    .as_nanos()
            ),
            block_type: "text".to_string(),
            model: "text_accurate_kimi".to_string(),
            prompt: "Translate to {language1}. Output ONLY the translation.".to_string(),
            language_vars: HashMap::new(),
            show_overlay: true,
            streaming_enabled: true,
            render_mode: "markdown_stream".to_string(),
            auto_copy: false,
            auto_speak: false,
        }
    }
}

impl ChainNode {
    pub fn is_input(&self) -> bool {
        matches!(self, ChainNode::Input { .. })
    }

    pub fn is_special(&self) -> bool {
        matches!(self, ChainNode::Special { .. })
    }

    /// Convert to ProcessingBlock for execution
    pub fn to_block(&self) -> ProcessingBlock {
        match self {
            ChainNode::Input {
                id,
                block_type: _,
                auto_copy,
                auto_speak,
                show_overlay,
                render_mode,
            } => {
                ProcessingBlock {
                    id: id.clone(),
                    block_type: "input_adapter".to_string(), // Always adapter for Input Node
                    model: String::new(),
                    prompt: String::new(),
                    selected_language: String::new(),
                    language_vars: HashMap::new(),
                    show_overlay: *show_overlay,
                    streaming_enabled: false,
                    render_mode: render_mode.clone(),
                    auto_copy: *auto_copy,
                    auto_speak: *auto_speak,
                }
            }
            ChainNode::Special {
                id,
                block_type,
                model,
                prompt,
                language_vars,
                show_overlay,
                streaming_enabled,
                render_mode,
                auto_copy,
                auto_speak,
            }
            | ChainNode::Process {
                id,
                block_type,
                model,
                prompt,
                language_vars,
                show_overlay,
                streaming_enabled,
                render_mode,
                auto_copy,
                auto_speak,
            } => ProcessingBlock {
                id: id.clone(),
                block_type: block_type.clone(),
                model: model.clone(),
                prompt: prompt.clone(),
                selected_language: language_vars.get("language1").cloned().unwrap_or_default(),
                language_vars: language_vars.clone(),
                show_overlay: *show_overlay,
                streaming_enabled: *streaming_enabled,
                render_mode: render_mode.clone(),
                auto_copy: *auto_copy,
                auto_speak: *auto_speak,
            },
        }
    }

    /// Create from ProcessingBlock
    pub fn from_block(block: &ProcessingBlock, role: &str) -> Self {
        // role: "input", "special", "process"

        // Populate language_vars from selected_language if missing (legacy support)
        let mut language_vars = block.language_vars.clone();
        if !language_vars.contains_key("language1") && !block.selected_language.is_empty() {
            language_vars.insert("language1".to_string(), block.selected_language.clone());
        }

        match role {
            "input" => {
                // For input_adapter blocks: respect the saved show_overlay value
                // For other block types used as input (legacy/virtual): default to false
                // Note: Old presets without explicit show_overlay may show overlay unexpectedly
                // (serde defaults to true), but users can easily disable it via the eye button
                let show_overlay = if block.block_type == "input_adapter" {
                    block.show_overlay
                } else {
                    false
                };

                ChainNode::Input {
                    id: block.id.clone(),
                    block_type: block.block_type.clone(),
                    auto_copy: block.auto_copy,
                    auto_speak: block.auto_speak,
                    show_overlay,
                    render_mode: block.render_mode.clone(),
                }
            }
            "special" => ChainNode::Special {
                id: block.id.clone(),
                block_type: block.block_type.clone(),
                model: block.model.clone(),
                prompt: block.prompt.clone(),
                language_vars,
                show_overlay: block.show_overlay,
                streaming_enabled: block.streaming_enabled,
                render_mode: block.render_mode.clone(),
                auto_copy: block.auto_copy,
                auto_speak: block.auto_speak,
            },
            _ => ChainNode::Process {
                id: block.id.clone(),
                block_type: block.block_type.clone(),
                model: block.model.clone(),
                prompt: block.prompt.clone(),
                language_vars,
                show_overlay: block.show_overlay,
                streaming_enabled: block.streaming_enabled,
                render_mode: block.render_mode.clone(),
                auto_copy: block.auto_copy,
                auto_speak: block.auto_speak,
            },
        }
    }

    pub fn id(&self) -> &str {
        match self {
            ChainNode::Input { id, .. }
            | ChainNode::Special { id, .. }
            | ChainNode::Process { id, .. } => id,
        }
    }

    pub fn set_auto_copy(&mut self, val: bool) {
        match self {
            ChainNode::Input { auto_copy, .. } => *auto_copy = val,
            ChainNode::Special { auto_copy, .. } => *auto_copy = val,
            ChainNode::Process { auto_copy, .. } => *auto_copy = val,
        }
    }
}
</file>

<file path="src/gui/settings_ui/preset.rs">
use eframe::egui;
use crate::config::{Config, ProcessingBlock};
use crate::gui::locale::LocaleText;
use super::get_localized_preset_name;
use egui_snarl::Snarl;
use super::node_graph::{ChainNode, render_node_graph, blocks_to_snarl, request_node_graph_view_reset};

pub fn render_preset_editor(
    ui: &mut egui::Ui,
    config: &mut Config,
    preset_idx: usize,
    _search_query: &mut String,
    _cached_monitors: &mut Vec<String>,
    recording_hotkey_for_preset: &mut Option<usize>,
    hotkey_conflict_msg: &Option<String>,
    text: &LocaleText,
    snarl: &mut Snarl<ChainNode>,
) -> bool {
    if preset_idx >= config.presets.len() { return false; }

    let mut preset = config.presets[preset_idx].clone();
    let mut changed = false;

    // Constrain entire preset editor to a consistent width (matching history UI)
    ui.set_max_width(510.0);

    // Check if this is a default preset (ID starts with "preset_")
    let is_default_preset = preset.id.starts_with("preset_");
    
    // Get localized name for default presets
    let display_name = if is_default_preset {
        get_localized_preset_name(&preset.id, &config.ui_language)
    } else {
        preset.name.clone()
    };

    // --- HEADER CARD: Name, Type & Settings ---
    let is_dark = ui.visuals().dark_mode;
    let header_bg = if is_dark {
        egui::Color32::from_rgba_unmultiplied(28, 32, 42, 250)  // Darker for better text contrast
    } else {
        egui::Color32::from_rgba_unmultiplied(255, 255, 255, 255)  // Pure white for light mode
    };
    let header_stroke = if is_dark {
        egui::Stroke::new(1.0, egui::Color32::from_gray(50))
    } else {
        egui::Stroke::new(1.0, egui::Color32::from_gray(210))
    };
    
    ui.add_space(5.0);
    egui::Frame::new()
        .fill(header_bg)
        .stroke(header_stroke)
        .inner_margin(12.0)
        .corner_radius(10.0)
        .show(ui, |ui| {
            // Row 1: Preset Name + Controller + Restore
            ui.horizontal(|ui| {
                ui.label(egui::RichText::new(text.preset_name_label).strong());
                
                if is_default_preset {
                    ui.label(egui::RichText::new(&display_name).strong().size(15.0));
                } else {
                    if ui.add(egui::TextEdit::singleline(&mut preset.name).font(egui::TextStyle::Body)).changed() {
                        changed = true;
                    }
                }
                
                ui.add_space(10.0);
                
                // Controller checkbox with subtle styling
                // Hide for realtime audio presets (they always use the realtime overlay)
                let is_realtime_audio = preset.preset_type == "audio" && preset.audio_processing_mode == "realtime";
                if !is_realtime_audio {
                    if ui.checkbox(&mut preset.show_controller_ui, text.controller_checkbox_label).clicked() {
                        if !preset.show_controller_ui && preset.blocks.is_empty() {
                            preset.blocks.push(create_default_block_for_type(&preset.preset_type));
                            *snarl = blocks_to_snarl(&preset.blocks, &preset.block_connections, &preset.preset_type);
                        }
                        changed = true;
                    }
                }
                
                if is_default_preset {
                    ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                        // Restore button with subtle styling
                        let restore_bg = if is_dark { 
                            egui::Color32::from_rgb(80, 70, 100) 
                        } else { 
                            egui::Color32::from_rgb(180, 170, 200) 
                        };
                        if ui.add(egui::Button::new(egui::RichText::new(text.restore_preset_btn).color(egui::Color32::WHITE).small())
                            .fill(restore_bg)
                            .corner_radius(8.0))
                            .on_hover_text(text.restore_preset_tooltip)
                            .clicked() {
                            let default_config = Config::default();
                            if let Some(default_p) = default_config.presets.iter().find(|p| p.id == preset.id) {
                                preset = default_p.clone();
                                *snarl = blocks_to_snarl(&preset.blocks, &preset.block_connections, &preset.preset_type);
                                request_node_graph_view_reset(ui.ctx());
                                changed = true;
                            }
                        }
                    });
                }
            });

            ui.add_space(6.0);
            
            // Row 2: Type + Mode selectors
            ui.horizontal(|ui| {
                ui.label(text.preset_type_label);
                let selected_text = match preset.preset_type.as_str() {
                    "audio" => text.preset_type_audio,
                    "video" => text.preset_type_video,
                    "text" => text.preset_type_text,
                    _ => text.preset_type_image,
                };
                
                egui::ComboBox::from_id_salt("preset_type_combo")
                    .selected_text(selected_text)
                    .show_ui(ui, |ui| {
                        if ui.selectable_value(&mut preset.preset_type, "image".to_string(), text.preset_type_image).clicked() {
                            if let Some(first) = preset.blocks.first_mut() {
                                first.block_type = "image".to_string();
                                first.model = "maverick".to_string();
                            }
                            changed = true;
                        }
                        if ui.selectable_value(&mut preset.preset_type, "text".to_string(), text.preset_type_text).clicked() {
                            if let Some(first) = preset.blocks.first_mut() {
                                first.block_type = "text".to_string();
                                first.model = "text_accurate_kimi".to_string();
                            }
                            changed = true;
                        }
                        if ui.selectable_value(&mut preset.preset_type, "audio".to_string(), text.preset_type_audio).clicked() {
                            if let Some(first) = preset.blocks.first_mut() {
                                first.block_type = "audio".to_string();
                                first.model = "whisper-accurate".to_string();
                            }
                            changed = true;
                        }
                        ui.add_enabled_ui(false, |ui| {
                            let _ = ui.selectable_value(&mut preset.preset_type, "video".to_string(), text.preset_type_video);
                        });
                    });

                ui.add_space(15.0);

                // Mode selectors based on type
                if preset.preset_type == "image" {
                    if !preset.show_controller_ui {
                        ui.label(text.command_mode_label);
                        egui::ComboBox::from_id_salt("prompt_mode_combo")
                            .selected_text(if preset.prompt_mode == "dynamic" { text.prompt_mode_dynamic } else { text.prompt_mode_fixed })
                            .show_ui(ui, |ui| {
                                if ui.selectable_value(&mut preset.prompt_mode, "fixed".to_string(), text.prompt_mode_fixed).clicked() { changed = true; }
                                if ui.selectable_value(&mut preset.prompt_mode, "dynamic".to_string(), text.prompt_mode_dynamic).clicked() { changed = true; }
                            });
                    }
                } else if preset.preset_type == "text" {
                    ui.label(text.text_input_mode_label);
                    egui::ComboBox::from_id_salt("text_input_mode_combo")
                        .selected_text(if preset.text_input_mode == "type" { text.text_mode_type } else { text.text_mode_select })
                        .show_ui(ui, |ui| {
                            if ui.selectable_value(&mut preset.text_input_mode, "select".to_string(), text.text_mode_select).clicked() { changed = true; }
                            if ui.selectable_value(&mut preset.text_input_mode, "type".to_string(), text.text_mode_type).clicked() { changed = true; }
                        });
                    
                    if preset.text_input_mode == "type" && !preset.show_controller_ui {
                        if ui.checkbox(&mut preset.continuous_input, text.continuous_input_label).clicked() { changed = true; }
                    }
                } else if preset.preset_type == "audio" {
                    if !preset.show_controller_ui {
                        let mode_label = match config.ui_language.as_str() {
                            "vi" => "Phương thức:",
                            "ko" => "작동 방식:",
                            _ => "Mode:",
                        };
                        ui.label(mode_label);
                        
                        let mode_record = match config.ui_language.as_str() {
                            "vi" => "Thu âm rồi xử lý",
                            "ko" => "녹음 후 처리",
                            _ => "Record then Process",
                        };
                        let mode_realtime = match config.ui_language.as_str() {
                            "vi" => "Xử lý thời gian thực",
                            "ko" => "실시간 처리",
                            _ => "Realtime Processing",
                        };
                        
                        let selected_mode_text = if preset.audio_processing_mode == "realtime" {
                            mode_realtime
                        } else {
                            mode_record
                        };
                        
                        egui::ComboBox::from_id_salt("audio_operation_mode_combo")
                            .selected_text(selected_mode_text)
                            .show_ui(ui, |ui| {
                                if ui.selectable_value(&mut preset.audio_processing_mode, "record_then_process".to_string(), mode_record).clicked() { changed = true; }
                                if ui.selectable_value(&mut preset.audio_processing_mode, "realtime".to_string(), mode_realtime).clicked() { changed = true; }
                            });


                    }
                }
            });

            // Row 2.5: Realtime Interface
            if preset.preset_type == "audio" && preset.audio_processing_mode == "realtime" && !preset.show_controller_ui {
                 ui.add_space(8.0);
                 ui.horizontal(|ui| {
                      let window_mode_label = match config.ui_language.as_str() {
                          "vi" => "Giao diện:",
                          "ko" => "인터페이스:",
                          _ => "Interface:",
                      };
                      ui.label(window_mode_label);

                      let mode_standard = match config.ui_language.as_str() {
                          "vi" => "Tiêu chuẩn",
                          "ko" => "표준",
                          _ => "Standard",
                      };
                      let mode_minimal = match config.ui_language.as_str() {
                          "vi" => "Tối giản",
                          "ko" => "최소",
                          _ => "Minimal",
                      };

                      let selected_window_mode = if preset.realtime_window_mode == "minimal" {
                          mode_minimal
                      } else {
                          mode_standard
                      };

                      egui::ComboBox::from_id_salt("realtime_window_mode_combo")
                          .selected_text(selected_window_mode)
                          .show_ui(ui, |ui| {
                              if ui.selectable_value(&mut preset.realtime_window_mode, "standard".to_string(), mode_standard).clicked() { changed = true; }
                              if ui.selectable_value(&mut preset.realtime_window_mode, "minimal".to_string(), mode_minimal).clicked() { changed = true; }
                          });
                 });
            }

            // Row 3: Audio source (if applicable) - Hide if Realtime mode
            if preset.preset_type == "audio" && preset.audio_processing_mode != "realtime" {
                ui.add_space(6.0);
                ui.horizontal(|ui| {
                    ui.label(text.audio_source_label);
                    let selected_text = if preset.audio_source == "mic" { text.audio_src_mic } else { text.audio_src_device };
                    egui::ComboBox::from_id_salt("audio_source_combo")
                        .selected_text(selected_text)
                        .show_ui(ui, |ui| {
                            if ui.selectable_value(&mut preset.audio_source, "mic".to_string(), text.audio_src_mic).clicked() { changed = true; }
                            if ui.selectable_value(&mut preset.audio_source, "device".to_string(), text.audio_src_device).clicked() { changed = true; }
                        });
                    if !preset.show_controller_ui {
                        ui.add_space(10.0);
                        if ui.checkbox(&mut preset.hide_recording_ui, text.hide_recording_ui_label).clicked() { changed = true; }
                        ui.add_space(6.0);
                        if ui.checkbox(&mut preset.auto_stop_recording, text.auto_stop_recording_label).clicked() { changed = true; }
                    }
                });
            }

            // Row 3b: Command mode for text select presets (new row)
            if preset.preset_type == "text" && preset.text_input_mode == "select" && !preset.show_controller_ui {
                ui.add_space(6.0);
                ui.horizontal(|ui| {
                    ui.label(text.command_mode_label);
                    egui::ComboBox::from_id_salt("text_prompt_mode_combo")
                        .selected_text(if preset.prompt_mode == "dynamic" { text.prompt_mode_dynamic } else { text.prompt_mode_fixed })
                        .show_ui(ui, |ui| {
                            if ui.selectable_value(&mut preset.prompt_mode, "fixed".to_string(), text.prompt_mode_fixed).clicked() { changed = true; }
                            if ui.selectable_value(&mut preset.prompt_mode, "dynamic".to_string(), text.prompt_mode_dynamic).clicked() { changed = true; }
                        });
                });
            }
        });

    ui.add_space(8.0);

    // Determine visibility conditions: Auto Paste is visible if any NON-input_adapter block has auto_copy enabled
    let has_any_auto_copy = preset.blocks.iter().any(|b| b.auto_copy && b.block_type != "input_adapter");
    
    // Show auto-paste control whenever any applicable block has auto_copy enabled AND controller UI is off
    if has_any_auto_copy && !preset.show_controller_ui {
        ui.horizontal(|ui| {
            if ui.checkbox(&mut preset.auto_paste, text.auto_paste_label).clicked() { changed = true; }
            
            // Auto Newline: visible when any (non-input-adapter) block has auto_copy
            // Since has_any_auto_copy already excludes input_adapter, we can show it directly
            if ui.checkbox(&mut preset.auto_paste_newline, text.auto_paste_newline_label).clicked() { changed = true; }
        });
    } else if !has_any_auto_copy {
        // No auto_copy means auto_paste must be off
        if preset.auto_paste {
            preset.auto_paste = false;
            changed = true;
        }
    }

    ui.add_space(10.0);

    // Hotkeys - always visible, even when controller UI is enabled
    ui.horizontal(|ui| {
        ui.label(egui::RichText::new(text.hotkeys_section).strong());
        
        let is_dark = ui.visuals().dark_mode;
        
        if *recording_hotkey_for_preset == Some(preset_idx) {
            let text_color = if is_dark { 
                egui::Color32::from_rgb(255, 200, 60)  // Warm orange-yellow for dark mode
            } else { 
                egui::Color32::from_rgb(200, 130, 0)   // Dark orange for light mode
            };
            ui.colored_label(text_color, text.press_keys);
            // Cancel button - subtle red pill
            let cancel_bg = if is_dark { 
                egui::Color32::from_rgb(120, 60, 60) 
            } else { 
                egui::Color32::from_rgb(220, 150, 150) 
            };
            if ui.add(egui::Button::new(egui::RichText::new(text.cancel_label).color(egui::Color32::WHITE))
                .fill(cancel_bg)
                .corner_radius(10.0))
                .clicked() { 
                *recording_hotkey_for_preset = None; 
            }
        } else {
            // Add hotkey button - teal pill
            let add_bg = if is_dark { 
                egui::Color32::from_rgb(50, 110, 120) 
            } else { 
                egui::Color32::from_rgb(100, 170, 180) 
            };
            if ui.add(egui::Button::new(egui::RichText::new(text.add_hotkey_button).color(egui::Color32::WHITE))
                .fill(add_bg)
                .corner_radius(10.0))
                .on_hover_cursor(egui::CursorIcon::PointingHand)
                .clicked() { 
                *recording_hotkey_for_preset = Some(preset_idx); 
            }
        }
        
        // Hotkey badges - purple/violet tint pills
        let hotkey_bg = if is_dark { 
            egui::Color32::from_rgb(90, 70, 130) 
        } else { 
            egui::Color32::from_rgb(170, 150, 200) 
        };
        
        let mut hotkey_to_remove = None;
        for (h_idx, hotkey) in preset.hotkeys.iter().enumerate() {
            if ui.add(egui::Button::new(egui::RichText::new(format!("{} ×", hotkey.name)).color(egui::Color32::WHITE).small())
                .fill(hotkey_bg)
                .corner_radius(10.0))
                .on_hover_cursor(egui::CursorIcon::PointingHand)
                .clicked() { 
                hotkey_to_remove = Some(h_idx); 
            }
        }
        if let Some(h) = hotkey_to_remove { preset.hotkeys.remove(h); changed = true; }
    });
    if let Some(msg) = hotkey_conflict_msg {
        if *recording_hotkey_for_preset == Some(preset_idx) {
            ui.colored_label(egui::Color32::RED, msg);
        }
    }

    // --- PROCESSING CHAIN UI ---
    // Hide nodegraph when controller UI is enabled OR when in Realtime mode (no graph needed)
    if !preset.show_controller_ui && !(preset.preset_type == "audio" && preset.audio_processing_mode == "realtime") {
        // Use a subtle background for the node graph area
        let is_dark = ui.visuals().dark_mode;
        let graph_bg = if is_dark {
            egui::Color32::from_rgba_unmultiplied(35, 40, 50, 200)  // Subtle dark blue-gray
        } else {
            egui::Color32::from_rgba_unmultiplied(240, 242, 248, 255)  // Soft light gray
        };
        
        ui.push_id("node_graph_area", |ui| {
            egui::Frame::new()
                .fill(graph_bg)
                .inner_margin(6.0)
                .corner_radius(8.0)
                .show(ui, |ui| {
                    ui.set_min_height(325.0); // Allocate space for the graph
                    if render_node_graph(ui, snarl, &config.ui_language, &preset.prompt_mode, config.use_groq, config.use_gemini, config.use_openrouter, config.use_ollama, &preset.preset_type, text) {
                        changed = true;
                    }
                });
        });
    } else {
        // Controller UI mode - show elegant, minimal description
        ui.add_space(20.0);
        
        // Use a subtle background that works in both light and dark modes
        let is_dark = ui.visuals().dark_mode;
        let bg_color = if is_dark {
            egui::Color32::from_rgba_unmultiplied(60, 70, 85, 180)  // Subtle dark blue-gray
        } else {
            egui::Color32::from_rgba_unmultiplied(230, 235, 245, 255)  // Soft light gray-blue
        };
        
        let text_color = if is_dark {
            egui::Color32::from_gray(200)
        } else {
            egui::Color32::from_gray(60)
        };
        
        let accent_color = if is_dark {
            egui::Color32::from_rgb(130, 180, 230)  // Soft blue
        } else {
            egui::Color32::from_rgb(70, 120, 180)   // Deeper blue for light mode
        };
        
        egui::Frame::new()
            .fill(bg_color)
            .inner_margin(24.0)
            .corner_radius(12.0)
            .show(ui, |ui| {
                ui.set_min_height(260.0);
                
                // Title - clean, no emoji overload
                let is_realtime = preset.preset_type == "audio" && preset.audio_processing_mode == "realtime";
                
                let title = if is_realtime {
                    match config.ui_language.as_str() {
                        "vi" => "Xử lý âm thanh (Thời gian thực)",
                        "ko" => "오디오 처리 (실시간)",
                        _ => "Audio Processing (Realtime)",
                    }
                } else {
                    match config.ui_language.as_str() {
                        "vi" => "Chế độ Bộ điều khiển",
                        "ko" => "컨트롤러 모드",
                        _ => "Controller Mode",
                    }
                };
                ui.label(egui::RichText::new(title).heading().color(accent_color));
                
                ui.add_space(16.0);
                
                // Main Description - combined into one clear paragraph
                let desc = if is_realtime {
                    match config.ui_language.as_str() {
                        "vi" => "Chế độ này cung cấp phụ đề và dịch thuật trực tiếp theo thời gian thực.\nMã API của Gemini là bắt buộc, tính năng chỉ hoạt động tốt trên âm thanh có lời nói to rõ như podcast!\n\nBạn có thể điều chỉnh cỡ chữ, nguồn âm thanh và ngôn ngữ dịch ngay trong cửa sổ kết quả.",
                        "ko" => "이 모드는 실시간 자막 및 번역을 제공합니다.\nGemini API 키가 필수이며, 명확한 음성이 있는 팟캐스트 같은 오디오에서 잘 작동합니다!\n\n결과 창에서 글꼴 크기, 오디오 소스, 번역 언어를 직접 조정할 수 있습니다.",
                        _ => "This mode provides real-time transcription and translation.\nGemini API key is required, works best on audio with clear speech like podcasts!\n\nYou can adjust font size, audio source, and translation language directly in the result window.",
                    }
                } else {
                    match config.ui_language.as_str() {
                        "vi" => "Đây là cấu hình MASTER. Khi kích hoạt, một bánh xe chọn sẽ xuất hiện để bạn chọn cấu hình muốn sử dụng.\n\nChỉ cần gán một phím tắt để truy cập nhanh nhiều cấu hình khác nhau.",
                        "ko" => "이것은 MASTER 프리셋입니다. 활성화하면 프리셋 휠이 나타나 사용할 프리셋을 선택할 수 있습니다.\n\n하나의 단축키로 여러 프리셋에 빠르게 접근하세요.",
                        _ => "This is a MASTER preset. When activated, a selection wheel will appear letting you choose which preset to use.\n\nAssign a single hotkey for quick access to multiple presets.",
                    }
                };
                ui.label(egui::RichText::new(desc).color(text_color));
            });
    }


    // Apply Logic Updates (Radio Button Sync & Auto Paste)
    if changed {


        config.presets[preset_idx] = preset;
    }

    changed
}

/// Creates a default processing block based on preset type
fn create_default_block_for_type(preset_type: &str) -> ProcessingBlock {
    match preset_type {
        "audio" => ProcessingBlock {
            block_type: "audio".to_string(),
            model: "whisper-accurate".to_string(),
            prompt: "Transcribe this audio.".to_string(),
            selected_language: "Vietnamese".to_string(),
            auto_copy: true,
            ..Default::default()
        },
        "text" => ProcessingBlock {
            block_type: "text".to_string(),
            model: "text_accurate_kimi".to_string(),
            prompt: "Process this text.".to_string(),
            selected_language: "Vietnamese".to_string(),
            auto_copy: true,
            ..Default::default()
        },
        _ => ProcessingBlock {
            block_type: "image".to_string(),
            model: "maverick".to_string(),
            prompt: "Extract text from this image.".to_string(),
            selected_language: "Vietnamese".to_string(),
            show_overlay: true,
            auto_copy: true,
            ..Default::default()
        },
    }
}
</file>

<file path="src/icon_gen.rs">
use eframe::egui;
use lazy_static::lazy_static;
use tray_icon::Icon;

// Wrapper to make Icon thread-safe for lazy_static
struct SafeIcon(Icon);
unsafe impl Send for SafeIcon {}
unsafe impl Sync for SafeIcon {}

lazy_static! {
    static ref TRAY_ICON_DARK: SafeIcon = SafeIcon(load_tray_icon(true));
    static ref TRAY_ICON_LIGHT: SafeIcon = SafeIcon(load_tray_icon(false));
}

fn load_tray_icon(is_system_dark: bool) -> Icon {
    // LOGIC:
    // If System is Dark (Dark Taskbar) -> Use Standard Icon (White)
    // If System is Light (Light Taskbar) -> Use Light Mode Icon (Dark/Colored)

    // FIX: Explicit type annotation &[u8] solves the match error
    let icon_bytes: &[u8] = if is_system_dark {
        include_bytes!("../assets/tray_icon.png")
    } else {
        include_bytes!("../assets/tray_icon-light.png")
    };

    let img = image::load_from_memory(icon_bytes).expect("Failed to load tray icon");
    let img_rgba = img.to_rgba8();
    let (width, height) = img_rgba.dimensions();
    let rgba = img_rgba.into_raw();
    tray_icon::Icon::from_rgba(rgba, width, height).unwrap()
}

// Helper to load raw bytes into Tray Icon format
// is_system_dark: TRUE if Windows is in Dark Mode, FALSE if Light Mode
pub fn get_tray_icon(is_system_dark: bool) -> Icon {
    if is_system_dark {
        TRAY_ICON_DARK.0.clone()
    } else {
        TRAY_ICON_LIGHT.0.clone()
    }
}

// Helper to load raw bytes into Window/Taskbar Icon format
pub fn get_window_icon(is_system_dark: bool) -> egui::IconData {
    let icon_bytes: &[u8] = if is_system_dark {
        include_bytes!("../assets/app-icon-small.png")
    } else {
        include_bytes!("../assets/app-icon-small-light.png")
    };

    let img = image::load_from_memory(icon_bytes).expect("Failed to load app icon");
    let img_rgba = img.to_rgba8();
    let (width, height) = img_rgba.dimensions();

    egui::IconData {
        rgba: img_rgba.into_vec(),
        width,
        height,
    }
}
</file>

<file path="src/overlay/favorite_bubble/render.rs">
use super::state::*;
use std::sync::atomic::Ordering;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::UI::WindowsAndMessaging::{GetWindowRect, UpdateLayeredWindow, ULW_ALPHA};

pub fn update_bubble_visual(hwnd: HWND) {
    // Sync theme state
    let is_dark = crate::overlay::is_dark_mode();
    LAST_THEME_IS_DARK.store(is_dark, Ordering::SeqCst);

    unsafe {
        let hdc_screen = GetDC(None);
        let hdc_mem = CreateCompatibleDC(Some(hdc_screen));

        let bubble_size = BUBBLE_SIZE.load(Ordering::SeqCst);

        // Create 32-bit ARGB bitmap
        let bmi = BITMAPINFO {
            bmiHeader: BITMAPINFOHEADER {
                biSize: std::mem::size_of::<BITMAPINFOHEADER>() as u32,
                biWidth: bubble_size,
                biHeight: -bubble_size, // Top-down
                biPlanes: 1,
                biBitCount: 32,
                biCompression: BI_RGB.0,
                ..Default::default()
            },
            ..Default::default()
        };

        let mut bits: *mut std::ffi::c_void = std::ptr::null_mut();
        let hbm =
            CreateDIBSection(Some(hdc_mem), &bmi, DIB_RGB_COLORS, &mut bits, None, 0).unwrap();
        let old_bm = SelectObject(hdc_mem, hbm.into());

        if !bits.is_null() {
            // Draw directly to pixel buffer with anti-aliasing
            let pixels = std::slice::from_raw_parts_mut(
                bits as *mut u32,
                (bubble_size * bubble_size) as usize,
            );
            let is_hovered = IS_HOVERED.load(Ordering::SeqCst);
            let is_expanded = IS_EXPANDED.load(Ordering::SeqCst);

            draw_bubble_pixels(pixels, bubble_size, is_hovered || is_expanded);
        }

        // Update layered window
        let size = SIZE {
            cx: bubble_size,
            cy: bubble_size,
        };
        let pt_src = POINT { x: 0, y: 0 };
        let blend = BLENDFUNCTION {
            BlendOp: AC_SRC_OVER as u8,
            BlendFlags: 0,
            SourceConstantAlpha: 255,
            AlphaFormat: AC_SRC_ALPHA as u8,
        };

        let mut rect = RECT::default();
        let _ = GetWindowRect(hwnd, &mut rect);
        let pt_dst = POINT {
            x: rect.left,
            y: rect.top,
        };

        let _ = UpdateLayeredWindow(
            hwnd,
            Some(hdc_screen),
            Some(&pt_dst),
            Some(&size),
            Some(hdc_mem),
            Some(&pt_src),
            COLORREF(0),
            Some(&blend),
            ULW_ALPHA,
        );

        let _ = SelectObject(hdc_mem, old_bm);
        let _ = DeleteObject(hbm.into());
        let _ = DeleteDC(hdc_mem);
        let _ = ReleaseDC(None, hdc_screen);
    }
}

fn draw_bubble_pixels(pixels: &mut [u32], size: i32, _is_active: bool) {
    // Use animated opacity for smooth transitions
    let opacity = CURRENT_OPACITY.load(Ordering::SeqCst);

    // Select icon based on theme
    let is_dark = LAST_THEME_IS_DARK.load(Ordering::SeqCst);
    let icon_data = get_icon_data(size, is_dark);

    // Use embedded icon if available
    if !icon_data.is_empty() {
        for y in 0..size {
            for x in 0..size {
                let idx = (y * size + x) as usize;
                let src_idx = idx * 4; // RGBA

                if src_idx + 3 < icon_data.len() {
                    let r = icon_data[src_idx] as u32;
                    let g = icon_data[src_idx + 1] as u32;
                    let b = icon_data[src_idx + 2] as u32;
                    let a = icon_data[src_idx + 3] as u32;

                    // Apply opacity multiplier
                    let final_a = (a * opacity as u32) / 255;

                    // Premultiplied alpha for UpdateLayeredWindow
                    let r_pm = (r * final_a) / 255;
                    let g_pm = (g * final_a) / 255;
                    let b_pm = (b * final_a) / 255;

                    // BGRA format for Windows (but stored as ARGB in u32)
                    pixels[idx] = (final_a << 24) | (r_pm << 16) | (g_pm << 8) | b_pm;
                } else {
                    pixels[idx] = 0;
                }
            }
        }
    } else {
        // Fallback: draw a simple purple circle if icon not available
        let center = size as f32 / 2.0;
        let radius = center - 2.0;

        for y in 0..size {
            for x in 0..size {
                let idx = (y * size + x) as usize;
                let fx = x as f32 + 0.5;
                let fy = y as f32 + 0.5;

                let dx = fx - center;
                let dy = fy - center;
                let dist = (dx * dx + dy * dy).sqrt();

                if dist <= radius {
                    let a = opacity as u32;
                    let r = (130u32 * a) / 255;
                    let g = (80u32 * a) / 255;
                    let b = (200u32 * a) / 255;
                    pixels[idx] = (a << 24) | (r << 16) | (g << 8) | b;
                } else {
                    pixels[idx] = 0;
                }
            }
        }
    }
}
</file>

<file path="src/overlay/favorite_bubble/state.rs">
use std::cell::RefCell;
use std::sync::{
    atomic::{AtomicBool, AtomicI32, AtomicIsize, AtomicU8},
    Once,
};
use wry::{WebContext, WebView};

// Constants
pub static BUBBLE_SIZE: AtomicI32 = AtomicI32::new(40);
pub const PANEL_WIDTH: i32 = 260;
pub const DRAG_THRESHOLD: i32 = 5; // Pixels of movement before counting as a drag

// Smooth opacity animation state
pub const OPACITY_TIMER_ID: usize = 1;
pub const OPACITY_STEP: u8 = 25; // Opacity change per frame (~150ms total animation)
pub const OPACITY_INACTIVE: u8 = 80; // ~31% opacity when not hovered
pub const OPACITY_ACTIVE: u8 = 255; // 100% opacity when hovered/expanded

pub const PHYSICS_TIMER_ID: usize = 2;

// Statics / Atomics
pub static REGISTER_BUBBLE_CLASS: Once = Once::new();
pub static REGISTER_PANEL_CLASS: Once = Once::new();
pub static BUBBLE_ACTIVE: AtomicBool = AtomicBool::new(false);
pub static BUBBLE_HWND: AtomicIsize = AtomicIsize::new(0);
pub static PANEL_HWND: AtomicIsize = AtomicIsize::new(0);
pub static IS_EXPANDED: AtomicBool = AtomicBool::new(false);
pub static IS_HOVERED: AtomicBool = AtomicBool::new(false);
pub static IS_DRAGGING: AtomicBool = AtomicBool::new(false);
pub static IS_DRAGGING_MOVED: AtomicBool = AtomicBool::new(false);
pub static DRAG_START_X: AtomicIsize = AtomicIsize::new(0);
pub static DRAG_START_Y: AtomicIsize = AtomicIsize::new(0);

// Animation state
pub static CURRENT_OPACITY: AtomicU8 = AtomicU8::new(80); // Start at inactive opacity
pub static BLINK_STATE: AtomicU8 = AtomicU8::new(0); // 0=None, 1..4=Blink Phases
pub static FADE_OUT_STATE: AtomicBool = AtomicBool::new(false); // True = fading out before close

// Focus restoration: Track the foreground window before any bubble interaction
// This is critical for text-select presets, which need to send Ctrl+C to the original window
pub static LAST_FOREGROUND_HWND: AtomicIsize = AtomicIsize::new(0);

// Track recursive theme updates
pub static LAST_THEME_IS_DARK: AtomicBool = AtomicBool::new(true);

// Thread Locals
thread_local! {
    pub static PANEL_WEBVIEW: RefCell<Option<WebView>> = RefCell::new(None);
    pub static PHYSICS_STATE: RefCell<(f32, f32)> = RefCell::new((0.0, 0.0));
    // Shared WebContext for this thread using common data directory
    pub static PANEL_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);

    // Icon cache: (size, data)
    static CACHED_ICON: RefCell<(i32, Vec<u8>)> = RefCell::new((0, vec![]));
    static CACHED_ICON_LIGHT: RefCell<(i32, Vec<u8>)> = RefCell::new((0, vec![]));
}

// App icon embedded at compile time
const ICON_PNG_BYTES: &[u8] = include_bytes!("../../../assets/app-icon-small.png");
const ICON_LIGHT_PNG_BYTES: &[u8] = include_bytes!("../../../assets/app-icon-small-light.png");

// Cached decoded RGBA pixels - Removed lazy_static to support dynamic sizing

pub fn get_icon_data(size: i32, is_dark: bool) -> Vec<u8> {
    if is_dark {
        CACHED_ICON.with(|cache| {
            let mut cache = cache.borrow_mut();
            if cache.0 != size {
                *cache = (size, decode_icon(ICON_PNG_BYTES, size));
            }
            cache.1.clone()
        })
    } else {
        CACHED_ICON_LIGHT.with(|cache| {
            let mut cache = cache.borrow_mut();
            if cache.0 != size {
                *cache = (size, decode_icon(ICON_LIGHT_PNG_BYTES, size));
            }
            cache.1.clone()
        })
    }
}

fn decode_icon(bytes: &[u8], size: i32) -> Vec<u8> {
    if let Ok(img) = image::load_from_memory(bytes) {
        let resized = img.resize_exact(
            size as u32,
            size as u32,
            image::imageops::FilterType::Lanczos3,
        );
        resized.to_rgba8().into_raw()
    } else {
        vec![]
    }
}
</file>

<file path="src/overlay/html_components/grid_js.rs">
pub fn get_css() -> &'static str {
    r#"
    /* --- Grid.js Theme-Adaptive Compact Styling --- */
    /* Uses CSS variables from markdown_view.rs theme system */
    
    .gridjs-container {
        color: var(--text-color, #e0e0e0);
        font-family: 'Google Sans Flex', 'Segoe UI', sans-serif !important;
        background: var(--table-bg, rgba(0,0,0,0.2)) !important;
        padding: 0 !important;
        border-radius: 8px;
        border: 1px solid var(--border-color, #333);
        box-shadow: none;
        margin: 0 !important;
        font-size: 13px !important;
        position: relative;
        overflow: auto !important;
        display: block !important;
    }
    
    .gridjs-wrapper, .gridjs-tbody, .gridjs-tr, .gridjs-td {
        background-color: var(--table-bg, rgba(0,0,0,0.2)) !important;
        border-color: var(--border-color, #333) !important;
    }
    
    .gridjs-table {
        /* Full width, let browser handle column sizing */
        width: 100% !important; 
        max-width: 100% !important;
        border-collapse: collapse !important;
        table-layout: auto !important; 
    }
    
    .gridjs-head {
        background: var(--table-header-bg, #252525) !important;
    }
    
    /* Header Styling */
    .gridjs-th {
        background: var(--table-header-bg, #252525) !important;
        color: var(--primary, #81d4fa) !important;
        border: none !important;
        border-bottom: 1px solid var(--border-color, #444) !important;
        /* Compact padding as requested */
        padding: 4px 8px !important;
        font-weight: 600 !important;
        position: relative !important;
        text-transform: none !important;
        outline: none !important;
        white-space: nowrap !important;
        width: auto !important;
    }
    
    .gridjs-th:hover {
        background: var(--glass, rgba(255,255,255,0.03)) !important;
    }
    
    /* Sort Icon - Inline */
    .gridjs-th-content {
        float: left !important;
        display: inline-block !important;
    }

    .gridjs-sort {
        float: none !important;
        display: inline-block !important;
        vertical-align: middle !important;
        opacity: 0.5 !important;
        /* Use filter to adapt to theme - dark mode inverts, light mode uses default */
        filter: var(--sort-icon-filter, invert(1) brightness(200%) grayscale(100%)) !important; 
        margin-left: 8px !important;
        margin-top: -2px !important;
        width: 10px !important;
        height: 10px !important;
    }
    .gridjs-th:hover .gridjs-sort { opacity: 1 !important; }
    
    /* Cells */
    .gridjs-td {
        border: none !important;
        border-bottom: 1px solid var(--border-color, #333) !important;
        color: var(--text-color, #e0e0e0) !important;
        /* Compact padding as requested */
        padding: 4px 8px !important;
        white-space: normal !important; 
        max-width: 400px;
        overflow-wrap: break-word;
    }
    
    .gridjs-tr:last-child .gridjs-td {
        border-bottom: none !important;
    }
    
    .gridjs-tr:hover .gridjs-td {
        background-color: var(--glass, rgba(255,255,255,0.03)) !important;
    }

    /* Footer */
    .gridjs-footer {
        background: var(--table-header-bg, #252525) !important;
        border-top: 1px solid var(--border-color, #333) !important;
        padding: 8px !important;
        width: 100% !important; 
        display: block !important;
    }
    
    .gridjs-pagination button {
        background: transparent !important;
        border: 1px solid var(--border-color, rgba(255,255,255,0.1)) !important;
        color: var(--h4-color, #aaa) !important;
        border-radius: 4px !important;
    }
    
    .gridjs-pagination button:hover:not([disabled]) {
        background: var(--glass, #333) !important;
        color: var(--text-color, #fff) !important;
    }
    
    .gridjs-pagination button.gridjs-currentPage {
        background: var(--glass, #333) !important;
        border-color: var(--primary, #81d4fa) !important;
        color: var(--primary, #81d4fa) !important;
        font-weight: bold;
    }
    
    .gridjs-tr-header { display: table-row !important; }
    
    .gridjs-wrapper::-webkit-scrollbar { width: 8px; height: 8px; }
    .gridjs-wrapper::-webkit-scrollbar-track { background: var(--table-bg, #1a1a1a); }
    .gridjs-wrapper::-webkit-scrollbar-thumb { background: var(--border-color, #444); border-radius: 4px; }
    .gridjs-wrapper::-webkit-scrollbar-thumb:hover { background: var(--h4-color, #555); }
    
    .gridjs-hidden-source {
        display: none !important;
    }
    "#
}

pub fn get_init_script() -> &'static str {
    r#"
    (function() {
        var processTimeout;

        var initGridJs = function() {
            if (typeof gridjs === 'undefined') {
                setTimeout(initGridJs, 50);
                return;
            }

            var tables = document.querySelectorAll('table:not(.gridjs-table):not([data-processed-table="true"])');
            
            for (var i = 0; i < tables.length; i++) {
                var table = tables[i];
                
                if (table.closest('.gridjs-container') || table.closest('.gridjs-injected-wrapper')) continue;
                
                table.setAttribute('data-processed-table', 'true');
                
                var wrapper = document.createElement('div');
                wrapper.className = 'gridjs-injected-wrapper';
                table.parentNode.insertBefore(wrapper, table);
                
                try {
                    var grid = new gridjs.Grid({
                        from: table,
                        sort: true,
                        fixedHeader: true,
                        search: false, 
                        resizable: false, 
                        autoWidth: false,
                        style: { 
                            table: { 'width': '100%' },
                            td: { 'border': '1px solid #333' },
                            th: { 'border': '1px solid #333' }
                        },
                        className: {
                            table: 'gridjs-table-premium',
                            th: 'gridjs-th-premium',
                            td: 'gridjs-td-premium'
                        }
                    });

                    grid.on('ready', function() {
                        table.classList.add('gridjs-hidden-source');
                    });

                    grid.render(wrapper);
                    
                } catch (e) {
                    console.error('Grid.js init error:', e);
                    if(wrapper.parentNode) wrapper.parentNode.removeChild(wrapper);
                }
            }
        };

        if (document.readyState === 'loading') {
            document.addEventListener('DOMContentLoaded', initGridJs);
        } else {
            initGridJs();
        }
        
        var observer = new MutationObserver(function(mutations) {
            var shouldCheck = false;
            
            for (var i = 0; i < mutations.length; i++) {
                var m = mutations[i];
                var target = m.target;
                
                if (target && (
                    target.closest('.gridjs-injected-wrapper') || 
                    target.closest('.gridjs-container') ||
                    target.classList.contains('gridjs-table') ||
                    target.classList.contains('gridjs-head') ||
                    target.classList.contains('gridjs-wrapper')
                )) {
                    continue;
                }

                if (m.addedNodes.length > 0) {
                    for (var k = 0; k < m.addedNodes.length; k++) {
                        var n = m.addedNodes[k];
                        if (n.nodeType !== 1) continue; 
                        
                        if (n.classList.contains('gridjs-container') || n.classList.contains('gridjs-wrapper')) continue;

                        if (n.nodeName === 'TABLE') {
                            if (!n.hasAttribute('data-processed-table') && !n.classList.contains('gridjs-table')) {
                                shouldCheck = true;
                                break;
                            }
                        } else if (n.querySelector) {
                            if (n.querySelector('table:not(.gridjs-table):not([data-processed-table="true"])')) {
                                shouldCheck = true;
                                break;
                            }
                        }
                    }
                }
                if (shouldCheck) break;
            }
            
            if (shouldCheck) {
                if (window.gridJsTimeout) clearTimeout(window.gridJsTimeout);
                window.gridJsTimeout = setTimeout(initGridJs, 100);
            }
        });
        
        observer.observe(document.body, { childList: true, subtree: true });
    })();
    "#
}

pub fn get_lib_urls() -> (&'static str, &'static str) {
    (
        "https://unpkg.com/gridjs/dist/theme/mermaid.min.css",
        "https://unpkg.com/gridjs/dist/gridjs.umd.js",
    )
}
</file>

<file path="src/overlay/html_components/icons.rs">
pub fn get_icon_svg(name: &str) -> &'static str {
    match name {
        "music_note" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16" viewBox="0 -960 960 960" width="16" fill="currentColor"><path d="M400-120q-66 0-113-47t-47-113q0-66 47-113t113-47q23 0 42.5 5.5T480-418v-382q0-17 11.5-28.5T520-840h160q17 0 28.5 11.5T720-800v80q0 17-11.5 28.5T680-680H560v400q0 66-47 113t-113 47Z"/></svg>"#
        }

        "headphones" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M280-120h-80q-33 0-56.5-23.5T120-200v-280q0-75 28.5-140.5t77-114q48.5-48.5 114-77T480-840q75 0 140.5 28.5t114 77q48.5 48.5 77 114T840-480v280q0 33-23.5 56.5T760-120h-80q-33 0-56.5-23.5T600-200v-160q0-33 23.5-56.5T680-440h80v-40q0-117-81.5-198.5T480-760q-117 0-198.5 81.5T200-480v40h80q33 0 56.5 23.5T360-360v160q0 33-23.5 56.5T280-120Z"/></svg>"#
        }

        "mic" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M480-400q-50 0-85-35t-35-85v-240q0-50 35-85t85-35q50 0 85 35t35 85v240q0 50-35 85t-85 35Zm-40 240v-83q-92-13-157.5-78T203-479q-2-17 9-29t28-12q17 0 28.5 11.5T284-480q14 70 69.5 115T480-320q72 0 127-45.5T676-480q4-17 15.5-28.5T720-520q17 0 28 12t9 29q-14 91-79 157t-158 79v83q0 17-11.5 28.5T480-120q-17 0-28.5-11.5T440-160Z"/></svg>"#
        }

        "speaker_group" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M400-200q-33 0-56.5-23.5T320-280v-560q0-33 23.5-56.5T400-920h360q33 0 56.5 23.5T840-840v560q0 33-23.5 56.5T760-200H400Zm180-460q25 0 42.5-17.5T640-720q0-25-17.5-42.5T580-780q-25 0-42.5 17.5T520-720q0 25 17.5 42.5T580-660Zm0 340q58 0 99-41t41-99q0-58-41-99t-99-41q-58 0-99 41t-41 99q0 58 41 99t99 41Zm0-80q-25 0-42.5-17.5T520-460q0-25 17.5-42.5T580-520q25 0 42.5 17.5T640-460q0 25-17.5 42.5T580-400Zm20 360H240q-33 0-56.5-23.5T160-120v-600q0-17 11.5-28.5T200-760q17 0 28.5 11.5T240-720v600h360q17 0 28.5 11.5T640-80q0 17-11.5 28.5T600-40Z"/></svg>"#
        }

        "volume_up" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16" viewBox="0 -960 960 960" width="16" fill="currentColor"><path d="M760-481q0-83-44-151.5T598-735q-15-7-22-21.5t-2-29.5q6-16 21.5-23t31.5 0q97 43 155 131.5T840-481q0 108-58 196.5T627-153q-16 7-31.5 0T574-176q-5-15 2-29.5t22-21.5q74-34 118-102.5T760-481ZM280-360H160q-17 0-28.5-11.5T120-400v-160q0-17 11.5-28.5T160-600h120l132-132q19-19 43.5-8.5T480-703v446q0 27-24.5 37.5T412-228L280-360Zm380-120q0 42-19 79.5T591-339q-10 6-20.5.5T560-356v-250q0-12 10.5-17.5t20.5.5q31 25 50 63t19 80Z"/></svg>"#
        }

        "auto_awesome" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="m706-706-70-32q-6-3-8.5-8t-2.5-10q0-5 2.5-10t8.5-8l70-32 32-70q3-6 8-9t10-3q5 0 10 3t8 9l32 70 70 32q6 3 9 8t3 10q0 5-3 10t-9 8l-70 32-32 70q-3 6-8 8.5t-10 2.5q-5 0-10-2.5t-8-8.5l-32-70ZM260-380l-160-73q-9-4-13-11.5T83-480q0-8 4-15.5t13-11.5l160-73 73-160q4-9 11.5-13t15.5-4q8 0 15.5 4t11.5 13l73 160 160 73q9 4 13 11.5t4 15.5q0 8-4 15.5T620-453l-160 73-73 160q-4 9-11.5 13t-15.5 4q-8 0-15.5-4T333-220l-73-160Zm450 230-70-32q-6-3-9-8t-3-10q0-5 3-10t9-8l70-32 32-70q3-6 8-9t10-3q5 0 10 3t8 9l32 70 70 32q6 3 9 8t3 10q0 5-3 10t-9 8l-70 32-32 70q-3 6-8 9t-10 3q-5 0-10-3t-8-9l-32-70Z"/></svg>"#
        }

        "speed" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M418-340q25 25 63 23.5t55-27.5l169-253q9-14-2.5-25.5T677-625L424-456q-26 18-28.5 54.5T418-340ZM204-160q-22 0-40.5-9.5T134-198q-26-47-40-97.5T80-400q0-83 31.5-156T197-683q54-54 127-85.5T480-800q82 0 154 31t126 84.5q54 53.5 86 125T879-406q1 55-12.5 107.5T825-198q-11 19-29.5 28.5T755-160H204Z"/></svg>"#
        }

        "language" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M480-80q-82 0-155-31.5t-127.5-86Q143-252 111.5-325T80-480q0-83 31.5-155.5t86-127Q252-817 325-848.5T480-880q83 0 155.5 31.5t127 86q54.5 54.5 86 127T880-480q0 82-31.5 155t-86 127.5q-54.5 54.5-127 86T480-80Zm0-82q26-36 45-75t31-83H404q12 44 31 83t45 75Zm-104-16q-18-33-31.5-68.5T322-320H204q29 50 72.5 87t99.5 55Zm208 0q56-18 99.5-55t72.5-87H638q-9 38-22.5 73.5T584-178ZM170-400h136q-3-20-4.5-39.5T300-480q0-21 1.5-40.5T306-560H170q-5 20-7.5 39.5T160-480q0 21 2.5 40.5T170-400Zm216 0h188q3-20 4.5-39.5T580-480q0-21-1.5-40.5T574-560H386q-3 20-4.5 39.5T380-480q0 21 1.5 40.5T386-400Zm268 0h136q5-20 7.5-39.5T800-480q0-21-2.5-40.5T790-560H654q3 20 4.5 39.5T660-480q0 21-1.5 40.5T654-400Zm-16-240h118q-29-50-72.5-87T584-782q18 33 31.5 68.5T638-640Zm-234 0h152q-12-44-31-83t-45-75q-26 36-45 75t-31 83Zm-200 0h118q9-38 22.5-73.5T376-782q-56 18-99.5 55T204-640Z"/></svg>"#
        }

        "content_copy" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16" viewBox="0 -960 960 960" width="16" fill="currentColor"><path d="M360-240q-33 0-56.5-23.5T280-320v-480q0-33 23.5-56.5T360-880h360q33 0 56.5 23.5T800-800v480q0 33-23.5 56.5T720-240H360ZM200-80q-33 0-56.5-23.5T120-160v-520q0-17 11.5-28.5T160-720q17 0 28.5 11.5T200-680v520h400q17 0 28.5 11.5T640-120q0 17-11.5 28.5T600-80H200Z"/></svg>"#
        }

        "remove" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M240-440q-17 0-28.5-11.5T200-480q0-17 11.5-28.5T240-520h480q17 0 28.5 11.5T760-480q0 17-11.5 28.5T720-440H240Z"/></svg>"#
        }

        "add" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M440-440H240q-17 0-28.5-11.5T200-480q0-17 11.5-28.5T240-520h200v-200q0-17 11.5-28.5T480-760q17 0 28.5 11.5T520-720v200h200q17 0 28.5 11.5T760-480q0 17-11.5 28.5T720-440H520v200q0 17-11.5 28.5T480-200q-17 0-28.5-11.5T440-240v-200Z"/></svg>"#
        }

        "subtitles" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M160-160q-33 0-56.5-23.5T80-240v-480q0-33 23.5-56.5T160-800h640q33 0 56.5 23.5T880-720v480q0 33-23.5 56.5T800-160H160Zm120-160h240q17 0 28.5-11.5T560-360q0-17-11.5-28.5T520-400H280q-17 0-28.5 11.5T240-360q0 17 11.5 28.5T280-320Zm160-160h240q17 0 28.5-11.5T720-520q0-17-11.5-28.5T680-560H440q-17 0-28.5 11.5T400-520q0 17 11.5 28.5T440-480Zm-160 0q17 0 28.5-11.5T320-520q0-17-11.5-28.5T280-560q-17 0-28.5 11.5T240-520q0 17 11.5 28.5T280-480Zm400 160q17 0 28.5-11.5T720-360q0-17-11.5-28.5T680-400q-17 0-28.5 11.5T640-360q0 17 11.5 28.5T680-320Z"/></svg>"#
        }

        "translate" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="m603-202-34 97q-4 11-14 18t-22 7q-20 0-32.5-16.5T496-133l152-402q5-11 15-18t22-7h30q12 0 22 7t15 18l152 403q8 19-4 35.5T868-80q-13 0-22.5-7T831-106l-34-96H603ZM362-401 188-228q-11 11-27.5 11.5T132-228q-11-11-11-28t11-28l174-174q-35-35-63.5-80T190-640h84q20 39 40 68t48 58q33-33 68.5-92.5T484-720H80q-17 0-28.5-11.5T40-760q0-17 11.5-28.5T80-800h240v-40q0-17 11.5-28.5T360-880q17 0 28.5 11.5T400-840v40h240q17 0 28.5 11.5T680-760q0 17-11.5 28.5T640-720h-76q-21 72-63 148t-83 116l96 98-30 82-122-125Zm266 129h144l-72-204-72 204Z"/></svg>"#
        }

        "expand_less" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M480-529 324-373q-11 11-28 11t-28-11q-11-11-11-28t11-28l184-184q6-6 13-8.5t15-2.5q8 0 15 2.5t13 8.5l184 184q11 11 11 28t-11 28q-11 11-28 11t-28-11L480-529Z"/></svg>"#
        }

        "picture_in_picture_small" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M120-160q-17 0-28.5-11.5T80-200q0-17 11.5-28.5T120-240h680v-520q0-17 11.5-28.5T840-800q17 0 28.5 11.5T880-760v520q0 33-23.5 56.5T800-160H120Zm320-160q-17 0-28.5-11.5T400-360v-160q0-17 11.5-28.5T440-560h240q17 0 28.5 11.5T720-520v160q0 17-11.5 28.5T680-320H440Z"/></svg>"#
        }

        "apps" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24" fill="currentColor"><path d="M240-160q-33 0-56.5-23.5T160-240q0-33 23.5-56.5T240-320q33 0 56.5 23.5T320-240q0 33-23.5 56.5T240-160Zm240 0q-33 0-56.5-23.5T400-240q0-33 23.5-56.5T480-320q33 0 56.5 23.5T560-240q0 33-23.5 56.5T480-160Zm240 0q-33 0-56.5-23.5T640-240q0-33 23.5-56.5T720-320q33 0 56.5 23.5T800-240q0 33-23.5 56.5T720-160ZM240-400q-33 0-56.5-23.5T160-480q0-33 23.5-56.5T240-560q33 0 56.5 23.5T320-480q0 33-23.5 56.5T240-400Zm240 0q-33 0-56.5-23.5T400-480q0-33 23.5-56.5T480-560q33 0 56.5 23.5T560-480q0 33-23.5 56.5T480-400Zm240 0q-33 0-56.5-23.5T640-480q0-33 23.5-56.5T720-560q33 0 56.5 23.5T800-480q0 33-23.5 56.5T720-400ZM240-640q-33 0-56.5-23.5T160-720q0-33 23.5-56.5T240-800q33 0 56.5 23.5T320-720q0 33-23.5 56.5T240-640Zm240 0q-33 0-56.5-23.5T400-720q0-33 23.5-56.5T480-800q33 0 56.5 23.5T560-720q0 33-23.5 56.5T480-640Zm240 0q-33 0-56.5-23.5T640-720q0-33 23.5-56.5T720-800q33 0 56.5 23.5T800-720q0 33-23.5 56.5T720-640Z"/></svg>"#
        }

        "play_arrow" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="40" viewBox="0 -960 960 960" width="40" fill="currentColor"><path d="M290.33-246.67V-718q0-23.18 16.03-38.26 16.02-15.07 37.5-15.07 6.15 0 13.64 1.83 7.5 1.83 15.09 5.45L743-526.33q12.83 7 19.08 19.17 6.25 12.18 6.25 25.16t-6.5 25.16q-6.5 12.17-18.83 18.51L372.59-200.62q-7.59 4.29-15.32 5.79t-13.79 1.5q-21.19 0-37.17-14.6-15.98-14.59-15.98-38.74Z"/></svg>"#
        }

        "close" => {
            r##"<svg xmlns="http://www.w3.org/2000/svg" height="40px" viewBox="0 -960 960 960" width="40px" fill="currentColor"><path d="M480.67-404.67 373.99-298q-16.06 16.67-37.16 15.67-21.1-1-37.5-16-16-15-16-37t16-38l106-107.36-106.66-107.32q-15.34-15.23-15.34-36.58 0-21.35 15.84-37.41 15.17-15.33 37.25-15.33T373.67-662l107 106.67 105-106.67q15.4-16 37.83-15.67 22.44.34 38.5 15.67 13.67 15 13.67 36.67 0 21.66-13.67 37L555.33-480.67 662-371.99q15.33 15.56 15.33 36.91 0 21.34-15.33 36.9-16 14.51-38.33 14.85Q601.33-283 586-298L480.67-404.67Z"/></svg>"##
        }

        "pause" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="40" viewBox="0 -960 960 960" width="40" fill="currentColor"><path d="M675.48-128q-56.48 0-95.98-39.31Q540-206.63 540-264v-433q0-55.97 39.32-95.99Q618.64-833 676.02-833 732-833 772-792.99q40 40.02 40 95.99v433q0 57.37-40.02 96.69Q731.96-128 675.48-128Zm-391.5 0Q228-128 188-167.31q-40-39.32-40-96.69v-433q0-55.97 40.02-95.99Q228.04-833 284.52-833t95.98 40.01Q420-752.97 420-697v433q0 57.37-39.32 96.69Q341.36-128 283.98-128Z"/></svg>"#
        }

        "check" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16" viewBox="0 -960 960 960" width="16" fill="currentColor"><path d="m382-354 339-339q12-12 28-12t28 12q12 12 12 28.5T777-636L410-268q-12 12-28 12t-28-12L182-440q-12-12-11.5-28.5T183-497q12-12 28.5-12t28.5 12l142 143Z"/></svg>"#
        }

        "download" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16" viewBox="0 -960 960 960" width="16" fill="currentColor"><path d="M480-320 280-520l56-58 104 104v-326h80v326l104-104 56 58-200 200ZM240-160q-33 0-56.5-23.5T160-240v-120h80v120h480v-120h80v120q0 33-23.5 56.5T720-160H240Z"/></svg>"#
        }

        "bolt_en" => {
            r##"<svg xmlns="http://www.w3.org/2000/svg" height="24" viewBox="0 -960 960 960" width="24"><path d="M240-80l80-320H120l280-520h120l-80 320h200L240-80Z" fill="currentColor"/><rect x="440" y="-520" width="520" height="480" rx="80" fill="currentColor" stroke="#1c1c1c" stroke-width="40"/><text x="700" y="-160" text-anchor="middle" font-family="Arial Black, sans-serif" font-size="380" font-weight="1000" fill="black">EN</text></svg>"##
        }

        "send" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960" width="24px" fill="currentColor"><path d="M176-183q-20 8-38-3.5T120-220v-180l320-80-320-80v-180q0-22 18-33.5t38-3.5l616 260q25 11 25 37t-25 37L176-183Z"/></svg>"#
        }

        "arrow_back" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="m313-440 196 196q12 12 11.5 28T508-188q-12 11-28 11.5T452-188L188-452q-6-6-8.5-13t-2.5-15q0-8 2.5-15t8.5-13l264-264q11-11 27.5-11t28.5 11q12 12 12 28.5T508-715L313-520h447q17 0 28.5 11.5T800-480q0 17-11.5 28.5T760-440H313Z"/></svg>"#
        }

        "arrow_forward" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M647-440H200q-17 0-28.5-11.5T160-480q0-17 11.5-28.5T200-520h447L451-716q-12-12-11.5-28t12.5-28q12-11 28-11.5t28 11.5l264 264q6 6 8.5 13t2.5 15q0 8-2.5 15t-8.5 13L508-188q-11 11-27.5 11T452-188q-12-12-12-28.5t12-28.5l195-195Z"/></svg>"#
        }

        "undo" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M320-200q-17 0-28.5-11.5T280-240q0-17 11.5-28.5T320-280h244q63 0 109.5-40T720-420q0-60-46.5-100T564-560H312l76 76q11 11 11 28t-11 28q-11 11-28 11t-28-11L188-572q-6-6-8.5-13t-2.5-15q0-8 2.5-15t8.5-13l144-144q11-11 28-11t28 11q11 11 11 28t-11 28l-76 76h252q97 0 166.5 63T800-420q0 94-69.5 157T564-200H320Z"/></svg>"#
        }

        "redo" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M648-560H396q-63 0-109.5 40T240-420q0 60 46.5 100T396-280h244q17 0 28.5 11.5T680-240q0 17-11.5 28.5T640-200H396q-97 0-166.5-63T160-420q0-94 69.5-157T396-640h252l-76-76q-11-11-11-28t11-28q11-11 28-11t28 11l144 144q6 6 8.5 13t2.5 15q0 8-2.5 15t-8.5 13L628-428q-11 11-28 11t-28-11q-11-11-11-28t11-28l76-76Z"/></svg>"#
        }

        "newsmode" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M160-120q-33 0-56.5-23.5T80-200v-560q0-33 23.5-56.5T160-840h640q33 0 56.5 23.5T880-760v560q0 33-23.5 56.5T800-120H160Zm0-80h640v-560H160v560Zm120-80h400q17 0 28.5-11.5T720-320q0-17-11.5-28.5T680-360H280q-17 0-28.5 11.5T240-320q0 17 11.5 28.5T280-280Zm0-160h80q17 0 28.5-11.5T400-480v-160q0-17-11.5-28.5T360-680h-80q-17 0-28.5 11.5T240-640v160q0 17 11.5 28.5T280-440Zm240 0h160q17 0 28.5-11.5T720-480q0-17-11.5-28.5T680-520H520q-17 0-28.5 11.5T480-480q0 17 11.5 28.5T520-440Zm0-160h160q17 0 28.5-11.5T720-640q0-17-11.5-28.5T680-680H520q-17 0-28.5 11.5T480-640q0 17 11.5 28.5T520-600ZM160-200v-560 560Z"/></svg>"#
        }

        "notes" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M160-240q-17 0-28.5-11.5T120-280q0-17 11.5-28.5T160-320h400q17 0 28.5 11.5T600-280q0 17-11.5 28.5T560-240H160Zm0-200q-17 0-28.5-11.5T120-480q0-17 11.5-28.5T160-520h640q17 0 28.5 11.5T840-480q0 17-11.5 28.5T800-440H160Zm0-200q-17 0-28.5-11.5T120-680q0-17 11.5-28.5T160-720h640q17 0 28.5 11.5T840-680q0 17-11.5 28.5T800-640H160Z"/></svg>"#
        }

        "hourglass_empty" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M320-160h320v-120q0-66-47-113t-113-47q-66 0-113 47t-47 113v120Zm160-360q66 0 113-47t47-113v-120H320v120q0 66 47 113t113 47ZM200-80q-17 0-28.5-11.5T160-120q0-17 11.5-28.5T200-160h40v-120q0-61 28.5-114.5T348-480q-51-32-79.5-85.5T240-680v-120h-40q-17 0-28.5-11.5T160-840q0-17 11.5-28.5T200-880h560q17 0 28.5 11.5T800-840q0 17-11.5 28.5T760-800h-40v120q0 61-28.5 114.5T612-480q51 32 79.5 85.5T720-280v120h40q17 0 28.5 11.5T800-120q0 17-11.5 28.5T760-80H200Z"/></svg>"#
        }

        "stop" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M240-320v-320q0-33 23.5-56.5T320-720h320q33 0 56.5 23.5T720-640v320q0 33-23.5 56.5T640-240H320q-33 0-56.5-23.5T240-320Zm80 0h320v-320H320v320Zm160-160Z"/></svg>"#
        }

        "cleaning_services" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M440-520h80v-280q0-17-11.5-28.5T480-840q-17 0-28.5 11.5T440-800v280ZM200-360h560v-80H200v80Zm-58 240h98v-80q0-17 11.5-28.5T280-240q17 0 28.5 11.5T320-200v80h120v-80q0-17 11.5-28.5T480-240q17 0 28.5 11.5T520-200v80h120v-80q0-17 11.5-28.5T680-240q17 0 28.5 11.5T720-200v80h98l-40-160H182l-40 160Zm676 80H142q-39 0-63-31t-14-69l55-220v-80q0-33 23.5-56.5T200-520h160v-280q0-50 35-85t85-35q50 0 85 35t35 85v280h160q33 0 56.5 23.5T840-440v80l55 220q13 38-11.5 69T818-40Zm-58-400H200h560Zm-240-80h-80 80Z"/></svg>"#
        }

        // Opacity icon (drop/water drop style for transparency)
        "opacity" => {
            r#"<svg xmlns="http://www.w3.org/2000/svg" height="16px" viewBox="0 -960 960 960" width="16px" fill="currentColor"><path d="M480-120q-133 0-226.5-92T160-436q0-65 25-121.5T254-658l226-222 226 222q44 44 69 100.5T800-436q0 132-93.5 224T480-120ZM242-400h474q12-72-13.5-123T650-600L480-768 310-600q-27 26-53 77t-15 123Z"/></svg>"#
        }

        _ => "",
    }
}
</file>

<file path="src/overlay/html_components/js_logic.rs">
pub fn get(placeholder_text: &str) -> String {
    format!(
        r###"        function updateText(oldText, newText) {{
            const hasContent = oldText || newText;
            
            if (isFirstText && hasContent) {{
                content.innerHTML = '';
                isFirstText = false;
                minContentHeight = 0;
                currentOldTextLength = 0;
                previousNewText = '';
            }}
            
            if (!hasContent) {{
                content.innerHTML = '<span class="placeholder">{placeholder_text}</span>';
                content.style.minHeight = '';
                isFirstText = true;
                minContentHeight = 0;
                targetScrollTop = 0;
                currentScrollTop = 0;
                viewport.scrollTop = 0;
                currentOldTextLength = 0;
                previousNewText = '';
                return;
            }}

            // Detect if newText was REPLACED (not extended)  
            // This happens when new translation starts - must do atomic rebuild
            // BUT: only if oldText didn't grow (if oldText grew, it's a commit with smooth transition)
            const isNewTextReplacement = previousNewText.length > 0 && 
                newText.length > 0 && 
                !newText.startsWith(previousNewText) &&
                oldText.length === currentOldTextLength;  // oldText unchanged = translation restart
            
            // 1. Handle history rewrite or shrink
            if (oldText.length < currentOldTextLength) {{
                content.innerHTML = '';
                currentOldTextLength = 0;
                previousNewText = '';
            }}
            
            // Get all existing chunks
            const allChunks = Array.from(content.querySelectorAll('.text-chunk'));
            let totalChunkText = allChunks.map(c => c.textContent).join('');
            const fullText = oldText + newText;
            
            // 2. If old text grew, transition chunks from new to old
            // Handle chunk splitting when a chunk spans the commit boundary
            if (oldText.length > currentOldTextLength) {{
                let committedLen = oldText.length;
                let accumulatedLen = 0;
                
                for (const chunk of allChunks) {{
                    const chunkText = chunk.textContent;
                    const chunkLen = chunkText.length;
                    const chunkStart = accumulatedLen;
                    const chunkEnd = accumulatedLen + chunkLen;
                    
                    if (chunkEnd <= committedLen) {{
                        // Entire chunk is within committed range - transition to old
                        if (!chunk.classList.contains('old')) {{
                            chunk.classList.remove('appearing', 'new');
                            chunk.classList.add('old');
                        }}
                    }} else if (chunkStart < committedLen && chunkEnd > committedLen) {{
                        // Chunk SPANS the commit boundary - need to split it
                        const splitPoint = committedLen - chunkStart;
                        const committedPart = chunkText.substring(0, splitPoint);
                        const uncommittedPart = chunkText.substring(splitPoint);
                        
                        // Update current chunk to be just the committed part (old style)
                        chunk.textContent = committedPart;
                        chunk.classList.remove('appearing', 'new');
                        chunk.classList.add('old');
                        
                        // Create new chunk for uncommitted part (stays new style)
                        if (uncommittedPart) {{
                            const newPartChunk = document.createElement('span');
                            newPartChunk.className = 'text-chunk new';
                            newPartChunk.textContent = uncommittedPart;
                            chunk.after(newPartChunk);
                        }}
                    }}
                    // else: chunk is entirely after committed range, stays as-is
                    accumulatedLen = chunkEnd;
                }}
            }}
            currentOldTextLength = oldText.length;
            previousNewText = newText;
            
            // 3. Handle text changes
            // Priority: replacement detection > append > general rebuild
            if (isNewTextReplacement) {{
                // Atomic replacement: rebuild with new content immediately
                content.innerHTML = '';
                if (oldText) {{
                    const oldChunk = document.createElement('span');
                    oldChunk.className = 'text-chunk old';
                    oldChunk.textContent = oldText;
                    content.appendChild(oldChunk);
                }}
                if (newText) {{
                    const newChunk = document.createElement('span');
                    newChunk.className = 'text-chunk new';
                    newChunk.textContent = newText;
                    content.appendChild(newChunk);
                }}
            }} else if (fullText.length > totalChunkText.length && fullText.startsWith(totalChunkText)) {{
                // Normal append mode - text grew
                const delta = fullText.substring(totalChunkText.length);
                
                const chunk = document.createElement('span');
                chunk.className = 'text-chunk appearing';
                chunk.textContent = delta;
                content.appendChild(chunk);
                
                // Trigger wipe animation
                requestAnimationFrame(() => {{
                    chunk.classList.add('show');
                    setTimeout(() => {{
                        chunk.classList.remove('appearing', 'show');
                        const chunkStart = totalChunkText.length;
                        if (chunkStart < currentOldTextLength) {{
                            chunk.classList.add('old');
                        }} else {{
                            chunk.classList.add('new');
                        }}
                    }}, 350);
                }});
            }} else if (fullText !== totalChunkText) {{
                // General rebuild for other cases
                content.innerHTML = '';
                if (oldText) {{
                    const oldChunk = document.createElement('span');
                    oldChunk.className = 'text-chunk old';
                    oldChunk.textContent = oldText;
                    content.appendChild(oldChunk);
                }}
                if (newText) {{
                    const newChunk = document.createElement('span');
                    newChunk.className = 'text-chunk new';
                    newChunk.textContent = newText;
                    content.appendChild(newChunk);
                }}
            }}
            
            // Scroll logic
            const naturalHeight = content.offsetHeight;
            if (naturalHeight > minContentHeight) {{
                minContentHeight = naturalHeight;
            }}
            content.style.minHeight = minContentHeight + 'px';
            const viewportHeight = viewport.offsetHeight;
            if (minContentHeight > viewportHeight) {{
                const maxScroll = minContentHeight - viewportHeight;
                if (maxScroll > targetScrollTop) {{
                    targetScrollTop = maxScroll;
                }}
            }}
            if (!animationFrame) {{
                animationFrame = requestAnimationFrame(animateScroll);
            }}
        }}

        window.updateText = updateText;
        
        // Canvas-based volume visualizer - cute pill bars scrolling left
        const volumeCanvas = document.getElementById('volume-canvas');
        const volumeCtx = volumeCanvas ? volumeCanvas.getContext('2d') : null;
        
        // Cute pill configuration
        const BAR_WIDTH = 4;
        const BAR_GAP = 3;
        const BAR_SPACING = BAR_WIDTH + BAR_GAP;
        const VISIBLE_BARS = 12;
        
        // Each bar has its own height that persists as it scrolls
        const barHeights = new Array(VISIBLE_BARS + 2).fill(3);
        let latestRMS = 0;
        let scrollProgress = 0; // 0 to 1, represents progress to next bar shift
        let lastTime = 0;
        
        function updateVolume(rms) {{
            latestRMS = rms;
        }}
        
        function drawWaveform(timestamp) {{
            if (!volumeCtx) return;
            
            // Delta time
            const dt = lastTime ? (timestamp - lastTime) / 1000 : 0.016;
            lastTime = timestamp;
            
            // Scroll progress (one full bar every ~200ms for relaxed look)
            scrollProgress += dt / 0.2;
            
            // When we've scrolled one full bar, shift and add new
            while (scrollProgress >= 1) {{
                scrollProgress -= 1;
                // Shift all bars left (oldest falls off)
                barHeights.shift();
                // Add new bar on right with current RMS
                const h = volumeCanvas.height;
                // RMS typically 0-0.3 for speech, multiply by 180 for better visibility
                const newHeight = Math.max(3, Math.min(h - 2, latestRMS * 180 + 3));
                barHeights.push(newHeight);
            }}
            
            // Clear
            const w = volumeCanvas.width;
            const h = volumeCanvas.height;
            volumeCtx.clearRect(0, 0, w, h);
            
            // Gradient
            const grad = volumeCtx.createLinearGradient(0, h, 0, 0);
            grad.addColorStop(0, '#00a8e0');
            grad.addColorStop(0.5, '#00c8ff');
            grad.addColorStop(1, '#40e0ff');
            volumeCtx.fillStyle = grad;
            
            // Pixel offset for smooth scroll
            const pixelOffset = scrollProgress * BAR_SPACING;
            
            // Draw bars
            for (let i = 0; i < barHeights.length; i++) {{
                const pillHeight = barHeights[i];
                const x = i * BAR_SPACING - pixelOffset;
                const y = (h - pillHeight) / 2;
                
                if (x > -BAR_WIDTH && x < w) {{
                    volumeCtx.beginPath();
                    volumeCtx.roundRect(x, y, BAR_WIDTH, pillHeight, BAR_WIDTH / 2);
                    volumeCtx.fill();
                }}
            }}
            
            // Apply fading curtain effect on both edges
            const fadeWidth = 15; // Width of the fade zone in canvas pixels
            
            volumeCtx.save();
            volumeCtx.globalCompositeOperation = 'destination-out';
            
            // Left fade (fully transparent at edge -> fully opaque inward)
            const leftGrad = volumeCtx.createLinearGradient(0, 0, fadeWidth, 0);
            leftGrad.addColorStop(0, 'rgba(0, 0, 0, 1)');
            leftGrad.addColorStop(1, 'rgba(0, 0, 0, 0)');
            volumeCtx.fillStyle = leftGrad;
            volumeCtx.fillRect(0, 0, fadeWidth, h);
            
            // Right fade (fully opaque inward -> fully transparent at edge)
            const rightGrad = volumeCtx.createLinearGradient(w - fadeWidth, 0, w, 0);
            rightGrad.addColorStop(0, 'rgba(0, 0, 0, 0)');
            rightGrad.addColorStop(1, 'rgba(0, 0, 0, 1)');
            volumeCtx.fillStyle = rightGrad;
            volumeCtx.fillRect(w - fadeWidth, 0, fadeWidth, h);
            
            volumeCtx.restore();
            
            requestAnimationFrame(drawWaveform);
        }}
        
        // Start animation
        if (volumeCanvas) {{
            requestAnimationFrame(drawWaveform);
        }}
        
        window.updateVolume = updateVolume;
        
        // Model switch animation (called when 429 fallback switches models)
        function switchModel(modelName) {{
            const icons = document.querySelectorAll('.model-icon');
            if (!icons.length) return;
            
            icons.forEach(icon => {{
                const val = icon.getAttribute('data-value');
                const shouldBeActive = val === modelName;
                
                // Update active state
                icon.classList.remove('active');
                if (shouldBeActive) {{
                    icon.classList.add('active');
                    // Add switching animation
                    icon.classList.add('switching');
                    // Remove animation class after it completes (2s)
                    setTimeout(() => icon.classList.remove('switching'), 2000);
                }}
            }});
        }}
        
        window.switchModel = switchModel;
        
        // Clear text and reset to initial placeholder state
        function clearText() {{
            content.innerHTML = '<span class=\"placeholder\">{placeholder_text}</span>';
            content.style.minHeight = '';
            isFirstText = true;
            minContentHeight = 0;
            targetScrollTop = 0;
            currentScrollTop = 0;
            viewport.scrollTop = 0;
            currentOldTextLength = 0;
            previousNewText = '';
        }}
        
        window.clearText = clearText;"###,
        placeholder_text = placeholder_text
    )
}
</file>

<file path="src/overlay/realtime_webview.rs">
pub mod app_selection;
pub mod manager;
pub mod state;
pub mod webview;
pub mod wndproc;

pub use manager::{
    is_realtime_overlay_active, show_realtime_overlay, stop_realtime_overlay,
};
pub use state::*;
</file>

<file path="src/overlay/realtime_webview/state.rs">
//! Shared state for realtime transcription overlay

use crate::api::realtime_audio::{RealtimeState, SharedRealtimeState};
use raw_window_handle::{
    HandleError, HasWindowHandle, RawWindowHandle, Win32WindowHandle, WindowHandle,
};
use std::collections::HashMap;
use std::num::NonZeroIsize;
use std::sync::{atomic::AtomicBool, Arc, Mutex, Once};
use windows::Win32::Foundation::*;
pub const WM_UPDATE_TTS_SPEED: u32 = 0x0400 + 401; // WM_USER + 401
pub const WM_APP_REALTIME_START: u32 = 0x0400 + 500; // WM_USER + 500
pub const WM_APP_REALTIME_HIDE: u32 = 0x0400 + 501; // WM_USER + 501

// Gap between realtime and translation overlays
pub const GAP: i32 = 20;

lazy_static::lazy_static! {
    pub static ref REALTIME_STOP_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref REALTIME_STATE: SharedRealtimeState = Arc::new(Mutex::new(RealtimeState::new()));
    /// Signal to change audio source (true = restart with new source)
    pub static ref AUDIO_SOURCE_CHANGE: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    /// The new audio source to use ("mic" or "device")
    pub static ref NEW_AUDIO_SOURCE: Mutex<String> = Mutex::new(String::new());
    /// Signal to change target language
    pub static ref LANGUAGE_CHANGE: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    /// The new target language to use
    pub static ref NEW_TARGET_LANGUAGE: Mutex<String> = Mutex::new(String::new());
    /// Signal to change translation model
    pub static ref TRANSLATION_MODEL_CHANGE: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    /// The new translation model to use ("google-gemma" or "groq-llama")
    pub static ref NEW_TRANSLATION_MODEL: Mutex<String> = Mutex::new(String::new());
    /// Signal to change transcription model
    pub static ref TRANSCRIPTION_MODEL_CHANGE: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    /// The new transcription model to use ("gemini" or "parakeet")
    pub static ref NEW_TRANSCRIPTION_MODEL: Mutex<String> = Mutex::new(String::new());
    /// Visibility state for windows
    pub static ref MIC_VISIBLE: Arc<AtomicBool> = Arc::new(AtomicBool::new(true));
    pub static ref TRANS_VISIBLE: Arc<AtomicBool> = Arc::new(AtomicBool::new(true));

    // --- Per-App Audio Capture State ---
    /// Selected app's Process ID for per-app audio capture (0 = not selected / use mic)
    pub static ref SELECTED_APP_PID: Arc<std::sync::atomic::AtomicU32> = Arc::new(std::sync::atomic::AtomicU32::new(0));
    /// Selected app's name for display in UI
    pub static ref SELECTED_APP_NAME: Mutex<String> = Mutex::new(String::new());

    // --- Realtime TTS State ---
    /// Enable/disable realtime TTS for committed translations
    pub static ref REALTIME_TTS_ENABLED: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    /// TTS playback speed (100 = 1.0x, 50 = 0.5x, 150 = 1.5x, etc.)
    pub static ref REALTIME_TTS_SPEED: Arc<std::sync::atomic::AtomicU32> = Arc::new(std::sync::atomic::AtomicU32::new(100));
    /// Auto-speed mode: automatically adjust speed based on queue length
    pub static ref REALTIME_TTS_AUTO_SPEED: Arc<AtomicBool> = Arc::new(AtomicBool::new(true));
    /// Queue of committed translation text segments to speak
    pub static ref COMMITTED_TRANSLATION_QUEUE: Mutex<std::collections::VecDeque<String>> = Mutex::new(std::collections::VecDeque::new());

    // --- Window Handle for App Selection ---
    pub static ref APP_SELECTION_HWND: Arc<std::sync::atomic::AtomicIsize> = Arc::new(std::sync::atomic::AtomicIsize::new(0));
    /// Track how much of the committed text has been sent to TTS
    pub static ref LAST_SPOKEN_LENGTH: Arc<std::sync::atomic::AtomicUsize> = Arc::new(std::sync::atomic::AtomicUsize::new(0));
    /// Current effective TTS speed (including auto-speed boost) for UI display
    pub static ref CURRENT_TTS_SPEED: Arc<std::sync::atomic::AtomicU32> = Arc::new(std::sync::atomic::AtomicU32::new(100));
    /// Signal to close TTS modal (shared between app selection and main window)
    pub static ref CLOSE_TTS_MODAL_REQUEST: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
}

pub static mut REALTIME_HWND: HWND = HWND(std::ptr::null_mut());
pub static mut TRANSLATION_HWND: HWND = HWND(std::ptr::null_mut());
pub static mut IS_ACTIVE: bool = false;
pub static mut IS_WARMED_UP: bool = false;
pub static mut IS_INITIALIZING: bool = false;

pub static REGISTER_REALTIME_CLASS: Once = Once::new();
pub static REGISTER_TRANSLATION_CLASS: Once = Once::new();

// Thread-local storage for WebViews
thread_local! {
    pub static REALTIME_WEBVIEWS: std::cell::RefCell<HashMap<isize, wry::WebView>> = std::cell::RefCell::new(HashMap::new());
    // Shared WebContext for this thread using common data directory
    pub static REALTIME_WEB_CONTEXT: std::cell::RefCell<Option<wry::WebContext>> = std::cell::RefCell::new(None);
}

/// Wrapper for HWND to implement HasWindowHandle
pub struct HwndWrapper(pub HWND);

impl HasWindowHandle for HwndWrapper {
    fn window_handle(&self) -> std::result::Result<WindowHandle<'_>, HandleError> {
        let hwnd = self.0 .0 as isize;
        if let Some(non_zero) = NonZeroIsize::new(hwnd) {
            let mut handle = Win32WindowHandle::new(non_zero);
            handle.hinstance = None;
            let raw = RawWindowHandle::Win32(handle);
            Ok(unsafe { WindowHandle::borrow_raw(raw) })
        } else {
            Err(HandleError::Unavailable)
        }
    }
}
</file>

<file path="src/overlay/result/event_handler/misc.rs">
use std::sync::Arc;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use crate::overlay::result::button_canvas;
use crate::overlay::result::markdown_view;
use crate::overlay::result::paint;
use crate::overlay::result::state::WINDOW_STATES;

pub const WM_CREATE_WEBVIEW: u32 = WM_USER + 200;
pub const WM_SHOW_MARKDOWN: u32 = WM_USER + 201;
pub const WM_HIDE_MARKDOWN: u32 = WM_USER + 202;
pub const WM_RESIZE_MARKDOWN: u32 = WM_USER + 203;
pub const WM_UNDO_CLICK: u32 = WM_USER + 210;
pub const WM_REDO_CLICK: u32 = WM_USER + 211;
pub const WM_COPY_CLICK: u32 = WM_USER + 212;
pub const WM_EDIT_CLICK: u32 = WM_USER + 213;
pub const WM_BACK_CLICK: u32 = WM_USER + 214;
pub const WM_FORWARD_CLICK: u32 = WM_USER + 215;
pub const WM_SPEAKER_CLICK: u32 = WM_USER + 216;
pub const WM_DOWNLOAD_CLICK: u32 = WM_USER + 217;

pub unsafe fn handle_erase_bkgnd(_hwnd: HWND, _wparam: WPARAM) -> LRESULT {
    LRESULT(1)
}

// handle_ctl_color_edit removed (was for native edit control)

pub unsafe fn handle_destroy(hwnd: HWND) -> LRESULT {
    // Collect windows to close (those sharing the same cancellation token)
    let windows_to_close: Vec<HWND>;
    let token_to_signal: Option<Arc<std::sync::atomic::AtomicBool>>;

    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.remove(&(hwnd.0 as isize)) {
            // Stop TTS if speaking
            if state.tts_request_id != 0 {
                crate::api::tts::TTS_MANAGER.stop_if_active(state.tts_request_id);
            }

            // Get the cancellation token from this window
            token_to_signal = state.cancellation_token.clone();

            // Find all other windows with the same cancellation token
            if let Some(ref token) = token_to_signal {
                // Signal cancellation first
                token.store(true, std::sync::atomic::Ordering::Relaxed);

                // Collect windows to close (can't close while iterating with lock held)
                windows_to_close = states
                    .iter()
                    .filter(|(_, s)| {
                        if let Some(ref other_token) = s.cancellation_token {
                            Arc::ptr_eq(token, other_token)
                        } else {
                            false
                        }
                    })
                    .map(|(k, _)| HWND(*k as *mut core::ffi::c_void))
                    .collect();
            } else {
                windows_to_close = Vec::new();
            }

            // Cleanup this window's resources
            if !state.content_bitmap.is_invalid() {
                let _ = DeleteObject(state.content_bitmap.into());
            }
            if !state.bg_bitmap.is_invalid() {
                let _ = DeleteObject(state.bg_bitmap.into());
            }

            // Cleanup refine input if active (state cleanup is handled by removing from WINDOW_STATES)
        } else {
            windows_to_close = Vec::new();
        }
    }

    // Cleanup markdown webview and timer (outside lock)
    let _ = KillTimer(Some(hwnd), 2);
    markdown_view::destroy_markdown_webview(hwnd);

    // Unregister from button canvas (outside lock to prevent deadlock)
    button_canvas::unregister_markdown_window(hwnd);

    // Close all other windows in the same chain (after dropping the lock)
    for other_hwnd in windows_to_close {
        if other_hwnd != hwnd {
            let _ = PostMessageW(Some(other_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
    }

    LRESULT(0)
}

pub unsafe fn handle_paint(hwnd: HWND) -> LRESULT {
    paint::paint_window(hwnd);
    LRESULT(0)
}

pub unsafe fn handle_keydown() -> LRESULT {
    LRESULT(0)
}

pub unsafe fn handle_create_webview(hwnd: HWND) -> LRESULT {
    // Get the text to render
    let (full_text, is_hovered) = {
        let states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get(&(hwnd.0 as isize)) {
            (state.full_text.clone(), state.is_hovered)
        } else {
            (String::new(), false)
        }
    };

    if markdown_view::has_markdown_webview(hwnd) {
        // WebView was pre-created, just show and update it
        markdown_view::update_markdown_content(hwnd, &full_text);
        markdown_view::show_markdown_webview(hwnd);
        markdown_view::resize_markdown_webview(hwnd, is_hovered);
        markdown_view::fit_font_to_window(hwnd);
        // Register with button canvas for floating buttons
        button_canvas::register_markdown_window(hwnd);
    } else {
        // Try to create WebView
        let result = markdown_view::create_markdown_webview(hwnd, &full_text, is_hovered);
        if !result {
            // Failed to create - revert markdown mode
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                state.is_markdown_mode = false;
            }
        } else {
            markdown_view::resize_markdown_webview(hwnd, is_hovered);
            markdown_view::fit_font_to_window(hwnd);
            // Register with button canvas for floating buttons
            button_canvas::register_markdown_window(hwnd);
        }
    }

    // IMPORTANT: If refine input is active, resize markdown to leave room for it
    // AND bring refine input to top so it stays visible
    // NOTE: Refine input is now part of button_canvas (overlay), so no resizing needed.

    let _ = InvalidateRect(Some(hwnd), None, false);
    LRESULT(0)
}

pub unsafe fn handle_show_markdown(hwnd: HWND) -> LRESULT {
    markdown_view::show_markdown_webview(hwnd);
    let _ = InvalidateRect(Some(hwnd), None, false);
    LRESULT(0)
}

pub unsafe fn handle_hide_markdown(hwnd: HWND) -> LRESULT {
    markdown_view::hide_markdown_webview(hwnd);
    let _ = InvalidateRect(Some(hwnd), None, false);
    LRESULT(0)
}

pub unsafe fn handle_resize_markdown(hwnd: HWND) -> LRESULT {
    let is_hovered = {
        let states = WINDOW_STATES.lock().unwrap();
        states
            .get(&(hwnd.0 as isize))
            .map(|s| s.is_hovered)
            .unwrap_or(false)
    };
    markdown_view::resize_markdown_webview(hwnd, is_hovered);
    markdown_view::fit_font_to_window(hwnd);
    LRESULT(0)
}

pub unsafe fn handle_back_click(hwnd: HWND) -> LRESULT {
    markdown_view::go_back(hwnd);
    LRESULT(0)
}

pub unsafe fn handle_forward_click(hwnd: HWND) -> LRESULT {
    markdown_view::go_forward(hwnd);
    LRESULT(0)
}

pub unsafe fn handle_download_click(hwnd: HWND) -> LRESULT {
    let text = {
        let states = WINDOW_STATES.lock().unwrap();
        states
            .get(&(hwnd.0 as isize))
            .map(|s| s.full_text.clone())
            .unwrap_or_default()
    };
    if !text.is_empty() {
        markdown_view::save_html_file(&text);
    }
    LRESULT(0)
}
</file>

<file path="src/overlay/result/event_handler/timer_tasks.rs">
use super::super::logic;
use crate::overlay::result::markdown_view;

use crate::overlay::result::state::WINDOW_STATES;
use crate::overlay::utils::to_wstring;
use std::time::{SystemTime, UNIX_EPOCH};
use windows::core::PCWSTR;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::InvalidateRect;
use windows::Win32::UI::WindowsAndMessaging::*;

pub unsafe fn handle_timer(hwnd: HWND, wparam: WPARAM) -> LRESULT {
    let timer_id = wparam.0;

    // Timer ID 2: Markdown hover polling (The Authority on WebView Sizing)
    if timer_id == 2 {
        let mut cursor_pos = POINT::default();
        let _ = GetCursorPos(&mut cursor_pos);
        let mut window_rect = RECT::default();
        let _ = GetWindowRect(hwnd, &mut window_rect);

        // Check if cursor is geometrically inside the window rect
        let cursor_inside = cursor_pos.x >= window_rect.left
            && cursor_pos.x < window_rect.right
            && cursor_pos.y >= window_rect.top
            && cursor_pos.y < window_rect.bottom;

        let (is_markdown_mode, current_hover_state) = {
            let states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get(&(hwnd.0 as isize)) {
                (state.is_markdown_mode, state.is_hovered)
            } else {
                (false, false)
            }
        };

        if is_markdown_mode {
            // State change detection
            if cursor_inside && !current_hover_state {
                // Enter: Mark hovered -> Shrink WebView -> Buttons visible
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.is_hovered = true;
                    }
                }
                markdown_view::resize_markdown_webview(hwnd, true);
                markdown_view::fit_font_to_window(hwnd);
                let _ = InvalidateRect(Some(hwnd), None, false);
            } else if !cursor_inside && current_hover_state {
                // Leave: Mark unhovered -> Expand WebView -> Clean look
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.is_hovered = false;
                        state.on_copy_btn = false;
                        state.on_undo_btn = false;
                        state.on_markdown_btn = false;
                        state.on_download_btn = false;
                        state.on_back_btn = false;
                        state.on_forward_btn = false;
                    }
                }
                markdown_view::resize_markdown_webview(hwnd, false);
                markdown_view::fit_font_to_window(hwnd);
                let _ = InvalidateRect(Some(hwnd), None, false);
            }
        }

        return LRESULT(0);
    }

    // Timer ID 1 and other timers: existing logic
    let mut need_repaint = false;

    let mut pending_update: Option<String> = None;
    let now = SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .map(|d| d.as_millis() as u32)
        .unwrap_or(0);

    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            // Handle animation updates if refining
            if state.is_refining {
                state.animation_offset -= 8.0;
                if state.animation_offset < -3600.0 {
                    state.animation_offset += 3600.0;
                }

                // Refresh markdown WebView when refinement starts to show the context quote
                if state.is_markdown_mode && state.font_cache_dirty {
                    state.font_cache_dirty = false;
                    markdown_view::update_markdown_content_ex(
                        hwnd,
                        &state.full_text,
                        true,
                        &state.preset_prompt,
                        &state.input_text,
                    );
                }

                need_repaint = true;
            }

            // Detect streaming end transition to force flush remaining text
            // When streaming was active but is now inactive, we must render any leftover text
            let streaming_just_ended = state.was_streaming_active && !state.is_streaming_active;
            if streaming_just_ended {
                state.was_streaming_active = false;
            }

            // Safety: If streaming is NOT active, always process pending text immediately
            // This ensures any leftover text is rendered even if streaming_just_ended was missed
            let not_streaming = !state.is_streaming_active;

            // Track if we need to force font cache dirty (bypass 200ms throttle)
            // This is critical for rendering the final text after streaming ends

            // Throttle - but bypass if:
            // 1. streaming_just_ended (transition detection)
            // 2. not_streaming (any pending text after streaming should render immediately)
            // 3. first update (last_text_update_time == 0)
            // 4. throttle expired (>16ms since last update)
            if state.pending_text.is_some()
                && (streaming_just_ended
                    || not_streaming
                    || state.last_text_update_time == 0
                    || now.wrapping_sub(state.last_text_update_time) > 16)
            {
                pending_update = state.pending_text.take();
                state.last_text_update_time = now;

                // CRITICAL: When streaming ends, force font recalculation
                // to ensure the final text is properly rendered (bypass 200ms throttle)
                if not_streaming {
                    state.font_cache_dirty = true;
                }
            }

            // Note: Native EDIT control handling removed - both plain text and markdown modes
            // now use WebView-based refine input. Polling happens outside the lock below.
        }
    }

    if let Some(txt) = pending_update {
        let (maybe_markdown_update, is_hovered, is_markdown_streaming, is_streaming) = {
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                // 200ms font recalc throttling during streaming/text updates
                let now = SystemTime::now()
                    .duration_since(UNIX_EPOCH)
                    .map(|d| d.as_millis() as u32)
                    .unwrap_or(0);
                let time_since_last_calc = now.wrapping_sub(state.last_font_calc_time);
                if time_since_last_calc >= 200 || state.last_font_calc_time == 0 {
                    state.font_cache_dirty = true;
                    state.last_font_calc_time = now;
                }
                state.full_text = txt.clone();

                if state.is_markdown_mode && !state.is_refining {
                    (
                        Some(state.full_text.clone()),
                        state.is_hovered,
                        state.is_markdown_streaming,
                        state.is_streaming_active,
                    )
                } else {
                    (None, false, false, false)
                }
            } else {
                (None, false, false, false)
            }
        };

        if let Some(md_text) = maybe_markdown_update {
            // MARKDOWN MODE - OPTIMIZED PATH
            // Skip SetWindowTextW and InvalidateRect to prevent double-rendering lag behind WebView

            // Use streaming-optimized update for markdown_stream mode during active streaming
            if is_markdown_streaming && is_streaming {
                let now = SystemTime::now()
                    .duration_since(UNIX_EPOCH)
                    .map(|d| d.as_millis() as u32)
                    .unwrap_or(0);

                let mut should_update_webview = false;
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        let time_since_last_webview =
                            now.wrapping_sub(state.last_webview_update_time);
                        if time_since_last_webview >= 80 || state.last_webview_update_time == 0 {
                            state.last_webview_update_time = now;
                            should_update_webview = true;
                        }
                    }
                }

                if should_update_webview {
                    markdown_view::stream_markdown_content(hwnd, &md_text);
                    // Register with button canvas (may already be registered, that's fine)
                    crate::overlay::result::button_canvas::register_markdown_window(hwnd);
                }
            } else if is_markdown_streaming && !is_streaming {
                // Streaming just ended in markdown_stream mode
                // Render the FINAL content first (in case last chunks weren't rendered due to throttling)
                markdown_view::stream_markdown_content(hwnd, &md_text);
                // Initialize Grid.js on any tables
                markdown_view::init_gridjs(hwnd);
                // Fit font to fill any unfilled space
                markdown_view::fit_font_to_window(hwnd);
                // Now reset for next session
                markdown_view::reset_stream_counter(hwnd);
                // Reset throttle for next time
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.last_webview_update_time = 0;
                    }
                }
                // Register with button canvas
                crate::overlay::result::button_canvas::register_markdown_window(hwnd);
            } else {
                // Regular markdown mode (not streaming) - full render
                markdown_view::reset_stream_counter(hwnd);
                markdown_view::create_markdown_webview(hwnd, &md_text, is_hovered);
                // Fit font to fill any unfilled space
                markdown_view::fit_font_to_window(hwnd);
                // Register with button canvas
                crate::overlay::result::button_canvas::register_markdown_window(hwnd);
            }

            // Do NOT set need_repaint = true here.
            // The WebView handles the display. Repainting parent window is wasteful and causes lag.
        } else {
            // PLAIN TEXT MODE (or Refining) - LEGACY PATH
            // Must update window text and trigger GDI repaint
            let wide_text = to_wstring(&txt);
            let _ = SetWindowTextW(hwnd, PCWSTR(wide_text.as_ptr()));
            need_repaint = true;
        }
    }

    logic::handle_timer(hwnd, wparam);
    if need_repaint {
        let _ = InvalidateRect(Some(hwnd), None, false);
    }
    LRESULT(0)
}
</file>

<file path="src/overlay/result/layout.rs">
use super::state::{ResizeEdge, WINDOW_STATES};
use windows::Win32::Foundation::{HWND, RECT};
use windows::Win32::UI::WindowsAndMessaging::{GetWindowRect, IsWindow, IsWindowVisible};

/// Determine if overlay buttons should be displayed based on window dimensions.
/// - Returns false when width is too small (would overlap with broom cursor/content)
/// - Returns true when width is adequate, even if height is small (buttons are right-aligned, center-vertical)
pub fn should_show_buttons(_window_w: i32, _window_h: i32) -> bool {
    // Buttons are now rendered by the button_canvas overlay, so we disable the inline ones.
    false
}

/// Check if two RECTs overlap (with a gap margin)
fn rects_overlap(a: &RECT, b: &RECT, gap: i32) -> bool {
    // Expand both rects by gap/2 to account for minimum gap between windows
    let half_gap = gap / 2;
    !(a.right + half_gap <= b.left - half_gap
        || b.right + half_gap <= a.left - half_gap
        || a.bottom + half_gap <= b.top - half_gap
        || b.bottom + half_gap <= a.top - half_gap)
}

/// Get RECTs of all currently visible result overlay windows
/// This provides intelligent detection of existing windows for collision avoidance
fn get_all_active_window_rects() -> Vec<RECT> {
    let mut rects = Vec::new();

    // Lock WINDOW_STATES to get all tracked overlay windows
    if let Ok(states) = WINDOW_STATES.lock() {
        for (&hwnd_key, _state) in states.iter() {
            let hwnd = HWND(hwnd_key as *mut std::ffi::c_void);
            unsafe {
                // Verify window is still valid and VISIBLE
                // We check visibility because windows being closed are hidden immediately
                // but might take a few milliseconds to be removed from WINDOW_STATES.
                if IsWindow(Some(hwnd)).as_bool() && IsWindowVisible(hwnd).as_bool() {
                    let mut rect = RECT::default();
                    if GetWindowRect(hwnd, &mut rect).is_ok() {
                        rects.push(rect);
                    }
                }
            }
        }
    }

    rects
}

/// Check if a proposed RECT overlaps with any existing window
fn would_overlap_existing(proposed: &RECT, existing: &[RECT], gap: i32) -> bool {
    existing.iter().any(|r| rects_overlap(proposed, r, gap))
}

/// Calculate the next window position with intelligent collision detection.
///
/// This improved algorithm:
/// 1. Collects all active overlay windows from WINDOW_STATES
/// 2. Tries positions in order: Right -> Bottom -> Left -> Top
/// 3. Checks each candidate against ALL existing windows (not just the previous one)
/// 4. Falls back to cascade positioning if all directions are blocked
///
/// Similar to the intelligent layout in node_graph.rs blocks_to_snarl()
pub fn calculate_next_window_rect(prev: RECT, monitor_rect: RECT) -> RECT {
    let gap = 15;
    let w = (prev.right - prev.left).abs();
    let h = (prev.bottom - prev.top).abs();

    // Get all active window RECTs for collision detection
    let existing_windows = get_all_active_window_rects();

    // 1. Try RIGHT
    let right_candidate = RECT {
        left: prev.right + gap,
        top: prev.top,
        right: prev.right + gap + w,
        bottom: prev.bottom,
    };
    if right_candidate.right <= monitor_rect.right
        && !would_overlap_existing(&right_candidate, &existing_windows, gap)
    {
        return right_candidate;
    }

    // 2. Try BOTTOM
    let bottom_candidate = RECT {
        left: prev.left,
        top: prev.bottom + gap,
        right: prev.right,
        bottom: prev.bottom + gap + h,
    };
    if bottom_candidate.bottom <= monitor_rect.bottom
        && !would_overlap_existing(&bottom_candidate, &existing_windows, gap)
    {
        return bottom_candidate;
    }

    // 3. Try LEFT
    let left_candidate = RECT {
        left: prev.left - gap - w,
        top: prev.top,
        right: prev.left - gap,
        bottom: prev.bottom,
    };
    if left_candidate.left >= monitor_rect.left
        && !would_overlap_existing(&left_candidate, &existing_windows, gap)
    {
        return left_candidate;
    }

    // 4. Try TOP
    let top_candidate = RECT {
        left: prev.left,
        top: prev.top - gap - h,
        right: prev.right,
        bottom: prev.top - gap,
    };
    if top_candidate.top >= monitor_rect.top
        && !would_overlap_existing(&top_candidate, &existing_windows, gap)
    {
        return top_candidate;
    }

    // 5. Try diagonals if cardinal directions are blocked
    let diagonals = [
        // Bottom-Right
        RECT {
            left: prev.right + gap,
            top: prev.bottom + gap,
            right: prev.right + gap + w,
            bottom: prev.bottom + gap + h,
        },
        // Bottom-Left
        RECT {
            left: prev.left - gap - w,
            top: prev.bottom + gap,
            right: prev.left - gap,
            bottom: prev.bottom + gap + h,
        },
        // Top-Right
        RECT {
            left: prev.right + gap,
            top: prev.top - gap - h,
            right: prev.right + gap + w,
            bottom: prev.top - gap,
        },
        // Top-Left
        RECT {
            left: prev.left - gap - w,
            top: prev.top - gap - h,
            right: prev.left - gap,
            bottom: prev.top - gap,
        },
    ];

    for diag in diagonals {
        if diag.left >= monitor_rect.left
            && diag.right <= monitor_rect.right
            && diag.top >= monitor_rect.top
            && diag.bottom <= monitor_rect.bottom
            && !would_overlap_existing(&diag, &existing_windows, gap)
        {
            return diag;
        }
    }

    // 6. Cascade fallback: find a non-overlapping cascade position
    for cascade_mult in 1..10 {
        let offset = 40 * cascade_mult;
        let cascade = RECT {
            left: prev.left + offset,
            top: prev.top + offset,
            right: prev.left + offset + w,
            bottom: prev.top + offset + h,
        };

        // Clamp to screen bounds
        if cascade.right <= monitor_rect.right
            && cascade.bottom <= monitor_rect.bottom
            && !would_overlap_existing(&cascade, &existing_windows, gap)
        {
            return cascade;
        }
    }

    // 7. Ultimate fallback: just use the simple cascade (may overlap)
    RECT {
        left: prev.left + 40,
        top: prev.top + 40,
        right: prev.left + 40 + w,
        bottom: prev.top + 40 + h,
    }
}

pub fn get_copy_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let btn_size = 28;
    let margin = 12;
    let threshold_h = btn_size + (margin * 2);
    let top = if window_h < threshold_h {
        (window_h - btn_size) / 2
    } else {
        window_h - margin - btn_size
    };

    RECT {
        left: window_w - margin - btn_size,
        top,
        right: window_w - margin,
        bottom: top + btn_size,
    }
}

pub fn get_edit_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let speaker_rect = get_speaker_btn_rect(window_w, window_h);
    let gap = 8;
    let width = speaker_rect.right - speaker_rect.left;
    RECT {
        left: speaker_rect.left - width - gap,
        top: speaker_rect.top,
        right: speaker_rect.left - gap,
        bottom: speaker_rect.bottom,
    }
}

// Markdown button is between Edit and Copy buttons
pub fn get_markdown_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let edit_rect = get_edit_btn_rect(window_w, window_h);
    let gap = 8;
    let width = edit_rect.right - edit_rect.left;
    RECT {
        left: edit_rect.left - width - gap,
        top: edit_rect.top,
        right: edit_rect.left - gap,
        bottom: edit_rect.bottom,
    }
}

// Download HTML button is between Markdown and Undo buttons
pub fn get_download_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let md_rect = get_markdown_btn_rect(window_w, window_h);
    let gap = 8;
    let width = md_rect.right - md_rect.left;
    RECT {
        left: md_rect.left - width - gap,
        top: md_rect.top,
        right: md_rect.left - gap,
        bottom: md_rect.bottom,
    }
}

pub fn get_undo_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let dl_rect = get_download_btn_rect(window_w, window_h);
    let gap = 8;
    let width = dl_rect.right - dl_rect.left;
    RECT {
        left: dl_rect.left - width - gap,
        top: dl_rect.top,
        right: dl_rect.left - gap,
        bottom: dl_rect.bottom,
    }
}

pub fn get_redo_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let undo_rect = get_undo_btn_rect(window_w, window_h);
    let gap = 8;
    let width = undo_rect.right - undo_rect.left;
    RECT {
        left: undo_rect.left - width - gap,
        top: undo_rect.top,
        right: undo_rect.left - gap,
        bottom: undo_rect.bottom,
    }
}

/// Speaker button for TTS - positioned left of copy button (rightmost after copy)
pub fn get_speaker_btn_rect(window_w: i32, window_h: i32) -> RECT {
    let copy_rect = get_copy_btn_rect(window_w, window_h);
    let gap = 8;
    let width = copy_rect.right - copy_rect.left;
    RECT {
        left: copy_rect.left - width - gap,
        top: copy_rect.top,
        right: copy_rect.left - gap,
        bottom: copy_rect.bottom,
    }
}

pub fn get_resize_edge(width: i32, height: i32, x: i32, y: i32) -> ResizeEdge {
    let margin = 8;
    let left = x < margin;
    let right = x >= width - margin;
    let top = y < margin;
    let bottom = y >= height - margin;

    if top && left {
        ResizeEdge::TopLeft
    } else if top && right {
        ResizeEdge::TopRight
    } else if bottom && left {
        ResizeEdge::BottomLeft
    } else if bottom && right {
        ResizeEdge::BottomRight
    } else if left {
        ResizeEdge::Left
    } else if right {
        ResizeEdge::Right
    } else if top {
        ResizeEdge::Top
    } else if bottom {
        ResizeEdge::Bottom
    } else {
        ResizeEdge::None
    }
}
</file>

<file path="src/overlay/screen_record/keyviz_config.json">
{
    "key_event_store": "{\"state\":{\"listening\":true,\"dragThreshold\":50,\"filter\":\"none\",\"allowedKeys\":[\"ControlLeft\",\"MetaLeft\",\"Alt\"],\"showEventHistory\":false,\"maxHistory\":2,\"lingerDurationMs\":1000,\"showMouseEvents\":true,\"toggleShortcut\":[\"ShiftLeft\",\"F10\"]},\"version\":0}",
    "key_style_store": "{\"state\":{\"appearance\":{\"monitor\":null,\"flexDirection\":\"column\",\"alignment\":\"bottom-center\",\"marginX\":100,\"marginY\":100,\"animation\":\"zoom\",\"animationDuration\":0.25,\"style\":\"lowprofile\"},\"layout\":{\"showIcon\":true,\"showSymbol\":true,\"showPressCount\":true,\"iconAlignment\":\"flex-end\"},\"color\":{\"color\":\"#ffffff\",\"secondaryColor\":\"#1a1a1a\",\"useGradient\":true},\"modifier\":{\"highlight\":false,\"color\":\"#3a86ff\",\"secondaryColor\":\"#000000\",\"textColor\":\"#000000\",\"borderColor\":\"#000000\"},\"text\":{\"size\":32,\"color\":\"#000000\",\"caps\":\"capitalize\",\"variant\":\"text-short\",\"alignment\":\"center\"},\"border\":{\"enabled\":true,\"width\":2,\"color\":\"#1a1a1a\",\"radius\":0.5},\"background\":{\"enabled\":true,\"color\":\"#ffffff99\"},\"mouse\":{\"showClicks\":false,\"size\":150,\"color\":\"#009dff\",\"keepHighlight\":false,\"showIndicator\":false,\"indicatorSize\":50,\"indicatorOffsetX\":50,\"indicatorOffsetY\":50}},\"version\":0}"
}
</file>

<file path="src/overlay/screen_record/keyviz.rs">
use std::fs;
use std::path::PathBuf;
use std::process::Command;
use std::sync::atomic::{AtomicBool, Ordering};

static KEYVIZ_RUNNING: AtomicBool = AtomicBool::new(false);
static KEYVIZ_ENABLED: AtomicBool = AtomicBool::new(false);

pub fn set_enabled(enabled: bool) {
    KEYVIZ_ENABLED.store(enabled, Ordering::SeqCst);
}

pub fn is_enabled() -> bool {
    KEYVIZ_ENABLED.load(Ordering::SeqCst)
}

pub fn get_keyviz_path() -> Option<PathBuf> {
    let local_app_data = std::env::var("LOCALAPPDATA").ok()?;
    let path = PathBuf::from(local_app_data).join("Programs\\Keyviz\\Keyviz.exe");
    if path.exists() {
        return Some(path);
    }
    // Check common Program Files locations
    let program_files = std::env::var("ProgramFiles").ok();
    if let Some(pf) = program_files {
        let path = PathBuf::from(pf).join("Keyviz\\Keyviz.exe");
        if path.exists() {
            return Some(path);
        }
    }

    // Check where command
    if let Ok(output) = Command::new("where").arg("Keyviz").output() {
        if output.status.success() {
            let s = String::from_utf8_lossy(&output.stdout);
            let p = PathBuf::from(s.trim());
            if p.exists() {
                return Some(p);
            }
        }
    }

    None
}

pub fn is_installed() -> bool {
    get_keyviz_path().is_some()
}

pub fn ensure_config() -> anyhow::Result<()> {
    let app_data = std::env::var("APPDATA")?;
    let config_dir = PathBuf::from(app_data).join("org.keyviz");
    if !config_dir.exists() {
        fs::create_dir_all(&config_dir)?;
    }

    let config_path = config_dir.join("store.json");

    // Read embedded config
    let config_content = include_str!("keyviz_config.json");

    // Optional: Only overwrite if it matches expected structure or user requested force reset?
    // User asked "with config file preconfigured". I'll overwrite it to ensure it matches.
    fs::write(config_path, config_content)?;

    Ok(())
}

pub fn start() -> anyhow::Result<()> {
    if !is_enabled() {
        return Ok(());
    }

    if let Some(path) = get_keyviz_path() {
        ensure_config()?;

        // Check if already running
        let output = Command::new("tasklist")
            .args(&["/FI", "IMAGENAME eq Keyviz.exe", "/NH"])
            .output()?;
        let output_str = String::from_utf8_lossy(&output.stdout);

        if !output_str.contains("Keyviz.exe") {
            crate::log_info!("Starting Keyviz from {:?}", path);
            Command::new(path).spawn()?;
            KEYVIZ_RUNNING.store(true, Ordering::SeqCst);
        } else {
            crate::log_info!("Keyviz already running");
            KEYVIZ_RUNNING.store(true, Ordering::SeqCst);
        }
    } else {
        crate::log_info!("Keyviz not found, cannot start");
    }
    Ok(())
}

pub fn stop() -> anyhow::Result<()> {
    // Only stop if we started it or we want to clean up?
    // User said "done recording turn the app off".
    if KEYVIZ_RUNNING.load(Ordering::SeqCst) || is_enabled() {
        crate::log_info!("Stopping Keyviz");
        Command::new("taskkill")
            .args(&["/IM", "Keyviz.exe", "/F"])
            .output()?;
        KEYVIZ_RUNNING.store(false, Ordering::SeqCst);
    }
    Ok(())
}

pub fn install_keyviz() -> anyhow::Result<()> {
    // 1. Get latest release
    let url = "https://api.github.com/repos/mulaRahul/keyviz/releases/latest";
    let resp = ureq::get(url)
        .header("User-Agent", "screen-goated-toolbox")
        .call()?;

    // Body needs to be converted to a reader
    let json: serde_json::Value = serde_json::from_reader(resp.into_body().into_reader())?;

    // Find asset
    let assets = json["assets"]
        .as_array()
        .ok_or(anyhow::anyhow!("No assets found"))?;

    // Look for setup exe
    let asset = assets
        .iter()
        .find(|a| {
            let name = a["name"].as_str().unwrap_or("");
            name.ends_with(".exe") && !name.contains("portable")
        })
        .ok_or(anyhow::anyhow!("No installer found"))?;

    let download_url = asset["browser_download_url"]
        .as_str()
        .ok_or(anyhow::anyhow!("No download URL"))?;
    let file_name = asset["name"].as_str().unwrap_or("keyviz_setup.exe");

    let temp_dir = std::env::temp_dir();
    let installer_path = temp_dir.join(file_name);

    crate::log_info!("Downloading Keyviz from {}", download_url);

    let response = ureq::get(download_url).call()?;
    let mut reader = response.into_body().into_reader();
    let mut file = fs::File::create(&installer_path)?;
    std::io::copy(&mut reader, &mut file)?;

    crate::log_info!("Running installer {:?}", installer_path);

    // Run installer
    // /S for silent? Many installers support it. NSIS usually supports /S. Electron-builder usually /S or /silent.
    // Try silent install first.
    let status = Command::new(&installer_path).arg("/S").status();

    if status.is_err() || !status.unwrap().success() {
        // If silent fails, try normal
        Command::new(&installer_path).spawn()?;
    }

    Ok(())
}
</file>

<file path="src/overlay/text_selection_webview/mod.rs">
use crate::APP;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc, Mutex, Once,
};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::System::DataExchange::*;
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::System::Memory::*;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;

mod html;

// Try to use the shared wrapper which likely implements what's needed
use crate::overlay::realtime_webview::state::HwndWrapper;

// Shared state struct (simplified for WebView)
struct TextSelectionState {
    hwnd: HWND,
    preset_idx: usize,
    is_selecting: bool,
    is_processing: bool,
    hook_handle: HHOOK,
    webview: Option<wry::WebView>,
}
unsafe impl Send for TextSelectionState {}

static SELECTION_STATE: Mutex<TextSelectionState> = Mutex::new(TextSelectionState {
    hwnd: HWND(std::ptr::null_mut()),
    preset_idx: 0,
    is_selecting: false,
    is_processing: false,
    hook_handle: HHOOK(std::ptr::null_mut()),
    webview: None,
});

static REGISTER_TAG_CLASS: Once = Once::new();

lazy_static::lazy_static! {
    pub static ref TAG_ABORT_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
}

pub fn is_active() -> bool {
    !SELECTION_STATE.lock().unwrap().hwnd.is_invalid()
}

pub fn cancel_selection() {
    TAG_ABORT_SIGNAL.store(true, Ordering::SeqCst);
    let hwnd = SELECTION_STATE.lock().unwrap().hwnd;
    unsafe {
        if !hwnd.is_invalid() {
            let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
    }
}

// Re-export processing function needed by logic (copied from original)
// Or better: keep original functions locally if possible, or import if moved.
// For now, I'll reproduce the necessary logic here since this module REPLACES the old one.

/// Try to process already-selected text instantly.
pub fn try_instant_process(preset_idx: usize) -> bool {
    unsafe {
        let original_clipboard = get_clipboard_text();
        if OpenClipboard(Some(HWND::default())).is_ok() {
            let _ = EmptyClipboard();
            let _ = CloseClipboard();
        }
        std::thread::sleep(std::time::Duration::from_millis(30));

        let send_input_event = |vk: u16, flags: KEYBD_EVENT_FLAGS| {
            let input = INPUT {
                r#type: INPUT_KEYBOARD,
                Anonymous: INPUT_0 {
                    ki: KEYBDINPUT {
                        wVk: VIRTUAL_KEY(vk),
                        dwFlags: flags,
                        time: 0,
                        dwExtraInfo: 0,
                        wScan: 0,
                    },
                },
            };
            SendInput(&[input], std::mem::size_of::<INPUT>() as i32);
        };

        send_input_event(VK_CONTROL.0, KEYBD_EVENT_FLAGS(0));
        std::thread::sleep(std::time::Duration::from_millis(15));
        send_input_event(0x43, KEYBD_EVENT_FLAGS(0));
        std::thread::sleep(std::time::Duration::from_millis(15));
        send_input_event(0x43, KEYEVENTF_KEYUP);
        std::thread::sleep(std::time::Duration::from_millis(15));
        send_input_event(VK_CONTROL.0, KEYEVENTF_KEYUP);

        let mut clipboard_text = String::new();
        for _ in 0..6 {
            std::thread::sleep(std::time::Duration::from_millis(20));
            clipboard_text = get_clipboard_text();
            if !clipboard_text.is_empty() {
                break;
            }
        }

        if clipboard_text.trim().is_empty() {
            if !original_clipboard.is_empty() {
                crate::overlay::utils::copy_to_clipboard(&original_clipboard, HWND::default());
            }
            return false;
        }

        process_selected_text(preset_idx, clipboard_text);
        true
    }
}

unsafe fn get_clipboard_text() -> String {
    let mut result = String::new();
    if OpenClipboard(Some(HWND::default())).is_ok() {
        if let Ok(h_data) = GetClipboardData(13u32) {
            let h_global: HGLOBAL = std::mem::transmute(h_data);
            let ptr = GlobalLock(h_global);
            if !ptr.is_null() {
                let size = GlobalSize(h_global);
                let wide_slice = std::slice::from_raw_parts(ptr as *const u16, size / 2);
                if let Some(end) = wide_slice.iter().position(|&c| c == 0) {
                    result = String::from_utf16_lossy(&wide_slice[..end]);
                }
            }
            let _ = GlobalUnlock(h_global);
        }
        let _ = CloseClipboard();
    }
    result
}

fn process_selected_text(preset_idx: usize, clipboard_text: String) {
    unsafe {
        let (is_master, _original_mode) = {
            let app = APP.lock().unwrap();
            let p = &app.config.presets[preset_idx];
            (p.is_master, p.text_input_mode.clone())
        };

        let final_preset_idx = if is_master {
            let mut cursor_pos = POINT { x: 0, y: 0 };
            let _ = GetCursorPos(&mut cursor_pos);
            let selected =
                crate::overlay::preset_wheel::show_preset_wheel("text", Some("select"), cursor_pos);
            if let Some(idx) = selected {
                idx
            } else {
                return;
            }
        } else {
            preset_idx
        };

        let (config, mut preset, screen_w, screen_h) = {
            let mut app = APP.lock().unwrap();
            app.config.active_preset_idx = final_preset_idx;
            (
                app.config.clone(),
                app.config.presets[final_preset_idx].clone(),
                GetSystemMetrics(SM_CXSCREEN),
                GetSystemMetrics(SM_CYSCREEN),
            )
        };

        preset.text_input_mode = "select".to_string();

        let center_rect = RECT {
            left: (screen_w - 700) / 2,
            top: (screen_h - 300) / 2,
            right: (screen_w + 700) / 2,
            bottom: (screen_h + 300) / 2,
        };
        let localized_name =
            crate::gui::settings_ui::get_localized_preset_name(&preset.id, &config.ui_language);
        let cancel_hotkey = preset
            .hotkeys
            .first()
            .map(|h| h.name.clone())
            .unwrap_or_default();

        crate::overlay::process::start_text_processing(
            clipboard_text,
            center_rect,
            config,
            preset,
            localized_name,
            cancel_hotkey,
        );
    }
}

unsafe extern "system" fn keyboard_hook_proc(code: i32, wparam: WPARAM, lparam: LPARAM) -> LRESULT {
    if code == HC_ACTION as i32 {
        let kbd_struct = &*(lparam.0 as *const KBDLLHOOKSTRUCT);
        if wparam.0 == WM_KEYDOWN as usize || wparam.0 == WM_SYSKEYDOWN as usize {
            if kbd_struct.vkCode == VK_ESCAPE.0 as u32 {
                TAG_ABORT_SIGNAL.store(true, Ordering::SeqCst);
                return LRESULT(1);
            }
        }
    }
    CallNextHookEx(None, code, wparam, lparam)
}

pub fn show_text_selection_tag(preset_idx: usize) {
    unsafe {
        // Scope 1: Check and Init
        {
            let mut state = SELECTION_STATE.lock().unwrap();
            if !state.hwnd.is_invalid() {
                // If already active, toggle off (cancel)
                // We need to drop the lock before calling cancel_selection to avoid deadlock
                // if cancel_selection tries to lock (it does).
                drop(state);
                cancel_selection();
                return;
            }

            state.preset_idx = preset_idx;
            state.is_selecting = false;
            state.is_processing = false;
            TAG_ABORT_SIGNAL.store(false, Ordering::SeqCst);
        }

        // Initialize COM for WebView
        unsafe {
            use windows::Win32::System::Com::*;
            let _ = CoInitializeEx(None, COINIT_APARTMENTTHREADED);
        }

        let instance = GetModuleHandleW(None).unwrap();
        let class_name = w!("SGT_TextTag_Web");

        REGISTER_TAG_CLASS.call_once(|| {
            let mut wc = WNDCLASSEXW::default();
            wc.cbSize = std::mem::size_of::<WNDCLASSEXW>() as u32;
            wc.lpfnWndProc = Some(tag_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
            wc.lpszClassName = class_name;
            wc.style = CS_HREDRAW | CS_VREDRAW;
            let _ = RegisterClassExW(&wc);
        });

        let hwnd = CreateWindowExW(
            // Key difference: WS_EX_TRANSPARENT + WS_EX_LAYERED for click-through and transparency
            WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_TRANSPARENT | WS_EX_NOACTIVATE,
            class_name,
            w!("SGT Tag Web"),
            WS_POPUP, // Initially hidden offscreen
            -1000,
            -1000,
            200,
            100, // Slightly taller for glow
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        {
            SELECTION_STATE.lock().unwrap().hwnd = hwnd;
        }

        // Install Keyboard Hook to swallow ESC
        let hook = SetWindowsHookExW(
            WH_KEYBOARD_LL,
            Some(keyboard_hook_proc),
            Some(GetModuleHandleW(None).unwrap().into()),
            0,
        );
        if let Ok(h) = hook {
            SELECTION_STATE.lock().unwrap().hook_handle = h;
        }

        // Initialize WebView
        let (is_dark, lang) = {
            let app = APP.lock().unwrap();
            let is_dark = match app.config.theme_mode {
                crate::config::ThemeMode::Dark => true,
                crate::config::ThemeMode::Light => false,
                crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
            };
            (is_dark, app.config.ui_language.clone())
        };

        let initial_text = match lang.as_str() {
            "vi" => "Bôi đen văn bản...",
            "ko" => "텍스트 선택...",
            _ => "Select text...",
        };

        let html = html::get_html(is_dark, initial_text);

        // Use ephemeral context to avoid lock issues
        let mut web_context = wry::WebContext::new(None);

        // Fix font loading: use data URL or robust loading
        let page_url = format!("data:text/html,{}", urlencoding::encode(&html));

        let builder = wry::WebViewBuilder::new_with_web_context(&mut web_context);
        let webview = {
            // LOCK SCOPE: Serialized build to prevent resource contention
            let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
            crate::log_info!("[SelectionV2] Acquired init lock. Building...");

            let build_res = builder
                .with_bounds(wry::Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(200, 100)),
                })
                .with_url(&page_url) // Use data URL directly for simplicity in this ephemeral window
                .with_transparent(true)
                .build_as_child(&HwndWrapper(hwnd));

            crate::log_info!(
                "[SelectionV2] Build finished. Status: {}",
                if build_res.is_ok() { "OK" } else { "ERR" }
            );
            build_res
        };

        if let Ok(webview) = webview {
            SELECTION_STATE.lock().unwrap().webview = Some(webview);
        } else {
            eprintln!("Failed to create TextSelection WebView");
        }

        let _ = ShowWindow(hwnd, SW_SHOWNOACTIVATE);

        let mut msg = MSG::default();

        // Game Loop
        loop {
            // 1. Process messages
            while PeekMessageW(&mut msg, None, 0, 0, PM_REMOVE).into() {
                if msg.message == WM_QUIT {
                    break;
                }
                let _ = TranslateMessage(&msg);
                DispatchMessageW(&msg);
            }
            if msg.message == WM_QUIT {
                break;
            }

            // 2. Abort check
            if TAG_ABORT_SIGNAL.load(Ordering::SeqCst) {
                cleaned_exit(hwnd);
                break;
            }

            // 3. Logic & Movement
            let mut pt = POINT::default();
            let _ = GetCursorPos(&mut pt);
            let target_x = pt.x - 30;
            let target_y = pt.y - 60; // Offset to sit above cursor

            // Move Window
            let _ = MoveWindow(hwnd, target_x, target_y, 200, 100, false);

            // Logic for selection state
            let lbutton_down = (GetAsyncKeyState(VK_LBUTTON.0 as i32) as u16 & 0x8000) != 0;
            let mut should_spawn_thread = false;
            let mut preset_idx_for_thread = 0;

            let update_js = {
                let mut state = SELECTION_STATE.lock().unwrap();

                let was_selecting = state.is_selecting;

                if !state.is_selecting && lbutton_down {
                    state.is_selecting = true;
                } else if state.is_selecting && !lbutton_down && !state.is_processing {
                    state.is_processing = true;
                    should_spawn_thread = true;
                    preset_idx_for_thread = state.preset_idx;
                }

                if state.is_selecting != was_selecting {
                    let new_text = if state.is_selecting {
                        match lang.as_str() {
                            "vi" => "Thả chuột để xử lý",
                            "ko" => "처리를 위해 마우스를 놓으세요",
                            _ => "Release to process",
                        }
                    } else {
                        initial_text
                    };

                    Some(format!(
                        "updateState({}, '{}')",
                        state.is_selecting, new_text
                    ))
                } else {
                    None
                }
            };

            if let Some(js) = update_js {
                if let Some(webview) = SELECTION_STATE.lock().unwrap().webview.as_ref() {
                    let _ = webview.evaluate_script(&js);
                }
            }

            // 4. Handle Thread Spawn
            if should_spawn_thread {
                let hwnd_val = hwnd.0 as isize;
                std::thread::spawn(move || {
                    let hwnd = HWND(hwnd_val as *mut _);
                    // logic similar to original, waiting for clipboard
                    // ...
                    // For brevity in this reimplantation step, I'll inline the core wait-and-process logic logic or reuse helpers?
                    // Cloning closure logic is cleanest to ensure thread safety
                    if TAG_ABORT_SIGNAL.load(Ordering::Relaxed) {
                        return;
                    }
                    std::thread::sleep(std::time::Duration::from_millis(50));

                    // Clear clipboard
                    if OpenClipboard(Some(HWND::default())).is_ok() {
                        let _ = EmptyClipboard();
                        let _ = CloseClipboard();
                    }

                    // Send Copy
                    // ... reuse key sending logic ...
                    let send_input_event = |vk: u16, flags: KEYBD_EVENT_FLAGS| {
                        let input = INPUT {
                            r#type: INPUT_KEYBOARD,
                            Anonymous: INPUT_0 {
                                ki: KEYBDINPUT {
                                    wVk: VIRTUAL_KEY(vk),
                                    dwFlags: flags,
                                    time: 0,
                                    dwExtraInfo: 0,
                                    wScan: 0,
                                },
                            },
                        };
                        SendInput(&[input], std::mem::size_of::<INPUT>() as i32);
                    };
                    send_input_event(VK_CONTROL.0, KEYBD_EVENT_FLAGS(0));
                    std::thread::sleep(std::time::Duration::from_millis(20));
                    send_input_event(0x43, KEYBD_EVENT_FLAGS(0));
                    std::thread::sleep(std::time::Duration::from_millis(20));
                    send_input_event(0x43, KEYEVENTF_KEYUP);
                    std::thread::sleep(std::time::Duration::from_millis(20));
                    send_input_event(VK_CONTROL.0, KEYEVENTF_KEYUP);

                    let mut clipboard_text = String::new();
                    for _ in 0..10 {
                        if TAG_ABORT_SIGNAL.load(Ordering::Relaxed) {
                            return;
                        }
                        std::thread::sleep(std::time::Duration::from_millis(25));
                        clipboard_text = get_clipboard_text();
                        if !clipboard_text.is_empty() {
                            break;
                        }
                    }

                    // We need to signal the MAIN loop to close.
                    // The HWND is valid.
                    // But we can't capture the HWND easily across threads safely if not Copy?
                    // HWND is Copy.
                    let hwnd_target = HWND(hwnd.0);

                    if !clipboard_text.trim().is_empty()
                        && !TAG_ABORT_SIGNAL.load(Ordering::Relaxed)
                    {
                        process_selected_text(preset_idx_for_thread, clipboard_text);
                        let _ = PostMessageW(Some(hwnd_target), WM_CLOSE, WPARAM(0), LPARAM(0));
                    } else {
                        // Reset state if no text found
                        // We need to synchronize this reset.
                        // But we can't easily access the mutex from here without Arc<Mutex>.
                        // Actually SELECTION_STATE is global static Mutex available everywhere.
                        let mut state = SELECTION_STATE.lock().unwrap();
                        state.is_selecting = false;
                        state.is_processing = false;
                    }
                });
            }

            // Sleep to yield CPU, standard framerate (~60fps)
            std::thread::sleep(std::time::Duration::from_millis(16));
        }

        // Ensure cleanup happens regardless of how the loop exited
        cleaned_exit(hwnd);
    }
}

unsafe fn cleaned_exit(hwnd: HWND) {
    let mut state = SELECTION_STATE.lock().unwrap();
    state.webview = None; // Drop WebView
    if !state.hook_handle.is_invalid() {
        let _ = UnhookWindowsHookEx(state.hook_handle);
        state.hook_handle = HHOOK::default();
    }
    state.hwnd = HWND::default();
    let _ = DestroyWindow(hwnd);
}

unsafe extern "system" fn tag_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    // catch unwind
    let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| match msg {
        WM_CLOSE => {
            TAG_ABORT_SIGNAL.store(true, Ordering::SeqCst);
            LRESULT(0)
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }));
    match result {
        Ok(lresult) => lresult,
        Err(_) => {
            eprintln!("Panic in tag_wnd_proc");
            // Try to provide default processing if panic occurred
            windows::Win32::UI::WindowsAndMessaging::DefWindowProcW(hwnd, msg, wparam, lparam)
        }
    }
}
</file>

<file path="src/registry_integration.rs">
use winreg::RegKey;
use winreg::enums::*;

// Image extensions supported by input handler
const IMAGE_EXTENSIONS: &[&str] = &[
    ".png", ".jpg", ".jpeg", ".gif", ".bmp", ".webp", ".ico", ".tiff", ".tif", ".svg",
];

// Audio extensions supported by input handler
const AUDIO_EXTENSIONS: &[&str] = &[
    ".wav", ".mp3", ".flac", ".ogg", ".m4a", ".aac", ".alac", ".aiff", ".aif", ".wma", ".opus",
    ".m4b",
];

// Expanded Text/Code extensions list
const TEXT_EXTENSIONS: &[&str] = &[
    ".txt",
    ".md",
    ".json",
    ".xml",
    ".rs",
    ".py",
    ".js",
    ".ts",
    ".tsx",
    ".jsx",
    ".html",
    ".css",
    ".scss",
    ".less",
    ".sql",
    ".java",
    ".cpp",
    ".c",
    ".h",
    ".hpp",
    ".cs",
    ".go",
    ".rb",
    ".php",
    ".sh",
    ".bat",
    ".ps1",
    ".cmd",
    ".yaml",
    ".yml",
    ".toml",
    ".ini",
    ".cfg",
    ".conf",
    ".gradle",
    ".properties",
    ".lua",
    ".swift",
    ".kt",
    ".kts",
    ".dart",
    ".R",
    ".pl",
    ".asm",
    ".vim",
    ".gitignore",
    ".env",
];

// Perceived types
const PERCEIVED_TYPES: &[&str] = &["text", "image", "audio"];

pub fn ensure_context_menu_entry() {
    let hkcu = RegKey::predef(HKEY_CURRENT_USER);

    // Current EXE path
    let exe_path = match std::env::current_exe() {
        Ok(path) => path,
        Err(_) => return,
    };
    let exe_path_str = exe_path.to_str().unwrap_or("");
    if exe_path_str.is_empty() {
        return;
    }

    // 1. Remove the old global entry if it exists (Cleanup)
    if let Ok(classes) = hkcu.open_subkey("Software\\Classes") {
        if let Ok(star) = classes.open_subkey("*") {
            if let Ok(shell) = star.open_subkey("shell") {
                let _ = shell.delete_subkey_all("SGT_Process");
                let _ = shell.delete_subkey_all("Process with SGT");
            }
        }
    }

    // 2. Register for specific extensions AND Perceived Types via SystemFileAssociations
    // Path: HKCU\Software\Classes\SystemFileAssociations\<Key>\shell\SGT_Process

    let all_keys: Vec<&str> = PERCEIVED_TYPES
        .iter()
        .chain(IMAGE_EXTENSIONS.iter())
        .chain(AUDIO_EXTENSIONS.iter())
        .chain(TEXT_EXTENSIONS.iter())
        .cloned()
        .collect();

    for key_name in all_keys {
        // Use SystemFileAssociations for robust context menu addition
        let path = format!(
            "Software\\Classes\\SystemFileAssociations\\{}\\shell\\SGT_Process",
            key_name
        );

        // We need to create the full path. create_subkey creates parents if missing.
        if let Ok((key, _)) = hkcu.create_subkey(&path) {
            let _ = key.set_value("", &"Process with SGT");
            let _ = key.set_value("Icon", &exe_path_str);

            // Command
            if let Ok((cmd_key, _)) = key.create_subkey("command") {
                let cmd_str = format!("\"{}\" \"%1\"", exe_path_str);
                let _ = cmd_key.set_value("", &cmd_str);
            }
        }
    }
}
</file>

<file path="src/updater.rs">
use std::sync::mpsc::Sender;
use std::thread;

#[derive(Debug, Clone)]
pub enum UpdateStatus {
    Idle,
    Checking,
    UpToDate(String), // Current version
    UpdateAvailable { version: String, body: String },
    Downloading,
    Error(String),
    UpdatedAndRestartRequired,
}

pub struct Updater {
    tx: Sender<UpdateStatus>,
}

impl Updater {
    pub fn new(tx: Sender<UpdateStatus>) -> Self {
        Self { tx }
    }

    pub fn check_for_updates(&self) {
        let tx = self.tx.clone();
        thread::spawn(move || {
            let _ = tx.send(UpdateStatus::Checking);

            // Use a custom manual request with a specific User-Agent to avoid 403 Forbidden
            // GitHub API requires a User-Agent, and self_update's default might be blocked or rate-limited.
            let url = "https://api.github.com/repos/nganlinh4/screen-goated-toolbox/releases?per_page=1&prerelease=false";

            // Use ureq 3.x API - create agent with config
            let config = ureq::Agent::config_builder()
                .timeout_global(Some(std::time::Duration::from_secs(10)))
                .build();
            let agent: ureq::Agent = config.into();

            let response = agent
                .get(url)
                .header("User-Agent", "screen-goated-toolbox-checker")
                .call();

            match response {
                Ok(mut resp) => {
                    let release_json: String = match resp.body_mut().read_to_string() {
                        Ok(s) => s,
                        Err(e) => {
                            let _ = tx.send(UpdateStatus::Error(format!(
                                "Failed to read response: {}",
                                e
                            )));
                            return;
                        }
                    };

                    let data: Result<Vec<serde_json::Value>, _> =
                        serde_json::from_str(&release_json);
                    match data {
                        Ok(mut releases) if !releases.is_empty() => {
                            let rel = releases.remove(0);
                            let tag_name =
                                rel.get("tag_name").and_then(|v| v.as_str()).unwrap_or("");
                            let version = tag_name.trim_start_matches('v').to_string();
                            let body = rel
                                .get("body")
                                .and_then(|v| v.as_str())
                                .unwrap_or("")
                                .to_string();

                            let current = env!("CARGO_PKG_VERSION");
                            let is_newer = self_update::version::bump_is_greater(current, &version)
                                .unwrap_or(false);

                            if is_newer {
                                let _ = tx.send(UpdateStatus::UpdateAvailable { version, body });
                            } else {
                                let _ = tx.send(UpdateStatus::UpToDate(current.to_string()));
                            }
                        }
                        Ok(_) => {
                            let _ = tx.send(UpdateStatus::Error(
                                "No releases found on GitHub".to_string(),
                            ));
                        }
                        Err(e) => {
                            let _ =
                                tx.send(UpdateStatus::Error(format!("JSON parse error: {}", e)));
                        }
                    }
                }
                Err(e) => {
                    let error_msg = {
                        let err_str = e.to_string();
                        if err_str.contains("403") {
                            "Status 403: GitHub API rate limit reached or access forbidden. Please try again later or check your network/VPN.".to_string()
                        } else {
                            format!("Network error: {}", e)
                        }
                    };
                    let _ = tx.send(UpdateStatus::Error(format!(
                        "Failed to fetch info: {}",
                        error_msg
                    )));
                }
            }
        });
    }

    pub fn perform_update(&self) {
        let tx = self.tx.clone();
        thread::spawn(move || {
            let _ = tx.send(UpdateStatus::Downloading);

            // Get current exe directory
            let exe_dir = match std::env::current_exe() {
                Ok(exe_path) => match exe_path.parent() {
                    Some(dir) => dir.to_path_buf(),
                    None => {
                        let _ = tx.send(UpdateStatus::Error(
                            "Could not find exe directory".to_string(),
                        ));
                        return;
                    }
                },
                Err(_) => {
                    let _ = tx.send(UpdateStatus::Error("Could not get exe path".to_string()));
                    return;
                }
            };

            let temp_path = exe_dir.join("temp_download");
            // We'll set this after getting the asset
            let mut staging_path = exe_dir.join("update_pending.exe");

            // Use a custom HTTP request to get the latest release (the one marked as "Latest" on GitHub)
            let release_json = match ureq::get("https://api.github.com/repos/nganlinh4/screen-goated-toolbox/releases?per_page=1&prerelease=false")
                .header("User-Agent", "screen-goated-toolbox-updater")
                .call()
            {
                Ok(mut response) => {
                    match response.body_mut().read_to_string() {
                        Ok(s) => s,
                        Err(e) => {
                            let _ = tx.send(UpdateStatus::Error(format!("Failed to parse response: {}", e)));
                            return;
                        }
                    }
                }
                Err(e) => {
                    let error_msg = {
                        let err_str = e.to_string();
                        if err_str.contains("403") {
                            "Status 403: GitHub API rate limit reached or access forbidden. Please try again later.".to_string()
                        } else {
                            format!("Failed to fetch release list: {}", e)
                        }
                    };
                    let _ = tx.send(UpdateStatus::Error(error_msg));
                    return;
                }
            };

            // Parse the JSON to get the first release
            let release_data: Result<Vec<serde_json::Value>, _> =
                serde_json::from_str(&release_json);
            let release = match release_data {
                Ok(mut releases) if !releases.is_empty() => {
                    let rel = releases.remove(0);
                    self_update::update::Release {
                        name: rel
                            .get("name")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        version: rel
                            .get("tag_name")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .trim_start_matches('v')
                            .to_string(),
                        date: rel
                            .get("published_at")
                            .and_then(|v| v.as_str())
                            .unwrap_or("")
                            .to_string(),
                        body: rel
                            .get("body")
                            .and_then(|v| v.as_str())
                            .map(|s| s.to_string()),
                        assets: rel
                            .get("assets")
                            .and_then(|a| a.as_array())
                            .unwrap_or(&vec![])
                            .iter()
                            .filter_map(|asset| {
                                let name = asset.get("name")?.as_str()?.to_string();
                                let download_url =
                                    asset.get("browser_download_url")?.as_str()?.to_string();
                                Some(self_update::update::ReleaseAsset { name, download_url })
                            })
                            .collect(),
                    }
                }
                _ => {
                    let _ = tx.send(UpdateStatus::Error("No releases found".to_string()));
                    return;
                }
            };

            // Find the .exe or .zip asset from release
            let asset = match release
                .assets
                .iter()
                .find(|a| a.name.ends_with(".exe") || a.name.ends_with(".zip"))
            {
                Some(a) => a,
                None => {
                    let _ = tx.send(UpdateStatus::Error(
                        "No .exe or .zip found in release assets".to_string(),
                    ));
                    return;
                }
            };

            // Set staging path to the asset name (for display) or update_pending.exe (for extraction)
            if asset.name.ends_with(".exe") {
                staging_path = exe_dir.join(&asset.name);
            }

            // Download the asset
            let mut file = match std::fs::File::create(&temp_path) {
                Ok(f) => f,
                Err(e) => {
                    let _ = tx.send(UpdateStatus::Error(format!(
                        "Failed to create temp file: {}",
                        e
                    )));
                    return;
                }
            };

            match ureq::get(&asset.download_url).call() {
                Ok(response) => {
                    let mut reader = response.into_body().into_reader();
                    if let Err(e) = std::io::copy(&mut reader, &mut file) {
                        let _ = tx.send(UpdateStatus::Error(format!("Download failed: {}", e)));
                        let _ = std::fs::remove_file(&temp_path);
                        return;
                    }
                    drop(file); // Close file before processing

                    // Process the downloaded file
                    if asset.name.ends_with(".zip") {
                        // Extract zip
                        match std::fs::File::open(&temp_path) {
                            Ok(zip_file) => match zip::ZipArchive::new(zip_file) {
                                Ok(mut archive) => match archive.by_index(0) {
                                    Ok(mut zipped_file) => {
                                        match std::fs::File::create(&staging_path) {
                                            Ok(mut exe_file) => {
                                                if std::io::copy(&mut zipped_file, &mut exe_file)
                                                    .is_ok()
                                                {
                                                    let _ = std::fs::remove_file(&temp_path);
                                                    let _ = tx.send(
                                                        UpdateStatus::UpdatedAndRestartRequired,
                                                    );
                                                } else {
                                                    let _ = tx.send(UpdateStatus::Error(
                                                        "Failed to extract zip".to_string(),
                                                    ));
                                                }
                                            }
                                            Err(e) => {
                                                let _ = tx.send(UpdateStatus::Error(format!(
                                                    "Failed to create staging file: {}",
                                                    e
                                                )));
                                            }
                                        }
                                    }
                                    Err(e) => {
                                        let _ = tx.send(UpdateStatus::Error(format!(
                                            "Failed to read zip entry: {}",
                                            e
                                        )));
                                    }
                                },
                                Err(e) => {
                                    let _ = tx.send(UpdateStatus::Error(format!(
                                        "Failed to open zip: {}",
                                        e
                                    )));
                                }
                            },
                            Err(e) => {
                                let _ = tx.send(UpdateStatus::Error(format!(
                                    "Failed to open temp file: {}",
                                    e
                                )));
                            }
                        }
                    } else {
                        // Direct exe - move to staging
                        match std::fs::rename(&temp_path, &staging_path) {
                            Ok(_) => {
                                let _ = tx.send(UpdateStatus::UpdatedAndRestartRequired);
                            }
                            Err(e) => {
                                let _ = tx.send(UpdateStatus::Error(format!(
                                    "Failed to stage exe: {}",
                                    e
                                )));
                            }
                        }
                    }
                }
                Err(e) => {
                    let _ = tx.send(UpdateStatus::Error(format!("Download failed: {}", e)));
                    let _ = std::fs::remove_file(&temp_path);
                }
            }
        });
    }
}
</file>

<file path="src/api/realtime_audio/state.rs">
//! Shared state for realtime transcription and translation

use std::sync::{Arc, Mutex};
use std::time::{Duration, Instant};

/// Timeout for User Silence (Wait for user to finish thought)
/// Reduced from 2000ms to 800ms for snappier response with Parakeet
pub const USER_SILENCE_TIMEOUT_MS: u64 = 800;
/// Timeout for AI Silence (Wait if AI stops generating)
pub const AI_SILENCE_TIMEOUT_MS: u64 = 1000;

/// Minimum characters required to trigger a force-commit on silence
const MIN_FORCE_COMMIT_CHARS: usize = 10;

// ============================================
// PARAKEET-SPECIFIC TIMEOUT CONSTANTS
// ============================================

pub const PARAKEET_BASE_TIMEOUT_MS: u64 = 800;
pub const PARAKEET_SHORT_TIMEOUT_MS: u64 = 1200;
pub const PARAKEET_MIN_WORDS: usize = 2;
pub const PARAKEET_MIN_TIMEOUT_MS: u64 = 350;
pub const PARAKEET_TIMEOUT_DECAY_RATE: f64 = 2.5;

/// Transcription method being used
#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub enum TranscriptionMethod {
    GeminiLive,
    Parakeet,
}

impl Default for TranscriptionMethod {
    fn default() -> Self {
        TranscriptionMethod::GeminiLive
    }
}

pub struct RealtimeState {
    pub full_transcript: String,
    pub display_transcript: String,

    /// Position after the last FULLY FINISHED sentence that was translated
    pub last_committed_pos: usize,
    /// The length of full_transcript when we last triggered a translation
    pub last_processed_len: usize,

    pub committed_translation: String,
    pub uncommitted_translation: String,
    pub display_translation: String,

    pub translation_history: Vec<(String, String)>,

    pub last_transcript_append_time: Instant,
    pub last_translation_update_time: Instant,

    pub is_downloading: bool,
    pub download_title: String,
    pub download_message: String,
    pub download_progress: f32,

    pub transcription_method: TranscriptionMethod,
    pub parakeet_segment_start_time: Instant,
}

impl RealtimeState {
    pub fn new() -> Self {
        Self {
            full_transcript: String::new(),
            display_transcript: String::new(),
            last_committed_pos: 0,
            last_processed_len: 0,
            committed_translation: String::new(),
            uncommitted_translation: String::new(),
            display_translation: String::new(),
            translation_history: Vec::new(),
            last_transcript_append_time: Instant::now(),
            last_translation_update_time: Instant::now(),
            is_downloading: false,
            download_title: String::new(),
            download_message: String::new(),
            download_progress: 0.0,
            transcription_method: TranscriptionMethod::GeminiLive,
            parakeet_segment_start_time: Instant::now(),
        }
    }

    fn update_display_transcript(&mut self) {
        self.display_transcript = self.full_transcript.clone();
    }

    fn update_display_translation(&mut self) {
        let full = if self.committed_translation.is_empty() {
            self.uncommitted_translation.clone()
        } else if self.uncommitted_translation.is_empty() {
            self.committed_translation.clone()
        } else {
            format!(
                "{} {}",
                self.committed_translation, self.uncommitted_translation
            )
        };
        self.display_translation = full;
    }

    pub fn append_transcript(&mut self, new_text: &str) {
        if self.transcription_method == TranscriptionMethod::Parakeet {
            if self.last_committed_pos >= self.full_transcript.len() {
                self.parakeet_segment_start_time = Instant::now();
            }
        }

        let mut text_to_append = new_text.to_string();

        if self.transcription_method == TranscriptionMethod::Parakeet {
            let needs_cap =
                self.full_transcript.trim().is_empty() || self.source_ends_with_sentence();

            if needs_cap {
                if let Some(first_char_idx) = text_to_append.find(|c: char| !c.is_whitespace()) {
                    let c = text_to_append.chars().nth(first_char_idx).unwrap();
                    let pre_space = &text_to_append[..first_char_idx];
                    let rest = &text_to_append[first_char_idx + 1..];
                    text_to_append = format!("{}{}{}", pre_space, c.to_uppercase(), rest);
                }
            }
        }

        self.full_transcript.push_str(&text_to_append);
        self.last_transcript_append_time = Instant::now();
        self.update_display_transcript();
    }

    pub fn set_transcription_method(&mut self, method: TranscriptionMethod) {
        self.transcription_method = method;
        if method == TranscriptionMethod::Parakeet {
            self.parakeet_segment_start_time = Instant::now();
        }
    }

    fn count_uncommitted_words(&self) -> usize {
        if self.last_committed_pos >= self.full_transcript.len() {
            return 0;
        }
        if !self
            .full_transcript
            .is_char_boundary(self.last_committed_pos)
        {
            return 0;
        }
        let uncommitted = &self.full_transcript[self.last_committed_pos..];
        uncommitted.split_whitespace().count()
    }

    fn calculate_parakeet_timeout_ms(&self) -> u64 {
        let word_count = self.count_uncommitted_words();

        // ADAPTIVE: Wait longer for short phrases to prevent cutting off sentences mid-thought
        if word_count < 5 {
            return PARAKEET_SHORT_TIMEOUT_MS; // 1200ms
        }

        let segment_len = if self.last_committed_pos >= self.full_transcript.len() {
            0
        } else if self
            .full_transcript
            .is_char_boundary(self.last_committed_pos)
        {
            self.full_transcript[self.last_committed_pos..].len()
        } else {
            0
        };

        let threshold = 30usize;
        if segment_len <= threshold {
            return PARAKEET_BASE_TIMEOUT_MS; // 800ms
        }

        let excess_chars = segment_len - threshold;
        let decay = (excess_chars as f64 * PARAKEET_TIMEOUT_DECAY_RATE) as u64;

        let timeout = PARAKEET_BASE_TIMEOUT_MS.saturating_sub(decay);
        timeout.max(PARAKEET_MIN_TIMEOUT_MS)
    }

    pub fn source_ends_with_sentence(&self) -> bool {
        let sentence_delimiters = ['.', '!', '?', '。', '！', '？'];
        if self.last_committed_pos >= self.full_transcript.len() {
            return false;
        }
        let uncommitted_source = &self.full_transcript[self.last_committed_pos..];
        uncommitted_source
            .trim()
            .chars()
            .last()
            .map(|c| sentence_delimiters.contains(&c))
            .unwrap_or(false)
    }

    pub fn should_force_commit_on_timeout(&self) -> bool {
        if self.transcription_method == TranscriptionMethod::Parakeet {
            if self.last_committed_pos >= self.full_transcript.len() {
                return false;
            }
            let word_count = self.count_uncommitted_words();
            if word_count < PARAKEET_MIN_WORDS {
                return false;
            }
            let now = Instant::now();
            let user_timeout = self.calculate_parakeet_timeout_ms();
            let user_silent = now.duration_since(self.last_transcript_append_time)
                > Duration::from_millis(user_timeout);

            return user_silent;
        }

        if self.uncommitted_translation.is_empty() {
            return false;
        }

        if self.last_committed_pos < self.full_transcript.len() {
            let pending_len = self.full_transcript.len() - self.last_committed_pos;
            if pending_len < MIN_FORCE_COMMIT_CHARS {
                return false;
            }
        }

        let now = Instant::now();
        let user_silent = now.duration_since(self.last_transcript_append_time)
            > Duration::from_millis(USER_SILENCE_TIMEOUT_MS);
        let ai_silent = now.duration_since(self.last_translation_update_time)
            > Duration::from_millis(AI_SILENCE_TIMEOUT_MS);

        let source_ready = self.source_ends_with_sentence()
            || self.last_committed_pos < self.full_transcript.len();

        source_ready && user_silent && ai_silent
    }

    pub fn force_commit_all(&mut self) {
        if self.transcription_method == TranscriptionMethod::Parakeet {
            if self.last_committed_pos < self.full_transcript.len()
                && !self.source_ends_with_sentence()
            {
                self.full_transcript.push_str(". ");
                self.update_display_transcript();
            }
            return;
        }

        if self.uncommitted_translation.is_empty() {
            return;
        }

        let trans_segment = self.uncommitted_translation.trim().to_string();

        if !trans_segment.is_empty() {
            let source_segment = if self.last_committed_pos < self.full_transcript.len() {
                self.full_transcript[self.last_committed_pos..]
                    .trim()
                    .to_string()
            } else {
                "[continued]".to_string()
            };

            self.add_to_history(source_segment, trans_segment.clone());

            if self.committed_translation.is_empty() {
                self.committed_translation = trans_segment;
            } else {
                self.committed_translation.push(' ');
                self.committed_translation.push_str(&trans_segment);
            }

            self.last_committed_pos = self.full_transcript.len();
            self.uncommitted_translation.clear();
        }

        self.update_display_translation();
    }

    /// Get text to translate.
    /// Returns: Option<(text_string, has_delimiter, byte_length_of_chunk)>
    pub fn get_translation_chunk(&self) -> Option<(String, bool, usize)> {
        if self.last_committed_pos >= self.full_transcript.len() {
            return None;
        }
        if !self
            .full_transcript
            .is_char_boundary(self.last_committed_pos)
        {
            return None;
        }

        let text = &self.full_transcript[self.last_committed_pos..];
        if text.trim().is_empty() {
            return None;
        }

        let sentence_delimiters = ['.', '!', '?', '。', '！', '？'];

        // Find the LAST delimiter in the chunk
        let mut split_idx: Option<usize> = None;
        for (i, c) in text.char_indices() {
            if sentence_delimiters.contains(&c) {
                // Include the delimiter length
                split_idx = Some(i + c.len_utf8());
            }
        }

        if let Some(idx) = split_idx {
            // Found delimiter. Return specific chunk and its exact length.
            let chunk = text[..idx].to_string();
            Some((chunk, true, idx))
        } else {
            // No delimiter. Return whole buffer, but length is 0 (don't commit yet).
            Some((text.to_string(), false, 0))
        }
    }

    pub fn is_transcript_unchanged(&self) -> bool {
        self.full_transcript.len() == self.last_processed_len
    }

    pub fn update_last_processed_len(&mut self) {
        self.last_processed_len = self.full_transcript.len();
    }

    /// Safely advance the commit pointer by a specific amount.
    /// Used to commit exactly what was translated, avoiding race conditions.
    pub fn advance_committed_pos(&mut self, amount: usize) {
        let new_pos = self.last_committed_pos + amount;

        // Safety bounds check
        if new_pos <= self.full_transcript.len() && self.full_transcript.is_char_boundary(new_pos) {
            self.last_committed_pos = new_pos;
        } else {
            // Fallback: if boundaries are messed up (rare), just go to end
            if new_pos > self.full_transcript.len() {
                self.last_committed_pos = self.full_transcript.len();
            }
        }
    }

    pub fn start_new_translation(&mut self) {
        self.uncommitted_translation.clear();
        self.update_display_translation();
    }

    pub fn commit_current_translation(&mut self) {
        let trans_segment = self.uncommitted_translation.trim().to_string();
        if !trans_segment.is_empty() {
            if self.committed_translation.is_empty() {
                self.committed_translation = trans_segment;
            } else {
                self.committed_translation.push(' ');
                self.committed_translation.push_str(&trans_segment);
            }
            self.uncommitted_translation.clear();
        }
        self.update_display_translation();
    }

    pub fn append_translation(&mut self, new_text: &str) {
        self.uncommitted_translation.push_str(new_text);
        self.last_translation_update_time = Instant::now();
        self.update_display_translation();
    }

    pub fn add_to_history(&mut self, source: String, translation: String) {
        self.translation_history.push((source, translation));
        while self.translation_history.len() > 3 {
            self.translation_history.remove(0);
        }
    }

    pub fn get_history_messages(&self, target_language: &str) -> Vec<serde_json::Value> {
        let mut messages = Vec::new();

        for (source, translation) in &self.translation_history {
            messages.push(serde_json::json!({
                "role": "user",
                "content": format!("Translate to {}:\n{}", target_language, source)
            }));
            messages.push(serde_json::json!({
                "role": "assistant",
                "content": translation
            }));
        }

        messages
    }
}

pub type SharedRealtimeState = Arc<Mutex<RealtimeState>>;
</file>

<file path="src/api/realtime_audio/translation.rs">
//! Translation loop for realtime audio

use isolang;
use std::io::BufRead;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc,
};
use std::time::{Duration, Instant};
use urlencoding;
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use crate::api::client::UREQ_AGENT;
use crate::config::Preset;
use crate::APP;

use super::state::SharedRealtimeState;
use super::utils::{refresh_transcription_window, update_translation_text};
use super::{TRANSLATION_INTERVAL_MS, WM_MODEL_SWITCH};

/// Translation loop using Cerebras' gpt-oss-120b model
pub fn run_translation_loop(
    preset: Preset,
    stop_signal: Arc<AtomicBool>,
    translation_hwnd_send: crate::win_types::SendHwnd,
    state: SharedRealtimeState,
) {
    let translation_hwnd = translation_hwnd_send.0;
    let interval = Duration::from_millis(TRANSLATION_INTERVAL_MS);
    let mut last_run = Instant::now();

    let translation_block = match preset.blocks.get(1) {
        Some(b) => b.clone(),
        None => return,
    };

    let mut target_language = {
        let from_ui = crate::overlay::realtime_webview::NEW_TARGET_LANGUAGE
            .lock()
            .ok()
            .and_then(|lang| {
                if lang.is_empty() {
                    None
                } else {
                    Some(lang.clone())
                }
            });

        from_ui.unwrap_or_else(|| {
            if !translation_block.selected_language.is_empty() {
                translation_block.selected_language.clone()
            } else {
                translation_block
                    .language_vars
                    .get("language")
                    .cloned()
                    .or_else(|| translation_block.language_vars.get("language1").cloned())
                    .unwrap_or_else(|| "English".to_string())
            }
        })
    };

    while !stop_signal.load(Ordering::Relaxed) {
        if translation_hwnd.0 != 0 as _ && !unsafe { IsWindow(Some(translation_hwnd)).as_bool() } {
            break;
        }

        if crate::overlay::realtime_webview::LANGUAGE_CHANGE.load(Ordering::SeqCst) {
            if let Ok(new_lang) = crate::overlay::realtime_webview::NEW_TARGET_LANGUAGE.lock() {
                if !new_lang.is_empty() {
                    target_language = new_lang.clone();
                    if let Ok(mut s) = state.lock() {
                        s.translation_history.clear();
                    }
                }
            }
            crate::overlay::realtime_webview::LANGUAGE_CHANGE.store(false, Ordering::SeqCst);
        }

        if crate::overlay::realtime_webview::TRANSLATION_MODEL_CHANGE.load(Ordering::SeqCst) {
            crate::overlay::realtime_webview::TRANSLATION_MODEL_CHANGE
                .store(false, Ordering::SeqCst);
        }

        // Timeout check
        {
            let should_force = { state.lock().unwrap().should_force_commit_on_timeout() };
            if should_force {
                if let Ok(mut s) = state.lock() {
                    s.force_commit_all();
                    let display = s.display_translation.clone();
                    update_translation_text(translation_hwnd, &display);
                    refresh_transcription_window();
                }
            }
        }

        if last_run.elapsed() >= interval {
            if !crate::overlay::realtime_webview::TRANS_VISIBLE.load(Ordering::SeqCst) {
                last_run = Instant::now();
                std::thread::sleep(Duration::from_millis(500));
                continue;
            }

            let (chunk, has_finished, bytes_to_commit, is_unchanged) = {
                let s = state.lock().unwrap();
                if s.is_transcript_unchanged() {
                    (None, false, 0, true)
                } else {
                    match s.get_translation_chunk() {
                        Some((text, has_finished, len)) => (Some(text), has_finished, len, false),
                        None => (None, false, 0, true),
                    }
                }
            };

            if is_unchanged {
                last_run = Instant::now();
                std::thread::sleep(Duration::from_millis(100));
                continue;
            }

            if let Some(chunk) = chunk {
                {
                    let mut s = state.lock().unwrap();
                    s.update_last_processed_len();
                    s.start_new_translation();
                }

                let (groq_key, gemini_key, cerebras_key, translation_model, history_messages) = {
                    let app = APP.lock().unwrap();
                    let groq = app.config.api_key.clone();
                    let gemini = app.config.gemini_api_key.clone();
                    let cerebras = app.config.cerebras_api_key.clone();
                    let model = app.config.realtime_translation_model.clone();
                    drop(app);
                    let history = if let Ok(s) = state.lock() {
                        s.get_history_messages(&target_language)
                    } else {
                        Vec::new()
                    };
                    (groq, gemini, cerebras, model, history)
                };

                let current_model = translation_model.as_str();
                let mut primary_failed = false;

                if current_model == "google-gtx" {
                    if let Some(text) = translate_with_google_gtx(&chunk, &target_language) {
                        if let Ok(mut s) = state.lock() {
                            s.append_translation(&text);
                            // Always commit source if finished, regardless of translation result
                            if has_finished {
                                s.commit_current_translation();
                                s.advance_committed_pos(bytes_to_commit);
                            }
                            let display = s.display_translation.clone();
                            update_translation_text(translation_hwnd, &display);
                        }
                    } else {
                        primary_failed = true;
                    }
                } else {
                    let is_google = current_model == "google-gemma";
                    let (url, model_name, api_key) = if is_google {
                        ("https://generativelanguage.googleapis.com/v1beta/openai/chat/completions".to_string(), "gemma-3-27b-it".to_string(), gemini_key.clone())
                    } else {
                        (
                            "https://api.cerebras.ai/v1/chat/completions".to_string(),
                            "gpt-oss-120b".to_string(),
                            cerebras_key.clone(),
                        )
                    };

                    let mut messages: Vec<serde_json::Value> = Vec::new();
                    let system_instruction = format!("You are a professional translator. Translate text to {} to append suitably to the context. Output ONLY the translation, nothing else.", target_language);

                    if is_google {
                        messages.extend(history_messages.clone());
                        messages.push(serde_json::json!({"role": "user", "content": format!("{}\n\nTranslate to {}:\n{}", system_instruction, target_language, chunk)}));
                    } else {
                        messages.push(
                            serde_json::json!({"role": "system", "content": system_instruction}),
                        );
                        messages.extend(history_messages.clone());
                        messages.push(serde_json::json!({"role": "user", "content": format!("Translate to {}:\n{}", target_language, chunk)}));
                    }

                    if !api_key.is_empty() {
                        let payload = serde_json::json!({"model": model_name, "messages": messages, "stream": true, "max_tokens": 512});
                        match UREQ_AGENT
                            .post(&url)
                            .header("Authorization", &format!("Bearer {}", api_key))
                            .header("Content-Type", "application/json")
                            .send_json(payload)
                        {
                            Ok(resp) => {
                                if !is_google {
                                    if let Some(remaining) = resp
                                        .headers()
                                        .get("x-ratelimit-remaining-requests-tokens")
                                        .and_then(|v| v.to_str().ok())
                                    {
                                        let limit = resp
                                            .headers()
                                            .get("x-ratelimit-limit-tokens")
                                            .and_then(|v| v.to_str().ok())
                                            .unwrap_or("?");
                                        if let Ok(mut app) = APP.lock() {
                                            app.model_usage_stats.insert(
                                                "gpt-oss-120b".to_string(),
                                                format!("{} / {}", remaining, limit),
                                            );
                                        }
                                    }
                                }
                                let reader =
                                    std::io::BufReader::new(resp.into_body().into_reader());
                                let mut full_translation = String::new();
                                for line in reader.lines().flatten() {
                                    if stop_signal.load(Ordering::Relaxed) {
                                        break;
                                    }
                                    if line.starts_with("data: ") {
                                        let json_str = &line["data: ".len()..];
                                        if json_str.trim() == "[DONE]" {
                                            break;
                                        }
                                        if let Ok(chunk_resp) =
                                            serde_json::from_str::<serde_json::Value>(json_str)
                                        {
                                            if let Some(content) = chunk_resp
                                                .get("choices")
                                                .and_then(|c| c.as_array())
                                                .and_then(|a| a.first())
                                                .and_then(|f| f.get("delta"))
                                                .and_then(|d| d.get("content"))
                                                .and_then(|t| t.as_str())
                                            {
                                                full_translation.push_str(content);
                                                if let Ok(mut s) = state.lock() {
                                                    s.append_translation(content);
                                                    let display = s.display_translation.clone();
                                                    update_translation_text(
                                                        translation_hwnd,
                                                        &display,
                                                    );
                                                }
                                            }
                                        }
                                    }
                                }

                                // FIXED: Commit exact bytes processed
                                if has_finished {
                                    if let Ok(mut s) = state.lock() {
                                        if !full_translation.is_empty() {
                                            s.commit_current_translation();
                                        }
                                        s.advance_committed_pos(bytes_to_commit);
                                    }
                                }
                            }
                            Err(_) => {
                                primary_failed = true;
                            }
                        }
                    } else {
                        primary_failed = true;
                    }
                }

                if primary_failed {
                    handle_fallback_translation(
                        &chunk,
                        &target_language,
                        current_model,
                        &groq_key,
                        &gemini_key,
                        &cerebras_key,
                        &history_messages,
                        has_finished,
                        bytes_to_commit,
                        translation_hwnd,
                        &state,
                        &stop_signal,
                    );
                }
            }
            last_run = Instant::now();
        }
        std::thread::sleep(Duration::from_millis(100));
    }
}

fn handle_fallback_translation(
    chunk: &str,
    target_language: &str,
    current_model: &str,
    _groq_key: &str,
    gemini_key: &str,
    cerebras_key: &str,
    history_messages: &[serde_json::Value],
    has_finished: bool,
    bytes_to_commit: usize,
    translation_hwnd: HWND,
    state: &SharedRealtimeState,
    stop_signal: &Arc<AtomicBool>,
) {
    let alt_model = if current_model == "cerebras-oss" {
        "google-gtx"
    } else if current_model == "google-gtx" {
        "cerebras-oss"
    } else {
        let pool = ["cerebras-oss", "google-gtx"];
        let nanos = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_nanos();
        pool[(nanos as usize) % pool.len()]
    };

    {
        let mut app = APP.lock().unwrap();
        app.config.realtime_translation_model = alt_model.to_string();
        crate::config::save_config(&app.config);
    }
    unsafe {
        let flag = match alt_model {
            "google-gemma" => 1,
            "google-gtx" => 2,
            _ => 0,
        };
        let _ = PostMessageW(
            Some(translation_hwnd),
            WM_MODEL_SWITCH,
            WPARAM(flag),
            LPARAM(0),
        );
    }

    if alt_model == "google-gtx" {
        if let Some(text) = translate_with_google_gtx(chunk, target_language) {
            if let Ok(mut s) = state.lock() {
                s.append_translation(&text);
                if has_finished {
                    s.commit_current_translation();
                    s.advance_committed_pos(bytes_to_commit);
                }
                let display = s.display_translation.clone();
                update_translation_text(translation_hwnd, &display);
            }
        }
    } else {
        let alt_is_google = alt_model == "google-gemma";
        let (alt_url, alt_model_name, alt_key) = if alt_is_google {
            (
                "https://generativelanguage.googleapis.com/v1beta/openai/chat/completions"
                    .to_string(),
                "gemma-3-27b-it".to_string(),
                gemini_key.to_string(),
            )
        } else {
            (
                "https://api.cerebras.ai/v1/chat/completions".to_string(),
                "gpt-oss-120b".to_string(),
                cerebras_key.to_string(),
            )
        };

        if !alt_key.is_empty() {
            let mut alt_msgs = Vec::new();
            let alt_sys = format!("You are a professional translator. Translate text to {} to append suitably to the context. Output ONLY the translation, nothing else.", target_language);
            if alt_is_google {
                alt_msgs.extend(history_messages.iter().cloned());
                alt_msgs.push(serde_json::json!({"role": "user", "content": format!("{}\n\nTranslate to {}:\n{}", alt_sys, target_language, chunk)}));
            } else {
                alt_msgs.push(serde_json::json!({"role": "system", "content": alt_sys}));
                alt_msgs.extend(history_messages.iter().cloned());
                alt_msgs.push(serde_json::json!({"role": "user", "content": format!("Translate to {}:\n{}", target_language, chunk)}));
            }
            let payload = serde_json::json!({"model": alt_model_name, "messages": alt_msgs, "stream": true, "max_tokens": 512});
            if let Ok(resp) = UREQ_AGENT
                .post(&alt_url)
                .header("Authorization", &format!("Bearer {}", alt_key))
                .header("Content-Type", "application/json")
                .send_json(payload)
            {
                if !alt_is_google {
                    if let Some(remaining) = resp
                        .headers()
                        .get("x-ratelimit-remaining-requests-tokens")
                        .and_then(|v| v.to_str().ok())
                    {
                        let limit = resp
                            .headers()
                            .get("x-ratelimit-limit-tokens")
                            .and_then(|v| v.to_str().ok())
                            .unwrap_or("?");
                        if let Ok(mut app) = APP.lock() {
                            app.model_usage_stats.insert(
                                "gpt-oss-120b".to_string(),
                                format!("{} / {}", remaining, limit),
                            );
                        }
                    }
                }
                let reader = std::io::BufReader::new(resp.into_body().into_reader());
                let mut full_t = String::new();
                for line in reader.lines().flatten() {
                    if stop_signal.load(Ordering::Relaxed) {
                        break;
                    }
                    if line.starts_with("data: ") {
                        let json_str = &line["data: ".len()..];
                        if json_str.trim() == "[DONE]" {
                            break;
                        }
                        if let Ok(c) = serde_json::from_str::<serde_json::Value>(json_str) {
                            if let Some(txt) = c
                                .get("choices")
                                .and_then(|a| a.as_array())
                                .and_then(|v| v.first())
                                .and_then(|f| f.get("delta"))
                                .and_then(|d| d.get("content"))
                                .and_then(|s| s.as_str())
                            {
                                full_t.push_str(txt);
                                if let Ok(mut s) = state.lock() {
                                    s.append_translation(txt);
                                    let d = s.display_translation.clone();
                                    update_translation_text(translation_hwnd, &d);
                                }
                            }
                        }
                    }
                }

                // FIXED: Commit exact bytes
                if has_finished {
                    if let Ok(mut s) = state.lock() {
                        if !full_t.is_empty() {
                            s.commit_current_translation();
                        }
                        s.advance_committed_pos(bytes_to_commit);
                    }
                }
            }
        }
    }
}

/// Unofficial Google Translate (GTX) fallback
pub fn translate_with_google_gtx(text: &str, target_lang: &str) -> Option<String> {
    let target_code = isolang::Language::from_name(target_lang)
        .and_then(|lang| lang.to_639_1())
        .map(|code| code.to_string())
        .unwrap_or_else(|| "en".to_string());

    let encoded_text = urlencoding::encode(text);
    let url = format!(
        "https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl={}&dt=t&q={}",
        target_code, encoded_text
    );

    match UREQ_AGENT
        .get(&url)
        .header("User-Agent", "Mozilla/5.0")
        .call()
    {
        Ok(resp) => {
            if let Ok(json) = resp.into_body().read_json::<serde_json::Value>() {
                if let Some(sentences) = json.get(0).and_then(|v| v.as_array()) {
                    let mut full_text = String::new();
                    for sentence_node in sentences {
                        if let Some(segment) = sentence_node.get(0).and_then(|s| s.as_str()) {
                            full_text.push_str(segment);
                        }
                    }
                    if !full_text.is_empty() {
                        return Some(full_text);
                    }
                }
            }
        }
        Err(_) => {}
    }
    None
}
</file>

<file path="src/config/preset/block.rs">
//! Processing Block - the fundamental unit of a processing chain.
//!
//! A block represents a single processing step (OCR, translation, TTS, etc.)
//! Multiple blocks can be chained together in a preset.

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

use crate::config::types::BlockType;

// ============================================================================
// PROCESSING BLOCK
// ============================================================================

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct ProcessingBlock {
    /// Unique identifier for this block
    #[serde(default = "generate_block_id")]
    pub id: String,

    /// Type of block: "input_adapter", "image", "text", "audio"
    #[serde(default)]
    pub block_type: String,

    /// Model ID to use for processing
    #[serde(default)]
    pub model: String,

    /// Prompt template (supports {language1}, {language2}, etc.)
    #[serde(default)]
    pub prompt: String,

    /// Primary selected language (legacy: maps to language_vars["language1"])
    #[serde(default)]
    pub selected_language: String,

    /// Language variable mappings for prompt template
    #[serde(default)]
    pub language_vars: HashMap<String, String>,

    /// Whether to stream the response
    #[serde(default = "default_true")]
    pub streaming_enabled: bool,

    /// Render mode: "stream", "plain", "markdown"
    #[serde(default = "default_render_mode")]
    pub render_mode: String,

    /// Whether to show the result overlay
    #[serde(default = "default_true")]
    pub show_overlay: bool,

    /// Auto-copy result to clipboard
    #[serde(default)]
    pub auto_copy: bool,

    /// Auto-speak result using TTS
    #[serde(default)]
    pub auto_speak: bool,
}

fn generate_block_id() -> String {
    format!(
        "{:x}",
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_nanos()
    )
}

fn default_true() -> bool {
    true
}

fn default_render_mode() -> String {
    "markdown_stream".to_string()
}

impl Default for ProcessingBlock {
    fn default() -> Self {
        Self {
            id: generate_block_id(),
            block_type: "text".to_string(),
            model: "text_accurate_kimi".to_string(),
            prompt: "Translate to {language1}. Output ONLY the translation.".to_string(),
            selected_language: "Vietnamese".to_string(),
            language_vars: HashMap::new(),
            streaming_enabled: true,
            render_mode: "markdown_stream".to_string(),
            show_overlay: true,
            auto_copy: false,
            auto_speak: false,
        }
    }
}

// ============================================================================
// BLOCK BUILDER - Fluent API for creating blocks
// ============================================================================

/// Builder for creating ProcessingBlocks with a fluent API.
///
/// # Example
/// ```
/// let block = BlockBuilder::text("text_accurate_kimi")
///     .prompt("Translate to {language1}.")
///     .language("Vietnamese")
///     .streaming(true)
///     .build();
/// ```
pub struct BlockBuilder {
    block: ProcessingBlock,
}

impl BlockBuilder {
    /// Create a new text processing block
    pub fn text(model: &str) -> Self {
        Self {
            block: ProcessingBlock {
                block_type: "text".to_string(),
                model: model.to_string(),
                ..Default::default()
            },
        }
    }

    /// Create a new image/vision processing block
    pub fn image(model: &str) -> Self {
        Self {
            block: ProcessingBlock {
                block_type: "image".to_string(),
                model: model.to_string(),
                streaming_enabled: false, // Vision models typically don't stream
                ..Default::default()
            },
        }
    }

    /// Create a new audio processing block
    pub fn audio(model: &str) -> Self {
        Self {
            block: ProcessingBlock {
                block_type: "audio".to_string(),
                model: model.to_string(),
                streaming_enabled: false,
                prompt: String::new(), // Audio blocks often don't need prompts
                ..Default::default()
            },
        }
    }

    /// Create an input adapter (pass-through) block
    pub fn input_adapter() -> Self {
        Self {
            block: ProcessingBlock {
                block_type: "input_adapter".to_string(),
                model: String::new(),
                prompt: String::new(),
                streaming_enabled: false,
                show_overlay: false,
                ..Default::default()
            },
        }
    }

    /// Set the prompt template
    pub fn prompt(mut self, prompt: &str) -> Self {
        self.block.prompt = prompt.to_string();
        self
    }

    /// Set the primary language (for {language1} substitution)
    pub fn language(mut self, lang: &str) -> Self {
        self.block.selected_language = lang.to_string();
        self.block
            .language_vars
            .insert("language1".to_string(), lang.to_string());
        self
    }

    /// Enable/disable streaming
    pub fn streaming(mut self, enabled: bool) -> Self {
        self.block.streaming_enabled = enabled;
        self
    }

    /// Shorthand for markdown render mode
    pub fn markdown(mut self) -> Self {
        self.block.render_mode = "markdown".to_string();
        self
    }

    /// Shorthand for markdown streaming render mode
    pub fn markdown_stream(mut self) -> Self {
        self.block.render_mode = "markdown_stream".to_string();
        self.block.streaming_enabled = true;
        self
    }

    /// Enable/disable overlay display
    pub fn show_overlay(mut self, show: bool) -> Self {
        self.block.show_overlay = show;
        self
    }

    /// Enable auto-copy to clipboard
    pub fn auto_copy(mut self) -> Self {
        self.block.auto_copy = true;
        self
    }

    /// Enable auto-speak (TTS)
    pub fn auto_speak(mut self) -> Self {
        self.block.auto_speak = true;
        self
    }

    /// Build the final ProcessingBlock
    pub fn build(self) -> ProcessingBlock {
        self.block
    }
}

// ============================================================================
// BLOCK TYPE HELPERS
// ============================================================================

impl ProcessingBlock {
    /// Check if this is an input adapter block
    pub fn is_input_adapter(&self) -> bool {
        self.block_type == "input_adapter"
    }

    /// Check if this is an image/vision block
    pub fn is_image(&self) -> bool {
        self.block_type == "image"
    }

    /// Check if this is a text block
    pub fn is_text(&self) -> bool {
        self.block_type == "text"
    }

    /// Check if this is an audio block
    pub fn is_audio(&self) -> bool {
        self.block_type == "audio"
    }

    /// Get the block type as enum
    pub fn block_type_enum(&self) -> BlockType {
        BlockType::from_str(&self.block_type)
    }
}
</file>

<file path="src/config/preset/defaults/image.rs">
//! Default image presets using the builder pattern.

use crate::config::preset::{BlockBuilder, PresetBuilder};
use crate::config::preset::Preset;
use crate::config::types::Hotkey;

/// Create all default image presets
pub fn create_image_presets() -> Vec<Preset> {
    vec![
        // =====================================================================
        // TRANSLATION PRESETS
        // =====================================================================
        
        // Translate - Basic image-to-text translation
        PresetBuilder::new("preset_translate", "Translate")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract text from this image and translate it to {language1}. Output ONLY the translation text directly, do not add introductory text.")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Stream -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // Translate (High accuracy) - OCR then translate
        {
            let mut p = PresetBuilder::new("preset_extract_retranslate", "Translate (High accuracy)")
                .image()
                .blocks(vec![
                    BlockBuilder::image("maverick")
                        .prompt("Extract all text from this image exactly as it appears. Output ONLY the text.")
                        .language("English")
                        .show_overlay(false)
                        .build(),
                    BlockBuilder::text("cerebras_qwen3")
                        .prompt("Translate to {language1}. Output ONLY the translation.")
                        .language("Vietnamese")
                        .markdown() // Upgraded: Thường -> Đẹp (Special: keeping non-streaming as requested by original logic for this specific preset)
                        .streaming(false)
                        .build(),
                ])
                .build();
            p.hotkeys.push(Hotkey::new(192, "` / ~", 0));
            p
        },

        // Translate (Auto paste) - Hidden overlay, auto-paste
        PresetBuilder::new("preset_translate_auto_paste", "Translate (Auto paste)")
            .image()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract text from this image and translate it to {language1}. Output ONLY the translation text directly, do not add introductory text.")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .markdown_stream() // Upgraded: Stream -> Đẹp+Str
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Translate+Retranslate - Korean then Vietnamese
        PresetBuilder::new("preset_translate_retranslate", "Translate+Retranslate")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract text from this image and translate it to {language1}. Output ONLY the translation text directly, do not add introductory text.")
                    .language("Korean")
                    .markdown() // Đẹp
                    .auto_copy()
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
            ])
            .build(),

        // Translate (Accurate)+Retranslate - Triple chain
        PresetBuilder::new("preset_extract_retrans_retrans", "Translate (Accurate)+Retranslate")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract all text from this image exactly as it appears. Output ONLY the text.")
                    .language("English")
                    .show_overlay(false)
                    .build(),
                BlockBuilder::text("cerebras_zai_glm_4_7")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Korean")
                    .markdown_stream() // Đẹp+Str
                    .auto_copy()
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
            ])
            .build(),

        // =====================================================================
        // EXTRACTION PRESETS
        // =====================================================================

        // Extract text (OCR)
        PresetBuilder::new("preset_ocr", "Extract text")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract all text from this image exactly as it appears. Output ONLY the text.")
                    .language("English")
                    .show_overlay(false)
                    .markdown() // Upgraded: Thường -> Đẹp
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Read this region - OCR with TTS
        PresetBuilder::new("preset_ocr_read", "Read this region")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract all text from this image exactly as it appears. Output ONLY the text.")
                    .language("English")
                    .show_overlay(false)
                    .markdown() // Upgraded: Thường -> Đẹp
                    .auto_speak()
                    .build(),
            ])
            .build(),

        // Quick Screenshot - Just capture and copy
        PresetBuilder::new("preset_quick_screenshot", "Quick Screenshot")
            .image()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Extract Table
        PresetBuilder::new("preset_extract_table", "Extract Table")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract all data from any tables, forms, or structured content in this image. Format the output as a markdown table. Output ONLY the table, no explanations.")
                    .language("Vietnamese")
                    .markdown()
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // QR Scanner - Scan and format QR code content
        PresetBuilder::new("preset_qr_scanner", "QR Scanner")
            .image()
            .blocks(vec![
                // Node 0: QR Scanner (non-LLM, extracts raw content)
                BlockBuilder::image("qr-scanner")
                    .prompt("") // QR scanner doesn't need a prompt
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
                // Node 1: Format the QR content nicely
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Format this QR code content for display. Rules:\n\
                        - If URL: Make it a clickable markdown link [URL](URL) and describe what this link points to\n\
                        - If vCard/contact: Format as a readable contact card with name, phone, email, address\n\
                        - If WiFi (WIFI:S:...): Extract and display SSID, password, and security type clearly\n\
                        - If plain text: Display as-is, translate if not in {language1}\n\
                        - If calendar event: Format as readable event with date/time/location\n\
                        - If email/SMS: Format with recipient and content clearly\n\
                        Output clean markdown. DO NOT include code blocks or backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // =====================================================================
        // ANALYSIS PRESETS
        // =====================================================================

        // Summarize content
        PresetBuilder::new("preset_summarize", "Summarize content")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Analyze this image and summarize its content in {language1}. Only return the summary text, super concisely. Format the output as a markdown. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // Image description
        PresetBuilder::new("preset_desc", "Image description")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Describe this image in {language1}. Format the output as a markdown. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // Ask about image - Dynamic prompt
        PresetBuilder::new("preset_ask_image", "Ask about image")
            .image()
            .dynamic_prompt()
            .blocks(vec![
                BlockBuilder::image("gemini-3-flash-preview")
                    .prompt("")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // =====================================================================
        // ADVANCED PRESETS
        // =====================================================================

        // Kiểm chứng thông tin (Fact Check)
        PresetBuilder::new("preset_fact_check", "Kiểm chứng thông tin")
            .image()
            .blocks(vec![
                BlockBuilder::image("maverick")
                    .prompt("Extract and describe all text, claims, statements, and information visible in this image. Include any context that might be relevant for fact-checking. Output the content clearly.")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .build(),
                BlockBuilder::text("compound_mini")
                    .prompt("Fact-check the following claims/information. Search the internet to verify accuracy. Provide a clear verdict (TRUE/FALSE/PARTIALLY TRUE/UNVERIFIABLE) for each claim with evidence and sources. Respond in {language1}. Format as markdown. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
            ])
            .build(),

        // Thần Trí tuệ (Omniscient God) - Complex branching graph
        PresetBuilder::new("preset_omniscient_god", "Thần Trí tuệ (Omniscient God)")
            .image()
            .blocks(vec![
                // Node 0: Extract from image
                BlockBuilder::image("maverick")
                    .prompt("Analyze this image and extract all text, claims, and key information. Be detailed and comprehensive.")
                    .language("English")
                    .markdown()
                    .build(),
                // Node 1: Make a learning HTML (from 0)
                BlockBuilder::text("cerebras_zai_glm_4_7")
                    .prompt("Create a standalone INTERACTIVE HTML learning card/game for the following text. Use internal CSS for a beautiful, modern, colored design, game-like and comprehensive interface. Only OUTPUT the raw HTML code, DO NOT include HTML file indicator (```html) or triple backticks.")
                    .language("Vietnamese")
                    .markdown()
                    .build(),
                // Node 2: Summarize with sources (from 3)
                BlockBuilder::text("compound_mini")
                    .prompt("Search the internet to ensure of the accuracy of the following text as well as getting as much source information as possible. Summarize the following text into a detailed markdown summary with clickable links to the sources. Structure it clearly. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
                // Node 3: Translate (from 0)
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
                // Node 4: Summarize keywords (from 3)
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Summarize the essence of this text into 3-5 keywords or a short phrase in {language1}.")
                    .markdown_stream() // Đẹp+Str
                    .language("Vietnamese")
                    .build(),
            ])
            .connections(vec![(0, 3), (0, 1), (3, 4), (3, 2)])
            .build(),

        // Treo ảnh - Input Adapter Only
        PresetBuilder::new("preset_hang_image", "Input Overlay (Image)")
            .image()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .show_overlay(true)
                    .markdown()
                    .build(),
            ])
            .build(),
    ]
}
</file>

<file path="src/gui/settings_ui/download_manager/persistence.rs">
use crate::gui::settings_ui::download_manager::types::{CookieBrowser, DownloadType};
use serde::{Deserialize, Serialize};
use std::fs;
use std::path::PathBuf;

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct DownloadManagerConfig {
    pub custom_download_path: Option<PathBuf>,
    pub use_metadata: bool,
    pub use_sponsorblock: bool,
    pub use_subtitles: bool,
    pub use_playlist: bool,
    pub cookie_browser: CookieBrowser,
    pub download_type: DownloadType,
    pub selected_subtitle: Option<String>,
}

impl Default for DownloadManagerConfig {
    fn default() -> Self {
        Self {
            custom_download_path: None,
            use_metadata: true,
            use_sponsorblock: false,
            use_subtitles: false,
            use_playlist: false,
            cookie_browser: CookieBrowser::None,
            download_type: DownloadType::Video,
            selected_subtitle: None,
        }
    }
}

pub fn get_config_path() -> PathBuf {
    dirs::config_dir()
        .unwrap_or(PathBuf::from("."))
        .join("screen-goated-toolbox")
        .join("download_manager.json")
}

pub fn load_config() -> DownloadManagerConfig {
    let path = get_config_path();
    if path.exists() {
        if let Ok(content) = fs::read_to_string(&path) {
            if let Ok(config) = serde_json::from_str(&content) {
                return config;
            }
        }
    }
    DownloadManagerConfig::default()
}

pub fn save_config(config: &DownloadManagerConfig) {
    let path = get_config_path();
    if let Some(parent) = path.parent() {
        let _ = fs::create_dir_all(parent);
    }
    if let Ok(content) = serde_json::to_string_pretty(config) {
        let _ = fs::write(path, content);
    }
}
</file>

<file path="src/gui/settings_ui/global/update_section.rs">
use crate::gui::locale::LocaleText;
use crate::updater::{UpdateStatus, Updater};
use eframe::egui;
#[cfg(windows)]
use std::os::windows::process::CommandExt;

pub fn render_update_section_content(
    ui: &mut egui::Ui,
    updater: &Option<Updater>,
    status: &UpdateStatus,
    text: &LocaleText,
) {
    match status {
        UpdateStatus::Idle => {
            ui.horizontal(|ui| {
                let ver_string = format!(
                    "{} v{}",
                    text.current_version_label,
                    env!("CARGO_PKG_VERSION")
                );
                ui.label(ver_string);
                if ui.button(text.check_for_updates_btn).clicked() {
                    if let Some(u) = updater {
                        u.check_for_updates();
                    }
                }
            });
        }
        UpdateStatus::Checking => {
            ui.horizontal(|ui| {
                ui.spinner();
                ui.label(text.checking_github);
            });
        }
        UpdateStatus::UpToDate(ver) => {
            ui.horizontal(|ui| {
                ui.label(
                    egui::RichText::new(format!("{} (v{})", text.up_to_date, ver))
                        .color(egui::Color32::from_rgb(34, 139, 34)),
                );
                if ui.button(text.check_again_btn).clicked() {
                    if let Some(u) = updater {
                        u.check_for_updates();
                    }
                }
            });
        }
        UpdateStatus::UpdateAvailable { version, body } => {
            ui.colored_label(
                egui::Color32::YELLOW,
                format!("{} {}", text.new_version_available, version),
            );
            ui.collapsing(text.release_notes_label, |ui| {
                ui.label(body);
            });
            ui.add_space(5.0);
            if ui
                .button(egui::RichText::new(text.download_update_btn).strong())
                .clicked()
            {
                if let Some(u) = updater {
                    u.perform_update();
                }
            }
        }
        UpdateStatus::Downloading => {
            ui.horizontal(|ui| {
                ui.spinner();
                ui.label(text.downloading_update);
            });
        }
        UpdateStatus::Error(e) => {
            ui.colored_label(egui::Color32::RED, format!("{} {}", text.update_failed, e));
            ui.label(egui::RichText::new(text.app_folder_writable_hint).size(11.0));
            if ui.button(text.retry_btn).clicked() {
                if let Some(u) = updater {
                    u.check_for_updates();
                }
            }
        }
        UpdateStatus::UpdatedAndRestartRequired => {
            ui.label(
                egui::RichText::new(text.update_success)
                    .color(egui::Color32::GREEN)
                    .heading(),
            );
            ui.label(text.restart_to_use_new_version);
            if ui.button(text.restart_app_btn).clicked() {
                if let Ok(exe_path) = std::env::current_exe() {
                    if let Some(exe_dir) = exe_path.parent() {
                        if let Ok(entries) = std::fs::read_dir(exe_dir) {
                            if let Some(newest_exe) = entries
                                .filter_map(|e| e.ok())
                                .filter(|e| {
                                    let name = e.file_name();
                                    let name_str = name.to_string_lossy();
                                    name_str.starts_with("ScreenGoatedToolbox_v")
                                        && name_str.ends_with(".exe")
                                })
                                .max_by_key(|e| e.metadata().ok().and_then(|m| m.modified().ok()))
                            {
                                let path = newest_exe.path();
                                println!("Attempting to spawn with delay: {:?}", path);

                                // Create a temporary batch file to handle the delayed restart reliably
                                // This avoids complex escaping issues with cmd /C inline commands
                                let kill_mutex_cmd = format!("timeout /t 2 /nobreak > NUL");
                                let start_cmd =
                                    format!("start \"\" \"{}\"", path.to_string_lossy());
                                let self_del_cmd = "(goto) 2>nul & del \"%~f0\"";

                                let batch_content = format!(
                                    "@echo off\r\n{}\r\n{}\r\n{}",
                                    kill_mutex_cmd, start_cmd, self_del_cmd
                                );

                                let temp_dir = std::env::temp_dir();
                                let bat_path = temp_dir
                                    .join(format!("sgt_restart_{}.bat", std::process::id()));

                                println!("Writing batch file to: {:?}", bat_path);
                                if let Ok(_) = std::fs::write(&bat_path, batch_content) {
                                    // Spawn the batch file hidden via cmd /C
                                    let mut cmd = std::process::Command::new("cmd");
                                    cmd.args(["/C", &bat_path.to_string_lossy()]);
                                    #[cfg(windows)]
                                    cmd.creation_flags(0x08000000); // CREATE_NO_WINDOW

                                    let status = cmd.spawn();

                                    match status {
                                        Ok(_) => std::process::exit(0),
                                        Err(e) => {
                                            eprintln!("Failed to spawn batch file: {}", e);
                                        }
                                    }
                                } else {
                                    eprintln!("Failed to write batch file");
                                }
                            }
                        }
                    }
                }
            }
        }
    }
}
</file>

<file path="src/model_config.rs">
/// Centralized Model Configuration

#[derive(Clone, Debug, PartialEq)]
pub enum ModelType {
    Vision,
    Text,
    Audio,
}

#[derive(Clone, Debug)]
pub struct ModelConfig {
    pub id: String,
    pub provider: String,
    pub name_vi: String,
    pub name_ko: String,
    pub name_en: String,
    pub full_name: String,
    pub model_type: ModelType,
    pub enabled: bool,
    pub quota_limit_vi: String,
    pub quota_limit_ko: String,
    pub quota_limit_en: String,
}

impl ModelConfig {
    pub fn new(
        id: &str,
        provider: &str,
        name_vi: &str,
        name_ko: &str,
        name_en: &str,
        full_name: &str,
        model_type: ModelType,
        enabled: bool,
        quota_limit_vi: &str,
        quota_limit_ko: &str,
        quota_limit_en: &str,
    ) -> Self {
        Self {
            id: id.to_string(),
            provider: provider.to_string(),
            name_vi: name_vi.to_string(),
            name_ko: name_ko.to_string(),
            name_en: name_en.to_string(),
            full_name: full_name.to_string(),
            model_type,
            enabled,
            quota_limit_vi: quota_limit_vi.to_string(),
            quota_limit_ko: quota_limit_ko.to_string(),
            quota_limit_en: quota_limit_en.to_string(),
        }
    }
}

/// Check if a model is a non-LLM model (doesn't use prompts)
/// These are specialized models that process input directly without instructions.
pub fn model_is_non_llm(model_id: &str) -> bool {
    match model_id {
        // QR Scanner - just decodes QR codes
        "qr-scanner" => true,
        // Google Translate (GTX) - translation only, language from instruction
        "google-gtx" => true,
        // Whisper models - speech-to-text only
        "whisper-fast" | "whisper-accurate" => true,
        // Streaming audio models - process input directly
        "gemini-live-audio" | "parakeet-local" => true,
        _ => false,
    }
}

lazy_static::lazy_static! {
    static ref ALL_MODELS: Vec<ModelConfig> = vec![
        ModelConfig::new(
            "google-gtx",
            "google-gtx",
            "Google Dịch",
            "Google 번역",
            "Google Translate",
            "translate.googleapis.com/gtx",
            ModelType::Text,
            true,
            "Không giới hạn",
            "무제한",
            "Unlimited"
        ),
        ModelConfig::new(
            "qr-scanner",
            "qrserver",
            "Quét mã QR",
            "QR 스캔",
            "QR Scanner",
            "api.qrserver.com/read-qr-code",
            ModelType::Vision,
            true,
            "Không giới hạn",
            "무제한",
            "Unlimited"
        ),
        ModelConfig::new(
            "scout",
            "groq",
            "Nhanh",
            "빠름",
            "Fast",
            "meta-llama/llama-4-scout-17b-16e-instruct",
            ModelType::Vision,
            true,
            "1000 lượt/ngày",
            "1000 요청/일",
            "1000 requests/day"
        ),
        ModelConfig::new(
            "maverick",
            "groq",
            "Chính xác",
            "정확함",
            "Accurate",
            "meta-llama/llama-4-maverick-17b-128e-instruct",
            ModelType::Vision,
            true,
            "1000 lượt/ngày",
            "1000 요청/일",
            "1000 requests/day"
        ),
        ModelConfig::new(
            "gemini-live-vision",
            "gemini-live",
            "Thử nghiệm",
            "실험적",
            "Experimental",
            "gemini-2.5-flash-native-audio-preview-12-2025",
            ModelType::Vision,
            true,
            "Không giới hạn",
            "무제한",
            "Unlimited"
        ),
        ModelConfig::new(
            "gemma-3-27b-vision",
            "google",
            "Cân bằng, chậm",
            "균형잡힌, 느림",
            "Balanced, Slow",
            "gemma-3-27b-it",
            ModelType::Vision,
            true,
            "14400 lượt/ngày",
            "14400 요청/일",
            "14400 requests/day"
        ),
        ModelConfig::new(
            "gemini-flash-lite",
            "google",
            "Chính xác hơn",
            "더 정확함",
            "More Accurate",
            "gemini-2.5-flash-lite",
            ModelType::Vision,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "gemini-flash",
            "google",
            "Rất chính xác",
            "매우 정확함",
            "Very Accurate",
            "gemini-2.5-flash",
            ModelType::Vision,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "gemini-pro",
            "google",
            "Siêu ch.xác, chậm",
            "초정밀, 느림",
            "Super Accurate, Slow",
            "gemini-robotics-er-1.5-preview",
            ModelType::Vision,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "gemini-3-flash-preview",
            "google",
            "Siêu chính xác",
            "초정밀",
            "Super Accurate",
            "gemini-3-flash-preview",
            ModelType::Vision,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "or-nemotron-vl",
            "openrouter",
            "OR-Cân bằng",
            "OR-균형",
            "OR-Balanced",
            "nvidia/nemotron-nano-12b-v2-vl:free",
            ModelType::Vision,
            true,
            "50 lượt chung/ngày",
            "50 공유 요청/일",
            "50 shared requests/day"
        ),
        ModelConfig::new(
            "text_fast_120b",
            "groq",
            "Nhanh",
            "빠름",
            "Fast",
            "openai/gpt-oss-120b",
            ModelType::Text,
            true,
            "1000 lượt/ngày",
            "1000 요청/일",
            "1000 requests/day"
        ),
        ModelConfig::new(
            "text_accurate_kimi",
            "groq",
            "Chính xác",
            "정확함",
            "Accurate",
            "moonshotai/kimi-k2-instruct-0905",
            ModelType::Text,
            true,
            "1000 lượt/ngày",
            "1000 요청/일",
            "1000 requests/day"
        ),
        ModelConfig::new(
            "compound_mini",
            "groq",
            "Search nhanh",
            "빠른 검색",
            "Quick Search",
            "groq/compound-mini",
            ModelType::Text,
            true,
            "250 lượt/ngày",
            "250 요청/일",
            "250 requests/day"
        ),
        ModelConfig::new(
            "compound",
            "groq",
            "Search kỹ",
            "상세 검색",
            "Deep Search",
            "groq/compound",
            ModelType::Text,
            true,
            "250 lượt/ngày",
            "250 요청/일",
            "250 requests/day"
        ),
        ModelConfig::new(
            "cerebras_llama33_70b",
            "cerebras",
            "C-Nhanh",
            "C-빠름",
            "C-Fast",
            "llama-3.3-70b",
            ModelType::Text,
            true,
            "14400 lượt/ngày",
            "14400 요청/일",
            "14400 requests/day"
        ),
        ModelConfig::new(
            "cerebras_gpt_oss",
            "cerebras",
            "C-Chính xác",
            "C-정확함",
            "C-Accurate",
            "gpt-oss-120b",
            ModelType::Text,
            true,
            "14400 lượt/ngày",
            "14400 요청/일",
            "14400 requests/day"
        ),
        ModelConfig::new(
            "cerebras_qwen3",
            "cerebras",
            "C-Chính xác hơn",
            "C-더 정확함",
            "C-More Accurate",
            "qwen-3-235b-a22b-instruct-2507",
            ModelType::Text,
            true,
            "1440 lượt/ngày",
            "1440 요청/일",
            "1440 requests/day"
        ),

        ModelConfig::new(
            "cerebras_zai_glm_4_7",
            "cerebras",
            "C-Siêu chính xác",
            "C-초정밀",
            "C-Super Accurate",
            "zai-glm-4.7",
            ModelType::Text,
            true,
            "100 lượt/ngày",
            "100 요청/일",
            "100 requests/day"
        ),
        ModelConfig::new(
            "gemini-live-text",
            "gemini-live",
            "Thử nghiệm",
            "실험적",
            "Experimental",
            "gemini-2.5-flash-native-audio-preview-12-2025",
            ModelType::Text,
            true,
            "Không giới hạn",
            "무제한",
            "Unlimited"
        ),
        ModelConfig::new(
            "gemma-3-27b",
            "google",
            "Cân bằng, chậm",
            "균형잡힌, 느림",
            "Balanced, Slow",
            "gemma-3-27b-it",
            ModelType::Text,
            true,
            "14400 lượt/ngày",
            "14400 요청/일",
            "14400 requests/day"
        ),
        ModelConfig::new(
            "text_gemini_flash_lite",
            "google",
            "Chính xác hơn",
            "더 정확함",
            "More Accurate",
            "gemini-2.5-flash-lite",
            ModelType::Text,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "text_gemini_flash",
            "google",
            "Rất chính xác",
            "매우 정확함",
            "Very Accurate",
            "gemini-2.5-flash",
            ModelType::Text,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "text_gemini_pro",
            "google",
            "Siêu ch.xác, chậm",
            "초정밀, 느림",
            "Super Accurate, Slow",
            "gemini-robotics-er-1.5-preview",
            ModelType::Text,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "text_gemini_3_0_flash",
            "google",
            "Siêu chính xác",
            "초정밀",
            "Super Accurate",
            "gemini-3-flash-preview",
            ModelType::Text,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "or-nemotron-text",
            "openrouter",
            "OR-Nhanh",
            "OR-빠름",
            "OR-Fast",
            "nvidia/nemotron-3-nano-30b-a3b:free",
            ModelType::Text,
            true,
            "50 lượt chung/ngày",
            "50 공유 요청/일",
            "50 shared requests/day"
        ),
        ModelConfig::new(
            "or-mimo",
            "openrouter",
            "OR-Cân bằng",
            "OR-균형",
            "OR-Balanced",
            "xiaomi/mimo-v2-flash:free",
            ModelType::Text,
            true,
            "50 lượt chung/ngày",
            "50 공유 요청/일",
            "50 shared requests/day"
        ),
        ModelConfig::new(
            "or-deepseek-chimera",
            "openrouter",
            "OR-Ch.xác, chậm",
            "OR-정확, 느림",
            "OR-Accurate, Slow",
            "tngtech/deepseek-r1t2-chimera:free",
            ModelType::Text,
            true,
            "50 lượt chung/ngày",
            "50 공유 요청/일",
            "50 shared requests/day"
        ),
        ModelConfig::new(
            "or-kat-coder",
            "openrouter",
            "OR-Chính xác",
            "OR-정확함",
            "OR-Accurate",
            "kwaipilot/kat-coder-pro:free",
            ModelType::Text,
            true,
            "50 lượt chung/ngày",
            "50 공유 요청/일",
            "50 shared requests/day"
        ),
        ModelConfig::new(
            "or-devstral",
            "openrouter",
            "OR-Rất ch.xác",
            "OR-매우 정확",
            "OR-Very Accurate",
            "mistralai/devstral-2512:free",
            ModelType::Text,
            true,
            "50 lượt chung/ngày",
            "50 공유 요청/일",
            "50 shared requests/day"
        ),

        ModelConfig::new(
            "whisper-fast",
            "groq",
            "Nhanh",
            "빠름",
            "Fast",
            "whisper-large-v3-turbo",
            ModelType::Audio,
            true,
            "8 giờ audio/ngày",
            "8시간 오디오/일",
            "8 hours audio/day"
        ),
        ModelConfig::new(
            "whisper-accurate",
            "groq",
            "Chính xác",
            "정확함",
            "Accurate",
            "whisper-large-v3",
            ModelType::Audio,
            true,
            "8 giờ audio/ngày",
            "8시간 오디오/일",
            "8 hours audio/day"
        ),
        ModelConfig::new(
            "parakeet-local",
            "parakeet",
            "Stream offline",
            "Stream offline",
            "Stream offline",
            "parakeet-120m-v1",
            ModelType::Audio,
            true,
            "Không giới hạn",
            "무제한",
            "Unlimited"
        ),
        ModelConfig::new(
            "gemini-live-audio",
            "gemini-live",
            "Stream online",
            "Stream online",
            "Stream online",
            "gemini-2.5-flash-native-audio-preview-12-2025",
            ModelType::Audio,
            true,
            "Không giới hạn",
            "무제한",
            "Unlimited"
        ),
        ModelConfig::new(
            "gemini-audio",
            "google",
            "Chính xác hơn",
            "더 정확함",
            "More Accurate",
            "gemini-2.5-flash-lite",
            ModelType::Audio,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "gemini-audio-flash",
            "google",
            "Rất chính xác",
            "매우 정확함",
            "Very Accurate",
            "gemini-2.5-flash",
            ModelType::Audio,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "gemini-audio-pro",
            "google",
            "Siêu ch.xác, chậm",
            "초정밀, 느림",
            "Super Accurate, Slow",
            "gemini-robotics-er-1.5-preview",
            ModelType::Audio,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),
        ModelConfig::new(
            "gemini-audio-3.0-flash",
            "google",
            "Siêu chính xác",
            "초정밀",
            "Super Accurate",
            "gemini-3-flash-preview",
            ModelType::Audio,
            true,
            "20 lượt/ngày",
            "20 요청/일",
            "20 requests/day"
        ),


    ];
}

pub fn get_all_models() -> &'static [ModelConfig] {
    &ALL_MODELS
}

pub fn get_model_by_id(id: &str) -> Option<ModelConfig> {
    get_all_models().iter().find(|m| m.id == id).cloned()
}

/// Resolve a fallback model for retry logic
/// Prioritizes:
/// 1. Same provider, same type (Prioritize based on list order - treating list as priority queue)
/// 2. Different provider, same type
use crate::config::Config;

/// Resolve a fallback model for retry logic
/// Prioritizes:
/// 1. Same provider, same type (Prioritize based on list order - treating list as priority queue)
/// 2. Different provider, same type
/// Checks if the provider is actually configured (has API key) before suggesting it.
pub fn resolve_fallback_model(
    failed_model_id: &str,
    failed_model_ids: &[String],
    current_model_type: &ModelType,
    config: &Config,
) -> Option<ModelConfig> {
    let all_models = get_all_models_with_ollama();
    let current_model_opt = get_model_by_id(failed_model_id);
    let current_provider = current_model_opt
        .as_ref()
        .map(|m| m.provider.as_str())
        .unwrap_or("");

    // Helper to check if a provider is configured
    let is_provider_configured = |provider: &str| -> bool {
        match provider {
            "groq" => !config.api_key.is_empty(),
            "google" => !config.gemini_api_key.is_empty(),
            "openai" => false, // We don't have openai_api_key in config struct (only openrouter/cerebras) - wait, checking Config struct..
            // Ah, standard OpenAI is not in the Config struct I saw.
            "openrouter" => !config.openrouter_api_key.is_empty(),
            "cerebras" => !config.cerebras_api_key.is_empty(),
            "ollama" => config.use_ollama, // No key needed, just enabled
            _ => true, // Assume others (like internal ones) are "configured" or we can't check
        }
    };

    // 1. Determine requirements from the failed model
    // If the failed model supported search, the fallback MUST also support search
    let must_support_search = model_supports_search_by_id(failed_model_id);

    // 2. Try Same Provider
    if !current_provider.is_empty() {
        let same_provider_candidates: Vec<&ModelConfig> = all_models
            .iter()
            .filter(|m| {
                m.provider == current_provider
                    && m.model_type == *current_model_type
                    && m.id != failed_model_id
                    && !failed_model_ids.contains(&m.id)
                    && (!must_support_search || model_supports_search_by_name(&m.full_name))
            })
            .collect();

        // Prioritize the LAST model in the list (often the most capable/specific one)
        if let Some(last) = same_provider_candidates.last() {
            return Some((*last).clone());
        }
    }

    // 3. Try Different Provider
    let diff_provider_candidates: Vec<&ModelConfig> = all_models
        .iter()
        .filter(|m| {
            m.provider != current_provider
                && m.model_type == *current_model_type
                && !failed_model_ids.contains(&m.id)
                && is_provider_configured(&m.provider)
                && (!must_support_search || model_supports_search_by_name(&m.full_name))
        })
        .collect();

    // Prioritize the LAST model in the list
    if let Some(last) = diff_provider_candidates.last() {
        return Some((*last).clone());
    }

    None
}

/// Get all models including dynamically fetched Ollama models
/// This combines static models with Ollama models (if Ollama is enabled)
pub fn get_all_models_with_ollama() -> Vec<ModelConfig> {
    let mut models: Vec<ModelConfig> = ALL_MODELS.iter().cloned().collect();

    // Add cached Ollama models
    let cached = OLLAMA_MODEL_CACHE.lock().unwrap();
    for ollama_model in cached.iter() {
        models.push(ollama_model.clone());
    }

    models
}

/// Check if a model supports search capabilities (grounding/web search) by its Full Name (API Name)
pub fn model_supports_search_by_name(full_name: &str) -> bool {
    // Exclusions
    if full_name.contains("gemma-3-27b-it") {
        return false;
    }
    if full_name.contains("gemini-3-flash-preview") {
        return false;
    }

    // Inclusions
    if full_name.contains("gemini") {
        return true;
    }
    if full_name.contains("gemma") {
        return false;
    }
    if full_name.contains("compound") {
        return true;
    }

    false
}

/// Check if a model supports search capabilities (grounding/web search) by its Internal ID
pub fn model_supports_search_by_id(id: &str) -> bool {
    if let Some(conf) = get_model_by_id(id) {
        return model_supports_search_by_name(&conf.full_name);
    }

    // Fallback logic for models not in static config (though currently most are)
    if id.contains("compound") {
        return true;
    }

    false
}

// === OLLAMA MODEL CACHE ===

use std::sync::{
    atomic::{AtomicBool, Ordering},
    Mutex,
};

lazy_static::lazy_static! {
    /// Cached Ollama models (populated by background scan)
    static ref OLLAMA_MODEL_CACHE: Mutex<Vec<ModelConfig>> = Mutex::new(Vec::new());

    /// Whether a scan is currently in progress
    static ref OLLAMA_SCAN_IN_PROGRESS: AtomicBool = AtomicBool::new(false);

    /// Last scan time (for debouncing) - initialized to 10s ago so first scan works immediately
    static ref OLLAMA_LAST_SCAN: Mutex<std::time::Instant> = Mutex::new(
        std::time::Instant::now().checked_sub(std::time::Duration::from_secs(10)).unwrap_or_else(std::time::Instant::now)
    );
}

/// Check if Ollama model scan is in progress
pub fn is_ollama_scan_in_progress() -> bool {
    OLLAMA_SCAN_IN_PROGRESS.load(Ordering::SeqCst)
}

/// Trigger background scan for Ollama models (non-blocking)
/// Returns immediately, models will be populated in cache when ready
pub fn trigger_ollama_model_scan() {
    // Check if Ollama is enabled
    let (use_ollama, base_url) = if let Ok(app) = crate::APP.lock() {
        (app.config.use_ollama, app.config.ollama_base_url.clone())
    } else {
        return;
    };

    if !use_ollama {
        return;
    }

    // Debounce: don't scan more than once per 5 seconds
    {
        let last_scan = OLLAMA_LAST_SCAN.lock().unwrap();
        if last_scan.elapsed().as_secs() < 5 {
            return;
        }
    }

    // Check if already scanning
    if OLLAMA_SCAN_IN_PROGRESS.swap(true, Ordering::SeqCst) {
        return; // Already scanning
    }

    // Update last scan time
    {
        let mut last_scan = OLLAMA_LAST_SCAN.lock().unwrap();
        *last_scan = std::time::Instant::now();
    }

    // Spawn background thread to scan
    std::thread::spawn(move || {
        let result = crate::api::ollama::fetch_ollama_models_with_caps(&base_url);

        if let Ok(ollama_models) = result {
            let mut new_models = Vec::new();

            for ollama_model in ollama_models {
                // Create model ID from name (e.g., "qwen3-vl:2b" -> "ollama-qwen3-vl-2b")
                let model_id = format!(
                    "ollama-{}",
                    ollama_model.name.replace(":", "-").replace("/", "-")
                );
                let display_name = format!("{} (Local)", ollama_model.name);

                // Vision models can do BOTH vision and text, so we add them to both
                // Text-only models just get Text type
                if ollama_model.has_vision {
                    // Add as Vision model
                    new_models.push(ModelConfig {
                        id: format!("{}-vision", model_id),
                        provider: "ollama".to_string(),
                        name_vi: display_name.clone(),
                        name_ko: display_name.clone(),
                        name_en: display_name.clone(),
                        full_name: ollama_model.name.clone(),
                        model_type: ModelType::Vision,
                        enabled: true,
                        quota_limit_vi: "Không giới hạn".to_string(),
                        quota_limit_ko: "무제한".to_string(),
                        quota_limit_en: "Unlimited".to_string(),
                    });

                    // Also add as Text model (vision models can do text too)
                    new_models.push(ModelConfig {
                        id: model_id,
                        provider: "ollama".to_string(),
                        name_vi: display_name.clone(),
                        name_ko: display_name.clone(),
                        name_en: display_name.clone(),
                        full_name: ollama_model.name.clone(),
                        model_type: ModelType::Text,
                        enabled: true,
                        quota_limit_vi: "Không giới hạn".to_string(),
                        quota_limit_ko: "무제한".to_string(),
                        quota_limit_en: "Unlimited".to_string(),
                    });
                } else {
                    // Text-only model
                    new_models.push(ModelConfig {
                        id: model_id,
                        provider: "ollama".to_string(),
                        name_vi: display_name.clone(),
                        name_ko: display_name.clone(),
                        name_en: display_name,
                        full_name: ollama_model.name,
                        model_type: ModelType::Text,
                        enabled: true,
                        quota_limit_vi: "Không giới hạn".to_string(),
                        quota_limit_ko: "무제한".to_string(),
                        quota_limit_en: "Unlimited".to_string(),
                    });
                }
            }

            // Update cache
            let mut cache = OLLAMA_MODEL_CACHE.lock().unwrap();
            *cache = new_models;
        }

        OLLAMA_SCAN_IN_PROGRESS.store(false, Ordering::SeqCst);
    });
}
</file>

<file path="src/overlay/favorite_bubble/html.rs">
use crate::config::Preset;
use crate::gui::settings_ui::get_localized_preset_name;

pub fn generate_panel_html(
    presets: &[Preset],
    lang: &str,
    is_dark: bool,
    keep_open: bool,
) -> String {
    let css = generate_panel_css(is_dark);
    let favorites_html = get_favorite_presets_html(presets, lang, is_dark);
    let keep_open_label = crate::gui::locale::LocaleText::get(lang).favorites_keep_open;
    let keep_open_js = if keep_open { "true" } else { "false" };
    let keep_open_class = if keep_open { " active" } else { "" };

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
{css}
</style>
</head>
<body>
<div class="container">
    <div class="keep-open-row visible" id="keepOpenRow">
        <div class="toggle-switch{keep_open_class}" id="keepOpenToggle" onclick="toggleKeepOpen()"></div>
        <span class="keep-open-label{keep_open_class}" id="keepOpenLabel">{keep_open_label}</span>
        <button class="size-btn" onclick="resizeBubble('desc')">-</button>
        <button class="size-btn" onclick="resizeBubble('inc')">+</button>
    </div>
    <div class="list">{favorites}</div>
</div>
<script>
function fitText() {{
    requestAnimationFrame(() => {{
        document.querySelectorAll('.name').forEach(el => {{
            el.className = 'name';
            if (el.scrollWidth > el.clientWidth) {{
                el.classList.add('condense');
        if (el.scrollWidth > el.clientWidth) {{
                    el.classList.remove('condense');
                    el.classList.add('condense-more');
                }}
            }}
        }});
        sendHeight();
    }});
}}

function resizeBubble(dir) {{
    if (dir === 'inc') window.ipc.postMessage('increase_size');
    else window.ipc.postMessage('decrease_size');
}}
window.onload = fitText;

function sendHeight() {{
    const container = document.querySelector('.container');
    if (container) {{
         window.ipc.postMessage('resize:' + Math.max(container.scrollHeight, container.offsetHeight));
    }}
}}

function startDrag(e) {{
    if (e.button === 0) window.ipc.postMessage('drag');
}}

let keepOpen = {keep_open_js};

function toggleKeepOpen() {{
    keepOpen = !keepOpen;
    const toggle = document.getElementById('keepOpenToggle');
    const label = document.getElementById('keepOpenLabel');
    toggle.classList.toggle('active', keepOpen);
    label.classList.toggle('active', keepOpen);
    // Notify Rust to persist the new state
    window.ipc.postMessage('set_keep_open:' + (keepOpen ? '1' : '0'));
}}

let holdTimer = null;
let holdIdx = null;
const HOLD_THRESHOLD = 500;

function onMouseDown(idx) {{
    holdIdx = idx;
    const item = event.currentTarget;
    const fill = item.querySelector('.progress-fill');
    
    if (fill) {{
        fill.style.width = '0%';
        fill.style.transition = 'width ' + HOLD_THRESHOLD + 'ms linear';
        requestAnimationFrame(() => fill.style.width = '100%');
    }}

    holdTimer = setTimeout(() => {{
        holdTimer = null;
        triggerContinuous(idx);
    }}, HOLD_THRESHOLD);
}}

function onMouseUp(idx) {{
    if (holdTimer) {{
        clearTimeout(holdTimer);
        holdTimer = null;
        triggerNormal(idx);
    }}
    resetFill();
}}

function onMouseLeave() {{
    if (holdTimer) {{
        clearTimeout(holdTimer);
        holdTimer = null;
    }}
    resetFill();
}}

function resetFill() {{
    document.querySelectorAll('.progress-fill').forEach(f => {{
        f.style.transition = 'none';
        f.style.width = '0%';
    }});
}}

function triggerNormal(idx) {{
    if (keepOpen) {{
        window.ipc.postMessage('trigger_only:' + idx);
    }} else {{
        closePanel();
        window.ipc.postMessage('trigger:' + idx);
    }}
}}

function triggerContinuous(idx) {{
    if (keepOpen) {{
        window.ipc.postMessage('trigger_continuous_only:' + idx);
    }} else {{
        closePanel();
        window.ipc.postMessage('trigger_continuous:' + idx);
    }}
}}

let currentTimeout = null;
let currentSide = 'right';
let lastBubblePos = {{ x: 0, y: 0 }};

function animateIn(bx, by) {{
    if (currentTimeout) {{
        clearTimeout(currentTimeout);
        currentTimeout = null;
    }}
    lastBubblePos = {{ x: bx, y: by }};
    
    const items = document.querySelectorAll('.preset-item, .empty');
    if (items.length === 0) return;

    items.forEach((item, i) => {{
        const rect = item.getBoundingClientRect();
        if (rect.width === 0) return; // Not rendered yet?

        // Target center
        const iy = rect.top + rect.height / 2;
        const ix = rect.left + rect.width / 2;
        
        // Offset TO move item TO bubble center
        const dx = bx - ix;
        const dy = by - iy;

        // 1. Force initial state (at bubble, invisible)
        item.style.transition = 'none';
        item.style.opacity = '0';
        item.style.transform = `translate(${{dx}}px, ${{dy}}px) scale(0.01)`;
        item.classList.remove('visible');
        
        item.offsetHeight; // Flush
        
        // 2. Set transition and target state
        item.style.transition = ''; 
        item.style.transitionDelay = `${{i * 15}}ms`;
        
        requestAnimationFrame(() => {{
            // Add class and set target state explicitly
            item.classList.add('visible');
            item.style.opacity = '1';
            item.style.transform = 'translate(0px, 0px) scale(1)';
            
            // Cleanup: remove inline styles after animation finishes to let CSS hover work
            setTimeout(() => {{
                if (item.classList.contains('visible')) {{
                    item.style.opacity = '';
                    item.style.transform = '';
                    item.style.transition = '';
                    item.style.transitionDelay = '';
                }}
            }}, 300 + (i * 15));
        }});
    }});
}}

function closePanel() {{
    if (currentTimeout) clearTimeout(currentTimeout);
    
    const items = Array.from(document.querySelectorAll('.preset-item, .empty'));
    const {{ x: bx, y: by }} = lastBubblePos;

    items.forEach((item, i) => {{
        const rect = item.getBoundingClientRect();
        const iy = rect.top + rect.height / 2;
        const ix = rect.left + rect.width / 2;
        
        const dx = bx - ix;
        const dy = by - iy;

        // Animate back to bubble with fade out
        item.style.transitionDelay = `${{(items.length - 1 - i) * 8}}ms`;
        item.classList.remove('visible');
        item.style.opacity = '0';
        item.style.transform = `translate(${{dx}}px, ${{dy}}px) scale(0.01)`;
    }});

    currentTimeout = setTimeout(() => {{
        window.ipc.postMessage('close_now');
        currentTimeout = null;
    }}, items.length * 8 + 300);
}}

window.setSide = (side) => {{ 
    currentSide = side;
    const container = document.querySelector('.container');
    container.classList.remove('side-left', 'side-right');
    container.classList.add('side-' + side);
}};
</script>
</body>
</html>"#,
        css = css,
        favorites = favorites_html,
        keep_open_label = keep_open_label,
        keep_open_class = keep_open_class,
        keep_open_js = keep_open_js
    )
}

pub fn generate_panel_css(is_dark: bool) -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    // Theme-specific colors
    let (
        text_color,
        item_bg,
        item_hover_bg,
        item_shadow,
        item_hover_shadow,
        empty_text_color,
        empty_bg,
        empty_border,
        label_color,
        label_active_color,
        label_shadow,
        toggle_bg,
        toggle_active_bg,
        toggle_knob_shadow,
        row_bg,
    ) = if is_dark {
        (
            "#eeeeee",
            "rgba(20, 20, 30, 0.85)",
            "rgba(40, 40, 55, 0.95)",
            "0 2px 8px rgba(0, 0, 0, 0.2)",
            "0 4px 12px rgba(0, 0, 0, 0.3)",
            "rgba(255, 255, 255, 0.6)",
            "rgba(20, 20, 30, 0.85)",
            "rgba(255, 255, 255, 0.1)",
            "rgba(255, 255, 255, 0.6)",
            "rgba(255, 255, 255, 0.95)", // White active label
            "0 1px 3px rgba(0, 0, 0, 0.5)",
            "rgba(60, 60, 70, 0.8)",
            "rgba(64, 196, 255, 0.9)", // Blue (Light Blue A200)
            "0 1px 3px rgba(0, 0, 0, 0.3)",
            "rgba(20, 20, 30, 0.85)", // Match item_bg
        )
    } else {
        // Light mode colors
        (
            "#222222",
            "rgba(255, 255, 255, 0.92)",
            "rgba(240, 240, 245, 0.98)",
            "0 2px 8px rgba(0, 0, 0, 0.08)",
            "0 4px 12px rgba(0, 0, 0, 0.12)",
            "rgba(0, 0, 0, 0.5)",
            "rgba(255, 255, 255, 0.92)",
            "rgba(0, 0, 0, 0.08)",
            "rgba(0, 0, 0, 0.6)",               // Darker label for visibility
            "rgba(0, 0, 0, 0.95)",              // Dark active label
            "0 0 4px rgba(255, 255, 255, 0.8)", // White glow for contrast
            "rgba(200, 200, 210, 0.8)",
            "rgba(33, 150, 243, 0.9)", // Blue (Material Blue 500)
            "0 1px 3px rgba(0, 0, 0, 0.15)",
            "rgba(255, 255, 255, 0.92)", // Match item_bg
        )
    };

    // Light mode needs adjusted border color for hover
    let item_hover_border = if is_dark {
        "rgba(255, 255, 255, 0.25)"
    } else {
        "rgba(0, 0, 0, 0.12)"
    };

    format!(
        r#"
{font_css}
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
html, body {{
    width: 100%;
    height: 100%;
    overflow: hidden;
    background: transparent;
    font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
    user-select: none;
}}

.container {{
    display: flex;
    flex-direction: column;
    padding: 30px 20px; /* Default padding, will be overridden by side class */
}}

/* Bubble on right = panel on left */
.container.side-right {{
    padding-left: 30px;
    padding-right: 10px;
}}

/* Bubble on left = panel on right */
.container.side-left {{
    padding-left: 10px;
    padding-right: 30px;
}}

.list {{
    display: block;
    column-gap: 8px;
}}

.preset-item, .empty {{
    display: flex;
    align-items: center;
    padding: 8px 12px;
    border-radius: 12px;
    cursor: pointer;
    color: {text_color};
    font-size: 13px;
    font-variation-settings: 'wght' 500, 'wdth' 100, 'ROND' 100;
    background: {item_bg};
    backdrop-filter: blur(12px);
    box-shadow: {item_shadow};
    margin-bottom: 4px;
    break-inside: avoid;
    page-break-inside: avoid;
    
    /* Animation state */
    opacity: 0;
    pointer-events: none;
    transform: scale(0.01);
    transition: 
        transform 0.3s cubic-bezier(0.22, 1, 0.36, 1),
        opacity 0.25s ease-out,
        background 0.2s ease,
        box-shadow 0.2s ease,
        font-variation-settings 0.2s ease;
    will-change: transform, opacity;
}}

.preset-item.visible, .empty.visible {{
    opacity: 1;
    transform: scale(1) translate(0px, 0px);
    pointer-events: auto;
}}

.preset-item.visible:hover {{
    background: {item_hover_bg};
    border-color: {item_hover_border};
    box-shadow: {item_hover_shadow};
    font-variation-settings: 'wght' 650, 'wdth' 105, 'ROND' 100;
    /* !important to override any lingering inline styles from bloom animation */
    transform: scale(1.05) translate(0px, 0px) !important;
    /* Fast hover-in for snappy response */
    transition: 
        transform 0.08s cubic-bezier(0.34, 1.2, 0.64, 1),
        background 0.05s ease,
        box-shadow 0.05s ease,
        font-variation-settings 0.08s ease,
        border-color 0.05s ease;
}}

.preset-item.visible:active {{
    transform: scale(0.98) translate(0px, 0px) !important;
}}

.preset-item {{
    position: relative;
    overflow: hidden;
}}

/* Progress Fill (Continuous Mode) */
.progress-fill {{
    position: absolute;
    top: 0;
    left: 0;
    width: 0%;
    height: 100%;
    background: rgba(64, 196, 255, 0.3); /* Blue tinted fill */
    pointer-events: none;
    z-index: 0;
    transition: width 0.05s linear;
}}

.preset-item .icon, .preset-item .name {{
    position: relative;
    z-index: 1;
}}

.icon {{
    display: flex;
    align-items: center;
    justify-content: center;
    margin-right: 10px;
    opacity: 0.9;
}}

.name {{
    flex: 1;
    min-width: 0;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
}}

.empty {{
    color: {empty_text_color};
    text-align: center;
    padding: 12px;
    font-size: 12px;
    background: {empty_bg};
    border-radius: 12px;
    border: 1px solid {empty_border};
}}

.condense {{ letter-spacing: -0.5px; }}
.condense-more {{ letter-spacing: -1px; }}

/* Keep Open Toggle Row */
.keep-open-row {{
    display: flex;
    align-items: center;
    justify-content: center; /* Center content in pill */
    gap: 12px;
    padding: 8px 16px;
    margin-bottom: 12px;
    background: {row_bg};
    backdrop-filter: blur(12px);
    box-shadow: {item_shadow};
    border-radius: 20px;
    width: fit-content;
    margin-left: auto;
    margin-right: auto;
    
    /* Animation state - similar to preset-item */
    opacity: 0;
    pointer-events: none;
    transform: scale(0.01);
    transition: 
        transform 0.3s cubic-bezier(0.22, 1, 0.36, 1),
        opacity 0.25s ease-out;
    will-change: transform, opacity;
}}
.keep-open-row.visible {{
    opacity: 0;
    transform: scale(1) translate(0px, 0px);
    pointer-events: auto;
    transition: opacity 0.2s ease;
}}

/* Show keep-open row when hovering the container */
.container:hover .keep-open-row.visible {{
    opacity: 1;
}}

/* Keep Open Label */
.keep-open-label {{
    color: {label_color};
    font-size: 13px;
    font-variation-settings: 'wght' 500, 'wdth' 100, 'ROND' 100;
    letter-spacing: 0px;
    text-shadow: {label_shadow};
    transition: 
        font-variation-settings 0.25s cubic-bezier(0.34, 1.2, 0.64, 1),
        letter-spacing 0.25s ease,
        color 0.2s ease;
}}
.keep-open-label.active {{
    color: {label_active_color};
    font-variation-settings: 'wght' 700, 'wdth' 120, 'ROND' 100;
    letter-spacing: 0.5px;
}}

/* Toggle Switch */
.toggle-switch {{
    position: relative;
    width: 36px;
    height: 20px;
    background: {toggle_bg};
    border-radius: 10px;
    cursor: pointer;
    transition: background 0.2s ease;
}}
.toggle-switch.active {{
    background: {toggle_active_bg};
}}
.toggle-switch::after {{
    content: '';
    position: absolute;
    top: 2px;
    left: 2px;
    width: 16px;
    height: 16px;
    background: white;
    border-radius: 50%;
    transition: transform 0.2s ease;
    box-shadow: {toggle_knob_shadow};
}}
.toggle-switch.active::after {{
    transform: translateX(16px);
}}

/* Size buttons */
.size-btn {{
    width: 24px;
    height: 24px;
    border-radius: 50%;
    border: none;
    background: {item_bg};
    color: {text_color};
    font-family: inherit;
    font-size: 18px;
    line-height: 1;
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: pointer;
    transition: all 0.2s ease;
    box-shadow: {toggle_knob_shadow};
    margin-left: 4px;
}}
.size-btn:hover {{
    background: {item_hover_bg};
    transform: scale(1.1);
    box-shadow: {item_hover_shadow};
}}
.size-btn:active {{
    transform: scale(0.95);
}}
"#,
        font_css = font_css,
        text_color = text_color,
        item_bg = item_bg,
        item_hover_bg = item_hover_bg,
        item_shadow = item_shadow,
        item_hover_shadow = item_hover_shadow,
        item_hover_border = item_hover_border,
        empty_text_color = empty_text_color,
        empty_bg = empty_bg,
        empty_border = empty_border,
        label_color = label_color,
        label_active_color = label_active_color,
        label_shadow = label_shadow,
        toggle_bg = toggle_bg,
        toggle_active_bg = toggle_active_bg,
        toggle_knob_shadow = toggle_knob_shadow,
        row_bg = row_bg
    )
}

pub fn get_favorite_presets_html(presets: &[Preset], lang: &str, is_dark: bool) -> String {
    let mut html_items = String::new();

    let icon_image = r#"<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M12 8.8a3.2 3.2 0 1 0 0 6.4 3.2 3.2 0 0 0 0-6.4z"/><path d="M9 2L7.17 4H4c-1.1 0-2 .9-2 2v12c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2h-3.17L15 2H9zm3 15c-2.76 0-5-2.24-5-5s2.24-5 5-5 5 2.24 5 5-2.24 5-5 5z"/></svg>"#;
    let icon_text_type = r#"<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M5 5h14v3h-2v-1h-3v10h2.5v2h-9v-2h2.5v-10h-3v1h-2z"/></svg>"#;
    let icon_text_select = r#"<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M4 7h11v1.5H4z M4 11h11v2.5H4z M4 15.5h11v1.5H4z M19 6h-2v1.5h0.5v9H17v1.5h2v-1.5h-0.5v-9H19z"/></svg>"#;
    let icon_mic = r#"<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M12 14c1.66 0 3-1.34 3-3V5c0-1.66-1.34-3-3-3S9 3.34 9 5v6c0 1.66 1.34 3 3 3zM17 11c0 2.76-2.24 5-5 5s-5-2.24-5-5H5c0 3.53 2.61 6.43 6 6.92V21h2v-3.08c3.39-.49 6-3.39 6-6.92h-2z"/></svg>"#;
    let icon_device = r#"<svg width="20" height="20" viewBox="0 0 24 24" fill="currentColor"><path d="M3 9v6h4l5 5V4L7 9H3zm13.5 3c0-1.77-1.02-3.29-2.5-4.03v8.05c1.48-.73 2.5-2.25 2.5-4.02zM14 3.23v2.06c2.89.86 5 3.54 5 6.71s-2.11 5.85-5 6.71v2.06c4.01-.91 7-4.49 7-8.77s-2.99-7.86-7-8.77z"/></svg>"#;
    let icon_realtime = r#"<svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M2 12h3 l1.5-3 l2 10 l3.5-14 l3.5 10 l2-3 h4.5"/></svg>"#;

    for (idx, preset) in presets.iter().enumerate() {
        if preset.is_favorite && !preset.is_upcoming {
            let name = if preset.id.starts_with("preset_") {
                get_localized_preset_name(&preset.id, lang)
            } else {
                preset.name.clone()
            };

            let (icon_svg, color_hex) = match preset.preset_type.as_str() {
                "audio" => {
                    if preset.audio_processing_mode == "realtime" {
                        // Realtime/Live: Red
                        (icon_realtime, if is_dark { "#ff5555" } else { "#d32f2f" })
                    } else if preset.audio_source == "device" {
                        // Device/Speaker: Orange
                        (icon_device, if is_dark { "#ffaa33" } else { "#f57c00" })
                    } else {
                        // Mic: Orange
                        (icon_mic, if is_dark { "#ffaa33" } else { "#f57c00" })
                    }
                }
                "text" => {
                    // Text: Green
                    let c = if is_dark { "#55ff88" } else { "#388e3c" };
                    if preset.text_input_mode == "select" {
                        (icon_text_select, c)
                    } else {
                        (icon_text_type, c)
                    }
                }
                _ => (icon_image, if is_dark { "#44ccff" } else { "#1976d2" }), // Image: Blue
            };

            let item = format!(
                r#"<div class="preset-item" onmousedown="onMouseDown({})" onmouseup="onMouseUp({})" onmouseleave="onMouseLeave()"><div class="progress-fill"></div><span class="icon" style="color: {};">{}</span><span class="name">{}</span></div>"#,
                idx,
                idx,
                color_hex,
                icon_svg,
                html_escape(&name)
            );

            html_items.push_str(&item);
        }
    }

    if html_items.is_empty() {
        let locale = crate::gui::locale::LocaleText::get(lang);
        html_items = format!(
            r#"<div class="empty">{}</div>"#,
            html_escape(locale.favorites_empty)
        );
    }

    html_items
}

fn html_escape(s: &str) -> String {
    s.replace('&', "&amp;")
        .replace('<', "&lt;")
        .replace('>', "&gt;")
        .replace('"', "&quot;")
}

pub fn escape_js(text: &str) -> String {
    text.replace('\\', "\\\\")
        .replace('"', "\\\"")
        .replace('\n', "\\n")
        .replace('\r', "")
}
</file>

<file path="src/overlay/html_components/font_manager.rs">
//! Font Manager - Bundles Google Sans Flex variable font
//!
//! Serves both HTML pages and fonts from a local HTTP server.
//! This ensures same-origin access, bypassing CORS/PNA restrictions.

use std::collections::HashMap;
use std::io::{Read, Write};
use std::net::TcpListener;
use std::sync::atomic::{AtomicU64, Ordering};
use std::sync::{Mutex, Once};
use windows::Win32::Graphics::Gdi::AddFontMemResourceEx;
use wry::WebViewBuilder;

/// Google Sans Flex variable font - bundled at compile time (~5MB)
static GOOGLE_SANS_FLEX_TTF: &[u8] = crate::assets::GOOGLE_SANS_FLEX;

static START_SERVER_ONCE: Once = Once::new();
static PAGE_ID_COUNTER: AtomicU64 = AtomicU64::new(1);

// Session-based cache buster - generated once at startup to prevent cache corruption
// This fixes ERR_CACHE_READ_FAILURE in persistent WebViews like preset_wheel
lazy_static::lazy_static! {
    static ref SESSION_CACHE_BUSTER: String = format!("{:x}", std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap_or_default()
        .as_millis());
}

lazy_static::lazy_static! {
    /// Server URL once started
    static ref SERVER_URL: Mutex<Option<String>> = Mutex::new(None);

    /// Pending HTML pages waiting to be served (page_id -> html)
    static ref PENDING_PAGES: Mutex<HashMap<u64, String>> = Mutex::new(HashMap::new());
}

/// Warmup: Start server and load font into GDI.
pub fn warmup_fonts() {
    load_gdi_font();
    start_server();
}

fn load_gdi_font() {
    unsafe {
        let mut num_fonts = 0;
        let len = GOOGLE_SANS_FLEX_TTF.len() as u32;
        let handle = AddFontMemResourceEx(
            GOOGLE_SANS_FLEX_TTF.as_ptr() as *mut _,
            len,
            None,
            &mut num_fonts,
        );

        if handle.is_invalid() {
            eprintln!("Failed to load Google Sans Flex into GDI");
        }
    }
}

fn start_server() {
    START_SERVER_ONCE.call_once(|| {
        std::thread::spawn(|| {
            let listener = match TcpListener::bind("127.0.0.1:0") {
                Ok(l) => l,
                Err(e) => {
                    eprintln!("Failed to bind font server: {}", e);
                    return;
                }
            };

            let port = listener.local_addr().map(|a| a.port()).unwrap_or(0);
            let url = format!("http://127.0.0.1:{}", port);

            if let Ok(mut guard) = SERVER_URL.lock() {
                *guard = Some(url);
            }

            for stream in listener.incoming() {
                if let Ok(mut stream) = stream {
                    let _ = handle_request(&mut stream);
                }
            }
        });
    });
}

fn handle_request(stream: &mut std::net::TcpStream) -> std::io::Result<()> {
    let mut buffer = [0u8; 4096];
    let n = stream.read(&mut buffer)?;
    let request = String::from_utf8_lossy(&buffer[..n]);

    // Parse the request line
    let first_line = request.lines().next().unwrap_or("");
    let parts: Vec<&str> = first_line.split_whitespace().collect();
    let method = parts.get(0).copied().unwrap_or("GET");
    let path = parts.get(1).copied().unwrap_or("/");

    // CORS headers for all responses
    let cors_headers = "Access-Control-Allow-Origin: *\r\n\
                        Access-Control-Allow-Methods: GET, HEAD, OPTIONS\r\n\
                        Access-Control-Allow-Headers: *\r\n\
                        Access-Control-Allow-Private-Network: true\r\n";

    // Handle OPTIONS preflight
    if method == "OPTIONS" {
        let response =
            format!("HTTP/1.1 204 No Content\r\n{cors_headers}Connection: close\r\n\r\n");
        stream.write_all(response.as_bytes())?;
        return Ok(());
    }

    // Route requests - strip query params for path matching
    let path_without_query = path.split('?').next().unwrap_or(path);

    if path_without_query == "/font/GoogleSansFlex.ttf" {
        // Serve font with reduced cache time to prevent cache corruption
        // The cache buster query param ensures fresh fetch each session
        let headers = format!(
            "HTTP/1.1 200 OK\r\n\
             Content-Type: font/ttf\r\n\
             Content-Length: {}\r\n\
             {cors_headers}\
             Cache-Control: max-age=3600\r\n\
             Connection: close\r\n\r\n",
            GOOGLE_SANS_FLEX_TTF.len()
        );
        stream.write_all(headers.as_bytes())?;
        if method != "HEAD" {
            stream.write_all(GOOGLE_SANS_FLEX_TTF)?;
        }
    } else if path.starts_with("/page/") {
        // Serve stored HTML page
        let id_str = path.strip_prefix("/page/").unwrap_or("0");
        let page_id: u64 = id_str.parse().unwrap_or(0);

        let html = PENDING_PAGES
            .lock()
            .ok()
            .and_then(|mut map| map.remove(&page_id))
            .unwrap_or_else(|| "<html><body>Page not found</body></html>".to_string());

        let html_bytes = html.as_bytes();
        let headers = format!(
            "HTTP/1.1 200 OK\r\n\
             Content-Type: text/html; charset=utf-8\r\n\
             Content-Length: {}\r\n\
             {cors_headers}\
             Connection: close\r\n\r\n",
            html_bytes.len()
        );
        stream.write_all(headers.as_bytes())?;
        if method != "HEAD" {
            stream.write_all(html_bytes)?;
        }
    } else {
        // 404
        let body = b"Not Found";
        let headers = format!(
            "HTTP/1.1 404 Not Found\r\n\
             Content-Type: text/plain\r\n\
             Content-Length: {}\r\n\
             {cors_headers}\
             Connection: close\r\n\r\n",
            body.len()
        );
        stream.write_all(headers.as_bytes())?;
        stream.write_all(body)?;
    }

    Ok(())
}

/// Get the server base URL, waiting if necessary
fn get_server_url() -> Option<String> {
    // Ensure server is started
    start_server();

    // Wait for URL to be available (up to 2 seconds)
    for _ in 0..40 {
        if let Ok(guard) = SERVER_URL.lock() {
            if let Some(url) = guard.as_ref() {
                return Some(url.clone());
            }
        }
        std::thread::sleep(std::time::Duration::from_millis(50));
    }
    None
}

/// Store HTML content and get a page URL to load it
pub fn store_html_page(html: String) -> Option<String> {
    let base_url = get_server_url()?;
    let page_id = PAGE_ID_COUNTER.fetch_add(1, Ordering::SeqCst);

    if let Ok(mut map) = PENDING_PAGES.lock() {
        map.insert(page_id, html);
    }

    Some(format!("{}/page/{}", base_url, page_id))
}

/// Configure WebViewBuilder (no-op, URL loading handles everything)
pub fn configure_webview(builder: WebViewBuilder) -> WebViewBuilder {
    builder
}

/// Returns the CSS @font-face rule using the local server
pub fn get_font_css() -> String {
    let base_url = get_server_url().unwrap_or_else(|| "http://127.0.0.1:0".to_string());
    let cache_buster = SESSION_CACHE_BUSTER.as_str();

    format!(
        r#"
        @font-face {{
            font-family: 'Google Sans Flex';
            font-style: normal;
            font-weight: 100 1000;
            font-stretch: 25% 1000%;
            font-display: swap;
            src: url('{}/font/GoogleSansFlex.ttf?v={}') format('truetype');
        }}
    "#,
        base_url, cache_buster
    )
}
</file>

<file path="src/overlay/realtime_webview/app_selection.rs">
//! App selection popup for per-app audio capture

use super::state::*;
use std::collections::HashMap;
use std::sync::Mutex;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::System::Threading::{
    OpenProcess, QueryFullProcessImageNameW, PROCESS_NAME_WIN32, PROCESS_QUERY_LIMITED_INFORMATION,
};
use windows::Win32::UI::Shell::ExtractIconExW;
use windows::Win32::UI::WindowsAndMessaging::*;

lazy_static::lazy_static! {
    /// Cache for app icons (PID -> base64 PNG)
    /// Cache for app icons (PID -> base64 PNG)
    static ref ICON_CACHE: Mutex<HashMap<u32, Option<String>>> = Mutex::new(HashMap::new());
}

thread_local! {
    static APP_SELECT_WEBVIEW: std::cell::RefCell<Option<wry::WebView>> = std::cell::RefCell::new(None);
}

/// Get the executable path for a given process ID
fn get_process_exe_path(pid: u32) -> Option<String> {
    unsafe {
        let handle = OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, false, pid).ok()?;

        let mut buffer = [0u16; 1024];
        let mut size = buffer.len() as u32;

        let result = QueryFullProcessImageNameW(
            handle,
            PROCESS_NAME_WIN32,
            windows::core::PWSTR(buffer.as_mut_ptr()),
            &mut size,
        );

        let _ = windows::Win32::Foundation::CloseHandle(handle);

        if result.is_ok() && size > 0 {
            Some(String::from_utf16_lossy(&buffer[..size as usize]))
        } else {
            None
        }
    }
}

/// Extract icon from an executable and convert to base64 PNG
fn extract_icon_as_base64(exe_path: &str) -> Option<String> {
    unsafe {
        // Convert path to wide string
        let wide_path: Vec<u16> = exe_path.encode_utf16().chain(std::iter::once(0)).collect();

        // Extract large icon (32x32)
        let mut large_icon = HICON::default();
        let count = ExtractIconExW(
            windows::core::PCWSTR(wide_path.as_ptr()),
            0,
            Some(&mut large_icon),
            None,
            1,
        );

        if count == 0 || large_icon.is_invalid() {
            return None;
        }

        // Get icon info to access the bitmap
        let mut icon_info = ICONINFO::default();
        if GetIconInfo(large_icon, &mut icon_info).is_err() {
            let _ = DestroyIcon(large_icon);
            return None;
        }

        // Get bitmap info
        let mut bmp = BITMAP::default();
        if GetObjectW(
            icon_info.hbmColor.into(),
            std::mem::size_of::<BITMAP>() as i32,
            Some(&mut bmp as *mut _ as *mut std::ffi::c_void),
        ) == 0
        {
            let _ = DeleteObject(icon_info.hbmMask.into());
            let _ = DeleteObject(icon_info.hbmColor.into());
            let _ = DestroyIcon(large_icon);
            return None;
        }

        let width = bmp.bmWidth as u32;
        let height = bmp.bmHeight as u32;

        // Create DC and get bitmap bits
        let hdc_screen = GetDC(None);
        let hdc_mem = CreateCompatibleDC(Some(hdc_screen));

        // Setup BITMAPINFO for 32-bit BGRA
        let bmi = BITMAPINFO {
            bmiHeader: BITMAPINFOHEADER {
                biSize: std::mem::size_of::<BITMAPINFOHEADER>() as u32,
                biWidth: width as i32,
                biHeight: -(height as i32), // Top-down
                biPlanes: 1,
                biBitCount: 32,
                biCompression: BI_RGB.0,
                ..Default::default()
            },
            ..Default::default()
        };

        // Allocate buffer for pixel data
        let mut pixels = vec![0u8; (width * height * 4) as usize];

        // Get the bits from the color bitmap
        let lines = GetDIBits(
            hdc_mem,
            icon_info.hbmColor,
            0,
            height,
            Some(pixels.as_mut_ptr() as *mut std::ffi::c_void),
            &bmi as *const _ as *mut _,
            DIB_RGB_COLORS,
        );

        let _ = DeleteDC(hdc_mem);
        let _ = ReleaseDC(None, hdc_screen);
        let _ = DeleteObject(icon_info.hbmMask.into());
        let _ = DeleteObject(icon_info.hbmColor.into());
        let _ = DestroyIcon(large_icon);

        if lines == 0 {
            return None;
        }

        // Convert BGRA to RGBA and check for alpha
        let mut has_alpha = false;
        for i in (0..pixels.len()).step_by(4) {
            // Swap B and R (BGRA -> RGBA)
            pixels.swap(i, i + 2);
            if pixels[i + 3] != 0 {
                has_alpha = true;
            }
        }

        // If no alpha channel, set all alpha to 255
        if !has_alpha {
            for i in (3..pixels.len()).step_by(4) {
                pixels[i] = 255;
            }
        }

        // Encode as PNG using image crate
        let rgba_image = match image::RgbaImage::from_raw(width, height, pixels) {
            Some(img) => img,
            None => return None,
        };

        let mut png_data: Vec<u8> = Vec::new();
        if rgba_image
            .write_to(
                &mut std::io::Cursor::new(&mut png_data),
                image::ImageFormat::Png,
            )
            .is_err()
        {
            return None;
        }

        // Encode to base64
        use base64::Engine;
        Some(base64::engine::general_purpose::STANDARD.encode(&png_data))
    }
}

/// Get icon for a process, using cache
fn get_app_icon(pid: u32) -> Option<String> {
    // Check cache first
    {
        let cache = ICON_CACHE.lock().ok()?;
        if let Some(cached) = cache.get(&pid) {
            return cached.clone();
        }
    }

    // Extract icon
    let icon = get_process_exe_path(pid).and_then(|path| extract_icon_as_base64(&path));

    // Cache result
    if let Ok(mut cache) = ICON_CACHE.lock() {
        cache.insert(pid, icon.clone());
    }

    icon
}
/// Enumerate visible windows with titles for app selection
/// Returns a list of (PID, Window Title) for apps that likely emit audio
pub fn enumerate_audio_apps() -> Vec<(u32, String)> {
    let mut apps: Vec<(u32, String)> = Vec::new();
    let mut seen_pids: std::collections::HashSet<u32> = std::collections::HashSet::new();

    unsafe {
        // Callback to collect window info
        let mut callback_data = (&mut apps, &mut seen_pids);

        extern "system" fn enum_callback(hwnd: HWND, lparam: LPARAM) -> windows_core::BOOL {
            unsafe {
                // Skip invisible windows
                if !IsWindowVisible(hwnd).as_bool() {
                    return windows_core::BOOL(1);
                }

                // Get window title
                let mut title_buf = [0u16; 256];
                let len = GetWindowTextW(hwnd, &mut title_buf);
                if len == 0 {
                    return windows_core::BOOL(1);
                }

                let title = String::from_utf16_lossy(&title_buf[..len as usize]);

                // Skip empty/system windows
                if title.is_empty() || title == "Program Manager" || title == "Settings" {
                    return windows_core::BOOL(1);
                }

                // Get process ID
                let mut pid: u32 = 0;
                GetWindowThreadProcessId(hwnd, Some(&mut pid));

                if pid == 0 {
                    return windows_core::BOOL(1);
                }

                // Get callback data from lparam
                let data = &mut *(lparam.0
                    as *mut (&mut Vec<(u32, String)>, &mut std::collections::HashSet<u32>));
                let (apps, seen_pids) = data;

                // Skip if we've already seen this PID (one entry per app)
                if seen_pids.contains(&pid) {
                    return windows_core::BOOL(1);
                }
                seen_pids.insert(pid);

                // Skip our own process
                let our_pid = std::process::id();
                if pid == our_pid {
                    return windows_core::BOOL(1);
                }

                apps.push((pid, title));

                windows_core::BOOL(1)
            }
        }

        let _ = EnumWindows(
            Some(enum_callback),
            LPARAM(&mut callback_data as *mut _ as isize),
        );
    }

    // Sort by title for better UX
    apps.sort_by(|a, b| a.1.to_lowercase().cmp(&b.1.to_lowercase()));

    apps
}

/// Show a popup window for selecting which app to capture audio from
/// This is called when TTS is enabled in device mode
pub fn show_app_selection_popup() {
    use crate::gui::locale::LocaleText;
    use crate::APP;
    use std::sync::atomic::Ordering;
    use windows::core::*;
    use windows::Win32::Graphics::Gdi::*;
    use windows::Win32::UI::WindowsAndMessaging::*;

    // Get locale text
    let locale_text = {
        let app = APP.lock().unwrap();
        let lang = app.config.ui_language.clone();
        LocaleText::get(&lang)
    };

    // Get apps list
    let apps = enumerate_audio_apps();
    if apps.is_empty() {
        eprintln!("No audio apps found for selection");
        return;
    }

    let music_note_svg = crate::overlay::html_components::icons::get_icon_svg("music_note");
    let headphones_svg = crate::overlay::html_components::icons::get_icon_svg("headphones");

    // Build HTML for app list
    let app_items: Vec<String> = apps
        .iter()
        .map(|(pid, name)| {
            let escaped_name = name
                .replace('\\', "\\\\")
                .replace('"', "\\\"")
                .replace('<', "&lt;")
                .replace('>', "&gt;");
            // Truncate by characters, not bytes (for Unicode safety)
            let short_name = if escaped_name.chars().count() > 50 {
                let truncated: String = escaped_name.chars().take(47).collect();
                format!("{}...", truncated)
            } else {
                escaped_name.clone()
            };

            // Get real app icon or use fallback
            let icon_html = if let Some(base64_icon) = get_app_icon(*pid) {
                format!(
                    r#"<img class="app-icon-img" src="data:image/png;base64,{}" alt=""/>"#,
                    base64_icon
                )
            } else {
                format!(
                    r#"<span class="material-symbols-rounded app-icon-fallback">{}</span>"#,
                    music_note_svg
                )
            };

            format!(
                r#"<div class="app-item" data-pid="{}" onclick="selectApp({}, '{}')">
                    <div class="app-icon">{}</div>
                    <div class="app-info">
                        <span class="app-name" title="{}">{}</span>
                        <span class="app-pid">PID: {}</span>
                    </div>
                </div>"#,
                pid,
                pid,
                escaped_name.replace('\'', "\\'"),
                icon_html,
                escaped_name,
                short_name,
                pid
            )
        })
        .collect();

    // Determine initial theme
    let is_dark = if let Ok(app) = crate::APP.lock() {
        match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        }
    } else {
        true
    };

    // Get CSS
    let css_content = get_app_selection_css(is_dark);

    let html = format!(
        r##"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style id="main-style">
        {css_content}
    </style>
</head>
<body>

    <h1><span class="material-symbols-rounded">{headphones_svg}</span> {app_title}</h1>
    <p class="hint">{app_hint}</p>
    <div class="app-list">
        {app_list}
    </div>
    <script>
        function selectApp(pid, name) {{
            window.ipc.postMessage('selectApp:' + pid + ':' + name);
        }}
    </script>
</body>
</html>"##,
        app_title = locale_text.app_select_title,
        app_hint = locale_text.app_select_hint,
        app_list = app_items.join("\n"),
        headphones_svg = headphones_svg,
        css_content = css_content
    );

    // Create popup window
    std::thread::spawn(move || {
        unsafe {
            use windows::Win32::Graphics::Dwm::{
                DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE, DWMWCP_ROUND,
            };
            use windows::Win32::UI::WindowsAndMessaging::{ShowWindow, SW_HIDE, WS_CLIPCHILDREN};

            // Register window class
            let class_name = w!("AppSelectPopup");
            let h_instance = GetModuleHandleW(None).unwrap_or_default();

            let wc = WNDCLASSEXW {
                cbSize: std::mem::size_of::<WNDCLASSEXW>() as u32,
                style: CS_HREDRAW | CS_VREDRAW,
                lpfnWndProc: Some(app_select_wndproc),
                hInstance: h_instance.into(),
                hCursor: LoadCursorW(None, IDC_ARROW).unwrap_or_default(),
                hbrBackground: HBRUSH(GetStockObject(BLACK_BRUSH).0),
                lpszClassName: class_name,
                ..Default::default()
            };
            RegisterClassExW(&wc);

            // Center the window on screen
            let screen_width = GetSystemMetrics(SM_CXSCREEN);
            let screen_height = GetSystemMetrics(SM_CYSCREEN);
            let win_width = 400;
            let win_height = 500;
            let x = (screen_width - win_width) / 2;
            let y = (screen_height - win_height) / 2;

            let hwnd = CreateWindowExW(
                WS_EX_TOPMOST | WS_EX_TOOLWINDOW,
                class_name,
                w!("Select App"),
                WS_POPUP | WS_VISIBLE | WS_CLIPCHILDREN,
                x,
                y,
                win_width,
                win_height,
                None,
                None,
                Some(h_instance.into()),
                None,
            )
            .unwrap();

            // Store handle for external closing
            APP_SELECTION_HWND.store(hwnd.0 as isize, Ordering::SeqCst);

            // Apply rounded corners
            let preference = DWMWCP_ROUND;
            let _ = DwmSetWindowAttribute(
                hwnd,
                DWMWA_WINDOW_CORNER_PREFERENCE,
                &preference as *const _ as *const _,
                std::mem::size_of::<u32>() as u32,
            );

            // Create WebView2 with shared context for RAM efficiency
            let html_clone = html.clone();
            let hwnd_val = hwnd.0 as isize;

            // Create a WebContext using the shared data directory
            let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("realtime"));
            let mut web_context = wry::WebContext::new(Some(shared_data_dir));

            // Store HTML in font server and get URL for same-origin font loading
            let page_url =
                crate::overlay::html_components::font_manager::store_html_page(html_clone.clone())
                    .unwrap_or_else(|| {
                        format!("data:text/html,{}", urlencoding::encode(&html_clone))
                    });

            let builder = wry::WebViewBuilder::new_with_web_context(&mut web_context);
            let result = {
                // LOCK SCOPE: Serialized build to prevent resource contention
                let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
                crate::log_info!("[AppSelection] Acquired init lock. Building...");

                let build_res =
                    crate::overlay::html_components::font_manager::configure_webview(builder)
                        .with_bounds(wry::Rect {
                            position: wry::dpi::Position::Physical(
                                wry::dpi::PhysicalPosition::new(0, 0),
                            ),
                            size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                                win_width as u32,
                                win_height as u32,
                            )),
                        })
                        .with_url(&page_url)
                        .with_transparent(true)
                        .with_ipc_handler(move |req| {
                            let body = req.body();
                            if body.starts_with("selectApp:") {
                                let rest = &body[10..];
                                if let Some((pid_str, name)) = rest.split_once(':') {
                                    if let Ok(pid) = pid_str.parse::<u32>() {
                                        // Store selected app
                                        SELECTED_APP_PID.store(pid, Ordering::SeqCst);
                                        if let Ok(mut app_name) = SELECTED_APP_NAME.lock() {
                                            *app_name = name.to_string();
                                        }

                                        // Set audio source to trigger restart (must set this for restart to work!)
                                        if let Ok(mut new_source) = NEW_AUDIO_SOURCE.lock() {
                                            *new_source = "device".to_string();
                                        }
                                        AUDIO_SOURCE_CHANGE.store(true, Ordering::SeqCst);

                                        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
                                        // Close native popup
                                        let _ = ShowWindow(hwnd, SW_HIDE);
                                        let _ = PostMessageW(
                                            Some(hwnd),
                                            WM_CLOSE,
                                            WPARAM(0),
                                            LPARAM(0),
                                        );

                                        // Close TTS Modal using shared flag (more robust)
                                        CLOSE_TTS_MODAL_REQUEST.store(true, Ordering::SeqCst);

                                        // Trigger updates on both windows to ensure the flag is checked immediately
                                        let trans_hwnd =
                                            std::ptr::addr_of!(TRANSLATION_HWND).read();
                                        let real_hwnd = std::ptr::addr_of!(REALTIME_HWND).read();

                                        if !trans_hwnd.is_invalid() {
                                            let _ = PostMessageW(
                                                Some(trans_hwnd),
                                                crate::api::realtime_audio::WM_TRANSLATION_UPDATE,
                                                WPARAM(0),
                                                LPARAM(0),
                                            );
                                        }

                                        if !real_hwnd.is_invalid() {
                                            let _ = PostMessageW(
                                                Some(real_hwnd),
                                                crate::api::realtime_audio::WM_REALTIME_UPDATE,
                                                WPARAM(0),
                                                LPARAM(0),
                                            );
                                        }
                                    } else {
                                        eprintln!(
                                            "App Selection: Failed to parse PID from '{}'",
                                            pid_str
                                        );
                                    }
                                }
                            }
                        })
                        .build_as_child(&HwndWrapper(hwnd));
                crate::log_info!(
                    "[AppSelection] Build finished. Status: {}",
                    if build_res.is_ok() { "OK" } else { "ERR" }
                );
                build_res
            };

            if result.is_err() {
                eprintln!("Failed to create WebView for app selection");
                let _ = DestroyWindow(hwnd);
                return;
            }

            // Keep WebView alive in thread-local storage
            let webview = result.unwrap();
            APP_SELECT_WEBVIEW.with(|w| {
                *w.borrow_mut() = Some(webview);
            });

            // Message loop
            let mut msg = MSG::default();
            while GetMessageW(&mut msg, None, 0, 0).as_bool() {
                let _ = TranslateMessage(&msg);
                DispatchMessageW(&msg);
            }
        }
    });
}

pub unsafe extern "system" fn app_select_wndproc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| {
        use crate::api::realtime_audio::WM_THEME_UPDATE;
        use windows::Win32::UI::WindowsAndMessaging::*;

        match msg {
            WM_THEME_UPDATE => {
                update_app_selection_theme(hwnd);
                LRESULT(0)
            }
            WM_CLOSE => {
                let _ = DestroyWindow(hwnd);
                LRESULT(0)
            }
            WM_DESTROY => {
                // Drop WebView before thread exit to ensure clean cleanup
                APP_SELECT_WEBVIEW.with(|w| {
                    *w.borrow_mut() = None;
                });

                APP_SELECTION_HWND.store(0, std::sync::atomic::Ordering::SeqCst);
                PostQuitMessage(0);
                LRESULT(0)
            }
            WM_SIZE => {
                // Resize child (WebView) to match parent
                let width = (lparam.0 & 0xFFFF) as i32;
                let height = ((lparam.0 >> 16) & 0xFFFF) as i32;
                if let Ok(child) = GetWindow(hwnd, GW_CHILD) {
                    if child.0 != std::ptr::null_mut() {
                        let _ = MoveWindow(child, 0, 0, width, height, true);
                    }
                }
                LRESULT(0)
            }
            _ => DefWindowProcW(hwnd, msg, wparam, lparam),
        }
    }));

    match result {
        Ok(lresult) => lresult,
        Err(_) => {
            eprintln!("Panic in app_select_wndproc");
            // Try to provide default processing if panic occurred
            windows::Win32::UI::WindowsAndMessaging::DefWindowProcW(hwnd, msg, wparam, lparam)
        }
    }
}

fn get_app_selection_css(is_dark: bool) -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();
    let (
        bg_color,
        text_color,
        hint_color,
        item_bg,
        item_hover_bg,
        item_border_hover,
        scrollbar_thumb,
    ) = if is_dark {
        (
            "rgba(20, 20, 30, 0.98)",    // bg
            "#fff",                      // text
            "#888",                      // hint
            "rgba(255, 255, 255, 0.05)", // item bg
            "rgba(255, 255, 255, 0.1)",  // item hover
            "rgba(100, 180, 255, 0.5)",  // item border hover
            "rgba(255, 255, 255, 0.2)",  // scrollbar thumb
        )
    } else {
        (
            "rgba(255, 255, 255, 0.98)",
            "#202124",
            "#5f6368",
            "rgba(0, 0, 0, 0.03)",
            "rgba(0, 200, 255, 0.08)",
            "#00c8ff50",
            "#dadce0",
        )
    };

    format!(
        r##"
        {font_css}
        * {{ margin: 0; padding: 0; box-sizing: border-box; }}
        body {{
            font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
            background: {bg_color};
            color: {text_color};
            padding: 20px;
            height: 100vh;
            overflow: hidden;
        }}

        .material-symbols-rounded {{
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 1em;
            height: 1em;
            font-size: 24px;
            vertical-align: middle;
        }}
        .material-symbols-rounded svg {{
            width: 100%;
            height: 100%;
            fill: currentColor;
            display: block;
        }}
        h1 {{
            font-size: 18px;
            font-weight: 500;
            margin-bottom: 8px;
            color: {text_color};
            display: flex;
            align-items: center;
            gap: 8px;
        }}
        h1 .material-symbols-rounded {{
            font-size: 22px;
            color: #00c8ff;
        }}
        .hint {{
            font-size: 12px;
            color: {hint_color};
            margin-bottom: 16px;
        }}
        .app-list {{
            display: flex;
            flex-direction: column;
            gap: 8px;
            max-height: calc(100vh - 100px);
            overflow-y: auto;
        }}
        .app-item {{
            display: flex;
            align-items: center;
            gap: 12px;
            padding: 12px 16px;
            background: {item_bg};
            border-radius: 8px;
            cursor: pointer;
            transition: all 0.15s ease;
            border: 1px solid transparent;
        }}
        .app-item:hover {{
            background: {item_hover_bg};
            border-color: {item_border_hover};
        }}
        .app-icon {{
            width: 40px;
            height: 40px;
            display: flex;
            align-items: center;
            justify-content: center;
            background: rgba(100, 180, 255, 0.15);
            border-radius: 8px;
            flex-shrink: 0;
            overflow: hidden;
        }}
        .app-icon-img {{
            width: 32px;
            height: 32px;
            object-fit: contain;
            image-rendering: auto;
        }}
        .app-icon-fallback {{
            font-size: 24px;
            color: #00c8ff;
        }}
        .app-info {{
            flex: 1;
            min-width: 0;
        }}
        .app-name {{
            display: block;
            font-size: 14px;
            font-weight: 500;
            white-space: nowrap;
            overflow: hidden;
            text-overflow: ellipsis;
            color: {text_color};
        }}
        .app-pid {{
            font-size: 11px;
            color: {hint_color};
        }}
        .app-list::-webkit-scrollbar {{
            width: 6px;
        }}
        .app-list::-webkit-scrollbar-track {{
            background: transparent;
        }}
        .app-list::-webkit-scrollbar-thumb {{
            background: {scrollbar_thumb};
            border-radius: 3px;
        }}
    "##,
        font_css = font_css,
        bg_color = bg_color,
        text_color = text_color,
        hint_color = hint_color,
        item_bg = item_bg,
        item_hover_bg = item_hover_bg,
        item_border_hover = item_border_hover,
        scrollbar_thumb = scrollbar_thumb
    )
}

pub fn update_app_selection_theme(_hwnd: HWND) {
    let is_dark = if let Ok(app) = crate::APP.lock() {
        match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        }
    } else {
        true
    };

    let css = get_app_selection_css(is_dark);
    let css_escaped = css.replace("`", "\\`");

    let script = format!(
        r#"
        if (document.getElementById('main-style')) {{
            document.getElementById('main-style').innerHTML = `{}`;
        }}
        "#,
        css_escaped
    );

    APP_SELECT_WEBVIEW.with(|w| {
        if let Some(webview) = w.borrow().as_ref() {
            let _ = webview.evaluate_script(&script);
        }
    });
}
</file>

<file path="src/overlay/result/event_handler/mod.rs">
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;

pub mod click_actions;
pub mod misc;
pub mod mouse_input;
pub mod timer_tasks;

/// Minimum window size to prevent rendering issues when resizing too small.
/// Below these dimensions, GDI operations can fail or cause system errors.
pub const MIN_WINDOW_WIDTH: i32 = 40;
pub const MIN_WINDOW_HEIGHT: i32 = 30;

pub unsafe extern "system" fn result_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_ERASEBKGND => misc::handle_erase_bkgnd(hwnd, wparam),

        // WM_CTLCOLOREDIT removed (native edit control deprecated)
        WM_SETCURSOR => mouse_input::handle_set_cursor(hwnd),

        WM_LBUTTONDOWN => mouse_input::handle_lbutton_down(hwnd, lparam),

        WM_RBUTTONDOWN => mouse_input::handle_rbutton_down(hwnd, lparam),

        WM_MOUSEMOVE => mouse_input::handle_mouse_move(hwnd, lparam),
        WM_MBUTTONDOWN => mouse_input::handle_mbutton_down(hwnd, lparam),

        0x02A3 => mouse_input::handle_mouse_leave(hwnd), // WM_MOUSELEAVE

        WM_LBUTTONUP => click_actions::handle_lbutton_up(hwnd),

        WM_RBUTTONUP => click_actions::handle_rbutton_up(hwnd),

        WM_MBUTTONUP => click_actions::handle_mbutton_up(hwnd),

        WM_TIMER => timer_tasks::handle_timer(hwnd, wparam),

        WM_DESTROY => misc::handle_destroy(hwnd),

        WM_PAINT => misc::handle_paint(hwnd),

        WM_KEYDOWN => misc::handle_keydown(),

        // Enforce minimum window size to prevent rendering issues
        WM_GETMINMAXINFO => {
            let mmi = lparam.0 as *mut MINMAXINFO;
            if !mmi.is_null() {
                (*mmi).ptMinTrackSize.x = MIN_WINDOW_WIDTH;
                (*mmi).ptMinTrackSize.y = MIN_WINDOW_HEIGHT;
            }
            LRESULT(0)
        }

        // Deferred WebView2 creation - handles the WM_CREATE_WEBVIEW we posted
        msg if msg == misc::WM_CREATE_WEBVIEW => misc::handle_create_webview(hwnd),
        msg if msg == misc::WM_SHOW_MARKDOWN => misc::handle_show_markdown(hwnd),
        msg if msg == misc::WM_HIDE_MARKDOWN => misc::handle_hide_markdown(hwnd),
        msg if msg == misc::WM_RESIZE_MARKDOWN => misc::handle_resize_markdown(hwnd),

        msg if msg == misc::WM_UNDO_CLICK => {
            crate::overlay::result::trigger_undo(hwnd);
            LRESULT(0)
        }
        msg if msg == misc::WM_REDO_CLICK => {
            crate::overlay::result::trigger_redo(hwnd);
            LRESULT(0)
        }
        msg if msg == misc::WM_COPY_CLICK => {
            crate::overlay::result::trigger_copy(hwnd);
            LRESULT(0)
        }
        msg if msg == misc::WM_EDIT_CLICK => {
            crate::overlay::result::trigger_edit(hwnd);
            LRESULT(0)
        }
        msg if msg == misc::WM_BACK_CLICK => misc::handle_back_click(hwnd),
        msg if msg == misc::WM_FORWARD_CLICK => misc::handle_forward_click(hwnd),
        msg if msg == misc::WM_SPEAKER_CLICK => {
            crate::overlay::result::trigger_speaker(hwnd);
            LRESULT(0)
        }
        msg if msg == misc::WM_DOWNLOAD_CLICK => misc::handle_download_click(hwnd),

        WM_WINDOWPOSCHANGED => {
            // Update button canvas position when window moves/resizes
            crate::overlay::result::button_canvas::register_markdown_window(hwnd);
            DefWindowProcW(hwnd, msg, wparam, lparam)
        }

        WM_ENTERSIZEMOVE => {
            // Set interaction mode to Resizing to triggering "Hide All Buttons" logic
            crate::overlay::result::state::set_window_interaction_mode(
                hwnd,
                crate::overlay::result::state::InteractionMode::Resizing(
                    crate::overlay::result::state::ResizeEdge::None,
                ),
            );
            crate::overlay::result::button_canvas::update_canvas();
            DefWindowProcW(hwnd, msg, wparam, lparam)
        }

        WM_EXITSIZEMOVE => {
            // Reset interaction mode to show buttons again
            crate::overlay::result::state::set_window_interaction_mode(
                hwnd,
                crate::overlay::result::state::InteractionMode::None,
            );

            // Re-trigger markdown view fitting after native resize ends
            let is_markdown = {
                let states = crate::overlay::result::state::WINDOW_STATES.lock().unwrap();
                states
                    .get(&(hwnd.0 as isize))
                    .map(|s| s.is_markdown_mode)
                    .unwrap_or(false)
            };
            if is_markdown {
                crate::overlay::result::markdown_view::fit_font_to_window(hwnd);
            }

            crate::overlay::result::button_canvas::update_canvas();
            DefWindowProcW(hwnd, msg, wparam, lparam)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/result/window.rs">
use std::mem::size_of;
use std::sync::Once;
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use super::event_handler::result_wnd_proc;
use super::state::{
    CursorPhysics, InteractionMode, RefineContext, ResizeEdge, WindowState, WindowType,
    WINDOW_STATES,
};

pub const CHAIN_PALETTE: [u32; 5] = [
    0x001a1a1c, // Slate Gray (Primary)
    0x00113832, // Deep Teal
    0x00162a4d, // Royal Navy
    0x00311b3e, // Deep Plum
    0x004a2c22, // Deep Sienna
];

pub const CHAIN_PALETTE_LIGHT: [u32; 5] = [
    0x00f5f5f7, // Off White (Primary)
    0x00e0f2f1, // Light Teal
    0x00e3f2fd, // Light Blue
    0x00f3e5f5, // Light Purple
    0x00fbe9e7, // Light Orange
];

pub fn get_chain_color(visible_index: usize) -> u32 {
    let is_dark = crate::overlay::is_dark_mode();
    let palette = if is_dark {
        &CHAIN_PALETTE
    } else {
        &CHAIN_PALETTE_LIGHT
    };

    if visible_index == 0 {
        palette[0]
    } else {
        let cycle_idx = (visible_index - 1) % (palette.len() - 1);
        palette[cycle_idx + 1]
    }
}

static REGISTER_RESULT_CLASS: Once = Once::new();

pub fn create_result_window(
    target_rect: RECT,
    _win_type: WindowType,
    context: RefineContext,
    model_id: String,
    provider: String,
    streaming_enabled: bool,
    start_editing: bool,
    preset_prompt: String,
    custom_bg_color: u32,
    render_mode: &str,
    initial_text: String,
) -> HWND {
    unsafe {
        let instance = GetModuleHandleW(None).unwrap();
        let class_name = w!("TranslationResult");

        REGISTER_RESULT_CLASS.call_once(|| {
            let mut wc = WNDCLASSW::default();
            wc.lpfnWndProc = Some(result_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
            wc.lpszClassName = class_name;
            wc.style = CS_HREDRAW | CS_VREDRAW | CS_DBLCLKS;
            wc.hbrBackground = HBRUSH::default();
            let _ = RegisterClassW(&wc);
        });

        let width = (target_rect.right - target_rect.left).abs();
        let height = (target_rect.bottom - target_rect.top).abs();

        // WindowType logic essentially just sets color now, but we override it via custom_bg_color usually
        let (x, y) = (target_rect.left, target_rect.top);

        // WS_CLIPCHILDREN prevents parent from drawing over child (Fixes Blinking)
        // WS_EX_NOACTIVATE prevents stealing focus when window appears
        // NOTE: For markdown modes, we match text_input's working configuration exactly
        let is_any_markdown_mode = render_mode == "markdown" || render_mode == "markdown_stream";
        let (ex_style, base_style) = if is_any_markdown_mode {
            // Markdown mode: Now including WS_EX_NOACTIVATE to prevent focus stealing
            (
                WS_EX_TOPMOST | WS_EX_LAYERED | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
                WS_POPUP,
            )
        } else {
            // Plain text mode: prevent focus stealing, use clip children
            (
                WS_EX_TOPMOST | WS_EX_LAYERED | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
                WS_POPUP, // Removed WS_CLIPCHILDREN to fix ghost text artifacts
            )
        };

        let hwnd = CreateWindowExW(
            ex_style,
            class_name,
            w!(""),
            base_style,
            x,
            y,
            width,
            height,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        // FOR MARKDOWN MODES: Create WebView IMMEDIATELY after window creation
        // See docs/WEBVIEW2_INITIALIZATION.md for why this is necessary
        if is_any_markdown_mode {
            let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 0, LWA_ALPHA);
            let _ = super::markdown_view::create_markdown_webview(hwnd, &initial_text, false);
            let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 217, LWA_ALPHA);
        }

        let mut physics = CursorPhysics::default();
        physics.initialized = true;

        // Initialize physics with current cursor position to prevent (0,0) glitch
        let mut pt = POINT::default();
        let _ = GetCursorPos(&mut pt);
        let _ = ScreenToClient(hwnd, &mut pt);
        physics.x = pt.x as f32;
        physics.y = pt.y as f32;

        // Get graphics mode from config
        let graphics_mode = {
            let app = crate::APP.lock().unwrap();
            app.config.graphics_mode.clone()
        };

        {
            let mut states = WINDOW_STATES.lock().unwrap();
            states.insert(
                hwnd.0 as isize,
                WindowState {
                    is_hovered: false,
                    on_copy_btn: false,
                    copy_success: false,
                    on_edit_btn: false,
                    on_undo_btn: false,
                    on_redo_btn: false,
                    is_editing: start_editing,
                    context_data: context,
                    full_text: initial_text.clone(),
                    text_history: Vec::new(),
                    redo_history: Vec::new(),
                    is_refining: false,
                    animation_offset: 0.0,
                    is_streaming_active: streaming_enabled,
                    was_streaming_active: streaming_enabled,
                    model_id,
                    provider,
                    streaming_enabled,
                    bg_color: custom_bg_color,
                    linked_window: None,
                    physics,
                    interaction_mode: InteractionMode::None,
                    current_resize_edge: ResizeEdge::None,
                    drag_start_mouse: POINT { x: 0, y: 0 },
                    drag_start_window_rect: RECT::default(),
                    has_moved_significantly: false,
                    font_cache_dirty: true,
                    cached_font_size: 72,
                    content_bitmap: HBITMAP::default(),
                    last_w: 0,
                    last_h: 0,
                    pending_text: Some(initial_text),
                    last_text_update_time: 0,
                    last_resize_time: 0,
                    last_font_calc_time: 0,
                    last_webview_update_time: 0,
                    bg_bitmap: HBITMAP::default(),
                    bg_w: 0,
                    bg_h: 0,
                    preset_prompt,
                    input_text: String::new(),
                    graphics_mode,
                    cancellation_token: None,
                    // Markdown mode state
                    is_markdown_mode: is_any_markdown_mode,
                    is_markdown_streaming: render_mode == "markdown_stream",
                    on_markdown_btn: false,
                    is_browsing: false,
                    navigation_depth: 0,
                    max_navigation_depth: 0,
                    on_back_btn: false,
                    on_forward_btn: false,
                    on_download_btn: false,
                    on_speaker_btn: false,
                    tts_request_id: 0,
                    tts_loading: false,
                    opacity_percent: 85,
                },
            );
        }

        let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 217, LWA_ALPHA);

        let corner_preference = 2u32;
        let _ = DwmSetWindowAttribute(
            hwnd,
            DWMWINDOWATTRIBUTE(33),
            &corner_preference as *const _ as *const _,
            size_of::<u32>() as u32,
        );

        if start_editing {
            // Just activate the window, let the button canvas handle the UI
            let _ = SetForegroundWindow(hwnd);
        }

        SetTimer(Some(hwnd), 3, 16, None);
        if is_any_markdown_mode {
            SetTimer(Some(hwnd), 2, 30, None);
            // WebView was already created immediately after window creation (see above)
        }

        let _ = InvalidateRect(Some(hwnd), None, false);
        let _ = UpdateWindow(hwnd);

        // Always register window with button canvas so floating buttons are available
        super::button_canvas::register_markdown_window(hwnd);

        hwnd
    }
}

pub fn update_window_text(hwnd: HWND, text: &str) {
    if !unsafe { IsWindow(Some(hwnd)).as_bool() } {
        return;
    }

    let mut states = WINDOW_STATES.lock().unwrap();
    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
        state.pending_text = Some(text.to_string());
        state.full_text = text.to_string();
    }
}
</file>

<file path="src/overlay/screen_record/audio_engine.rs">
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use hound::{SampleFormat, WavSpec, WavWriter};
use ringbuf::traits::*;
use ringbuf::HeapRb;
use std::fs::File;
use std::io::BufWriter;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::thread;
use std::time::Duration;

pub fn record_audio(path: String, stop_signal: Arc<AtomicBool>, finished_signal: Arc<AtomicBool>) {
    thread::spawn(move || {
        let host = match cpal::host_from_id(cpal::HostId::Wasapi) {
            Ok(h) => h,
            Err(e) => {
                eprintln!("Failed to get WASAPI host: {}", e);
                cpal::default_host()
            }
        };

        let device = match host.default_output_device() {
            Some(d) => d,
            None => {
                eprintln!("No default output device found for loopback");
                finished_signal.store(true, Ordering::SeqCst);
                return;
            }
        };

        let config = match device.default_output_config() {
            Ok(c) => c,
            Err(e) => {
                eprintln!("Failed to get default output config: {}", e);
                finished_signal.store(true, Ordering::SeqCst);
                return;
            }
        };

        // Create a ring buffer for audio data
        let buffer_len = 4 * 1024 * 1024; // ~4 million samples
        let rb = HeapRb::<f32>::new(buffer_len);
        let (mut producer, mut consumer) = rb.split();

        let stream_config: cpal::StreamConfig = config.clone().into();
        let channels = stream_config.channels;
        let sample_rate = stream_config.sample_rate;

        let err_fn = |err| eprintln!("Audio stream error: {}", err);

        // Capture in float, but we will convert to 16-bit integer
        let stream = match device.build_input_stream(
            &stream_config,
            move |data: &[f32], _: &_| {
                let _ = producer.push_slice(data);
            },
            err_fn,
            None,
        ) {
            Ok(s) => s,
            Err(e) => {
                eprintln!("Failed to build audio input stream: {}", e);
                finished_signal.store(true, Ordering::SeqCst);
                return;
            }
        };

        if let Err(e) = stream.play() {
            eprintln!("Failed to start audio stream: {}", e);
            finished_signal.store(true, Ordering::SeqCst);
            return;
        }

        println!(
            "Audio recording started (16-bit PCM): {} (Rate: {}, Channels: {})",
            path, sample_rate, channels
        );

        // Use 16-bit Signed Integer (PCM) instead of Float.
        // This is much more compatible and less prone to "static pops"
        let spec = WavSpec {
            channels: channels as u16,
            sample_rate,
            bits_per_sample: 16,
            sample_format: SampleFormat::Int,
        };

        let file = match File::create(&path) {
            Ok(f) => f,
            Err(e) => {
                eprintln!("Failed to create audio file: {}", e);
                return;
            }
        };

        let buf_writer = BufWriter::new(file);
        let mut writer = match WavWriter::new(buf_writer, spec) {
            Ok(w) => w,
            Err(e) => {
                eprintln!("Failed to create WAV writer: {}", e);
                return;
            }
        };

        let mut chunk = vec![0.0f32; 16384];

        while !stop_signal.load(Ordering::SeqCst) {
            if consumer.is_empty() {
                thread::sleep(Duration::from_millis(5));
                continue;
            }

            let count = consumer.pop_slice(&mut chunk);
            if count > 0 {
                for i in 0..count {
                    // Hard clamp to [-1.0, 1.0] and convert to i16
                    // This eliminates floating point range issues causing pops
                    let sample = chunk[i].clamp(-1.0, 1.0);
                    let pcm_sample = (sample * 32767.0) as i16;

                    if let Err(e) = writer.write_sample(pcm_sample) {
                        eprintln!("WAV Write error: {}", e);
                        break;
                    }
                }
            }
        }

        println!("Audio stop signal received. Flushing buffer...");
        drop(stream);

        // Flush remainder
        loop {
            let count = consumer.pop_slice(&mut chunk);
            if count == 0 {
                break;
            }
            for i in 0..count {
                let sample = chunk[i].clamp(-1.0, 1.0);
                let pcm_sample = (sample * 32767.0) as i16;
                let _ = writer.write_sample(pcm_sample);
            }
        }

        if let Err(e) = writer.finalize() {
            eprintln!("Failed to finalize WAV file: {}", e);
        } else {
            println!("Audio recording finished: {}", path);
        }

        finished_signal.store(true, Ordering::SeqCst);
    });
}
</file>

<file path="src/overlay/utils.rs">
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::{
    CreateDIBitmap, GetDC, ReleaseDC, BITMAPINFO, BITMAPINFOHEADER, CBM_INIT, DIB_RGB_COLORS,
};
use windows::Win32::System::Com::{CoCreateInstance, CLSCTX_INPROC_SERVER};
use windows::Win32::System::DataExchange::*;
use windows::Win32::System::Memory::*;
use windows::Win32::System::Threading::*;
use windows::Win32::UI::Accessibility::*;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use std::sync::atomic::{AtomicU64, Ordering};
use std::time::{SystemTime, UNIX_EPOCH};

/// Timestamp (millis since epoch) of last "no caret" error badge.
/// Used to rate-limit error notifications during streaming typing.
static LAST_NO_CARET_ERROR_MS: AtomicU64 = AtomicU64::new(0);
const NO_CARET_ERROR_COOLDOWN_MS: u64 = 5000; // Show error at most once per 5 seconds

/// Checks if there's a text input element focused using UI Automation.
/// This works for modern apps (Chrome, VS Code, Electron) unlike the legacy caret API.
/// Returns true if a text input is focused, false otherwise.
pub fn is_text_input_focused() -> bool {
    unsafe {
        // Try UI Automation first (works for modern apps)
        // We use a pattern-based approach which is robust for Chrome/Electron/VSCode
        if let Ok(uia) =
            CoCreateInstance::<_, IUIAutomation>(&CUIAutomation, None, CLSCTX_INPROC_SERVER)
        {
            if let Ok(focused) = uia.GetFocusedElement() {
                // Check for ValuePattern (simpler text inputs)
                // UIA_ValuePatternId = 10002
                if focused.GetCurrentPattern(UIA_ValuePatternId).is_ok() {
                    return true;
                }

                // Check for TextPattern (rich text editors)
                // UIA_TextPatternId = 10014
                if focused.GetCurrentPattern(UIA_TextPatternId).is_ok() {
                    return true;
                }
            }
        }

        // Fallback: Check legacy Win32 caret (for traditional Win32 apps like Notepad)
        let hwnd_foreground = GetForegroundWindow();
        if !hwnd_foreground.is_invalid() {
            let thread_id = GetWindowThreadProcessId(hwnd_foreground, None);
            if thread_id != 0 {
                let mut gui_info = GUITHREADINFO::default();
                gui_info.cbSize = std::mem::size_of::<GUITHREADINFO>() as u32;

                if GetGUIThreadInfo(thread_id, &mut gui_info).is_ok() {
                    let has_caret = !gui_info.hwndCaret.is_invalid();
                    let blinking = (gui_info.flags & GUI_CARETBLINKING).0 != 0;

                    if has_caret || blinking {
                        return true;
                    }
                }
            }
        }

        false
    }
}

pub fn to_wstring(s: &str) -> Vec<u16> {
    s.encode_utf16().chain(std::iter::once(0)).collect()
}

/// Global switch for the "context quote" displayed in result windows during refining.
/// Set to false to hide the quote and only show the glow animation.
pub const SHOW_REFINING_CONTEXT_QUOTE: bool = false;

pub fn get_context_quote(text: &str) -> String {
    let words: Vec<&str> = text.split_whitespace().collect();
    let len = words.len();
    if len > 50 {
        format!("\"... {}\"", words[len - 50..].join(" "))
    } else {
        format!("\"... {}\"", words.join(" "))
    }
}

// --- CLIPBOARD SUPPORT ---
pub fn copy_to_clipboard(text: &str, hwnd: HWND) {
    unsafe {
        // Retry loop to handle temporary clipboard locks
        for attempt in 0..5 {
            if OpenClipboard(Some(hwnd)).is_ok() {
                let _ = EmptyClipboard();

                // Convert text to UTF-16
                let wide_text: Vec<u16> = text.encode_utf16().chain(std::iter::once(0)).collect();
                let mem_size = wide_text.len() * 2;

                // Allocate global memory
                if let Ok(h_mem) = GlobalAlloc(GMEM_MOVEABLE, mem_size) {
                    let ptr = GlobalLock(h_mem) as *mut u16;
                    std::ptr::copy_nonoverlapping(wide_text.as_ptr(), ptr, wide_text.len());
                    let _ = GlobalUnlock(h_mem);

                    // Set clipboard data (CF_UNICODETEXT = 13)
                    let h_mem_handle = HANDLE(h_mem.0);
                    let _ = SetClipboardData(13u32, Some(h_mem_handle));
                }

                let _ = CloseClipboard();
                return; // Success
            }

            // If failed and not last attempt, wait before retrying
            if attempt < 4 {
                std::thread::sleep(std::time::Duration::from_millis(10));
            } else {
                eprintln!("Failed to copy to clipboard after 5 attempts");
            }
        }
    }
}

pub fn copy_image_to_clipboard(image_bytes: &[u8]) {
    // Convert PNG/etc bytes to BMP format using image crate
    // Clipboard expects CF_DIB which is BMP without the File Header (first 14 bytes)
    if let Ok(img) = image::load_from_memory(image_bytes) {
        let mut bmp_data = Vec::new();
        let mut cursor = std::io::Cursor::new(&mut bmp_data);
        if img.write_to(&mut cursor, image::ImageFormat::Bmp).is_ok() {
            // Check if valid BMP (starts with BM)
            if bmp_data.len() > 14 && bmp_data[0] == 0x42 && bmp_data[1] == 0x4D {
                // Skip the 14-byte BITMAPFILEHEADER to get BITMAPINFOHEADER + Pixels (DIB)
                let dib_data = &bmp_data[14..];

                unsafe {
                    // Retry loop
                    for attempt in 0..5 {
                        if OpenClipboard(None).is_ok() {
                            let _ = EmptyClipboard();

                            let mem_size = dib_data.len();
                            if let Ok(h_mem) = GlobalAlloc(GMEM_MOVEABLE, mem_size) {
                                let ptr = GlobalLock(h_mem) as *mut u8;
                                std::ptr::copy_nonoverlapping(dib_data.as_ptr(), ptr, mem_size);
                                let _ = GlobalUnlock(h_mem);

                                // Set CF_DIB (8)
                                let h_mem_handle = HANDLE(h_mem.0);
                                let _ = SetClipboardData(8, Some(h_mem_handle));

                                // ALSO set CF_BITMAP (2) to ensure Windows Clipboard History picks it up.
                                // Many modern Windows apps/features prefer having a GDI handle or both formats.
                                {
                                    let hdc = GetDC(None);
                                    if !hdc.is_invalid() {
                                        // Read header size (first 4 bytes of DIB data)
                                        if dib_data.len() >= 4 {
                                            let header_size = u32::from_le_bytes(
                                                dib_data[0..4].try_into().unwrap_or([0; 4]),
                                            );
                                            // The bits usually start after the header.
                                            // Make sure we don't go out of bounds.
                                            if (header_size as usize) < dib_data.len() {
                                                let bits_ptr =
                                                    dib_data.as_ptr().add(header_size as usize);
                                                let pbmih =
                                                    dib_data.as_ptr() as *const BITMAPINFOHEADER;
                                                let pbmi = dib_data.as_ptr() as *const BITMAPINFO;

                                                let hbitmap = CreateDIBitmap(
                                                    hdc,
                                                    Some(pbmih),
                                                    CBM_INIT as u32,
                                                    Some(bits_ptr as *const std::ffi::c_void),
                                                    Some(pbmi),
                                                    DIB_RGB_COLORS,
                                                );

                                                if !hbitmap.is_invalid() {
                                                    // ownership transferred to system
                                                    let _ = SetClipboardData(
                                                        2, // CF_BITMAP
                                                        Some(HANDLE(hbitmap.0 as *mut _)),
                                                    );
                                                }
                                            }
                                        }
                                        ReleaseDC(None, hdc);
                                    }
                                }

                                let _ = CloseClipboard();
                                return;
                            }
                        }
                        if attempt < 4 {
                            std::thread::sleep(std::time::Duration::from_millis(10));
                        }
                    }
                }
            }
        }
    }
}

/// Read image bytes from clipboard (returns PNG-encoded bytes)
/// Returns None if no image is available in clipboard
pub fn get_clipboard_image_bytes() -> Option<Vec<u8>> {
    use windows::Win32::System::DataExchange::IsClipboardFormatAvailable;

    unsafe {
        // Try to open clipboard with retries
        for _attempt in 0..5 {
            if OpenClipboard(None).is_ok() {
                // Check if any image format is available
                // CF_DIB = 8, CF_DIBV5 = 17
                let has_dib = IsClipboardFormatAvailable(8).is_ok();
                let has_dibv5 = IsClipboardFormatAvailable(17).is_ok();

                if !has_dib && !has_dibv5 {
                    let _ = CloseClipboard();
                    return None;
                }

                // Try CF_DIB first (8), then CF_DIBV5 (17)
                let format_to_try = if has_dib { 8u32 } else { 17u32 };

                if let Ok(h_data) = GetClipboardData(format_to_try) {
                    let ptr = GlobalLock(HGLOBAL(h_data.0));
                    if !ptr.is_null() {
                        // Get the size of the global memory block
                        let size = GlobalSize(HGLOBAL(h_data.0));
                        if size > 0 {
                            // Read DIB data
                            let dib_data = std::slice::from_raw_parts(ptr as *const u8, size);

                            // Parse BITMAPINFOHEADER to get dimensions
                            if dib_data.len() >= std::mem::size_of::<BITMAPINFOHEADER>() {
                                let header = &*(dib_data.as_ptr() as *const BITMAPINFOHEADER);
                                let width = header.biWidth;
                                let height = header.biHeight.abs();
                                let bit_count = header.biBitCount;
                                let is_top_down = header.biHeight < 0;

                                // We support 24-bit and 32-bit images
                                if (bit_count == 24 || bit_count == 32) && width > 0 && height > 0 {
                                    // Calculate the offset to pixel data
                                    let header_size = header.biSize as usize;
                                    let color_table_size = if header.biClrUsed > 0 {
                                        (header.biClrUsed as usize) * 4
                                    } else if bit_count <= 8 {
                                        (1 << bit_count) * 4
                                    } else {
                                        0
                                    };
                                    let pixel_offset = header_size + color_table_size;

                                    if dib_data.len() > pixel_offset {
                                        let pixel_data = &dib_data[pixel_offset..];
                                        let bytes_per_pixel = (bit_count / 8) as usize;
                                        let row_size =
                                            ((width as usize * bytes_per_pixel + 3) / 4) * 4; // DWORD aligned

                                        // Create RGBA buffer
                                        let mut rgba_buffer =
                                            Vec::with_capacity((width * height * 4) as usize);

                                        for y in 0..height {
                                            let src_y =
                                                if is_top_down { y } else { height - 1 - y };
                                            let row_start = (src_y as usize) * row_size;

                                            for x in 0..width {
                                                let px_start =
                                                    row_start + (x as usize) * bytes_per_pixel;
                                                if px_start + bytes_per_pixel <= pixel_data.len() {
                                                    // DIB is BGR(A)
                                                    let b = pixel_data[px_start];
                                                    let g = pixel_data[px_start + 1];
                                                    let r = pixel_data[px_start + 2];
                                                    let a = if bytes_per_pixel == 4 {
                                                        pixel_data[px_start + 3]
                                                    } else {
                                                        255
                                                    };
                                                    rgba_buffer.push(r);
                                                    rgba_buffer.push(g);
                                                    rgba_buffer.push(b);
                                                    rgba_buffer.push(a);
                                                }
                                            }
                                        }

                                        let _ = GlobalUnlock(HGLOBAL(h_data.0));
                                        let _ = CloseClipboard();

                                        // Encode as PNG
                                        if let Some(img) =
                                            image::ImageBuffer::<image::Rgba<u8>, _>::from_raw(
                                                width as u32,
                                                height as u32,
                                                rgba_buffer,
                                            )
                                        {
                                            let mut png_data = Vec::new();
                                            let mut cursor = std::io::Cursor::new(&mut png_data);
                                            if img
                                                .write_to(&mut cursor, image::ImageFormat::Png)
                                                .is_ok()
                                            {
                                                return Some(png_data);
                                            }
                                        }

                                        return None;
                                    }
                                }
                            }
                        }
                        let _ = GlobalUnlock(HGLOBAL(h_data.0));
                    }
                }
                let _ = CloseClipboard();
                return None;
            }
            std::thread::sleep(std::time::Duration::from_millis(10));
        }
        None
    }
}

// --- AUTO PASTE UTILS ---

/// Returns the foreground window to attempt paste on.
/// We don't filter by caret here anymore, deferring the check to force_focus_and_paste
/// where we use more robust UI Automation.
pub fn get_target_window_for_paste() -> Option<HWND> {
    unsafe {
        let hwnd_foreground = GetForegroundWindow();
        if hwnd_foreground.is_invalid() {
            return None;
        }
        Some(hwnd_foreground)
    }
}

pub fn force_focus_and_paste(hwnd_target: HWND) {
    unsafe {
        // 1. Force focus back to the target window
        if IsWindow(Some(hwnd_target)).as_bool() {
            let cur_thread = GetCurrentThreadId();
            let target_thread = GetWindowThreadProcessId(hwnd_target, None);

            if cur_thread != target_thread {
                let _ = AttachThreadInput(cur_thread, target_thread, true);
                let _ = SetForegroundWindow(hwnd_target);
                // Important: Bring window to top so it receives input
                let _ = BringWindowToTop(hwnd_target);
                let _ = SetFocus(Some(hwnd_target));
                let _ = AttachThreadInput(cur_thread, target_thread, false);
            } else {
                let _ = SetForegroundWindow(hwnd_target);
            }
        } else {
            return;
        }

        // 2. Wait for focus to settle
        std::thread::sleep(std::time::Duration::from_millis(350));

        // 2.5 Check if there's a writable area using UI Automation
        if !is_text_input_focused() {
            // Rate limit error notifications
            let now_ms = SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0);
            let last_error_ms = LAST_NO_CARET_ERROR_MS.load(Ordering::Relaxed);

            if now_ms.saturating_sub(last_error_ms) >= NO_CARET_ERROR_COOLDOWN_MS {
                LAST_NO_CARET_ERROR_MS.store(now_ms, Ordering::Relaxed);
                let app = crate::APP.lock().unwrap();
                let ui_lang = app.config.ui_language.clone();
                let locale = crate::gui::locale::LocaleText::get(&ui_lang);
                let msg = locale.cannot_type_no_caret;
                drop(app);
                crate::overlay::auto_copy_badge::show_error_notification(msg);
            }
            return;
        }

        // 3. CLEANUP MODIFIERS SMARTLY
        // Only send KeyUp if the key is actually physically pressed to avoid side effects
        let release_if_pressed = |vk: u16| {
            let state = GetAsyncKeyState(vk as i32);
            if (state as u16 & 0x8000) != 0 {
                let input = INPUT {
                    r#type: INPUT_KEYBOARD,
                    Anonymous: INPUT_0 {
                        ki: KEYBDINPUT {
                            wVk: VIRTUAL_KEY(vk),
                            dwFlags: KEYEVENTF_KEYUP,
                            ..Default::default()
                        },
                    },
                };
                SendInput(&[input], std::mem::size_of::<INPUT>() as i32);
            }
        };

        release_if_pressed(VK_MENU.0); // Alt
        release_if_pressed(VK_SHIFT.0); // Shift
        release_if_pressed(VK_LWIN.0); // Win Left
        release_if_pressed(VK_RWIN.0); // Win Right
        release_if_pressed(VK_CONTROL.0); // Ctrl

        std::thread::sleep(std::time::Duration::from_millis(50));

        // 4. Send Ctrl+V Sequence
        let send_input_event = |vk: u16, flags: KEYBD_EVENT_FLAGS| {
            let input = INPUT {
                r#type: INPUT_KEYBOARD,
                Anonymous: INPUT_0 {
                    ki: KEYBDINPUT {
                        wVk: VIRTUAL_KEY(vk),
                        dwFlags: flags,
                        time: 0,
                        dwExtraInfo: 0,
                        wScan: 0,
                    },
                },
            };
            SendInput(&[input], std::mem::size_of::<INPUT>() as i32);
        };

        // Ctrl Down
        send_input_event(VK_CONTROL.0, KEYBD_EVENT_FLAGS(0));
        std::thread::sleep(std::time::Duration::from_millis(50));

        // V Down
        send_input_event(VK_V.0, KEYBD_EVENT_FLAGS(0));
        std::thread::sleep(std::time::Duration::from_millis(50));

        // V Up
        send_input_event(VK_V.0, KEYEVENTF_KEYUP);
        std::thread::sleep(std::time::Duration::from_millis(50));

        // Ctrl Up
        send_input_event(VK_CONTROL.0, KEYEVENTF_KEYUP);
    }
}

pub fn type_text_to_window(hwnd_target_opt: Option<HWND>, text: &str) {
    if text.is_empty() {
        return;
    }
    unsafe {
        // Determine the actual target window
        let fg_window = GetForegroundWindow();
        let target_window = if let Some(hwnd) = hwnd_target_opt {
            if IsWindow(Some(hwnd)).as_bool() {
                hwnd
            } else {
                fg_window
            }
        } else {
            fg_window
        };

        // Don't try to type into nothing
        if target_window.is_invalid() {
            return;
        }

        // Check if there's a writable area using UI Automation
        if !is_text_input_focused() {
            // Rate limit error notifications
            let now_ms = SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .map(|d| d.as_millis() as u64)
                .unwrap_or(0);
            let last_error_ms = LAST_NO_CARET_ERROR_MS.load(Ordering::Relaxed);

            if now_ms.saturating_sub(last_error_ms) >= NO_CARET_ERROR_COOLDOWN_MS {
                LAST_NO_CARET_ERROR_MS.store(now_ms, Ordering::Relaxed);
                let app = crate::APP.lock().unwrap();
                let ui_lang = app.config.ui_language.clone();
                let locale = crate::gui::locale::LocaleText::get(&ui_lang);
                let msg = locale.cannot_type_no_caret;
                drop(app);
                crate::overlay::auto_copy_badge::show_error_notification(msg);
            }
            return;
        }

        if fg_window != target_window {
            let cur_thread = GetCurrentThreadId();
            let target_thread = GetWindowThreadProcessId(target_window, None);
            if cur_thread != target_thread {
                let _ = AttachThreadInput(cur_thread, target_thread, true);
                let _ = SetForegroundWindow(target_window);
                let _ = AttachThreadInput(cur_thread, target_thread, false);
            } else {
                let _ = SetForegroundWindow(target_window);
            }
        }

        // Send Chars
        // NOTE: Notepad and some other legacy apps process synthetic input slowly.
        // We use extended delays and special space handling to avoid dropped characters.
        let mut prev_was_space = false;
        for c in text.chars() {
            // If previous char was a space, add extra delay before next char
            // This fixes Notepad dropping the first consonant after a space
            if prev_was_space {
                std::thread::sleep(std::time::Duration::from_millis(25));
            }
            prev_was_space = c == ' ';

            // Use VK_SPACE for space characters (more reliable in Notepad)
            if c == ' ' {
                let input_down = INPUT {
                    r#type: INPUT_KEYBOARD,
                    Anonymous: INPUT_0 {
                        ki: KEYBDINPUT {
                            wVk: VK_SPACE,
                            wScan: 0,
                            dwFlags: KEYBD_EVENT_FLAGS(0),
                            ..Default::default()
                        },
                    },
                };
                let input_up = INPUT {
                    r#type: INPUT_KEYBOARD,
                    Anonymous: INPUT_0 {
                        ki: KEYBDINPUT {
                            wVk: VK_SPACE,
                            wScan: 0,
                            dwFlags: KEYEVENTF_KEYUP,
                            ..Default::default()
                        },
                    },
                };
                SendInput(&[input_down], std::mem::size_of::<INPUT>() as i32);
                std::thread::sleep(std::time::Duration::from_millis(8));
                SendInput(&[input_up], std::mem::size_of::<INPUT>() as i32);
                std::thread::sleep(std::time::Duration::from_millis(15));
                continue;
            }

            let mut buffer = [0u16; 2];
            let encoded = c.encode_utf16(&mut buffer);

            for utf16_val in encoded.iter() {
                let val = *utf16_val;
                let input_down = INPUT {
                    r#type: INPUT_KEYBOARD,
                    Anonymous: INPUT_0 {
                        ki: KEYBDINPUT {
                            wVk: VIRTUAL_KEY(0),
                            wScan: val,
                            dwFlags: KEYEVENTF_UNICODE,
                            ..Default::default()
                        },
                    },
                };
                let input_up = INPUT {
                    r#type: INPUT_KEYBOARD,
                    Anonymous: INPUT_0 {
                        ki: KEYBDINPUT {
                            wVk: VIRTUAL_KEY(0),
                            wScan: val,
                            dwFlags: KEYEVENTF_UNICODE | KEYEVENTF_KEYUP,
                            ..Default::default()
                        },
                    },
                };
                // Send keydown and keyup separately with delay between for better app compatibility
                SendInput(&[input_down], std::mem::size_of::<INPUT>() as i32);
                std::thread::sleep(std::time::Duration::from_millis(5));
                SendInput(&[input_up], std::mem::size_of::<INPUT>() as i32);
                std::thread::sleep(std::time::Duration::from_millis(12));
            }
        }
    }
}

pub fn get_error_message(error: &str, lang: &str, model_name: Option<&str>) -> String {
    // Parse NO_API_KEY:provider format
    if error.starts_with("NO_API_KEY") {
        let provider = if error.contains(':') {
            let parts: Vec<&str> = error.split(':').collect();
            if parts.len() > 1 {
                match parts[1] {
                    "groq" => "Groq",
                    "google" => "Google Gemini",
                    "openai" => "OpenAI",
                    other => other,
                }
            } else {
                "API"
            }
        } else {
            "API"
        };

        return match lang {
            "vi" => format!("Bạn chưa nhập {} API key!", provider),
            "ko" => format!("{} API 키를 입력하지 않았습니다!", provider),
            "ja" => format!("{} APIキーが入力されていません!", provider),
            "zh" => format!("您还没有输入 {} API key!", provider),
            _ => format!("You haven't entered a {} API key!", provider),
        };
    }

    // Parse INVALID_API_KEY:provider format
    if error.starts_with("INVALID_API_KEY") {
        let provider = if error.contains(':') {
            let parts: Vec<&str> = error.split(':').collect();
            if parts.len() > 1 {
                match parts[1] {
                    "groq" => "Groq",
                    "google" => "Google Gemini",
                    "openai" => "OpenAI",
                    other => other,
                }
            } else {
                "API"
            }
        } else {
            "API"
        };

        return match lang {
            "vi" => format!("{} API key không hợp lệ!", provider),
            "ko" => format!("{} API 키가 유효하지 않습니다!", provider),
            "ja" => format!("{} APIキーが無効です!", provider),
            "zh" => format!("{} API key 无效!", provider),
            _ => format!("Invalid {} API key!", provider),
        };
    }

    // Parse HTTP status codes from API error messages
    // Example: "Error: https://api.groq.com/openai/v1/chat/completions: status code 429"
    if let Some(status_code) = extract_http_status_code(error) {
        let provider = extract_provider_from_error(error);
        return format_http_error(status_code, &provider, model_name, lang);
    }

    // Fallback for other errors
    match lang {
        "vi" => format!("Lỗi: {}", error),
        "ko" => format!("오류: {}", error),
        "ja" => format!("エラー: {}", error),
        "zh" => format!("错误: {}", error),
        _ => format!("Error: {}", error),
    }
}

/// Extracts HTTP status code from error message
fn extract_http_status_code(error: &str) -> Option<u16> {
    // Pattern: "status code XXX" or just a 3-digit code at the end
    if let Some(pos) = error.find("status code ") {
        let after = &error[pos + 12..];
        let code_str: String = after.chars().take_while(|c| c.is_ascii_digit()).collect();
        return code_str.parse().ok();
    }

    // Also check for patterns like ": 429" at the end
    let trimmed = error.trim();
    if trimmed.len() >= 3 {
        let last_3: String = trimmed
            .chars()
            .rev()
            .take(3)
            .collect::<String>()
            .chars()
            .rev()
            .collect();
        if last_3.chars().all(|c| c.is_ascii_digit()) {
            if let Ok(code) = last_3.parse::<u16>() {
                if (400..=599).contains(&code) {
                    return Some(code);
                }
            }
        }
    }

    // Check for "XXX" anywhere (common error codes)
    for code in [429, 400, 401, 403, 404, 500, 502, 503, 504] {
        if error.contains(&code.to_string()) {
            return Some(code);
        }
    }

    None
}

/// Extracts provider name from error URL
fn extract_provider_from_error(error: &str) -> String {
    if error.contains("api.groq.com") {
        "Groq".to_string()
    } else if error.contains("generativelanguage.googleapis.com") || error.contains("gemini") {
        "Google Gemini".to_string()
    } else if error.contains("api.openai.com") {
        "OpenAI".to_string()
    } else if error.contains("api.anthropic.com") || error.contains("claude") {
        "Anthropic".to_string()
    } else {
        "API".to_string()
    }
}

/// Formats HTTP error with localized message
fn format_http_error(
    status_code: u16,
    provider: &str,
    model_name: Option<&str>,
    lang: &str,
) -> String {
    // Format the model/provider info for display
    let model_info = if let Some(model) = model_name {
        format!("{} ({})", model, provider)
    } else {
        provider.to_string()
    };

    match status_code {
        429 => match lang {
            "vi" => format!("Lỗi 429: Đã vượt quá hạn mức của mô hình {} (Rate Limit). Vui lòng chờ một lát rồi thử lại.", model_info),
            "ko" => format!("오류 429: {} 모델의 요청 제한 초과 (Rate Limit). 잠시 후 다시 시도해 주세요.", model_info),
            "ja" => format!("エラー 429: {} のレート制限を超えました。しばらくしてから再試行してください。", model_info),
            "zh" => format!("错误 429: {} 模型请求超出限制 (Rate Limit)。请稍后再试。", model_info),
            _ => format!("Error 429: Rate limit exceeded for model {}. Please wait a moment and try again.", model_info),
        },
        400 => match lang {
            "vi" => format!("Lỗi 400: Yêu cầu không hợp lệ đến {}. Vui lòng kiểm tra lại cài đặt.", model_info),
            "ko" => format!("오류 400: {}에 대한 잘못된 요청입니다. 설정을 확인해 주세요.", model_info),
            "ja" => format!("エラー 400: {} へのリクエストが無効です。設定を確認してください。", model_info),
            "zh" => format!("错误 400: {} 请求无效。请检查设置。", model_info),
            _ => format!("Error 400: Bad request to {}. Please check your settings.", model_info),
        },
        401 => match lang {
            "vi" => format!("Lỗi 401: API key của {} không hợp lệ hoặc đã hết hạn.", provider),
            "ko" => format!("오류 401: {} API 키가 유효하지 않거나 만료되었습니다.", provider),
            "ja" => format!("エラー 401: {} の API キーが無効または期限切れです。", provider),
            "zh" => format!("错误 401: {} API 密钥无效或已过期。", provider),
            _ => format!("Error 401: {} API key is invalid or expired.", provider),
        },
        403 => match lang {
            "vi" => format!("Lỗi 403: Không có quyền truy cập {}. Vui lòng kiểm tra API key.", provider),
            "ko" => format!("오류 403: {}에 대한 접근 권한이 없습니다. API 키를 확인해 주세요.", provider),
            "ja" => format!("エラー 403: {} へのアクセス権限がありません。API キーを確認してください。", provider),
            "zh" => format!("错误 403: 无权访问 {}。请检查 API 密钥。", provider),
            _ => format!("Error 403: Access forbidden to {}. Please check your API key.", provider),
        },
        404 => match lang {
            "vi" => format!("Lỗi 404: Không tìm thấy mô hình {} trên {}.", model_name.unwrap_or("này"), provider),
            "ko" => format!("오류 404: {}에서 {} 모델을 찾을 수 없습니다.", provider, model_name.unwrap_or("해당")),
            "ja" => format!("エラー 404: {} で {} が見つかりません。", provider, model_name.unwrap_or("このモデル")),
            "zh" => format!("错误 404: 在 {} 上找不到模型 {}。", provider, model_name.unwrap_or("此")),
            _ => format!("Error 404: Model {} not found on {}.", model_name.unwrap_or("this"), provider),
        },
        500 => match lang {
            "vi" => format!("Lỗi 500: Máy chủ {} gặp lỗi nội bộ. Vui lòng thử lại sau.", provider),
            "ko" => format!("오류 500: {} 서버 내부 오류입니다. 나중에 다시 시도해 주세요.", provider),
            "ja" => format!("エラー 500: {} サーバー内部エラー。後で再試行してください。", provider),
            "zh" => format!("错误 500: {} 服务器内部错误。请稍后再试。", provider),
            _ => format!("Error 500: {} internal server error. Please try again later.", provider),
        },
        502 => match lang {
            "vi" => format!("Lỗi 502: Bad Gateway - {} đang gặp sự cố. Vui lòng thử lại sau.", provider),
            "ko" => format!("오류 502: Bad Gateway - {}에 문제가 발생했습니다. 나중에 다시 시도해 주세요.", provider),
            "ja" => format!("エラー 502: Bad Gateway - {} に問題が発生しています。後で再試行してください。", provider),
            "zh" => format!("错误 502: Bad Gateway - {} 遇到问题。请稍后再试。", provider),
            _ => format!("Error 502: Bad Gateway - {} is having issues. Please try again later.", provider),
        },
        503 => match lang {
            "vi" => format!("Lỗi 503: Dịch vụ {} đang quá tải hoặc bảo trì. Vui lòng thử lại sau.", provider),
            "ko" => format!("오류 503: {} 서비스가 과부하 상태이거나 점검 중입니다. 나중에 다시 시도해 주세요.", provider),
            "ja" => format!("エラー 503: {} サービスが過負荷またはメンテナンス中です。後で再試行してください。", provider),
            "zh" => format!("错误 503: {} 服务过载或维护中。请稍后再试。", provider),
            _ => format!("Error 503: {} service is overloaded or under maintenance. Please try again later.", provider),
        },
        504 => match lang {
            "vi" => format!("Lỗi 504: Hết thời gian chờ phản hồi từ {}. Vui lòng thử lại.", model_info),
            "ko" => format!("오류 504: {} 응답 시간 초과. 다시 시도해 주세요.", model_info),
            "ja" => format!("エラー 504: {} からの応答がタイムアウトしました。再試行してください。", model_info),
            "zh" => format!("错误 504: {} 响应超时。请重试。", model_info),
            _ => format!("Error 504: Gateway timeout from {}. Please try again.", model_info),
        },
        _ => match lang {
            "vi" => format!("Lỗi {}: Có lỗi xảy ra với {} (HTTP {}).", status_code, model_info, status_code),
            "ko" => format!("오류 {}: {}에서 오류가 발생했습니다 (HTTP {}).", status_code, model_info, status_code),
            "ja" => format!("エラー {}: {} でエラーが発生しました (HTTP {}).", status_code, model_info, status_code),
            "zh" => format!("错误 {}: {} 发生错误 (HTTP {}).", status_code, model_info, status_code),
            _ => format!("Error {}: An error occurred with {} (HTTP {}).", status_code, model_info, status_code),
        },
    }
}

pub fn is_retryable_error(error: &str) -> bool {
    // 1. Check for explicit Auth errors (Never retry)
    if error.contains("NO_API_KEY") || error.contains("INVALID_API_KEY") {
        return false;
    }

    // 2. Check HTTP status if present
    if let Some(code) = extract_http_status_code(error) {
        // 429: Rate Limit (Retry!)
        if code == 429 || code == 400 {
            return true;
        }
        // 5xx: Server Errors (Retry!)
        if code >= 500 && code <= 599 {
            return true;
        }
        return false;
    }

    // 3. Fallback text checks
    let lower_err = error.to_lowercase();
    if lower_err.contains("rate limit")
        || lower_err.contains("too many requests")
        || lower_err.contains("quota exceeded")
    {
        return true;
    }

    false
}
</file>

<file path="screen-record/src/App.css">
@tailwind base;
@tailwind components;
@tailwind utilities;

/* Root theme variables - keeping these since they're used by the UI system */
@layer base {
    body {
        user-select: none;
    }

    input,
    textarea {
        user-select: text;
    }

    :root {
        --background: 0 0% 100%;
        --foreground: 0 0% 3.9%;
        --card: 0 0% 100%;
        --card-foreground: 0 0% 3.9%;
        --popover: 0 0% 100%;
        --popover-foreground: 0 0% 3.9%;
        --primary: 0 0% 9%;
        --primary-foreground: 0 0% 98%;
        --secondary: 0 0% 96.1%;
        --secondary-foreground: 0 0% 9%;
        --muted: 0 0% 96.1%;
        --muted-foreground: 0 0% 45.1%;
        --accent: 0 0% 96.1%;
        --accent-foreground: 0 0% 9%;
        --destructive: 0 84.2% 60.2%;
        --destructive-foreground: 0 0% 98%;
        --border: 0 0% 89.8%;
        --input: 0 0% 89.8%;
        --ring: 0 0% 3.9%;
        --chart-1: 12 76% 61%;
        --chart-2: 173 58% 39%;
        --chart-3: 197 37% 24%;
        --chart-4: 43 74% 66%;
        --chart-5: 27 87% 67%;
        --radius: 0.5rem;
    }

    .dark {
        --background: 0 0% 3.9%;
        --foreground: 0 0% 98%;
        --card: 0 0% 3.9%;
        --card-foreground: 0 0% 98%;
        --popover: 0 0% 3.9%;
        --popover-foreground: 0 0% 98%;
        --primary: 0 0% 98%;
        --primary-foreground: 0 0% 9%;
        --secondary: 0 0% 14.9%;
        --secondary-foreground: 0 0% 98%;
        --muted: 0 0% 14.9%;
        --muted-foreground: 0 0% 63.9%;
        --accent: 0 0% 14.9%;
        --accent-foreground: 0 0% 98%;
        --destructive: 0 62.8% 30.6%;
        --destructive-foreground: 0 0% 98%;
        --border: 0 0% 14.9%;
        --input: 0 0% 14.9%;
        --ring: 0 0% 83.1%;
        --chart-1: 220 70% 50%;
        --chart-2: 160 60% 45%;
        --chart-3: 30 80% 55%;
        --chart-4: 280 65% 60%;
        --chart-5: 340 75% 55%;
    }
}

@layer base {
    * {
        @apply border-border;
    }

    body {
        @apply bg-background text-foreground;
    }
}
</file>

<file path="screen-record/src/lib/autoZoom.ts">
import { VideoSegment, MousePosition, ZoomKeyframe } from '@/types/video';

// Physics Configuration
const PHYSICS = {
  // Mass-Spring-Damper Constants
  TENSION: 25,    // Softer pull (was 40) - "Laziness"
  FRICTION: 25,   // Heavy damping (was 15) - "Stability"
  MASS: 3.0,      // Very Heavy camera (was 2.0) - "Inertia"

  // Behaviour
  LOOK_AHEAD: 0.2, // seconds (was 0.15) - smoother anticipation
  IDLE_ZOOM_SPEED: 0.3, // Slower idle zoom
  ZOOM_OUT_SPEED: 1.5,  // Slower zoom out

  // Limits
  MAX_VELOCITY_ZOOM_PENALTY: 1000, // Pixels per second
  BASE_ZOOM: 1.4,                  // Default (was 1.5)
  MIN_ZOOM: 1.0,
  MAX_ZOOM: 2.0
};

interface InteractionState {
  isClicking: boolean;
  clickTime: number;
  hoverTime: number;
  lastPos: { x: number, y: number };
}

interface PhysicsState {
  x: number;
  y: number;
  zoom: number;
  vx: number;
  vy: number;
  vz: number;
}

export class AutoZoomGenerator {
  private readonly WIDTH = 1920;
  private readonly HEIGHT = 1080;

  generateMotionPath(
    segment: VideoSegment,
    mousePositions: MousePosition[]
  ): { time: number; x: number; y: number; zoom: number }[] {

    const path: { time: number; x: number; y: number; zoom: number }[] = [];

    // 0. Filter and Sort Data
    const data = mousePositions
      .filter(p => p.timestamp >= segment.trimStart - 1.0 && p.timestamp <= segment.trimEnd + 1.0)
      .sort((a, b) => a.timestamp - b.timestamp);

    if (data.length < 2) return [];

    // 1. Initialize Simulation
    const dt = 1 / 60; // 60hz Physics Simulation

    let state: PhysicsState = {
      x: this.WIDTH / 2, // Start centered
      y: this.HEIGHT / 2,
      zoom: 1.0,
      vx: 0,
      vy: 0,
      vz: 0
    };

    let interaction: InteractionState = {
      isClicking: false,
      clickTime: -100,
      hoverTime: 0,
      lastPos: { x: data[0].x, y: data[0].y }
    };

    // Run Simulation
    for (let t = segment.trimStart; t <= segment.trimEnd; t += dt) {

      // A. Identify Target (Where SHOULD the camera be?)
      const currentMouse = this.sample(data, t);
      const futureMouse = this.sample(data, t + PHYSICS.LOOK_AHEAD);

      // Calculate Mouse Characteristics
      const velocity = this.getVelocity(data, t); // pixels per sec
      const isClicked = this.checkClick(data, t, 0.5); // Check if click happens within 0.5s window

      // Update Interaction State
      const moveDist = Math.sqrt(Math.pow(currentMouse.x - interaction.lastPos.x, 2) + Math.pow(currentMouse.y - interaction.lastPos.y, 2));
      if (moveDist < 2.0) { // Mouse is still (< 2px movement in this step)
        interaction.hoverTime += dt;
      } else {
        interaction.hoverTime = Math.max(0, interaction.hoverTime - dt * 2); // Decay hover status
      }
      interaction.lastPos = { x: currentMouse.x, y: currentMouse.y };

      // B. Determine Target Zoom
      let targetZoom = PHYSICS.BASE_ZOOM;

      // Rule 1: Velocity Penalty (Go fast -> Zoom out)
      // factor goes from 0.0 (stopped) to 1.0 (max speed)
      const speedFactor = Math.min(1.0, velocity / PHYSICS.MAX_VELOCITY_ZOOM_PENALTY);
      // If moving fast, reduce zoom towards 1.0
      targetZoom = targetZoom * (1 - speedFactor) + PHYSICS.MIN_ZOOM * speedFactor;

      // Rule 2: Click Focus (Clicking -> Zoom In)
      if (isClicked) {
        targetZoom = Math.max(targetZoom, 1.7);
      }

      // Rule 3: Deep Read (Long Hover -> Zoom In Deep)
      if (interaction.hoverTime > 2.0) {
        targetZoom = PHYSICS.MAX_ZOOM;
      }

      // Rule 4: Edge Penalty (Near edge -> Zoom out to show context)
      const edgeDistX = Math.min(futureMouse.x, this.WIDTH - futureMouse.x);
      const edgeDistY = Math.min(futureMouse.y, this.HEIGHT - futureMouse.y);
      const edgeMargin = 200; // pixels

      if (edgeDistX < edgeMargin || edgeDistY < edgeMargin) {
        // Closer to edge = more zoom out
        // If at 0 distance, force MIN_ZOOM
        const factor = Math.min(edgeDistX, edgeDistY) / edgeMargin; // 0..1
        targetZoom = Math.min(targetZoom, PHYSICS.MIN_ZOOM + (targetZoom - PHYSICS.MIN_ZOOM) * factor);
      }

      // C. Determine Target Position
      // We start with the Future Mouse Position (Anticipation)
      let targetX = futureMouse.x;
      let targetY = futureMouse.y;

      // Override: Manual Keyframes
      // If user sets a manual keyframe, it acts as a magnet
      if (segment.zoomKeyframes && segment.zoomKeyframes.length > 0) {
        const kfInfluence = this.getKeyframeInfluence(segment.zoomKeyframes, t);
        if (kfInfluence.weight > 0) {
          // targetX/Y are pixels, kf is normalized 0-1
          const kfX = kfInfluence.x * this.WIDTH;
          const kfY = kfInfluence.y * this.HEIGHT;
          const kfZ = kfInfluence.zoom;

          // Blend Target
          // If weight is 1.0, we strictly follow keyframe
          targetX = targetX * (1 - kfInfluence.weight) + kfX * kfInfluence.weight;
          targetY = targetY * (1 - kfInfluence.weight) + kfY * kfInfluence.weight;
          targetZoom = targetZoom * (1 - kfInfluence.weight) + kfZ * kfInfluence.weight;
        }
      }

      // Rule: Center of Screen Pull
      // If zoomed out, pull towards center. If zoomed in, stick to mouse.
      // const centerFactor = 1.0 - ((targetZoom - PHYSICS.MIN_ZOOM) / (PHYSICS.MAX_ZOOM - PHYSICS.MIN_ZOOM));
      // centerFactor: 1.0 (Zoomed Out) -> 0.0 (Zoomed In)
      // Actually, we usually want the camera to center on the mouse, but clamped to screen bounds

      // D. Apply Physics (Spring/Damper)
      // Force = -k*(x - target) - d*v
      const ax = (-PHYSICS.TENSION * (state.x - targetX) - PHYSICS.FRICTION * state.vx) / PHYSICS.MASS;
      const ay = (-PHYSICS.TENSION * (state.y - targetY) - PHYSICS.FRICTION * state.vy) / PHYSICS.MASS;
      const az = (-PHYSICS.TENSION * (state.zoom - targetZoom) - PHYSICS.FRICTION * state.vz) / (PHYSICS.MASS * 3); // More mass on zoom for sluggish feel

      state.vx += ax * dt;
      state.vy += ay * dt;
      state.vz += az * dt;

      state.x += state.vx * dt;
      state.y += state.vy * dt;
      state.zoom += state.vz * dt;

      // E. Hard Constraints (Keep Viewport inside Screen)
      // Viewport Dimensions
      const viewW = this.WIDTH / state.zoom;
      const viewH = this.HEIGHT / state.zoom;

      // Half dimensions
      const hw = viewW / 2;
      const hh = viewH / 2;

      // Clamp Camera Center
      if (state.x - hw < 0) { state.x = hw; state.vx = 0; }
      if (state.x + hw > this.WIDTH) { state.x = this.WIDTH - hw; state.vx = 0; }
      if (state.y - hh < 0) { state.y = hh; state.vy = 0; }
      if (state.y + hh > this.HEIGHT) { state.y = this.HEIGHT - hh; state.vy = 0; }

      // Clamp Zoom safety
      state.zoom = Math.max(1.0, Math.min(5.0, state.zoom)); // Absolute safety limits

      // F. Record Frame
      path.push({
        time: Number(t.toFixed(3)),
        x: Number(state.x.toFixed(1)),
        y: Number(state.y.toFixed(1)),
        zoom: Number(state.zoom.toFixed(3))
      });
    }

    return path;
  }

  // --- Helpers ---

  private sample(data: MousePosition[], t: number): { x: number, y: number } {
    if (t <= data[0].timestamp) return { x: data[0].x, y: data[0].y };
    if (t >= data[data.length - 1].timestamp) return { x: data[data.length - 1].x, y: data[data.length - 1].y };

    // Find index
    const idx = data.findIndex(p => p.timestamp >= t);
    if (idx === -1) return { x: data[data.length - 1].x, y: data[data.length - 1].y };

    // Lerp
    const p1 = data[idx - 1];
    const p2 = data[idx];
    const ratio = (t - p1.timestamp) / (p2.timestamp - p1.timestamp);

    return {
      x: p1.x + (p2.x - p1.x) * ratio,
      y: p1.y + (p2.y - p1.y) * ratio
    };
  }

  private getVelocity(data: MousePosition[], t: number): number {
    const window = 0.1;
    const p1 = this.sample(data, t - window);
    const p2 = this.sample(data, t + window);
    const dist = Math.sqrt(Math.pow(p2.x - p1.x, 2) + Math.pow(p2.y - p1.y, 2));
    return dist / (window * 2);
  }

  private checkClick(data: MousePosition[], t: number, window: number): boolean {
    // Check if there are any clicks in [t - window/2, t + window/2]
    const start = t - window / 2;
    const end = t + window / 2;

    // Optimization: Binary search start index could be better but linear scan in small range is fine
    // We already sorted data
    // Let's filter range first (efficient enough for N < 10000)
    return data.some(p => p.timestamp >= start && p.timestamp <= end && p.isClicked);
  }

  private getKeyframeInfluence(keyframes: ZoomKeyframe[], t: number): { x: number, y: number, zoom: number, weight: number } {
    const WINDOW = 1.5; // seconds influence radius (3s total window)

    // Find closest keyframe within window
    const nearby = keyframes
      .map(kf => ({ kf, dist: Math.abs(kf.time - t) }))
      .filter(item => item.dist < WINDOW)
      .sort((a, b) => a.dist - b.dist);

    if (nearby.length === 0) return { x: 0.5, y: 0.5, zoom: 1, weight: 0 };

    const best = nearby[0];

    // Weight 0..1 based on distance (Cosine falloff)
    // ratio 0 (at keyframe) -> weight 1
    // ratio 1 (at edge) -> weight 0
    const ratio = best.dist / WINDOW;
    const weight = (1 + Math.cos(ratio * Math.PI)) / 2;

    // Boost sharpness - we want strong lock when close
    // pow(weight, 0.5) makes it stay near 1.0 longer? No, that broadens it.
    // pow(weight, 2) makes it sharper (peak only).
    // We want broad lock. simple cosine is fine.

    return {
      x: best.kf.positionX,
      y: best.kf.positionY,
      zoom: best.kf.zoomFactor,
      weight: weight
    };
  }
}

export const autoZoomGenerator = new AutoZoomGenerator();
</file>

<file path="screen-record/src/lib/videoExporter.ts">
import type {
  ExportOptions,
} from '@/types/video';

export const EXPORT_PRESETS: Record<string, { label: string; quality: number }> = {
  balanced: { label: 'Balanced (Recommended)', quality: 0.8 },
  original: { label: 'Original Quality', quality: 1.0 },
};

export const DIMENSION_PRESETS: Record<string, { label: string; width: number; height: number }> = {
  original: { label: 'Original Size', width: 0, height: 0 },
  '1080p': { label: 'Full HD (1080p)', width: 1920, height: 1080 },
  '720p': { label: 'HD (720p)', width: 1280, height: 720 },
};

export class VideoExporter {
  private isExporting = false;

  async exportAndDownload(options: ExportOptions & { audioFilePath: string }) {
    if (this.isExporting) {
      throw new Error('Export already in progress');
    }
    this.isExporting = true;

    const { video: sourceVideo, segment, backgroundConfig, mousePositions, speed = 1, audioFilePath } = options;

    const preset = DIMENSION_PRESETS[options.dimensions] || DIMENSION_PRESETS['1080p'];
    let width = preset.width;
    let height = preset.height;

    if (width === 0 || height === 0) {
      width = sourceVideo?.videoWidth || 1920;
      height = sourceVideo?.videoHeight || 1080;
      if (width % 2 !== 0) width--;
      if (height % 2 !== 0) height--;
    }

    const fps = 60;

    // Construct Config Payload
    const exportConfig = {
      width,
      height,
      framerate: fps,
      audioPath: audioFilePath,
      trimStart: segment?.trimStart || 0,
      duration: (segment?.trimEnd || 0) - (segment?.trimStart || 0),
      speed: speed,
      segment: segment,
      backgroundConfig: backgroundConfig,
      mousePositions: mousePositions
    };

    // @ts-ignore
    const { invoke } = window.__TAURI__.core;

    try {
      // Send to Rust for native processing
      const res = await invoke('start_export_server', exportConfig);
      console.log('Export Success:', res);

      // Optional: Open file location
      // await invoke('show_item_in_folder', { path: res.path });

    } catch (e) {
      console.error("Native Export Failed:", e);
      throw e;
    } finally {
      this.isExporting = false;
    }
  }

  cancel() {
    // Cancellation logic would need an abort signal to Rust
  }
}

export const videoExporter = new VideoExporter();
</file>

<file path="src/config/preset/defaults/text.rs">
//! Default text presets using the builder pattern.

use crate::config::preset::Preset;
use crate::config::preset::{BlockBuilder, PresetBuilder};

/// Create all default text presets
pub fn create_text_presets() -> Vec<Preset> {
    vec![
        // =====================================================================
        // TEXT SELECTION PRESETS (highlight text to process)
        // =====================================================================

        // Read aloud - TTS for selected text
        PresetBuilder::new("preset_read_aloud", "Read aloud")
            .text_select()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .auto_speak()
                    .build(),
            ])
            .build(),

        // Trans (Select text) - Translate highlighted text
        PresetBuilder::new("preset_translate_select", "Trans (Select text)")
            .text_select()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream()
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Dịch (Arena) - Compare 3 translation models in parallel
        PresetBuilder::new("preset_translate_arena", "Dịch (Arena)")
            .text_select()
            .blocks(vec![
                // Node 0: Input adapter (text selection)
                BlockBuilder::input_adapter()
                    .build(),
                // Node 1: Google Translate (GTX) - fast, non-LLM
                BlockBuilder::text("google-gtx")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream()
                    .build(),
                // Node 2: Groq Kimi - accurate LLM
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream()
                    .build(),
                // Node 3: Gemini Flash Lite - Google's fast LLM
                BlockBuilder::text("text_gemini_flash_lite")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream()
                    .build(),
            ])
            // All 3 translation nodes branch from input (0 -> 1, 0 -> 2, 0 -> 3)
            .connections(vec![(0, 1), (0, 2), (0, 3)])
            .build(),

        // Trans+Retrans (Select) - Korean then Vietnamese
        PresetBuilder::new("preset_trans_retrans_select", "Trans+Retrans (Select)")
            .text_select()
            .blocks(vec![
                BlockBuilder::text("cerebras_zai_glm_4_7")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Korean")
                    .markdown_stream()
                    .auto_copy()
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream()
                    .build(),
            ])
            .build(),

        // Select-Trans-Replace - Translate and paste back
        PresetBuilder::new("preset_select_translate_replace", "Select-Trans-Replace")
            .text_select()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown()
                    .streaming(false)
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Fix Grammar
        PresetBuilder::new("preset_fix_grammar", "Fix Grammar")
            .text_select()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Correct grammar, spelling, and punctuation errors in the following text. Do not change the meaning or tone. Output ONLY the corrected text.")
                    .language("Vietnamese")
                    .markdown()
                    .streaming(false)
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Rephrase
        PresetBuilder::new("preset_rephrase", "Rephrase")
            .text_select()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Paraphrase the following text using varied vocabulary while maintaining the exact original meaning and language. Output ONLY the paraphrased text.")
                    .language("Vietnamese")
                    .markdown()
                    .streaming(false)
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Make Formal
        PresetBuilder::new("preset_make_formal", "Make Formal")
            .text_select()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Rewrite the following text to be professional and formal, suitable for business communication. CRITICAL: Your output MUST be in the EXACT SAME LANGUAGE as the input text (if input is Korean, output Korean; if Vietnamese, output Vietnamese; if Japanese, output Japanese, etc.). Do NOT translate to English. Maintain the original meaning. Output ONLY the rewritten text.")
                    .language("Vietnamese")
                    .markdown()
                    .streaming(false)
                    .show_overlay(false)
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // Explain
        PresetBuilder::new("preset_explain", "Explain")
            .text_select()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Explain what this is in {language1}. Be concise but thorough. Mention the purpose, key logic, and any important patterns or techniques used. Format the output as a markdown. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) triple backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // Ask about text - Dynamic prompt
        PresetBuilder::new("preset_ask_text", "Ask about text")
            .text_select()
            .dynamic_prompt()
            .blocks(vec![
                BlockBuilder::text("compound_mini")
                    .prompt("")
                    .language("Vietnamese")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // Edit as follows - Dynamic prompt with auto-paste
        PresetBuilder::new("preset_edit_as_follows", "Edit as follows:")
            .text_select()
            .dynamic_prompt()
            .auto_paste()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Edit the following text according to the user's specific instructions. CRITICAL: Maintain the original language of the text unless instructed otherwise. Output ONLY the edited result without any introductory text, explanations, or quotes.")
                    .language("Vietnamese")
                    .show_overlay(false)
                    .markdown() // Upgraded: Thường -> Đẹp
                    .auto_copy()
                    .build(),
            ])
            .build(),

        // 101 on this (Tất tần tật) - Complex branching graph
        PresetBuilder::new("preset_101_on_this", "101 on this")
            .text_select()
            .blocks(vec![
                // Node 0: Input text
                BlockBuilder::input_adapter()
                    .build(),
                // Node 1: Make a learning HTML (from 0)
                BlockBuilder::text("cerebras_zai_glm_4_7")
                    .prompt("Create a standalone INTERACTIVE HTML learning card/game for the following text. Use internal CSS for a beautiful, modern, colored design, game-like and comprehensive interface. Only OUTPUT the raw HTML code, DO NOT include HTML file indicator (```html) or triple backticks.")
                    .language("Vietnamese")
                    .markdown()
                    .build(),
                // Node 2: Summarize with sources (from 3)
                BlockBuilder::text("compound_mini")
                    .prompt("Search the internet to ensure of the accuracy of the following text as well as getting as much source information as possible. Summarize the following text into a detailed markdown summary with clickable links to the sources. Structure it clearly. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
                // Node 3: Translate (from 0)
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream() // Đẹp+Str
                    .build(),
                // Node 4: Summarize keywords (from 3)
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Summarize the essence of this text into 3-5 keywords or a short phrase in {language1}.")
                    .markdown_stream() // Đẹp+Str
                    .language("Vietnamese")
                    .build(),
            ])
            .connections(vec![(0, 3), (0, 1), (3, 4), (3, 2)])
            .build(),

        // =====================================================================
        // TEXT TYPING PRESETS (type text to process)
        // =====================================================================

        // Treo text - Input Adapter Only
        PresetBuilder::new("preset_hang_text", "Input Overlay (Text)")
            .text_select()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .show_overlay(true)
                    .build(),
            ])
            .build(),

        // Trans+Retrans (Type) - Korean then Vietnamese with continuous mode
        PresetBuilder::new("preset_trans_retrans_typing", "Trans+Retrans (Type)")
            .text_type()
            .continuous()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate the following text to {language1}. Output ONLY the translation. Text to translate:")
                    .language("Korean")
                    .markdown_stream()
                    .auto_copy()
                    .build(),
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Translate to {language1}. Output ONLY the translation.")
                    .language("Vietnamese")
                    .markdown_stream()
                    .build(),
            ])
            .build(),

        // Ask AI
        PresetBuilder::new("preset_ask_ai", "Ask AI")
            .text_type()
            .blocks(vec![
                BlockBuilder::text("cerebras_qwen3")
                    .prompt("Answer the following question or request helpfully and comprehensively. Format the output as markdown creatively. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks. QUESTION/REQUEST:")
                    .markdown_stream()
                    .build(),
            ])
            .build(),

        // Internet Search
        PresetBuilder::new("preset_internet_search", "Internet Search")
            .text_type()
            .blocks(vec![
                BlockBuilder::text("compound_mini")
                    .prompt("Search the internet for information about the following query and provide a comprehensive summary. Include key facts, recent developments, and relevant details with clickable links to sources if possible. Format the output as markdown creatively. Only OUTPUT the markdown, DO NOT include markdown file indicator (```markdown) or triple backticks. SEARCH FOR:")
                    .markdown_stream() // Upgraded: Đẹp -> Đẹp+Str
                    .build(),
            ])
            .build(),

        // Make a Game
        PresetBuilder::new("preset_make_game", "Make a Game")
            .text_type()
            .blocks(vec![
                BlockBuilder::text("text_gemini_3_0_flash")
                    .prompt("Create a complete, standalone HTML game. The game MUST be playable using ONLY MOUSE CONTROLS (like swipe , drag or clicks, no keyboard required). Avoid the looping Game Over UI at startup. Use modern and trending CSS on the internet for a polished look, prefer using images or icons or svg assets from the internet for a convincing game aesthetics. Provide HTML code only. Only OUTPUT the raw HTML code, DO NOT include HTML file indicator (```html) or triple backticks. Create the game based on the following request:")
                    .markdown()
                    .build(),
            ])
            .build(),

        // Note nhanh - Input Adapter Only
        PresetBuilder::new("preset_quick_note", "Quick Note")
            .text_type()
            .blocks(vec![
                BlockBuilder::input_adapter()
                    .show_overlay(true)
                    .build(),
            ])
            .build(),
    ]
}
</file>

<file path="src/gui/app/utils.rs">
use super::types::{SettingsApp, RESTORE_SIGNAL};
use crate::config::save_config;
use eframe::egui;
use std::sync::atomic::Ordering;
use windows::core::*;
use windows::Win32::Foundation::CloseHandle;
use windows::Win32::System::Threading::*;

// Simple Linear Congruential Generator for randomness without external crate
pub fn simple_rand(seed: u32) -> u32 {
    seed.wrapping_mul(1103515245).wrapping_add(12345)
}

/// Public function to signal the main window to restore (called from tray popup)
pub fn signal_restore_window() {
    RESTORE_SIGNAL.store(true, Ordering::SeqCst);
    unsafe {
        if let Ok(event) = OpenEventW(
            EVENT_ALL_ACCESS,
            false,
            w!("Global\\ScreenGoatedToolboxRestoreEvent"),
        ) {
            let _ = SetEvent(event);
            let _ = CloseHandle(event);
        }
    }
}

impl SettingsApp {
    pub(crate) fn save_and_sync(&mut self) {
        if let crate::gui::settings_ui::ViewMode::Preset(idx) = self.view_mode {
            self.config.active_preset_idx = idx;
        }

        let mut state = self.app_state_ref.lock().unwrap();
        state.hotkeys_updated = true;
        state.config = self.config.clone();
        drop(state);
        save_config(&self.config);

        // Sync PromptDJ settings if window is active
        crate::overlay::prompt_dj::update_settings();

        unsafe {
            let class = w!("HotkeyListenerClass");
            let title = w!("Listener");
            let hwnd = windows::Win32::UI::WindowsAndMessaging::FindWindowW(class, title)
                .unwrap_or_default();
            if !hwnd.is_invalid() {
                let _ = windows::Win32::UI::WindowsAndMessaging::PostMessageW(
                    Some(hwnd),
                    0x0400 + 101,
                    windows::Win32::Foundation::WPARAM(0),
                    windows::Win32::Foundation::LPARAM(0),
                );
            }
        }
    }

    pub(crate) fn restore_window(&self, ctx: &egui::Context) {
        ctx.send_viewport_cmd(egui::ViewportCommand::Visible(true));
        ctx.send_viewport_cmd(egui::ViewportCommand::Minimized(false));
        ctx.send_viewport_cmd(egui::ViewportCommand::Focus);
        ctx.send_viewport_cmd(egui::ViewportCommand::WindowLevel(
            egui::WindowLevel::AlwaysOnTop,
        ));
        ctx.send_viewport_cmd(egui::ViewportCommand::WindowLevel(
            egui::WindowLevel::Normal,
        ));
        ctx.request_repaint();
    }

    pub(crate) fn check_hotkey_conflict(
        &self,
        vk: u32,
        mods: u32,
        current_preset_idx: usize,
    ) -> Option<String> {
        self.config
            .check_hotkey_conflict(vk, mods, Some(current_preset_idx))
    }
}

/// Robustly restart the application on Windows.
/// Uses a temporary batch file with a small delay to ensure the current process exits
/// and releases its single-instance mutex before the new instance starts.
pub fn restart_app() {
    if let Ok(exe_path) = std::env::current_exe() {
        // Create a temporary batch file to handle the delayed restart reliably
        let kill_mutex_cmd = "timeout /t 1 /nobreak > NUL".to_string();
        // Pass --restarted flag to show notification on next start
        let start_cmd = format!("start \"\" \"{}\" --restarted", exe_path.to_string_lossy());
        let self_del_cmd = "(goto) 2>nul & del \"%~f0\"";

        let batch_content = format!(
            "@echo off\r\n{}\r\n{}\r\n{}",
            kill_mutex_cmd, start_cmd, self_del_cmd
        );

        let temp_dir = std::env::temp_dir();
        let bat_path = temp_dir.join(format!("sgt_restart_{}.bat", std::process::id()));

        if let Ok(_) = std::fs::write(&bat_path, batch_content) {
            // Spawn the batch file hidden via cmd /C with CREATE_NO_WINDOW
            use std::os::windows::process::CommandExt;
            let _ = std::process::Command::new("cmd")
                .args(["/C", &bat_path.to_string_lossy()])
                .creation_flags(0x08000000) // CREATE_NO_WINDOW
                .spawn();
            std::process::exit(0);
        } else {
            // Fallback: Just try to spawn directly if batch fails
            let _ = std::process::Command::new(exe_path)
                .arg("--restarted")
                .spawn();
            std::process::exit(0);
        }
    }
}
</file>

<file path="src/gui/settings_ui/download_manager/types.rs">
use std::path::PathBuf;

#[derive(Clone, PartialEq, Debug)]
pub enum InstallStatus {
    Checking,
    Missing,
    Downloading(f32), // 0.0 to 1.0
    Extracting,
    Installed,
    Error(String),
}

#[derive(Clone, PartialEq, Debug)]
pub enum DownloadState {
    Idle,
    Downloading(f32, String),  // Progress, Status message
    Finished(PathBuf, String), // File Path, Success message
    Error(String),             // Error message
}

#[derive(Clone, PartialEq, Debug)]
pub enum UpdateStatus {
    Idle,
    Checking,
    UpdateAvailable(String), // remote_version
    UpToDate,
    Error(String),
}

#[derive(Clone, PartialEq, Debug, Serialize, Deserialize)]
pub enum DownloadType {
    Video, // Best video+audio -> mkv/mp4
    Audio, // Audio only -> mp3
}

use serde::{Deserialize, Serialize};

#[derive(Clone, PartialEq, Debug, Eq, Hash, Serialize, Deserialize)]
pub enum CookieBrowser {
    None,
    Chrome,
    Firefox,
    Edge,
    Brave,
    Opera,
    Vivaldi,
    Chromium,
    Whale,
}

impl CookieBrowser {
    pub fn to_string(&self) -> String {
        match self {
            CookieBrowser::None => "None".to_string(),
            CookieBrowser::Chrome => "Chrome".to_string(),
            CookieBrowser::Firefox => "Firefox".to_string(),
            CookieBrowser::Edge => "Edge".to_string(),
            CookieBrowser::Brave => "Brave".to_string(),
            CookieBrowser::Opera => "Opera".to_string(),
            CookieBrowser::Vivaldi => "Vivaldi".to_string(),
            CookieBrowser::Chromium => "Chromium".to_string(),
            CookieBrowser::Whale => "Whale".to_string(),
        }
    }
}
</file>

<file path="src/gui/settings_ui/download_manager/utils.rs">
use super::types::InstallStatus;
use std::fs;
use std::io::{self, Read, Write};
use std::path::PathBuf;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::{Arc, Mutex};

pub fn log(logs: &Arc<Mutex<Vec<String>>>, msg: impl Into<String>) {
    logs.lock().unwrap().push(msg.into());
}

pub fn download_file(
    url: &str,
    path: &PathBuf,
    status: &Arc<Mutex<InstallStatus>>,
    cancel: &Arc<AtomicBool>,
) -> Result<(), String> {
    let resp = ureq::get(url).call().map_err(|e| e.to_string())?;

    let total_size = resp
        .headers()
        .get("Content-Length")
        .and_then(|v| v.to_str().ok())
        .and_then(|s| s.parse::<u64>().ok())
        .unwrap_or(0);

    // Download to temp file first
    let temp_path = path.with_extension("tmp");
    let mut reader = resp.into_body().into_reader();
    let mut file = fs::File::create(&temp_path).map_err(|e| e.to_string())?;

    let mut buffer = [0; 8192];
    let mut downloaded: u64 = 0;

    loop {
        if cancel.load(Ordering::Relaxed) {
            // Cleanup temp file on cancel
            drop(file);
            let _ = fs::remove_file(&temp_path);
            return Err("Cancelled".to_string());
        }
        let bytes_read = reader.read(&mut buffer).map_err(|e| e.to_string())?;
        if bytes_read == 0 {
            break;
        }
        file.write_all(&buffer[..bytes_read])
            .map_err(|e| e.to_string())?;
        downloaded += bytes_read as u64;

        if total_size > 0 {
            let progress = downloaded as f32 / total_size as f32;
            *status.lock().unwrap() = InstallStatus::Downloading(progress);
        }
    }

    // Ensure file is flushed and closed before rename
    drop(file);

    // Rename temp file to final path
    fs::rename(&temp_path, path).map_err(|e| {
        let _ = fs::remove_file(&temp_path);
        format!("Failed to rename temp file: {}", e)
    })?;

    Ok(())
}

pub fn extract_ffmpeg(zip_path: &PathBuf, bin_dir: &PathBuf) -> Result<(), String> {
    let file = fs::File::open(zip_path).map_err(|e| e.to_string())?;
    let mut archive = zip::ZipArchive::new(file).map_err(|e| e.to_string())?;

    for i in 0..archive.len() {
        let mut file = archive.by_index(i).map_err(|e| e.to_string())?;
        let name = file.name();

        // We only care about ffmpeg.exe
        if name.ends_with("ffmpeg.exe") {
            let mut out_file =
                fs::File::create(bin_dir.join("ffmpeg.exe")).map_err(|e| e.to_string())?;
            io::copy(&mut file, &mut out_file).map_err(|e| e.to_string())?;
            return Ok(());
        }
    }

    Err("ffmpeg.exe not found in archive".to_string())
}

use super::types::CookieBrowser;
#[cfg(target_os = "windows")]
use std::os::windows::process::CommandExt;
use std::process::Command;

pub fn fetch_video_formats(
    url: &str,
    bin_dir: &PathBuf,
    cookie_browser: CookieBrowser,
) -> Result<(Vec<String>, Vec<String>, Vec<String>), String> {
    let ytdlp_path = bin_dir.join("yt-dlp.exe");
    if !ytdlp_path.exists() {
        return Err("yt-dlp is missing".to_string());
    }

    let mut args = vec!["--dump-json".to_string(), "--no-playlist".to_string()];

    // Add cookie args
    match cookie_browser {
        CookieBrowser::None => {}
        CookieBrowser::Chrome => {
            args.push("--cookies-from-browser".to_string());
            args.push("chrome".to_string());
        }
        CookieBrowser::Firefox => {
            args.push("--cookies-from-browser".to_string());
            args.push("firefox".to_string());
        }
        CookieBrowser::Edge => {
            args.push("--cookies-from-browser".to_string());
            args.push("edge".to_string());
        }
        CookieBrowser::Brave => {
            args.push("--cookies-from-browser".to_string());
            args.push("brave".to_string());
        }
        CookieBrowser::Opera => {
            args.push("--cookies-from-browser".to_string());
            args.push("opera".to_string());
        }
        CookieBrowser::Vivaldi => {
            args.push("--cookies-from-browser".to_string());
            args.push("vivaldi".to_string());
        }
        CookieBrowser::Chromium => {
            args.push("--cookies-from-browser".to_string());
            args.push("chromium".to_string());
        }
        CookieBrowser::Whale => {
            args.push("--cookies-from-browser".to_string());
            args.push("whale".to_string());
        }
    }

    args.push(url.to_string());

    let mut cmd = Command::new(ytdlp_path);
    cmd.args(&args);
    #[cfg(target_os = "windows")]
    cmd.creation_flags(0x08000000); // CREATE_NO_WINDOW

    let output = cmd.output().map_err(|e| e.to_string())?;

    if !output.status.success() {
        return Err("Failed to fetch info".to_string());
    }

    let json_str = String::from_utf8_lossy(&output.stdout);
    let v: serde_json::Value = serde_json::from_str(&json_str).map_err(|e| e.to_string())?;

    // 1. Extract resolutions
    let mut heights = std::collections::HashSet::new();
    if let Some(formats) = v.get("formats").and_then(|f| f.as_array()) {
        for f in formats {
            if let Some(h) = f.get("height").and_then(|h| h.as_u64()) {
                if h > 0 {
                    heights.insert(h as u32);
                }
            }
        }
    }

    // Fallback Robust manual parsing for "height": 123 if JSON array failed for some reason
    if heights.is_empty() {
        let key = "\"height\":";
        for (i, _) in json_str.match_indices(key) {
            let after_key = &json_str[i + key.len()..];
            let num_start_idx = after_key.find(|c: char| !c.is_whitespace()).unwrap_or(0);
            let after_ws = &after_key[num_start_idx..];
            let num_end_idx = after_ws
                .find(|c: char| !c.is_ascii_digit())
                .unwrap_or(after_ws.len());
            if num_end_idx > 0 {
                let num_str = &after_ws[..num_end_idx];
                if let Ok(h) = num_str.parse::<u32>() {
                    if h > 0 {
                        heights.insert(h);
                    }
                }
            }
        }
    }

    let mut sorted_heights: Vec<u32> = heights.into_iter().collect();
    sorted_heights.sort_unstable_by(|a, b| b.cmp(a)); // Descending
    let format_results: Vec<String> = sorted_heights
        .into_iter()
        .map(|h| format!("{}p", h))
        .collect();

    // 2. Extract Subtitles
    let mut manual_langs = std::collections::HashSet::new();
    if let Some(subs) = v.get("subtitles").and_then(|s| s.as_object()) {
        for lang in subs.keys() {
            manual_langs.insert(lang.clone());
        }
    }

    let mut auto_langs = std::collections::HashSet::new();
    if let Some(auto_subs) = v.get("automatic_captions").and_then(|s| s.as_object()) {
        for lang in auto_subs.keys() {
            auto_langs.insert(lang.clone());
        }
    }

    let mut sorted_manual: Vec<String> = manual_langs.into_iter().collect();
    sorted_manual.sort();

    let mut sorted_auto: Vec<String> = auto_langs.into_iter().collect();
    sorted_auto.sort();

    Ok((format_results, sorted_manual, sorted_auto))
}
</file>

<file path="src/gui/utils.rs">
use eframe::egui;
#[cfg(windows)]
use std::os::windows::process::CommandExt;
use std::process::Command;
use windows::core::w;
use windows::Win32::Foundation::{HANDLE, HWND, LPARAM, RECT, WPARAM};
use windows::Win32::Graphics::Dwm::{
    DwmExtendFrameIntoClientArea, DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE,
    DWMWCP_ROUND,
};
use windows::Win32::Graphics::Gdi::{
    EnumDisplayMonitors, GetMonitorInfoW, HDC, HMONITOR, MONITORINFOEXW,
};
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::WindowsAndMessaging::{
    CreateIcon, FindWindowW, GetSystemMetrics, SetWindowPos, ICON_BIG, ICON_SMALL, SM_CXICON,
    SM_CXSMICON, SM_CYICON, SM_CYSMICON, SWP_FRAMECHANGED, SWP_NOMOVE, SWP_NOSIZE, SWP_NOZORDER,
    WM_SETICON,
};
use windows_core::BOOL;

// --- Monitor Enumeration (Existing Code) ---

struct MonitorEnumContext {
    monitors: Vec<String>,
}

unsafe extern "system" fn monitor_enum_proc(
    hmonitor: HMONITOR,
    _hdc: HDC,
    _lprc: *mut RECT,
    dwdata: LPARAM,
) -> BOOL {
    let context = &mut *(dwdata.0 as *mut MonitorEnumContext);
    let mut mi = MONITORINFOEXW::default();
    mi.monitorInfo.cbSize = std::mem::size_of::<MONITORINFOEXW>() as u32;

    if GetMonitorInfoW(hmonitor, &mut mi as *mut _ as *mut _).as_bool() {
        let device_name = String::from_utf16_lossy(&mi.szDevice);
        let trimmed_name = device_name.trim_matches(char::from(0)).to_string();
        context.monitors.push(trimmed_name);
    }
    BOOL::from(true)
}

pub fn get_monitor_names() -> Vec<String> {
    let mut ctx = MonitorEnumContext {
        monitors: Vec::new(),
    };
    unsafe {
        let _ = EnumDisplayMonitors(
            None,
            None,
            Some(monitor_enum_proc),
            LPARAM(&mut ctx as *mut _ as isize),
        );
    }
    ctx.monitors
}

// --- Clipboard Helper (Existing Code) ---
pub fn copy_to_clipboard_text(text: &str) {
    crate::overlay::utils::copy_to_clipboard(text, HWND::default());
}

// --- Admin Check (Existing Code) ---

#[cfg(target_os = "windows")]
pub fn is_running_as_admin() -> bool {
    use windows::Win32::Security::{
        GetTokenInformation, TokenElevation, TOKEN_ELEVATION, TOKEN_QUERY,
    };
    use windows::Win32::System::Threading::{GetCurrentProcess, OpenProcessToken};

    unsafe {
        let mut h_token = HANDLE::default();

        if OpenProcessToken(GetCurrentProcess(), TOKEN_QUERY, &mut h_token).is_ok() {
            let mut elevation: TOKEN_ELEVATION = std::mem::zeroed();
            let mut return_length: u32 = 0;
            let size = std::mem::size_of::<TOKEN_ELEVATION>() as u32;

            if GetTokenInformation(
                h_token,
                TokenElevation,
                Some(&mut elevation as *mut _ as *mut std::ffi::c_void),
                size,
                &mut return_length,
            )
            .is_ok()
            {
                return elevation.TokenIsElevated != 0;
            }
        }
        false
    }
}

// --- System Theme Detection ---
pub fn is_system_in_dark_mode() -> bool {
    #[cfg(target_os = "windows")]
    {
        use winreg::enums::*;
        use winreg::RegKey;
        let hkcu = RegKey::predef(HKEY_CURRENT_USER);
        // We check "SystemUsesLightTheme".
        // 0 = Dark Mode (Standard), 1 = Light Mode.
        if let Ok(key) =
            hkcu.open_subkey("Software\\Microsoft\\Windows\\CurrentVersion\\Themes\\Personalize")
        {
            if let Ok(val) = key.get_value::<u32, &str>("SystemUsesLightTheme") {
                return val == 0;
            }
        }
        true
    }
    #[cfg(not(target_os = "windows"))]
    {
        true
    }
}

// --- Font Configuration (Existing Code) ---

pub fn configure_fonts(ctx: &egui::Context) {
    let mut fonts = egui::FontDefinitions::default();

    let gs_font_name = "google_sans_flex";
    // Use large byte array from centralized assets
    let gs_data = crate::assets::GOOGLE_SANS_FLEX;
    fonts.font_data.insert(
        gs_font_name.to_owned(),
        std::sync::Arc::new(egui::FontData::from_static(gs_data)),
    );

    let viet_font_name = "segoe_ui";

    let windir = std::env::var("WINDIR").unwrap_or_else(|_| "C:\\Windows".to_string());
    let font_dir = std::path::Path::new(&windir).join("Fonts");

    let viet_font_path = font_dir.join("segoeui.ttf");
    let viet_fallback_path = font_dir.join("arial.ttf");
    let viet_data = std::fs::read(&viet_font_path).or_else(|_| std::fs::read(&viet_fallback_path));

    let korean_font_name = "malgun_gothic";
    let korean_font_path = font_dir.join("malgun.ttf");
    let korean_data = std::fs::read(&korean_font_path);

    if let Ok(data) = viet_data {
        fonts.font_data.insert(
            viet_font_name.to_owned(),
            std::sync::Arc::new(egui::FontData::from_owned(data)),
        );
        if let Some(vec) = fonts.families.get_mut(&egui::FontFamily::Proportional) {
            vec.insert(0, viet_font_name.to_owned());
        }
        if let Some(vec) = fonts.families.get_mut(&egui::FontFamily::Monospace) {
            vec.insert(0, viet_font_name.to_owned());
        }
    }
    if let Ok(data) = korean_data {
        fonts.font_data.insert(
            korean_font_name.to_owned(),
            std::sync::Arc::new(egui::FontData::from_owned(data)),
        );
        if let Some(vec) = fonts.families.get_mut(&egui::FontFamily::Proportional) {
            let idx = if vec.contains(&viet_font_name.to_string()) {
                1
            } else {
                0
            };
            vec.insert(idx, korean_font_name.to_owned());
        }
        if let Some(vec) = fonts.families.get_mut(&egui::FontFamily::Monospace) {
            let idx = if vec.contains(&viet_font_name.to_string()) {
                1
            } else {
                0
            };
            vec.insert(idx, korean_font_name.to_owned());
        }
    }

    // Force Google Sans Flex to front
    if let Some(vec) = fonts.families.get_mut(&egui::FontFamily::Proportional) {
        vec.insert(0, gs_font_name.to_owned());
    }

    ctx.set_fonts(fonts);
}

// --- Task Scheduler / Admin Startup (Existing Code) ---

const TASK_NAME: &str = "ScreenGoatedToolbox_AutoStart";

pub fn set_admin_startup(enable: bool) -> bool {
    if enable {
        let exe_path = match std::env::current_exe() {
            Ok(path) => path,
            Err(_) => return false,
        };

        let exe_str = match exe_path.to_str() {
            Some(s) => s,
            None => return false,
        };

        if exe_str.is_empty() {
            return false;
        }

        let mut cmd = Command::new("schtasks");
        cmd.args(&[
            "/create",
            "/tn",
            TASK_NAME,
            "/tr",
            &format!("\"{}\"", exe_str),
            "/sc",
            "onlogon",
            "/rl",
            "highest",
            "/f",
        ]);
        // CREATE_NO_WINDOW = 0x08000000 - prevents console window flash
        #[cfg(windows)]
        cmd.creation_flags(0x08000000);

        let output = cmd.output();

        match output {
            Ok(o) => o.status.success(),
            Err(_) => false,
        }
    } else {
        let mut cmd = Command::new("schtasks");
        cmd.args(&["/delete", "/tn", TASK_NAME, "/f"]);
        // CREATE_NO_WINDOW = 0x08000000 - prevents console window flash
        #[cfg(windows)]
        cmd.creation_flags(0x08000000);

        let output = cmd.output();

        match output {
            Ok(o) => o.status.success(),
            Err(_) => false,
        }
    }
}

pub fn is_admin_startup_enabled() -> bool {
    // 1. Check if ANY task with our name exists
    let mut cmd = Command::new("schtasks");
    cmd.args(&["/query", "/tn", TASK_NAME]);
    #[cfg(windows)]
    cmd.creation_flags(0x08000000);

    let output = cmd.output();
    let exists = match output {
        Ok(o) => o.status.success(),
        Err(_) => false,
    };

    if !exists {
        return false;
    }

    // 2. Check if it points to US.
    // If it points to the wrong EXE, we consider it "Not Enabled" for this build.
    is_admin_startup_pointing_to_current_exe()
}

pub fn is_admin_startup_pointing_to_current_exe() -> bool {
    let exe_path = match std::env::current_exe() {
        Ok(path) => path,
        Err(_) => return false,
    };
    let exe_str = match exe_path.to_str() {
        Some(s) => s,
        None => return false,
    };

    let mut cmd = Command::new("schtasks");
    cmd.args(&["/query", "/tn", TASK_NAME, "/xml"]);
    // CREATE_NO_WINDOW = 0x08000000
    #[cfg(windows)]
    cmd.creation_flags(0x08000000);

    if let Ok(output) = cmd.output() {
        if output.status.success() {
            let xml_content = String::from_utf8_lossy(&output.stdout);
            // The XML contains the path, likely quoted.
            // We just check if the path substring is present.
            // This handles cases where it might be "C:\Path\To\App.exe" or just C:\Path\To\App.exe
            return xml_content.to_lowercase().contains(&exe_str.to_lowercase());
        }
    }
    false
}

// --- NATIVE ICON UPDATER (FIXED) ---

fn rgba_to_bgra(data: &[u8]) -> Vec<u8> {
    let mut bgra = data.to_vec();
    for chunk in bgra.chunks_exact_mut(4) {
        chunk.swap(0, 2); // Swap R and B
    }
    bgra
}

unsafe fn create_hicon_from_bytes(bytes: &[u8], target_w: i32, target_h: i32) -> Option<HANDLE> {
    let img = image::load_from_memory(bytes).ok()?;

    // High-quality resize to fix aliasing
    let resized = img.resize_exact(
        target_w as u32,
        target_h as u32,
        image::imageops::FilterType::Lanczos3,
    );
    let rgba = resized.to_rgba8();
    let bgra_data = rgba_to_bgra(rgba.as_raw());

    let mask_len = ((target_w * target_h) / 8) as usize;
    let mask_bits = vec![0u8; mask_len];

    // Fixed: CreateIcon returns a Result<HICON> in windows 0.48+
    let hicon_result = CreateIcon(
        None,
        target_w,
        target_h,
        1,
        32,
        mask_bits.as_ptr(),
        bgra_data.as_ptr(),
    );

    match hicon_result {
        Ok(hicon) => {
            // Fixed: Unwrap HICON and cast to HANDLE - in windows 0.62 HICON wraps *mut c_void
            if hicon.is_invalid() {
                None
            } else {
                Some(std::mem::transmute::<_, HANDLE>(hicon))
            }
        }
        Err(_) => None,
    }
}

pub fn set_window_icon(hwnd: HWND, is_dark_mode: bool) {
    let icon_bytes: &[u8] = if is_dark_mode {
        include_bytes!("../../assets/app-icon-small.png")
    } else {
        include_bytes!("../../assets/app-icon-small-light.png")
    };

    unsafe {
        if !hwnd.is_invalid() {
            let small_w = GetSystemMetrics(SM_CXSMICON);
            let small_h = GetSystemMetrics(SM_CYSMICON);

            let big_w = GetSystemMetrics(SM_CXICON);
            let big_h = GetSystemMetrics(SM_CYICON);

            if let Some(hicon_small) = create_hicon_from_bytes(icon_bytes, small_w, small_h) {
                let _ = windows::Win32::UI::WindowsAndMessaging::PostMessageW(
                    Some(hwnd),
                    WM_SETICON,
                    WPARAM(ICON_SMALL as usize),
                    LPARAM(hicon_small.0 as isize),
                );
            }

            if let Some(hicon_big) = create_hicon_from_bytes(icon_bytes, big_w, big_h) {
                let _ = windows::Win32::UI::WindowsAndMessaging::PostMessageW(
                    Some(hwnd),
                    WM_SETICON,
                    WPARAM(ICON_BIG as usize),
                    LPARAM(hicon_big.0 as isize),
                );
            }
        }
    }
}

pub fn update_window_icon_native(is_dark_mode: bool) {
    unsafe {
        let class_name = w!("eframe");
        let title_name = w!("Screen Goated Toolbox (SGT by nganlinh4)");

        let mut hwnd = FindWindowW(class_name, title_name).unwrap_or_default();

        if hwnd.is_invalid() {
            hwnd = FindWindowW(None, title_name).unwrap_or_default();
        }

        if !hwnd.is_invalid() {
            set_window_icon(hwnd, is_dark_mode);
            apply_window_shadow_native(hwnd);
        }
    }
}

pub fn apply_window_shadow_native(hwnd: HWND) {
    unsafe {
        // 1. DWM Shadow (Nice modern shadow)
        // Using only top margin = 1 avoids the dark artifacts at bottom corners
        // while still triggering the system shadow for the whole window.
        let margins = MARGINS {
            cxLeftWidth: 0,
            cxRightWidth: 0,
            cyTopHeight: 1,
            cyBottomHeight: 0,
        };
        let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

        // 2. Windows 11 Rounding Preference
        // This ensures the OS understands we want rounded corners, matching the app's internal UI radius.
        let corner_pref = DWMWCP_ROUND;
        let _ = DwmSetWindowAttribute(
            hwnd,
            DWMWA_WINDOW_CORNER_PREFERENCE,
            std::ptr::addr_of!(corner_pref) as *const _,
            std::mem::size_of_val(&corner_pref) as u32,
        );

        // 3. Force update to apply the shadow and style changes reliably
        let _ = SetWindowPos(
            hwnd,
            None,
            0,
            0,
            0,
            0,
            SWP_NOMOVE | SWP_NOSIZE | SWP_NOZORDER | SWP_FRAMECHANGED,
        );
    }
}
</file>

<file path="src/overlay/continuous_mode.rs">
//! Continuous Mode State Management
//!
//! This module handles the "hold-to-activate continuous mode" feature for image and text presets.
//! When activated, the preset will automatically retrigger after each completion.

use std::sync::atomic::{AtomicBool, AtomicUsize, Ordering};
use std::sync::Mutex;

/// Whether continuous mode is currently active
static CONTINUOUS_MODE_ACTIVE: AtomicBool = AtomicBool::new(false);

/// Whether continuous mode is pending start (e.g. from favorite bubble)
static CONTINUOUS_PENDING_START: AtomicBool = AtomicBool::new(false);

/// The preset index that is running in continuous mode
static CONTINUOUS_PRESET_IDX: AtomicUsize = AtomicUsize::new(0);

/// The hotkey name to display in the exit message (e.g., "Ctrl+Shift+T")
static CONTINUOUS_HOTKEY_NAME: Mutex<String> = Mutex::new(String::new());

/// The name of the latest hotkey that triggered an action (used for "Hold" detection logic finding the name)
static LATEST_HOTKEY_NAME: Mutex<String> = Mutex::new(String::new());

/// Check if continuous mode is currently active
pub fn is_active() -> bool {
    CONTINUOUS_MODE_ACTIVE.load(Ordering::SeqCst)
}

/// Check if continuous mode is pending start
pub fn is_pending_start() -> bool {
    CONTINUOUS_PENDING_START.load(Ordering::SeqCst)
}

/// Set pending start for a preset
pub fn set_pending_start(preset_idx: usize, hotkey_name: String) {
    CONTINUOUS_PRESET_IDX.store(preset_idx, Ordering::SeqCst);
    *CONTINUOUS_HOTKEY_NAME.lock().unwrap() = hotkey_name;
    CONTINUOUS_PENDING_START.store(true, Ordering::SeqCst);
}

/// Get the preset index running in continuous mode
pub fn get_preset_idx() -> usize {
    CONTINUOUS_PRESET_IDX.load(Ordering::SeqCst)
}

/// Get the hotkey name for the exit message
pub fn get_hotkey_name() -> String {
    CONTINUOUS_HOTKEY_NAME.lock().unwrap().clone()
}

/// Set the latest hotkey name (called by main loop)
pub fn set_latest_hotkey_name(name: String) {
    crate::log_info!("[Continuous] Setting Latest Hotkey Name: '{}'", name);
    *LATEST_HOTKEY_NAME.lock().unwrap() = name;
}

/// Get the latest hotkey name
pub fn get_latest_hotkey_name() -> String {
    LATEST_HOTKEY_NAME.lock().unwrap().clone()
}

/// Activate continuous mode for a preset (promotes pending to active)
pub fn activate(preset_idx: usize, hotkey_name: String) {
    CONTINUOUS_PRESET_IDX.store(preset_idx, Ordering::SeqCst);
    *CONTINUOUS_HOTKEY_NAME.lock().unwrap() = hotkey_name;
    CONTINUOUS_MODE_ACTIVE.store(true, Ordering::SeqCst);
    CONTINUOUS_PENDING_START.store(false, Ordering::SeqCst);
}

/// Deactivate continuous mode
pub fn deactivate() {
    CONTINUOUS_MODE_ACTIVE.store(false, Ordering::SeqCst);
    CONTINUOUS_PENDING_START.store(false, Ordering::SeqCst);
    CONTINUOUS_PRESET_IDX.store(0, Ordering::SeqCst);
    *CONTINUOUS_HOTKEY_NAME.lock().unwrap() = String::new();
}

/// Show the continuous mode activation notification
/// Show the continuous mode activation notification
pub fn show_activation_notification(preset_id: &str, hotkey_name: &str) {
    let lang = {
        if let Ok(app) = crate::APP.lock() {
            app.config.ui_language.clone()
        } else {
            "en".to_string()
        }
    };

    crate::log_info!(
        "[Continuous] Notification Request - Preset: {}, Hotkey: '{}'",
        preset_id,
        hotkey_name
    );

    let localized_name = crate::gui::settings_ui::get_localized_preset_name(preset_id, &lang);

    // 1. Title Suffix
    let suffix = match lang.as_str() {
        "vi" => "Chế độ liên tục",
        "ko" => "연속 모드",
        _ => "Continuous Mode",
    };
    let title = format!("{} - {}", localized_name, suffix);

    // 2. Prepare message from locale
    let locale = crate::gui::locale::LocaleText::get(&lang);
    let mut message = locale.continuous_mode_activated.to_string();

    // Remove Sparkle (User requested to remove sparkle icon from text)
    message = message.replace("✨ ", "").replace("✨", "");

    // Remove Preset Name part (because it's in title now)
    message = message
        .replace("\"{preset}\"", "")
        .replace("'{preset}'", "")
        .replace("{preset}", "");

    // 3. Hotkey Logic
    // If triggered by UI (Bubble), hotkey_name is typically empty or generic "Hotkey"
    // In that case, we want "... press ESC [ ] to exit" (removing the "or choice")
    if hotkey_name.is_empty()
        || hotkey_name.to_lowercase() == "hotkey"
        || hotkey_name.to_lowercase() == "esc"
    {
        // Remove " or {hotkey}" variants
        message = message
            .replace(" hay {hotkey}", "")
            .replace(" or {hotkey}", "")
            .replace(" 또는 {hotkey}", "");

        // Final cleanup for remaining {hotkey} if the structure was different
        message = message.replace("{hotkey}", "");
    } else {
        // Specific Hotkey - keep the structure
        message = message.replace("{hotkey}", hotkey_name);
    }

    // Clean up any double spaces introduced by removals
    loop {
        let new_msg = message.replace("  ", " ");
        if new_msg == message {
            break;
        }
        message = new_msg;
    }
    let message = message.trim();

    // Call the detailed notification
    crate::overlay::auto_copy_badge::show_detailed_notification(
        &title,
        message,
        crate::overlay::auto_copy_badge::NotificationType::Update,
    );
}

/// Check if a preset type supports continuous mode (only image and text)
pub fn supports_continuous_mode(preset_type: &str) -> bool {
    preset_type == "image" || preset_type == "text"
}

// =============================================================================
// HOLD DETECTION STATE
// These are used to track when a hotkey is being held down for continuous mode
// =============================================================================

use std::time::Instant;

/// The hotkey that triggered the current action (for checking if still held)
/// The hotkey that triggered the current action (for checking if still held)
static CURRENT_HOTKEY: Mutex<Option<(u32, u32)>> = Mutex::new(None); // (modifiers, vk_code)

/// Timestamp of the last hotkey trigger attempt (used for heartbeat hold detection)
static LAST_HOTKEY_TRIGGER_TIME: Mutex<Option<Instant>> = Mutex::new(None);
static HEARTBEAT_COUNT: AtomicUsize = AtomicUsize::new(0);

/// Reset the heartbeat count for a new session
pub fn reset_heartbeat() {
    HEARTBEAT_COUNT.store(0, Ordering::SeqCst);
}

/// Update the last trigger time (heartbeat)
pub fn update_last_trigger_time() {
    HEARTBEAT_COUNT.fetch_add(1, Ordering::SeqCst);
    *LAST_HOTKEY_TRIGGER_TIME.lock().unwrap() = Some(Instant::now());
}

/// Check if the hotkey was triggered recently (within ms)
pub fn was_triggered_recently(ms: u128) -> bool {
    if let Some(last) = *LAST_HOTKEY_TRIGGER_TIME.lock().unwrap() {
        let elapsed = last.elapsed().as_millis();
        let count = HEARTBEAT_COUNT.load(Ordering::SeqCst);
        let recent = elapsed <= ms;
        // A "Hold" must have been triggered at least twice (initial + at least one repeat)
        let is_hold = recent && count > 1;

        is_hold
    } else {
        false
    }
}

/// Store the hotkey that triggered the current action
pub fn set_current_hotkey(modifiers: u32, vk_code: u32) {
    *CURRENT_HOTKEY.lock().unwrap() = Some((modifiers, vk_code));
}

/// Get the current hotkey info (modifiers, vk_code)
pub fn get_current_hotkey_info() -> Option<(u32, u32)> {
    *CURRENT_HOTKEY.lock().unwrap()
}

/// Check if the current hotkey's modifiers are still being held
/// This uses GetAsyncKeyState to check real-time key state
pub fn are_modifiers_still_held() -> bool {
    use windows::Win32::UI::Input::KeyboardAndMouse::*;

    let hotkey = CURRENT_HOTKEY.lock().unwrap().clone();
    if let Some((modifiers, _vk_code)) = hotkey {
        unsafe {
            // Check each modifier
            let alt_required = (modifiers & 0x0001) != 0; // MOD_ALT
            let ctrl_required = (modifiers & 0x0002) != 0; // MOD_CONTROL
            let shift_required = (modifiers & 0x0004) != 0; // MOD_SHIFT
            let win_required = (modifiers & 0x0008) != 0; // MOD_WIN

            let alt_held = (GetAsyncKeyState(VK_MENU.0 as i32) as u16 & 0x8000) != 0;
            let ctrl_held = (GetAsyncKeyState(VK_CONTROL.0 as i32) as u16 & 0x8000) != 0;
            let shift_held = (GetAsyncKeyState(VK_SHIFT.0 as i32) as u16 & 0x8000) != 0;
            let lwin_held = (GetAsyncKeyState(VK_LWIN.0 as i32) as u16 & 0x8000) != 0;
            let rwin_held = (GetAsyncKeyState(VK_RWIN.0 as i32) as u16 & 0x8000) != 0;
            let win_held = lwin_held || rwin_held;

            // RELAXED CHECK: If the user is holding AT LEAST ONE of the required modifiers, we consider it a "Hold".
            // If NO modifiers are required, we check the main key itself.

            let mut satisfied = false;
            let mut debug_str = String::new();

            if modifiers == 0 {
                // Single key hotkey (e.g. F9, `, etc.)
                // Check the key code itself
                // vk_code is usually u32, GetAsyncKeyState expects i32
                let key_held = (GetAsyncKeyState(_vk_code as i32) as u16 & 0x8000) != 0;
                if key_held {
                    satisfied = true;
                }
                debug_str.push_str(&format!("Key({}):{}, ", _vk_code, key_held));
            } else {
                // Modifier combo
                if alt_required {
                    if alt_held {
                        satisfied = true;
                    }
                    debug_str.push_str(&format!("Alt:{}, ", alt_held));
                }
                if ctrl_required {
                    if ctrl_held {
                        satisfied = true;
                    }
                    debug_str.push_str(&format!("Ctrl:{}, ", ctrl_held));
                }
                if shift_required {
                    if shift_held {
                        satisfied = true;
                    }
                    debug_str.push_str(&format!("Shift:{}, ", shift_held));
                }
                if win_required {
                    if win_held {
                        satisfied = true;
                    }
                    debug_str.push_str(&format!("Win:{}, ", win_held));
                }
            }

            println!(
                "[Continuous] Hold check (mods={}): {} -> Satisfied: {}",
                modifiers, debug_str, satisfied
            );
            satisfied
        }
    } else {
        println!("[Continuous] No current hotkey stored.");
        false
    }
}
</file>

<file path="src/overlay/favorite_bubble/window.rs">
use super::panel::{
    close_panel, destroy_panel, ensure_panel_created, move_panel_to_bubble, save_bubble_position,
    show_panel, WM_FORCE_SHOW_PANEL,
};
use super::render::update_bubble_visual;
use super::state::*;
use crate::APP;
use std::sync::atomic::Ordering;
use windows::core::w;
use windows::Win32::Foundation::*;

use windows::Win32::System::Com::{CoInitialize, CoUninitialize};
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::Input::KeyboardAndMouse::{
    ReleaseCapture, SetCapture, TrackMouseEvent, TME_LEAVE, TRACKMOUSEEVENT,
};
use windows::Win32::UI::WindowsAndMessaging::*;

// We need to access WM_REFRESH_PANEL too, but it's private in panel.rs.
// However, we know it's WM_APP + 42. It's safe to use the constant here.
const WM_REFRESH_PANEL: u32 = WM_APP + 42;

// Show the favorite bubble overlay
pub fn show_favorite_bubble() {
    // Prevent duplicates
    if BUBBLE_ACTIVE.swap(true, Ordering::SeqCst) {
        return; // Already active
    }

    // Reset opacity to 0 for fade-in animation
    CURRENT_OPACITY.store(0, Ordering::SeqCst);
    // Clear any pending fade-out
    FADE_OUT_STATE.store(false, Ordering::SeqCst);

    std::thread::spawn(|| {
        create_bubble_window();
    });
}

// Hide the favorite bubble overlay with fade-out animation
pub fn hide_favorite_bubble() {
    if !BUBBLE_ACTIVE.load(Ordering::SeqCst) {
        return;
    }

    let hwnd_val = BUBBLE_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        // Start fade-out animation
        FADE_OUT_STATE.store(true, Ordering::SeqCst);
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe {
            // Start opacity timer to handle fade-out
            let _ = SetTimer(Some(hwnd), OPACITY_TIMER_ID, 16, None);
        }
    }
}

pub fn trigger_blink_animation() {
    let hwnd_val = BUBBLE_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        BLINK_STATE.store(1, Ordering::SeqCst); // Start Blink Phase 1
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe {
            // Force timer start
            let _ = SetTimer(Some(hwnd), OPACITY_TIMER_ID, 16, None);
        }
    }
}

fn create_bubble_window() {
    unsafe {
        let _ = CoInitialize(None); // Required for WebView warmup
        let instance = GetModuleHandleW(None).unwrap_or_default();
        let class_name = w!("SGTFavoriteBubble");

        REGISTER_BUBBLE_CLASS.call_once(|| {
            let wc = WNDCLASSW {
                lpfnWndProc: Some(bubble_wnd_proc),
                hInstance: instance.into(),
                lpszClassName: class_name,
                hCursor: LoadCursorW(None, IDC_HAND).unwrap_or_default(),
                ..Default::default()
            };
            RegisterClassW(&wc);
        });

        // Get saved position or use default
        let (initial_x, initial_y, current_size) = if let Ok(app) = APP.lock() {
            let size = app.config.favorite_bubble_size as i32;
            BUBBLE_SIZE.store(size, Ordering::SeqCst);

            let v_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
            let v_y = GetSystemMetrics(SM_YVIRTUALSCREEN);
            let v_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
            let v_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);

            // Get primary monitor metrics for safe defaults
            let screen_w = GetSystemMetrics(SM_CXSCREEN);
            let screen_h = GetSystemMetrics(SM_CYSCREEN);

            let pos = app.config.favorite_bubble_position.unwrap_or_else(|| {
                // Start at far bottom-right of primary screen
                (screen_w - size - 10, screen_h - size - 120)
            });

            // Safety: Ensure saved or default position is within current virtual screen bounds
            // This handles cases where monitors are disconnected or resolution changed.
            let final_x = pos.0.clamp(v_x, v_x + v_w - size);
            let final_y = pos.1.clamp(v_y, v_y + v_h - size);

            (final_x, final_y, size)
        } else {
            (100, 100, 40)
        };

        // Create layered window for transparency (NOACTIVATE prevents focus stealing)
        let hwnd = CreateWindowExW(
            WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED | WS_EX_NOACTIVATE,
            class_name,
            w!("FavBubble"),
            WS_POPUP,
            initial_x,
            initial_y,
            current_size,
            current_size,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        if hwnd.is_invalid() {
            BUBBLE_ACTIVE.store(false, Ordering::SeqCst);
            return;
        }

        BUBBLE_HWND.store(hwnd.0 as isize, Ordering::SeqCst);

        // Paint the bubble (starts invisible due to CURRENT_OPACITY = 0)
        update_bubble_visual(hwnd);

        let _ = ShowWindow(hwnd, SW_SHOWNOACTIVATE);

        // Start fade-in animation immediately
        let _ = SetTimer(Some(hwnd), OPACITY_TIMER_ID, 16, None);

        // Warmup: Create panel window AND WebView2 process immediately.
        // We do this here (hidden) so the first click shows the panel instantly.
        // HOWEVER: If the tray popup is currently open, skip the warmup to avoid
        // focus conflicts that would close the popup. The warmup will happen
        // on first panel open instead.
        if !crate::overlay::tray_popup::is_popup_open() {
            ensure_panel_created(hwnd, true);
        }

        // Message loop
        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
        }

        // Cleanup
        destroy_panel();
        BUBBLE_ACTIVE.store(false, Ordering::SeqCst);
        BUBBLE_HWND.store(0, Ordering::SeqCst);
        let _ = CoUninitialize();
    }
}

unsafe extern "system" fn bubble_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    const WM_MOUSELEAVE: u32 = 0x02A3;

    match msg {
        WM_LBUTTONDOWN => {
            // Stop any ongoing physics
            let _ = KillTimer(Some(hwnd), PHYSICS_TIMER_ID);
            PHYSICS_STATE.with(|p| *p.borrow_mut() = (0.0, 0.0));

            IS_DRAGGING.store(true, Ordering::SeqCst);
            IS_DRAGGING_MOVED.store(false, Ordering::SeqCst);

            // Store initial click position for threshold check
            let x = (lparam.0 as i32) & 0xFFFF;
            let y = ((lparam.0 as i32) >> 16) & 0xFFFF;
            DRAG_START_X.store(x as isize, Ordering::SeqCst);
            DRAG_START_Y.store(y as isize, Ordering::SeqCst);

            let _ = SetCapture(hwnd);
            LRESULT(0)
        }

        WM_LBUTTONUP => {
            let was_dragging_moved = IS_DRAGGING_MOVED.load(Ordering::SeqCst);
            IS_DRAGGING.store(false, Ordering::SeqCst);
            let _ = ReleaseCapture();

            // Only toggle if we didn't drag/move the bubble
            if !was_dragging_moved {
                if IS_EXPANDED.load(Ordering::SeqCst) {
                    close_panel();
                } else {
                    show_panel(hwnd);
                }
            } else {
                // Start physics inertia if we were moving
                let _ = SetTimer(Some(hwnd), PHYSICS_TIMER_ID, 16, None);
            }
            // Always save current position after movement interaction ends
            save_bubble_position();
            LRESULT(0)
        }

        WM_MOUSEMOVE => {
            if IS_DRAGGING.load(Ordering::SeqCst) && (wparam.0 & 0x0001) != 0 {
                // Left button held - check for drag
                let x = (lparam.0 as i32) & 0xFFFF;
                let y = ((lparam.0 as i32) >> 16) & 0xFFFF;

                // Convert to signed 16-bit to handle negative coordinates properly
                let x = x as i16 as i32;
                let y = y as i16 as i32;

                // Check if we've exceeded the drag threshold
                if !IS_DRAGGING_MOVED.load(Ordering::SeqCst) {
                    let start_x = DRAG_START_X.load(Ordering::SeqCst) as i32;
                    let start_y = DRAG_START_Y.load(Ordering::SeqCst) as i32;
                    let dx = (x - start_x).abs();
                    let dy = (y - start_y).abs();

                    if dx > DRAG_THRESHOLD || dy > DRAG_THRESHOLD {
                        IS_DRAGGING_MOVED.store(true, Ordering::SeqCst);
                    }
                }

                // Only actually move the window if threshold was exceeded
                if IS_DRAGGING_MOVED.load(Ordering::SeqCst) {
                    let mut rect = RECT::default();
                    let _ = GetWindowRect(hwnd, &mut rect);

                    // Use Virtual Screen bounds for cross-monitor dragging
                    let v_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
                    let v_y = GetSystemMetrics(SM_YVIRTUALSCREEN);
                    let v_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
                    let v_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);

                    let bubble_size = BUBBLE_SIZE.load(Ordering::SeqCst);
                    let new_x =
                        (rect.left + x - bubble_size / 2).clamp(v_x, v_x + v_w - bubble_size);
                    let new_y =
                        (rect.top + y - bubble_size / 2).clamp(v_y, v_y + v_h - bubble_size);

                    // Track velocity (instantaneous delta) with smoothing and boost
                    let raw_vx = (new_x - rect.left) as f32;
                    let raw_vy = (new_y - rect.top) as f32;

                    // Boost factor allows "throwing" to feel more powerful
                    // Smoothing helps filter out jitter from high polling rates
                    const THROW_BOOST: f32 = 2.5;
                    const SMOOTHING: f32 = 0.6; // Weight for new value

                    PHYSICS_STATE.with(|p| {
                        let (old_vx, old_vy) = *p.borrow();
                        let target_vx = raw_vx * THROW_BOOST;
                        let target_vy = raw_vy * THROW_BOOST;

                        let final_vx = old_vx * (1.0 - SMOOTHING) + target_vx * SMOOTHING;
                        let final_vy = old_vy * (1.0 - SMOOTHING) + target_vy * SMOOTHING;

                        *p.borrow_mut() = (final_vx, final_vy);
                    });

                    let _ = SetWindowPos(
                        hwnd,
                        None,
                        new_x,
                        new_y,
                        0,
                        0,
                        SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
                    );

                    // Move panel if open
                    if IS_EXPANDED.load(Ordering::SeqCst) {
                        move_panel_to_bubble(new_x, new_y);
                    }
                }
            }

            if !IS_HOVERED.load(Ordering::SeqCst) {
                IS_HOVERED.store(true, Ordering::SeqCst);

                // Start animation timer
                let _ = SetTimer(Some(hwnd), OPACITY_TIMER_ID, 16, None); // ~60 FPS

                // Track mouse leave
                let mut tme = TRACKMOUSEEVENT {
                    cbSize: std::mem::size_of::<TRACKMOUSEEVENT>() as u32,
                    dwFlags: TME_LEAVE,
                    hwndTrack: hwnd,
                    dwHoverTime: 0,
                };
                let _ = TrackMouseEvent(&mut tme);
            }
            LRESULT(0)
        }

        WM_MOUSELEAVE => {
            IS_HOVERED.store(false, Ordering::SeqCst);
            // Start animation timer to fade out (unless expanded)
            let _ = SetTimer(Some(hwnd), OPACITY_TIMER_ID, 16, None);
            LRESULT(0)
        }

        WM_TIMER => {
            if wparam.0 == OPACITY_TIMER_ID {
                let is_hovered = IS_HOVERED.load(Ordering::SeqCst);
                let is_expanded = IS_EXPANDED.load(Ordering::SeqCst);
                let blink_state = BLINK_STATE.load(Ordering::SeqCst);
                let is_fading_out = FADE_OUT_STATE.load(Ordering::SeqCst);

                // Fade-out takes priority over everything
                let target = if is_fading_out {
                    0u8
                } else if blink_state > 0 {
                    // Blink animation: Odd state = Active (255), Even state = Low (50)
                    if blink_state % 2 != 0 {
                        OPACITY_ACTIVE
                    } else {
                        50 // Drop lower than inactive to be distinct
                    }
                } else if is_hovered || is_expanded {
                    OPACITY_ACTIVE
                } else {
                    OPACITY_INACTIVE
                };

                let current = CURRENT_OPACITY.load(Ordering::SeqCst);

                if current != target {
                    // Faster step for blinking, normal step otherwise
                    let step = if blink_state > 0 { 45 } else { OPACITY_STEP };

                    let new_opacity = if current < target {
                        (current as u16 + step as u16).min(target as u16) as u8
                    } else {
                        (current as i16 - step as i16).max(target as i16) as u8
                    };
                    CURRENT_OPACITY.store(new_opacity, Ordering::SeqCst);
                    update_bubble_visual(hwnd);
                } else {
                    // Target reached
                    if is_fading_out && current == 0 {
                        // Fade-out complete, now close the window
                        let _ = KillTimer(Some(hwnd), OPACITY_TIMER_ID);
                        FADE_OUT_STATE.store(false, Ordering::SeqCst);
                        let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                    } else if blink_state > 0 {
                        // Transition to next blink state
                        if blink_state >= 4 {
                            BLINK_STATE.store(0, Ordering::SeqCst);
                        } else {
                            BLINK_STATE.fetch_add(1, Ordering::SeqCst);
                        }
                        // Keep timer running for next phase (no KillTimer)
                    } else {
                        let _ = KillTimer(Some(hwnd), OPACITY_TIMER_ID);
                    }
                }
            } else if wparam.0 == PHYSICS_TIMER_ID {
                PHYSICS_STATE.with(|p| {
                    let (mut vx, mut vy) = *p.borrow();

                    // Lower friction for longer travel (was 0.92)
                    vx *= 0.95;
                    vy *= 0.95;

                    // Stop if slow
                    if vx.abs() < 0.2 && vy.abs() < 0.2 {
                        // Lower threshold for smoother stop
                        let _ = KillTimer(Some(hwnd), PHYSICS_TIMER_ID);
                        *p.borrow_mut() = (0.0, 0.0);
                        // Save the final resting position
                        save_bubble_position();
                        return;
                    }

                    let mut rect = RECT::default();
                    let _ = GetWindowRect(hwnd, &mut rect);

                    let mut next_x = rect.left as f32 + vx;
                    let mut next_y = rect.top as f32 + vy;

                    let bubble_size = BUBBLE_SIZE.load(Ordering::SeqCst);
                    let bubble_size_f = bubble_size as f32;

                    // Use Virtual Screen bounds for physics bouncing
                    let min_x = GetSystemMetrics(SM_XVIRTUALSCREEN) as f32;
                    let v_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
                    let max_x = (min_x + v_w as f32) - bubble_size_f;

                    let min_y = GetSystemMetrics(SM_YVIRTUALSCREEN) as f32;
                    let v_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);
                    let max_y = (min_y + v_h as f32) - bubble_size_f;

                    let bounce_factor = 0.75; // Rubbery bounce

                    // Bounce off edges
                    if next_x < min_x {
                        next_x = min_x;
                        vx = -vx * bounce_factor;
                    } else if next_x > max_x {
                        next_x = max_x;
                        vx = -vx * bounce_factor;
                    }

                    if next_y < min_y {
                        next_y = min_y;
                        vy = -vy * bounce_factor;
                    } else if next_y > max_y {
                        next_y = max_y;
                        vy = -vy * bounce_factor;
                    }

                    *p.borrow_mut() = (vx, vy);

                    let _ = SetWindowPos(
                        hwnd,
                        None,
                        next_x as i32,
                        next_y as i32,
                        0,
                        0,
                        SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
                    );

                    if IS_EXPANDED.load(Ordering::SeqCst) {
                        move_panel_to_bubble(next_x as i32, next_y as i32);
                    }
                });
            }
            LRESULT(0)
        }

        WM_CLOSE => {
            close_panel();
            let _ = DestroyWindow(hwnd);
            LRESULT(0)
        }

        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }

        WM_FORCE_SHOW_PANEL => {
            // Received request from main thread to show/refresh update panel
            if !IS_EXPANDED.load(Ordering::SeqCst) {
                // Not open? Open it (this triggers refresh internally)
                show_panel(hwnd);
            } else {
                // Already open? Force refresh manually
                let panel_val = PANEL_HWND.load(Ordering::SeqCst);
                if panel_val != 0 {
                    let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);
                    let _ = PostMessageW(Some(panel_hwnd), WM_REFRESH_PANEL, WPARAM(0), LPARAM(0));
                }
            }
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/process/chain.rs">
use crate::api::{translate_image_streaming, translate_text_streaming};
use crate::config::{Config, Preset, ProcessingBlock};
use crate::gui::settings_ui::get_localized_preset_name;
use crate::overlay::result::{
    create_result_window, get_chain_color, link_windows, update_window_text, RefineContext,
    WindowType, WINDOW_STATES,
};
use crate::overlay::text_input;
use crate::win_types::SendHwnd;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc, Mutex,
};
use windows::Win32::Foundation::*;
use windows::Win32::UI::Input::KeyboardAndMouse::SetFocus;
use windows::Win32::UI::WindowsAndMessaging::*;

use super::types::{generate_chain_id, get_next_window_position_for_chain};
use super::window::create_processing_window;

// --- CORE PIPELINE LOGIC ---

pub fn execute_chain_pipeline(
    initial_input: String,
    rect: RECT,
    config: Config,
    preset: Preset,
    context: RefineContext,
) {
    // 1. Create Processing Window (Gradient Glow)
    // This window stays on the current thread (UI thread context for this operation)
    let graphics_mode = config.graphics_mode.clone();
    let processing_hwnd = unsafe { create_processing_window(rect, graphics_mode) };
    unsafe {
        let _ = SendMessageW(processing_hwnd, WM_TIMER, Some(WPARAM(1)), Some(LPARAM(0)));
    }

    // 2. Start the chain execution on a BACKGROUND thread
    // We pass the processing_hwnd so the background thread can close it when appropriate
    let conf_clone = config.clone();
    let blocks = preset.blocks.clone();
    let connections = preset.block_connections.clone();
    let preset_id = preset.id.clone();

    let processing_hwnd_send = SendHwnd(processing_hwnd);
    std::thread::spawn(move || {
        // Generate unique chain ID for this processing chain
        let chain_id = generate_chain_id();

        run_chain_step(
            0,
            initial_input,
            rect,
            blocks,
            connections, // Graph connections
            conf_clone,
            Arc::new(Mutex::new(None)),
            context,
            false,
            Some(processing_hwnd_send), // Pass the handle to be closed later
            Arc::new(AtomicBool::new(false)), // New chains start with cancellation = false
            preset_id,
            false,    // disable_auto_paste
            chain_id, // Per-chain position tracking
            None,     // No input refocus
        );
    });

    // 3. Keep the Processing Window alive on this thread until it is destroyed by the worker
    unsafe {
        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
            if !IsWindow(Some(processing_hwnd)).as_bool() {
                break;
            }
        }
    }
}

/// Execute chain pipeline with a pre-created cancellation token
/// Used for continuous input mode to track and close previous chain windows
/// NOTE: For text presets, we don't create a processing window (gradient glow).
/// Instead, we rely on the refining animation baked into the result window.
pub fn execute_chain_pipeline_with_token(
    initial_input: String,
    rect: RECT,
    config: Config,
    preset: Preset,
    context: RefineContext,
    cancel_token: Arc<AtomicBool>,
    input_hwnd_refocus: Option<SendHwnd>,
) {
    // For text presets: NO processing window (gradient glow).
    // The result window itself shows the refining animation.

    let blocks = preset.blocks.clone();
    let connections = preset.block_connections.clone();

    // Generate unique chain ID for this processing chain
    let chain_id = generate_chain_id();

    run_chain_step(
        0,
        initial_input,
        rect,
        blocks,
        connections,
        config,
        Arc::new(Mutex::new(None)),
        context,
        false,
        None, // No processing window for text presets
        cancel_token,
        preset.id.clone(),
        false,    // disable_auto_paste
        chain_id, // Per-chain position tracking
        input_hwnd_refocus,
    );
}

/// Recursive step to run a block in the chain (now supports graph with connections)
pub fn run_chain_step(
    block_idx: usize,
    input_text: String,
    current_rect: RECT,
    blocks: Vec<ProcessingBlock>,
    connections: Vec<(usize, usize)>, // Graph edges: (from_idx, to_idx)
    config: Config,
    parent_hwnd: Arc<Mutex<Option<SendHwnd>>>,
    context: RefineContext, // Passed to Block 0 (Image context)
    skip_execution: bool,   // If true, we just display result
    mut processing_indicator_hwnd: Option<SendHwnd>, // Handle to the "Processing..." overlay
    cancel_token: Arc<AtomicBool>, // Cancellation flag - if true, stop processing
    preset_id: String,
    disable_auto_paste: bool,
    chain_id: String, // Per-chain position tracking - windows in same chain use snake placement
    input_hwnd_refocus: Option<SendHwnd>,
) {
    // Check if cancelled before starting
    if cancel_token.load(Ordering::Relaxed) {
        if let Some(h) = processing_indicator_hwnd {
            unsafe {
                let _ = PostMessageW(Some(h.0), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    if block_idx >= blocks.len() {
        // End of chain. If processing overlay is still active (e.g., all blocks were hidden), close it now.
        if let Some(h) = processing_indicator_hwnd {
            unsafe {
                let _ = PostMessageW(Some(h.0), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    let block = &blocks[block_idx];

    // 1. Resolve Model & Prompt
    let model_id = block.model.clone();
    let model_conf = crate::model_config::get_model_by_id(&model_id);
    let provider = model_conf
        .clone()
        .map(|m| m.provider)
        .unwrap_or("groq".to_string());
    let model_full_name = model_conf.map(|m| m.full_name).unwrap_or(model_id.clone());

    let mut final_prompt = block.prompt.clone();
    for (key, value) in &block.language_vars {
        final_prompt = final_prompt.replace(&format!("{{{}}}", key), value);
    }
    // Fallback: if {language1} is still in prompt but not in language_vars, use selected_language
    if final_prompt.contains("{language1}") && !block.language_vars.contains_key("language1") {
        final_prompt = final_prompt.replace("{language1}", &block.selected_language);
    }
    final_prompt = final_prompt.replace("{language}", &block.selected_language);

    // 2. Determine Visibility & Position
    let visible_count_before = blocks
        .iter()
        .take(block_idx)
        .filter(|b| b.show_overlay)
        .count();
    let bg_color = get_chain_color(visible_count_before);

    // For visible windows: use per-chain queue for sequential snake positioning (first-come-first-serve)
    // Windows in the same chain use snake placement, different chains are independent
    let my_rect = if block.show_overlay {
        get_next_window_position_for_chain(&chain_id, current_rect)
    } else {
        current_rect // Hidden blocks don't consume a position
    };

    let mut my_hwnd: Option<HWND> = None;

    // 3. Create Window (if visible)
    // All blocks (including input_adapter) can show overlay if show_overlay is enabled
    let should_create_window = block.show_overlay;

    if block.block_type == "input_adapter" && !block.show_overlay {
        // Input adapter without overlay - invisible and instant pass-through
        // Do nothing here, skipping window creation
    } else if should_create_window {
        // For input_adapter with show_overlay: use the input context for display
        let ctx_clone = if block.block_type == "input_adapter" || block_idx == 0 {
            context.clone()
        } else {
            RefineContext::None
        };
        let m_id = model_id.clone();
        let prov = provider.clone();
        let prompt_c = final_prompt.clone();
        // CRITICAL: Override streaming to false if render_mode is markdown
        // Markdown + streaming doesn't work properly (causes missing content)
        // Also force false if skip_execution is true (static result display)
        let stream_en = if block.render_mode == "markdown" || skip_execution {
            false
        } else {
            block.streaming_enabled
        };
        let render_md = block.render_mode.clone();

        let parent_clone = parent_hwnd.clone();
        let (tx_hwnd, rx_hwnd) = std::sync::mpsc::channel();
        // For image blocks (processing), we defer showing until data arrives.
        // For input_adapter (display), we show immediately (handled by initial_content).
        let is_image_block = block.block_type == "image";

        // Check if we need to set full opacity (input adapter with image context)
        let is_input_adapter_image =
            block.block_type == "input_adapter" && matches!(context, RefineContext::Image(_));

        let locale = crate::gui::locale::LocaleText::get(&config.ui_language);

        // Generate initial content (HTML/Text) for the window immediately
        // This decouples content generation from window display loop
        let initial_content = if block.block_type == "input_adapter" {
            match &context {
                RefineContext::Image(img_data) => {
                    use base64::Engine;
                    let base64_img = base64::engine::general_purpose::STANDARD.encode(img_data);

                    // Simple magic byte detection for MIME type
                    let mime_type = if img_data.starts_with(&[0xff, 0xd8, 0xff]) {
                        "image/jpeg"
                    } else if img_data.starts_with(&[0x89, 0x50, 0x4e, 0x47]) {
                        "image/png"
                    } else {
                        "image/png" // Fallback
                    };

                    // Get locally cached font CSS for proper Unicode support
                    let font_css = crate::overlay::html_components::font_manager::get_font_css();

                    format!(
                        r#"<!DOCTYPE html>
<html>
<head>
<style>
{}
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
body {{ 
    display: flex; 
    justify-content: center; 
    align-items: center; 
    min-height: 100vh;
    background: transparent;
    font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
}}
::-webkit-scrollbar {{ display: none; }}
.container {{
    position: relative;
    width: 100%;
    height: 100%;
    display: flex;
    justify-content: center;
    align-items: center;
    background: rgba(20, 20, 25, 0.98);
    border-radius: 8px;
}}
.image {{
    width: 100%;
    height: auto;
    object-fit: contain;
    border-radius: 8px;
    transition: opacity 0.15s ease;
}}
</style>
</head>
<body>
<div class="container">
    <img class="image" id="img" src="data:{};base64,{}" />
</div>
</body>
</html>"#,
                        font_css, mime_type, base64_img
                    )
                }
                RefineContext::Audio(wav_data) => {
                    use base64::Engine;
                    let base64_audio = base64::engine::general_purpose::STANDARD.encode(wav_data);
                    // Get locally cached font CSS for proper Unicode support
                    let font_css = crate::overlay::html_components::font_manager::get_font_css();
                    format!(
                        r#"<!DOCTYPE html>
<html>
<head>
<style>
{}
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
body {{ 
    display: flex; 
    justify-content: center; 
    align-items: center; 
    min-height: 100vh; 
    background: transparent;
    font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
}}
::-webkit-scrollbar {{ display: none; }}
.audio-player {{
    background: #1e1e1e;
    border-radius: 12px;
    padding: 20px 24px;
    width: 100%;
    max-width: 400px;
    box-shadow: 0 4px 24px rgba(0, 0, 0, 0.3);
    border: 1px solid rgba(255, 255, 255, 0.08);
    position: relative;
}}
.waveform {{
    display: flex;
    align-items: center;
    gap: 2px;
    height: 60px;
    margin-bottom: 16px;
    justify-content: center;
}}
.wave-bar {{
    width: 3px;
    min-height: 4px;
    background: #8ab4f8;
    border-radius: 2px;
    transition: height 0.05s ease-out;
}}
.controls {{
    display: flex;
    align-items: center;
    gap: 14px;
}}
.play-btn {{
    width: 44px;
    height: 44px;
    background: #8ab4f8;
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: transform 0.2s, background-color 0.2s;
    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.2);
    flex-shrink: 0;
}}
.play-btn:hover {{
    transform: scale(1.05);
    background: #aecbfa;
}}
.play-btn svg {{
    fill: #1e1e1e;
    width: 18px;
    height: 18px;
    margin-left: 2px;
}}
.play-btn.playing svg {{
    margin-left: 0;
}}
.download-btn {{
    width: 36px;
    height: 36px;
    background: transparent;
    border: none;
    border-radius: 50%;
    cursor: pointer;
    display: flex;
    align-items: center;
    justify-content: center;
    transition: all 0.2s;
    flex-shrink: 0;
    margin-left: 4px;
}}
.download-btn:hover {{
    background: rgba(255, 255, 255, 0.1);
}}
.download-btn svg {{
    fill: #9aa0a6;
    width: 20px;
    height: 20px;
    transition: fill 0.2s;
}}
.download-btn:hover svg {{
    fill: #fff;
}}
.download-btn.success svg {{
    fill: #4CAF50;
}}
.download-btn.success:hover {{
    background: rgba(76, 175, 80, 0.15);
}}
.progress-container {{
    flex: 1;
    display: flex;
    flex-direction: column;
    gap: 6px;
}}
.progress-bar {{
    height: 4px;
    background: rgba(255,255,255,0.1);
    border-radius: 2px;
    overflow: hidden;
    cursor: pointer;
}}
.progress-fill {{
    height: 100%;
    background: #8ab4f8;
    border-radius: 2px;
    width: 0%;
    transition: width 0.1s;
}}
.time-display {{
    display: flex;
    justify-content: space-between;
    font-size: 11px;
    color: #9aa0a6;
}}
.toast {{
    position: absolute;
    bottom: 74px;
    left: 50%;
    transform: translateX(-50%);
    background: rgba(30, 30, 35, 0.95);
    color: #fff;
    padding: 8px 16px;
    border-radius: 20px;
    font-size: 13px;
    font-weight: 500;
    pointer-events: none;
    opacity: 0;
    transition: opacity 0.3s ease;
    box-shadow: 0 4px 12px rgba(0,0,0,0.3);
    border: 1px solid rgba(255,255,255,0.1);
    white-space: nowrap;
    z-index: 100;
    backdrop-filter: blur(4px);
}}
.toast.show {{
    opacity: 1;
}}
audio {{ display: none; }}
</style>
</head>
<body>
<div class="audio-player">
    <div class="toast" id="toast">{}</div>
    <div class="waveform" id="waveform"></div>
    <div class="controls">
        <button class="play-btn" id="playBtn">
            <svg id="playIcon" viewBox="0 0 24 24"><path d="M8 5v14l11-7z"/></svg>
        </button>
        <div class="progress-container">
            <div class="progress-bar" id="progressBar">
                <div class="progress-fill" id="progress"></div>
            </div>
            <div class="time-display">
                <span id="current">0:00</span>
                <span id="duration">0:00</span>
            </div>
        </div>
        <button class="download-btn" id="downloadBtn" title="{}">
            <svg viewBox="0 0 24 24"><path d="M5 20h14v-2H5v2zM19 9h-4V3H9v6H5l7 7 7-7z"/></svg>
        </button>
    </div>
</div>
<audio id="audio">
    <source src="data:audio/wav;base64,{}" type="audio/wav">
</audio>
<script>
const audio = document.getElementById('audio');
const progress = document.getElementById('progress');
const playIcon = document.getElementById('playIcon');
const playBtn = document.getElementById('playBtn');
const downloadBtn = document.getElementById('downloadBtn');
const toast = document.getElementById('toast');
const currentTimeEl = document.getElementById('current');
const durationEl = document.getElementById('duration');
const waveformEl = document.getElementById('waveform');
const progressBar = document.getElementById('progressBar');

// Create waveform bars
const BAR_COUNT = 32;
for (let i = 0; i < BAR_COUNT; i++) {{
    const bar = document.createElement('div');
    bar.className = 'wave-bar';
    bar.style.height = '4px';
    waveformEl.appendChild(bar);
}}
const bars = waveformEl.querySelectorAll('.wave-bar');

// Web Audio API setup
let audioContext, analyser, source, dataArray;
let isSetup = false;

function setupAudio() {{
    if (isSetup) return;
    audioContext = new (window.AudioContext || window.webkitAudioContext)();
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 64;
    source = audioContext.createMediaElementSource(audio);
    source.connect(analyser);
    analyser.connect(audioContext.destination);
    dataArray = new Uint8Array(analyser.frequencyBinCount);
    isSetup = true;
}}

function formatTime(s) {{
    if (isNaN(s)) return '0:00';
    const m = Math.floor(s / 60);
    const sec = Math.floor(s % 60);
    return m + ':' + (sec < 10 ? '0' : '') + sec;
}}

function visualize() {{
    if (!analyser || audio.paused) return;
    analyser.getByteFrequencyData(dataArray);
    for (let i = 0; i < BAR_COUNT; i++) {{
        const idx = Math.floor(i * dataArray.length / BAR_COUNT);
        const value = dataArray[idx];
        const height = Math.max(4, (value / 255) * 56);
        bars[i].style.height = height + 'px';
    }}
    requestAnimationFrame(visualize);
}}

audio.onloadedmetadata = () => {{
    durationEl.textContent = formatTime(audio.duration);
}};

audio.ontimeupdate = () => {{
    const pct = (audio.currentTime / audio.duration) * 100;
    progress.style.width = pct + '%';
    currentTimeEl.textContent = formatTime(audio.currentTime);
}};

audio.onended = () => {{
    playIcon.innerHTML = '<path d="M8 5v14l11-7z"/>';
    playBtn.classList.remove('playing');
    bars.forEach(b => b.style.height = '4px');
}};

playBtn.onclick = () => {{
    setupAudio();
    if (audio.paused) {{
        audio.play();
        playIcon.innerHTML = '<path d="M6 19h4V5H6v14zm8-14v14h4V5h-4z"/>';
        playBtn.classList.add('playing');
        visualize();
    }} else {{
        audio.pause();
        playIcon.innerHTML = '<path d="M8 5v14l11-7z"/>';
        playBtn.classList.remove('playing');
    }}
}};

downloadBtn.onclick = () => {{
    const link = document.createElement('a');
    link.href = audio.querySelector('source').src;
    const date = new Date();
    const ts = date.getFullYear() + '-' + (date.getMonth()+1) + '-' + date.getDate() + '_' + date.getHours() + '-' + date.getMinutes() + '-' + date.getSeconds();
    link.download = 'recording_' + ts + '.wav';
    document.body.appendChild(link);
    link.click();
    document.body.removeChild(link);

    // Visual Feedback
    const originalIcon = downloadBtn.innerHTML;
    // Checkmark
    downloadBtn.innerHTML = '<svg viewBox="0 0 24 24"><path d="M9 16.17L4.83 12l-1.42 1.41L9 19 21 7l-1.41-1.41z"/></svg>';
    downloadBtn.classList.add('success');
    toast.classList.add('show');

    setTimeout(() => {{
        downloadBtn.innerHTML = originalIcon;
        downloadBtn.classList.remove('success');
        toast.classList.remove('show');
    }}, 2500);
}};

progressBar.onclick = (e) => {{
    const rect = progressBar.getBoundingClientRect();
    const pct = (e.clientX - rect.left) / rect.width;
    audio.currentTime = pct * audio.duration;
}};
</script>
</body>
</html>"#,
                        font_css,
                        locale.downloaded_successfully,
                        locale.download_recording_tooltip,
                        base64_audio
                    )
                }
                RefineContext::None => input_text.clone(),
            }
        } else {
            String::new()
        };
        let initial_content_clone = initial_content.clone();

        let cancel_token_thread = cancel_token.clone();
        let input_hwnd_refocus_thread = input_hwnd_refocus.clone();
        std::thread::spawn(move || {
            // NOTE: wry handles COM internally, explicit initialization may interfere

            let hwnd = create_result_window(
                my_rect,
                WindowType::Primary,
                ctx_clone,
                m_id,
                prov,
                stream_en,
                false,
                prompt_c,
                bg_color,
                &render_md,
                initial_content_clone,
            );

            // Assign cancellation token immediately for linking/grouping
            // This is critical for input adapters since we don't wait for them in main thread
            {
                let mut s = WINDOW_STATES.lock().unwrap();
                if let Some(st) = s.get_mut(&(hwnd.0 as isize)) {
                    st.cancellation_token = Some(cancel_token_thread.clone());
                }
            }

            if let Ok(p_guard) = parent_clone.lock() {
                if let Some(ph) = *p_guard {
                    link_windows(ph.0, hwnd);
                }
            }

            // For image blocks: DON'T show window yet - keep it hidden
            // It will be shown when first data arrives (in the streaming callback)
            // For text blocks: show immediately with refining animation
            if !is_image_block {
                unsafe {
                    // Use SW_SHOWNA (Show No Activate) to prevent stealing focus from text input
                    let _ = ShowWindow(hwnd, SW_SHOWNA);

                    // FORCE REFOCUS: If we have a validation to refocus the input window (continuous mode), do it now!
                    if let Some(h_input) = input_hwnd_refocus_thread {
                        let _ = SetForegroundWindow(h_input.0);
                        let _ = SetFocus(Some(h_input.0));
                    }
                }
            }
            let _ = tx_hwnd.send(SendHwnd(hwnd));

            unsafe {
                // If it's an image input adapter, set opacity to 255 (full opaque)
                // This allows the image itself to be fully visible, while the slider controls the image opacity
                if is_input_adapter_image {
                    // Import SetLayeredWindowAttributes locally if needed, or assume it's available via windows crate
                    use windows::Win32::Foundation::COLORREF;
                    use windows::Win32::UI::WindowsAndMessaging::{
                        SetLayeredWindowAttributes, LWA_ALPHA,
                    };
                    let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 255, LWA_ALPHA);
                }

                let mut m = MSG::default();
                while GetMessageW(&mut m, None, 0, 0).into() {
                    let _ = TranslateMessage(&m);
                    DispatchMessageW(&m);
                    if !IsWindow(Some(hwnd)).as_bool() {
                        break;
                    }
                }
            }
        });

        if block.block_type == "input_adapter" {
            // Decoupled: don't wait for input adapter window
            my_hwnd = None;
        } else {
            my_hwnd = rx_hwnd.recv().ok().map(|h| h.0);
        }

        // Associate cancellation token with this window so destruction stops the chain
        if let Some(h) = my_hwnd {
            let mut s = WINDOW_STATES.lock().unwrap();
            if let Some(st) = s.get_mut(&(h.0 as isize)) {
                st.cancellation_token = Some(cancel_token.clone());
            }
        }

        // Show loading state in the new window
        // For TEXT blocks: use the refining rainbow edge animation
        // For IMAGE blocks: keep using the gradient glow/laser processing window
        // For input_adapter: show the input content immediately (no refining animation)
        if !skip_execution && my_hwnd.is_some() {
            if block.block_type == "input_adapter" {
                // Input adapter: show input content immediately, no refining animation
                let mut s = WINDOW_STATES.lock().unwrap();
                if let Some(st) = s.get_mut(&(my_hwnd.unwrap().0 as isize)) {
                    st.is_refining = false;
                    st.is_streaming_active = false; // Show buttons immediately
                    st.font_cache_dirty = true;
                }
            } else if block.block_type != "image" {
                // Text block: use rainbow edge refining animation
                let mut s = WINDOW_STATES.lock().unwrap();
                if let Some(st) = s.get_mut(&(my_hwnd.unwrap().0 as isize)) {
                    st.input_text = input_text.clone();
                    st.is_refining = true;
                    st.is_streaming_active = true; // Hide buttons during streaming
                    st.was_streaming_active = true; // Track for end-of-stream flush
                    st.font_cache_dirty = true;
                }
            } else {
                // Image block: also set streaming active to hide buttons
                let mut s = WINDOW_STATES.lock().unwrap();
                if let Some(st) = s.get_mut(&(my_hwnd.unwrap().0 as isize)) {
                    st.is_streaming_active = true; // Hide buttons during streaming
                    st.was_streaming_active = true; // Track for end-of-stream flush
                }
            }
        }

        // CRITICAL: Close the old "Processing..." overlay ONLY for text blocks (not input_adapter)
        // For image blocks, we want to keep the beautiful gradient glow animation alive
        if block.block_type != "image" && block.block_type != "input_adapter" {
            if let Some(h) = processing_indicator_hwnd {
                unsafe {
                    let _ = PostMessageW(Some(h.0), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
                // Consumed. Don't pass it to next steps.
                processing_indicator_hwnd = None;
            }
        }
    } else {
        // HIDDEN BLOCK:
        // We do NOT close processing_indicator_hwnd.
        // It keeps spinning/glowing while we execute this hidden block.
        // It will be passed to the next block.
    }

    // 4. Execution (API Call)
    // 4. Execution (API Call)
    let input_text_for_history = input_text.clone();
    let result_text = if block.block_type == "input_adapter" {
        // Pass-through: return input as-is immediately
        input_text.clone()
    } else if skip_execution {
        if let Some(h) = my_hwnd {
            update_window_text(h, &input_text);
        }
        input_text
    } else {
        let groq_key = config.api_key.clone();
        let gemini_key = config.gemini_api_key.clone();
        // Use JSON format for single-block image extraction (helps with structured output)
        let use_json = block_idx == 0 && blocks.len() == 1 && blocks[0].block_type == "image";

        // CRITICAL: Override streaming to false if render_mode is markdown (but NOT markdown_stream)
        // Regular markdown mode doesn't work well with streaming (causes missing content)
        // But markdown_stream is specifically designed for streaming with markdown rendering
        let actual_streaming_enabled = if block.render_mode == "markdown" {
            false
        } else {
            block.streaming_enabled
        };

        let accumulated = Arc::new(Mutex::new(String::new()));
        let acc_clone = accumulated.clone();

        // Identify if this is the first block in the chain that actually processes input (skipping adapters)
        let is_first_processing_block = blocks
            .iter()
            .position(|b| b.block_type != "input_adapter")
            .map(|pos| pos == block_idx)
            .unwrap_or(false);

        // SETUP RETRY VARIABLES
        let mut current_model_id = model_id.clone();
        let mut current_provider = provider.clone();
        let mut current_model_full_name = model_full_name.clone();
        let mut failed_model_ids: Vec<String> = Vec::new();
        let mut retry_count = 0;
        const MAX_RETRIES: usize = 2;

        // For image blocks: track if window has been shown and share processing_hwnd
        let window_shown = Arc::new(Mutex::new(block.block_type != "image")); // true for text, false for image
        let window_shown_clone = window_shown.clone();
        let processing_hwnd_shared = Arc::new(Mutex::new(processing_indicator_hwnd));
        let processing_hwnd_clone = processing_hwnd_shared.clone();

        // RETRY LOOP
        let res = loop {
            let res_inner = if is_first_processing_block
                && block.block_type == "image"
                && matches!(context, RefineContext::Image(_))
            {
                // Image Block (first processing block in chain)
                if let RefineContext::Image(img_data) = context.clone() {
                    let img = image::load_from_memory(&img_data)
                        .expect("Failed to load png")
                        .to_rgba8();

                    let acc_clone_inner = acc_clone.clone();
                    let my_hwnd_inner = my_hwnd;
                    let window_shown_inner = window_shown_clone.clone();
                    let proc_hwnd_inner = processing_hwnd_clone.clone();

                    // CLEAR ACCUMULATOR ON RETRY
                    if retry_count > 0 {
                        if let Ok(mut lock) = acc_clone.lock() {
                            lock.clear();
                        }
                    }

                    translate_image_streaming(
                        &groq_key,
                        &gemini_key,
                        final_prompt.clone(),
                        current_model_full_name.clone(),
                        current_provider.clone(),
                        img,
                        Some(img_data),
                        actual_streaming_enabled,
                        use_json,
                        move |chunk| {
                            let _now = std::time::SystemTime::now()
                                .duration_since(std::time::UNIX_EPOCH)
                                .map(|d| d.as_millis() as u32)
                                .unwrap_or(0);

                            let mut t = acc_clone_inner.lock().unwrap();
                            // Handle WIPE_SIGNAL - clear accumulator and use content after signal
                            if chunk.starts_with(crate::api::WIPE_SIGNAL) {
                                t.clear();
                                t.push_str(&chunk[crate::api::WIPE_SIGNAL.len()..]);
                            } else {
                                t.push_str(chunk);
                            }

                            if let Some(h) = my_hwnd_inner {
                                // On first chunk for image blocks: show window and close processing indicator
                                {
                                    let mut shown = window_shown_inner.lock().unwrap();
                                    if !*shown {
                                        *shown = true;
                                        unsafe {
                                            let _ = ShowWindow(h, SW_SHOW);
                                        }
                                        // Close processing indicator
                                        let mut proc_hwnd = proc_hwnd_inner.lock().unwrap();
                                        if let Some(ph) = proc_hwnd.take() {
                                            unsafe {
                                                let _ = PostMessageW(
                                                    Some(ph.0),
                                                    WM_CLOSE,
                                                    WPARAM(0),
                                                    LPARAM(0),
                                                );
                                            }
                                        }
                                    }
                                }
                                {
                                    let mut s = WINDOW_STATES.lock().unwrap();
                                    if let Some(st) = s.get_mut(&(h.0 as isize)) {
                                        st.is_refining = false;

                                        st.font_cache_dirty = true;
                                    }
                                }
                                update_window_text(h, &t);
                            }
                        },
                    )
                } else {
                    Err(anyhow::anyhow!("Missing image context"))
                }
            } else {
                // Text Block
                // Compute search label for compound models
                let search_label = Some(get_localized_preset_name(&preset_id, &config.ui_language));

                // CLEAR ACCUMULATOR ON RETRY
                if retry_count > 0 {
                    if let Ok(mut lock) = acc_clone.lock() {
                        lock.clear();
                    }
                }

                let acc_clone_inner = acc_clone.clone();
                translate_text_streaming(
                    &groq_key,
                    &gemini_key,
                    input_text.clone(),
                    final_prompt.clone(),
                    current_model_full_name.clone(),
                    current_provider.clone(),
                    actual_streaming_enabled,
                    false,
                    search_label,
                    &config.ui_language,
                    move |chunk| {
                        let _now = std::time::SystemTime::now()
                            .duration_since(std::time::UNIX_EPOCH)
                            .map(|d| d.as_millis() as u32)
                            .unwrap_or(0);

                        let mut t = acc_clone_inner.lock().unwrap();
                        // Handle WIPE_SIGNAL - clear accumulator and use content after signal
                        if chunk.starts_with(crate::api::WIPE_SIGNAL) {
                            t.clear();
                            t.push_str(&chunk[crate::api::WIPE_SIGNAL.len()..]);
                        } else {
                            t.push_str(chunk);
                        }

                        if let Some(h) = my_hwnd {
                            {
                                let mut s = WINDOW_STATES.lock().unwrap();
                                if let Some(st) = s.get_mut(&(h.0 as isize)) {
                                    st.is_refining = false;

                                    st.font_cache_dirty = true;
                                }
                            }
                            update_window_text(h, &t);
                        }
                    },
                )
            };

            // CHECK RESULT AND RETRY IF NEEDED
            match res_inner {
                Ok(val) => break Ok(val),
                Err(e) => {
                    // Check if retryable
                    if retry_count < MAX_RETRIES
                        && crate::overlay::utils::is_retryable_error(&e.to_string())
                    {
                        retry_count += 1;
                        failed_model_ids.push(current_model_id.clone());

                        // Determine fallback
                        let current_type = if block.block_type == "image" {
                            crate::model_config::ModelType::Vision
                        } else {
                            crate::model_config::ModelType::Text
                        };

                        // Try to get next model
                        if let Some(next_model) = crate::model_config::resolve_fallback_model(
                            &current_model_id,
                            &failed_model_ids,
                            &current_type,
                            &config,
                        ) {
                            current_model_id = next_model.id;
                            current_provider = next_model.provider;
                            current_model_full_name = next_model.full_name;

                            // Notify via Window Text
                            if let Some(h) = my_hwnd {
                                let lang = config.ui_language.clone();
                                let retry_msg = match lang.as_str() {
                                    "vi" => {
                                        format!("(Đang thử lại {}...)", current_model_full_name)
                                    }
                                    "ko" => format!("({} 재시도 중...)", current_model_full_name),
                                    "ja" => format!("({} 再試行中...)", current_model_full_name),
                                    "zh" => format!("(正在重试 {}...)", current_model_full_name),
                                    _ => format!("(Retrying {}...)", current_model_full_name),
                                };
                                update_window_text(h, &retry_msg);
                            }

                            continue; // Retry Loop
                        }
                    }
                    // Not retryable or max retries exceeded
                    break Err(e);
                }
            }
        };

        // CRITICAL: Set is_streaming_active = false AND pending_text atomically in the same lock
        // to prevent race condition where the timer detects streaming_just_ended but pending_text
        // hasn't been set yet (causing the final text to be throttled and not rendered)
        match res {
            Ok(txt) => {
                if let Some(h) = my_hwnd {
                    let mut s = WINDOW_STATES.lock().unwrap();
                    if let Some(st) = s.get_mut(&(h.0 as isize)) {
                        st.is_refining = false;
                        st.is_streaming_active = false; // Streaming complete, show buttons
                        st.font_cache_dirty = true;
                        // Set pending_text in same lock to avoid race condition
                        st.pending_text = Some(txt.clone());
                        st.full_text = txt.clone();
                    }
                }
                txt
            }
            Err(e) => {
                let lang = config.ui_language.clone();
                let err = crate::overlay::utils::get_error_message(
                    &e.to_string(),
                    &lang,
                    Some(&current_model_full_name),
                );
                if let Some(h) = my_hwnd {
                    // CRITICAL: For image blocks, the window may still be hidden if on_chunk was never called
                    // We must show it now to display the error message
                    {
                        let mut shown = window_shown.lock().unwrap();
                        if !*shown {
                            *shown = true;
                            unsafe {
                                let _ = ShowWindow(h, SW_SHOW);
                            }
                            // Also close the processing indicator
                            let mut proc_hwnd = processing_hwnd_shared.lock().unwrap();
                            if let Some(ph) = proc_hwnd.take() {
                                unsafe {
                                    let _ =
                                        PostMessageW(Some(ph.0), WM_CLOSE, WPARAM(0), LPARAM(0));
                                }
                            }
                        }
                    }
                    // Set is_streaming_active = false AND pending_text atomically
                    let mut s = WINDOW_STATES.lock().unwrap();
                    if let Some(st) = s.get_mut(&(h.0 as isize)) {
                        st.is_refining = false;
                        st.is_streaming_active = false;
                        st.font_cache_dirty = true;
                        st.pending_text = Some(err.clone());
                        st.full_text = err.clone();
                    }
                }
                String::new()
            }
        }
    };

    // 5. Post-Processing (Copy)
    // 5. Post-Processing (Copy)
    // Handle Auto-Copy for both Text and Image inputs
    // For input_adapter, we must check if we should copy the SOURCE (Image or Text)
    // result_text is input_text for adapters
    let is_input_adapter = block.block_type == "input_adapter";
    let has_content = !result_text.trim().is_empty();

    if block.auto_copy {
        // CASE 1: Image Input Adapter (Source Copy)
        // If this is an input adapter AND we have image context, copy the image.
        // We do this even if result_text (input_text) is empty, because image source has no text.
        if is_input_adapter {
            if let RefineContext::Image(img_data) = context.clone() {
                let img_data_clone = img_data.clone();
                std::thread::spawn(move || {
                    crate::overlay::utils::copy_image_to_clipboard(&img_data_clone);
                });
            }
        }

        // CASE 2: Text Content (Result or Source Text) OR Image Content (Source Copy)
        // Only copy text if it is NOT empty.
        // For paste logic: we proceed if EITHER we have text content OR we just copied an image (is_input_adapter && image context).
        let image_copied = is_input_adapter && matches!(context, RefineContext::Image(_));

        if has_content {
            let txt_c = result_text.clone();
            let txt_for_badge = result_text.clone();
            // Only show badge for actual processed results, NOT for input_adapter blocks
            // because input_adapter just passes through text that was already copied to clipboard
            // by text_selection.rs (the "b?? ??? d?" copy for processing)
            let should_show_badge = !is_input_adapter;
            std::thread::spawn(move || {
                crate::overlay::utils::copy_to_clipboard(&txt_c, HWND::default());
                // Show auto-copy badge notification with text snippet (skip for input_adapter)
                if should_show_badge {
                    crate::overlay::auto_copy_badge::show_auto_copy_badge_text(&txt_for_badge);
                }
            });
        } else if image_copied {
            // For image-only copy, show the badge with image message
            // (this is intentional - image wasn't in clipboard before)
            crate::overlay::auto_copy_badge::show_auto_copy_badge_image();
        }

        // Only trigger paste for:
        // 1. Non-input_adapter blocks with text content (actual processed results)
        // 2. Image copies from input_adapter (intentional image copy)
        // This prevents double-paste when input_adapter has auto_copy enabled alongside a processing block
        let should_trigger_paste = (has_content && !is_input_adapter) || image_copied;

        if should_trigger_paste && !disable_auto_paste {
            // Re-clone for the paste thread
            let txt_c = result_text.clone();
            let preset_id_clone = preset_id.clone();

            std::thread::spawn(move || {
                std::thread::sleep(std::time::Duration::from_millis(100));

                // Get auto_paste settings from the RUNNING preset (by ID), not active_preset_idx
                let (should_add_newline, should_paste, target_window) = {
                    let app = crate::APP.lock().unwrap();
                    // Find the preset that's actually running this chain
                    if let Some(preset) =
                        app.config.presets.iter().find(|p| p.id == preset_id_clone)
                    {
                        (
                            preset.auto_paste_newline,
                            preset.auto_paste,
                            app.last_active_window,
                        )
                    } else {
                        // Fallback to active preset if not found (shouldn't happen)
                        let active_idx = app.config.active_preset_idx;
                        if active_idx < app.config.presets.len() {
                            let preset = &app.config.presets[active_idx];
                            (
                                preset.auto_paste_newline,
                                preset.auto_paste,
                                app.last_active_window,
                            )
                        } else {
                            (false, false, app.last_active_window)
                        }
                    }
                };

                // If strictly image copied (no text content), we ignore newline logic and just paste (Ctrl+V)
                // If text content exists, we do the full text logic.
                let final_text = if !txt_c.trim().is_empty() {
                    if should_add_newline {
                        format!("{}\n", txt_c)
                    } else {
                        txt_c.clone()
                    }
                } else {
                    String::new() // No text to modify/inject
                };

                // NOTE: We ALREADY copied to clipboard above (Text or Image).
                // Now we just handle the PASTE action.

                if should_paste {
                    // Special Case: If it's pure image copy (no text), we MUST use generic Ctrl+V paste.
                    // We cannot use text injection or set_editor_text.
                    if txt_c.trim().is_empty() {
                        // Image-only paste path
                        if let Some(target) = target_window {
                            crate::overlay::utils::force_focus_and_paste(target.0);
                        }
                    } else {
                        // Text paste path (supports injection)
                        // Check if text input window is active - if so, set text directly
                        if text_input::is_active() {
                            // Use set_editor_text to inject text into the webview editor
                            text_input::set_editor_text(&final_text);
                            text_input::refocus_editor();
                        }
                        // Check if refine input is active - if so, set text there
                        else if crate::overlay::result::is_any_refine_active() {
                            if let Some(parent) = crate::overlay::result::get_active_refine_parent()
                            {
                                crate::overlay::result::set_refine_text(parent, &final_text, true);
                            }
                        } else if let Some(target) = target_window {
                            // Normal paste to last active window
                            crate::overlay::utils::force_focus_and_paste(target.0);
                        }
                    }
                }
            });
        }
    }

    // Auto-Speak
    if block.auto_speak && !result_text.trim().is_empty() {
        let txt_s = result_text.clone();
        std::thread::spawn(move || {
            std::thread::sleep(std::time::Duration::from_millis(200));
            crate::api::tts::TTS_MANAGER.speak(&txt_s, 0);
        });
    }

    // SAVE TO HISTORY: Handle both Text and Image blocks
    if block.show_overlay && !result_text.trim().is_empty() {
        let text_for_history = result_text.clone();

        if block.block_type == "text" {
            let input_text_clone = input_text_for_history.clone();
            std::thread::spawn(move || {
                if let Ok(app) = crate::APP.lock() {
                    app.history.save_text(text_for_history, input_text_clone);
                }
            });
        } else if block.block_type == "image" {
            // For image blocks, we need to grab the image data from the context
            // context is RefineContext::Image(Vec<u8>) for the first block
            if let RefineContext::Image(img_bytes) = context.clone() {
                std::thread::spawn(move || {
                    // Decode PNG bytes back to ImageBuffer for the history saver
                    // (HistoryManager::save_image expects ImageBuffer<Rgba<u8>, ...>)
                    if let Ok(img_dynamic) = image::load_from_memory(&img_bytes) {
                        let img_buffer = img_dynamic.to_rgba8();
                        if let Ok(app) = crate::APP.lock() {
                            app.history.save_image(img_buffer, text_for_history);
                        }
                    }
                });
            }
        }
    }

    // 6. Chain Next Steps (Graph-based: find all downstream blocks)
    // Check cancellation before continuing
    if cancel_token.load(Ordering::Relaxed) {
        if let Some(h) = processing_indicator_hwnd {
            unsafe {
                let _ = PostMessageW(Some(h.0), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
        return;
    }

    // For input_adapter blocks, ALWAYS continue to downstream blocks even if result_text is empty
    // This is critical for image presets where the image data is in context, not input_text
    let should_continue = !result_text.trim().is_empty() || block.block_type == "input_adapter";

    if should_continue {
        // Find all downstream blocks from connections
        let downstream_indices: Vec<usize> = connections
            .iter()
            .filter(|(from, _)| *from == block_idx)
            .map(|(_, to)| *to)
            .collect();

        // Determine next blocks:
        // - If connections vec is completely empty (legacy linear chain), use block_idx + 1 fallback
        // - If connections vec has entries (graph mode), use ONLY explicit connections
        let next_blocks: Vec<usize> = if connections.is_empty() {
            // Legacy mode: no graph connections defined, use linear chain
            if block_idx + 1 < blocks.len() {
                vec![block_idx + 1]
            } else {
                vec![]
            }
        } else {
            // Graph mode: use only explicit connections (no fallback)
            downstream_indices
        };

        if next_blocks.is_empty() {
            // End of chain
            if let Some(h) = processing_indicator_hwnd {
                unsafe {
                    let _ = PostMessageW(Some(h.0), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
            }
            return;
        }

        let next_parent = if my_hwnd.is_some() {
            Arc::new(Mutex::new(my_hwnd.map(|h| SendHwnd(h))))
        } else {
            parent_hwnd
        };

        let base_rect = if my_hwnd.is_some() {
            my_rect
        } else {
            current_rect
        };

        // For the first downstream block, pass the processing indicator (if any)
        // For additional parallel branches, spawn new threads without the indicator
        let first_next = next_blocks[0];
        let parallel_branches: Vec<usize> = next_blocks.into_iter().skip(1).collect();

        // Spawn parallel threads for additional branches FIRST
        let next_context = if block.block_type == "input_adapter" {
            context.clone()
        } else {
            RefineContext::None
        };

        let next_skip_execution = if skip_execution {
            // Continue skipping if current block didn't "consume" the skipped output
            // Input adapter never consumes/displays, so we keep skipping until we hit the actual source block
            block.block_type == "input_adapter"
        } else {
            false
        };

        let _s_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
        let _s_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };

        for (branch_index, next_idx) in parallel_branches.iter().enumerate() {
            let result_clone = result_text.clone();
            let blocks_clone = blocks.clone();
            let conns_clone = connections.clone();
            let config_clone = config.clone();
            let cancel_clone = cancel_token.clone();
            let parent_clone = next_parent.clone();
            let preset_id_clone = preset_id.clone();
            let chain_id_clone = chain_id.clone();
            let next_idx_copy = *next_idx;

            // Capture next_context for parallel branches
            let branch_context = next_context.clone();

            // Position will be determined individually by get_next_window_position_for_chain inside run_chain_step
            // We just pass the base_rect as a reference point
            let branch_rect = base_rect;

            // Incremental delay for each branch (300ms, 600ms, 900ms, ...)
            // This naturally staggers WebView2 creation without blocking mutexes
            let delay_ms = (branch_index as u64 + 1) * 300;

            std::thread::spawn(move || {
                // CRITICAL: Initialize COM on this thread - required for WebView2
                unsafe {
                    use windows::Win32::System::Com::{CoInitializeEx, COINIT_APARTMENTTHREADED};
                    let _ = CoInitializeEx(None, COINIT_APARTMENTTHREADED);
                }

                // Stagger WebView2 creation across parallel branches
                std::thread::sleep(std::time::Duration::from_millis(delay_ms));

                run_chain_step(
                    next_idx_copy,
                    result_clone,
                    branch_rect,
                    blocks_clone,
                    conns_clone,
                    config_clone,
                    parent_clone,
                    branch_context, // Pass the captured context
                    next_skip_execution,
                    None, // No processing indicator for parallel branches
                    cancel_clone,
                    preset_id_clone,
                    disable_auto_paste, // Propagate the flag
                    chain_id_clone,     // Same chain ID for all branches
                    None, // Only Refocus on main branch or pass it down? Pass None for now in parallel branches
                );
            });
        }

        // Continue with the first downstream block on current thread
        run_chain_step(
            first_next,
            result_text,
            base_rect,
            blocks.clone(),
            connections,
            config,
            next_parent,
            next_context, // Pass the context
            next_skip_execution,
            processing_indicator_hwnd, // Pass it along (might be None or Some)
            cancel_token,              // Pass the same token through the chain
            preset_id,
            disable_auto_paste, // Propagate the flag
            chain_id,           // Same chain ID through the chain
            input_hwnd_refocus, // Propagate the refocus target
        );
    } else {
        // Chain stopped unexpectedly (empty result or error)
        // Ensure processing overlay is closed
        if let Some(h) = processing_indicator_hwnd {
            unsafe {
                let _ = PostMessageW(Some(h.0), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
    }
}
</file>

<file path="src/overlay/realtime_webview/manager.rs">
//! Overlay lifecycle management (show/stop/check active)

use super::state::*;
use super::webview::*;
use super::wndproc::*;
use crate::api::realtime_audio::{start_realtime_transcription, RealtimeState};
use crate::APP;
use std::sync::atomic::Ordering;
use windows::core::w;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE, DWMWCP_ROUND,
};
use windows::Win32::Graphics::Gdi::HBRUSH;
use windows::Win32::System::Com::{CoInitialize, CoUninitialize};
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::WindowsAndMessaging::*;

pub fn is_realtime_overlay_active() -> bool {
    unsafe { IS_ACTIVE && !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() }
}

/// Stop the realtime overlay and hide windows
pub fn stop_realtime_overlay() {
    // Stop any playing TTS immediately
    crate::api::tts::TTS_MANAGER.stop();

    // Stop Minimal Mode if active
    crate::overlay::realtime_egui::MINIMAL_ACTIVE.store(false, std::sync::atomic::Ordering::SeqCst);
    REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);

    unsafe {
        // Close app selection popup if open
        let popup_val = APP_SELECTION_HWND.load(std::sync::atomic::Ordering::SeqCst);
        if popup_val != 0 {
            let popup_hwnd = HWND(popup_val as *mut std::ffi::c_void);
            let _ = PostMessageW(Some(popup_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            APP_SELECTION_HWND.store(0, std::sync::atomic::Ordering::SeqCst);
        }

        if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
            let _ = PostMessageW(
                Some(REALTIME_HWND),
                WM_APP_REALTIME_HIDE,
                WPARAM(0),
                LPARAM(0),
            );
        }
    }
}

pub fn show_realtime_overlay(preset_idx: usize) {
    unsafe {
        // Initialize on-demand if not warmed up
        if !IS_WARMED_UP {
            if !IS_INITIALIZING {
                IS_INITIALIZING = true;
                std::thread::spawn(move || {
                    internal_create_realtime_loop();
                });
            }

            // Polling thread to auto-show once ready
            std::thread::spawn(move || {
                // Poll for 10 seconds (100 * 100ms)
                for _ in 0..100 {
                    std::thread::sleep(std::time::Duration::from_millis(100));
                    if IS_WARMED_UP && !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                        let _ = PostMessageW(
                            Some(REALTIME_HWND),
                            WM_APP_REALTIME_START,
                            WPARAM(preset_idx),
                            LPARAM(0),
                        );
                        return;
                    }
                }
            });
            return;
        }

        if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
            let _ = PostMessageW(
                Some(REALTIME_HWND),
                WM_APP_REALTIME_START,
                WPARAM(preset_idx),
                LPARAM(0),
            );
        }
    }
}

unsafe fn internal_create_realtime_loop() {
    let _ = CoInitialize(None); // Required for WebView
    let instance = GetModuleHandleW(None).unwrap();

    // --- Register Classes ---
    let class_name = w!("RealtimeWebViewOverlay");
    REGISTER_REALTIME_CLASS.call_once(|| {
        let mut wc = WNDCLASSW::default();
        wc.lpfnWndProc = Some(realtime_wnd_proc_internal);
        wc.hInstance = instance.into();
        wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
        wc.lpszClassName = class_name;
        wc.style = CS_HREDRAW | CS_VREDRAW;
        wc.hbrBackground = HBRUSH(std::ptr::null_mut());
        let _ = RegisterClassW(&wc);
    });

    let trans_class = w!("RealtimeTranslationWebViewOverlay");
    REGISTER_TRANSLATION_CLASS.call_once(|| {
        let mut wc = WNDCLASSW::default();
        wc.lpfnWndProc = Some(translation_wnd_proc_internal);
        wc.hInstance = instance.into();
        wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
        wc.lpszClassName = trans_class;
        wc.style = CS_HREDRAW | CS_VREDRAW;
        wc.hbrBackground = HBRUSH(std::ptr::null_mut());
        let _ = RegisterClassW(&wc);
    });

    // Create windows hidden
    let main_hwnd = CreateWindowExW(
        WS_EX_TOPMOST | WS_EX_TOOLWINDOW,
        class_name,
        w!("Realtime Transcription"),
        WS_POPUP, // Hidden initially
        0,
        0,
        100,
        100,
        None,
        None,
        Some(instance.into()),
        None,
    )
    .unwrap();

    let trans_hwnd = CreateWindowExW(
        WS_EX_TOPMOST | WS_EX_TOOLWINDOW,
        trans_class,
        w!("Translation"),
        WS_POPUP, // Hidden initially
        0,
        0,
        100,
        100,
        None,
        None,
        Some(instance.into()),
        None,
    )
    .unwrap();

    // Enable rounded corners (Windows 11+)
    let corner_pref = DWMWCP_ROUND;
    let _ = DwmSetWindowAttribute(
        main_hwnd,
        DWMWA_WINDOW_CORNER_PREFERENCE,
        &corner_pref as *const _ as *const std::ffi::c_void,
        std::mem::size_of_val(&corner_pref) as u32,
    );
    let _ = DwmSetWindowAttribute(
        trans_hwnd,
        DWMWA_WINDOW_CORNER_PREFERENCE,
        &corner_pref as *const _ as *const std::ffi::c_void,
        std::mem::size_of_val(&corner_pref) as u32,
    );

    REALTIME_HWND = main_hwnd;
    TRANSLATION_HWND = trans_hwnd;

    // Create WebViews
    create_realtime_webview(
        main_hwnd,
        false,
        "device",
        "English",
        "google-gtx",
        "gemini",
        16,
    );
    create_realtime_webview(
        trans_hwnd,
        true,
        "device",
        "English",
        "google-gtx",
        "gemini",
        16,
    );

    // Mark as warmed up and ready
    IS_WARMED_UP = true;

    // Message loop
    let mut msg = MSG::default();
    while GetMessageW(&mut msg, None, 0, 0).into() {
        let _ = TranslateMessage(&msg);
        DispatchMessageW(&msg);
        if msg.message == WM_QUIT {
            break;
        }
    }

    // Cleanup
    destroy_realtime_webview(REALTIME_HWND);
    destroy_realtime_webview(TRANSLATION_HWND);
    IS_ACTIVE = false;
    IS_WARMED_UP = false;
    IS_INITIALIZING = false;
    REALTIME_HWND = HWND::default();
    TRANSLATION_HWND = HWND::default();
    let _ = CoUninitialize();
}

unsafe extern "system" fn realtime_wnd_proc_internal(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    if msg == WM_APP_REALTIME_START {
        let preset_idx = wparam.0;
        handle_start_overlay(preset_idx);
        return LRESULT(0);
    }
    realtime_wnd_proc(hwnd, msg, wparam, lparam)
}

unsafe extern "system" fn translation_wnd_proc_internal(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    translation_wnd_proc(hwnd, msg, wparam, lparam)
}

unsafe fn handle_start_overlay(preset_idx: usize) {
    if IS_ACTIVE {
        return;
    }

    let mut preset = APP.lock().unwrap().config.presets[preset_idx].clone();

    // Check if Minimal Mode
    if preset.realtime_window_mode == "minimal" {
        crate::overlay::realtime_egui::show_realtime_egui_overlay(preset_idx);
        return;
    }

    // Reset state
    IS_ACTIVE = true;
    REALTIME_STOP_SIGNAL.store(false, Ordering::SeqCst);
    MIC_VISIBLE.store(true, Ordering::SeqCst);
    TRANS_VISIBLE.store(true, Ordering::SeqCst);
    AUDIO_SOURCE_CHANGE.store(false, Ordering::SeqCst);
    LANGUAGE_CHANGE.store(false, Ordering::SeqCst);
    TRANSLATION_MODEL_CHANGE.store(false, Ordering::SeqCst);

    {
        let mut state = REALTIME_STATE.lock().unwrap();
        *state = RealtimeState::new();
    }

    // Fetch config
    let (
        font_size,
        config_audio_source,
        config_language,
        config_translation_model,
        config_transcription_model,
        trans_size,
        transcription_size,
    ) = {
        let app = APP.lock().unwrap();
        (
            app.config.realtime_font_size,
            app.config.realtime_audio_source.clone(),
            app.config.realtime_target_language.clone(),
            app.config.realtime_translation_model.clone(),
            app.config.realtime_transcription_model.clone(),
            app.config.realtime_translation_size,
            app.config.realtime_transcription_size,
        )
    };

    // Default to "device" if no audio source is saved
    let effective_audio_source = if config_audio_source.is_empty() {
        "device".to_string()
    } else {
        config_audio_source.clone()
    };

    preset.audio_source = effective_audio_source.clone();
    if let Ok(mut new_source) = NEW_AUDIO_SOURCE.lock() {
        *new_source = effective_audio_source.clone();
    }

    let target_language = if !config_language.is_empty() {
        config_language
    } else if preset.blocks.len() > 1 {
        let trans_block = &preset.blocks[1];
        if !trans_block.selected_language.is_empty() {
            trans_block.selected_language.clone()
        } else {
            trans_block
                .language_vars
                .get("language")
                .cloned()
                .or_else(|| trans_block.language_vars.get("language1").cloned())
                .unwrap_or_else(|| "English".to_string())
        }
    } else {
        "English".to_string()
    };

    if !target_language.is_empty() {
        if let Ok(mut new_lang) = NEW_TARGET_LANGUAGE.lock() {
            *new_lang = target_language.clone();
        }
        LANGUAGE_CHANGE.store(true, Ordering::SeqCst);
    }

    // Calculate positions
    let screen_w = GetSystemMetrics(SM_CXSCREEN);
    let screen_h = GetSystemMetrics(SM_CYSCREEN);
    let has_translation = preset.blocks.len() > 1;
    let main_w = transcription_size.0;
    let main_h = transcription_size.1;
    let trans_w = trans_size.0;
    let trans_h = trans_size.1;

    let (main_x, main_y) = if has_translation {
        let total_w = main_w + trans_w + GAP;
        ((screen_w - total_w) / 2, (screen_h - main_h) / 2)
    } else {
        ((screen_w - main_w) / 2, (screen_h - main_h) / 2)
    };

    // Update window positions and sizes
    let _ = SetWindowPos(
        REALTIME_HWND,
        Some(HWND_TOPMOST),
        main_x,
        main_y,
        main_w,
        main_h,
        SWP_SHOWWINDOW,
    );
    if has_translation {
        let trans_x = main_x + main_w + GAP;
        let _ = SetWindowPos(
            TRANSLATION_HWND,
            Some(HWND_TOPMOST),
            trans_x,
            main_y,
            trans_w,
            trans_h,
            SWP_SHOWWINDOW,
        );
    } else {
        let _ = ShowWindow(TRANSLATION_HWND, SW_HIDE);
    }

    // Notify WebViews of new settings
    notify_webview_settings(
        REALTIME_HWND,
        &effective_audio_source,
        &target_language,
        &config_translation_model,
        &config_transcription_model,
        font_size,
    );

    // Explicitly resize WebViews to match window sizes
    resize_webview(REALTIME_HWND, main_w, main_h);

    // Clear text to start fresh
    clear_webview_text(REALTIME_HWND);

    if has_translation {
        notify_webview_settings(
            TRANSLATION_HWND,
            "mic",
            &target_language,
            &config_translation_model,
            &config_transcription_model,
            font_size,
        );
        resize_webview(TRANSLATION_HWND, trans_w, trans_h);
        clear_webview_text(TRANSLATION_HWND);
    }

    // Sync visibility state to webviews (fixes toggled->hidden state on re-show)
    sync_visibility_to_webviews();

    // Start transcription
    let trans_hwnd_opt = if has_translation {
        Some(TRANSLATION_HWND)
    } else {
        None
    };
    start_realtime_transcription(
        preset,
        REALTIME_STOP_SIGNAL.clone(),
        REALTIME_HWND,
        trans_hwnd_opt,
        REALTIME_STATE.clone(),
    );
}

fn notify_webview_settings(
    hwnd: HWND,
    source: &str,
    lang: &str,
    model: &str,
    trans_model: &str,
    font_size: u32,
) {
    let hwnd_key = hwnd.0 as isize;
    let script = format!(
        "if(window.updateSettings) window.updateSettings({{ audioSource: '{}', targetLanguage: '{}', translationModel: '{}', transcriptionModel: '{}', fontSize: {} }});",
        source, lang, model, trans_model, font_size
    );
    REALTIME_WEBVIEWS.with(|wvs| {
        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
            let _ = webview.evaluate_script(&script);
        }
    });
}

fn resize_webview(hwnd: HWND, width: i32, height: i32) {
    let hwnd_key = hwnd.0 as isize;
    REALTIME_WEBVIEWS.with(|wvs| {
        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
            let _ = webview.set_bounds(wry::Rect {
                position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                    width as u32,
                    height as u32,
                )),
            });
        }
    });
}
</file>

<file path="src/overlay/realtime_webview/webview.rs">
//! WebView creation and IPC handling for realtime overlay

use super::state::*;
use crate::api::realtime_audio::WM_COPY_TEXT;
use crate::api::realtime_audio::{WM_REALTIME_UPDATE, WM_TRANSLATION_UPDATE};
use crate::config::get_all_languages;
use crate::gui::locale::LocaleText;
use crate::overlay::realtime_html::get_realtime_html;
use crate::APP;
use std::sync::atomic::Ordering;
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebViewBuilder};
pub fn create_realtime_webview(
    hwnd: HWND,
    is_translation: bool,
    audio_source: &str,
    current_language: &str,
    translation_model: &str,
    transcription_model: &str,
    font_size: u32,
) {
    let hwnd_key = hwnd.0 as isize;
    crate::log_info!("[Realtime] Creating WebView for HWND: {:?}", hwnd);

    let mut rect = RECT::default();
    unsafe {
        let _ = GetClientRect(hwnd, &mut rect);
    }

    // Use full language list from isolang crate
    let languages = get_all_languages();

    // Fetch locale text
    let locale_text = {
        let app = APP.lock().unwrap();
        let lang = app.config.ui_language.clone();
        LocaleText::get(&lang)
    };

    let is_dark = if let Ok(app) = crate::APP.lock() {
        match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        }
    } else {
        true
    };

    let html = get_realtime_html(
        is_translation,
        audio_source,
        &languages,
        current_language,
        translation_model,
        transcription_model,
        font_size,
        &locale_text,
        is_dark,
    );
    let wrapper = HwndWrapper(hwnd);

    // Capture hwnd for the IPC handler closure
    let hwnd_for_ipc = hwnd;

    REALTIME_WEB_CONTEXT.with(|ctx| {
        if ctx.borrow().is_none() {
            let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
            *ctx.borrow_mut() = Some(wry::WebContext::new(Some(shared_data_dir)));
        }
    });

    let result = {
        // LOCK SCOPE: Only one WebView builds at a time to prevent "Not enough quota"
        let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
        crate::log_info!(
            "[Realtime] Acquired init lock. Building for HWND: {:?}...",
            hwnd
        );

        let build_res = REALTIME_WEB_CONTEXT.with(|ctx| {
            let mut ctx_ref = ctx.borrow_mut();
            let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                WebViewBuilder::new_with_web_context(web_ctx)
            } else {
                WebViewBuilder::new()
            };
            let builder = crate::overlay::html_components::font_manager::configure_webview(builder);

            // Store HTML in font server and get URL for same-origin font loading
            let page_url =
                crate::overlay::html_components::font_manager::store_html_page(html.clone())
                    .unwrap_or_else(|| format!("data:text/html,{}", urlencoding::encode(&html)));

            builder
                .with_bounds(Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                        (rect.right - rect.left) as u32,
                        (rect.bottom - rect.top) as u32,
                    )),
                })
                .with_url(&page_url)
                .with_transparent(false)
                .with_ipc_handler(move |msg: wry::http::Request<String>| {
                    let body = msg.body();
                    if body == "startDrag" {
                        // Initiate window drag directly
                        unsafe {
                            let _ = windows::Win32::UI::Input::KeyboardAndMouse::ReleaseCapture();
                            SendMessageW(
                                hwnd_for_ipc,
                                WM_NCLBUTTONDOWN,
                                Some(WPARAM(HTCAPTION as usize)),
                                Some(LPARAM(0)),
                            );
                        }
                    } else if body.starts_with("toggleMic:") {
                        // Toggle transcription window visibility directly
                        let visible = &body[10..] == "1";
                        MIC_VISIBLE.store(visible, Ordering::SeqCst);
                        unsafe {
                            if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                                if visible {
                                    update_webview_theme(REALTIME_HWND);
                                }
                                let _ = ShowWindow(
                                    REALTIME_HWND,
                                    if visible { SW_SHOW } else { SW_HIDE },
                                );
                            }
                            // Sync to other webview
                            sync_visibility_to_webviews();

                            // If both windows are now off, hide and reset state (but keep windows alive)
                            if !MIC_VISIBLE.load(Ordering::SeqCst)
                                && !TRANS_VISIBLE.load(Ordering::SeqCst)
                            {
                                REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);
                                crate::api::tts::TTS_MANAGER.stop();
                                IS_ACTIVE = false;
                            } else if visible {
                                // Force update since we suppressed them while hidden
                                let _ = PostMessageW(
                                    Some(REALTIME_HWND),
                                    WM_REALTIME_UPDATE,
                                    WPARAM(0),
                                    LPARAM(0),
                                );
                            }
                        }
                    } else if body.starts_with("toggleTrans:") {
                        // Toggle translation window visibility directly
                        let visible = &body[12..] == "1";
                        TRANS_VISIBLE.store(visible, Ordering::SeqCst);

                        // Stop TTS when translation window is hidden
                        if !visible {
                            crate::api::tts::TTS_MANAGER.stop();
                        }

                        unsafe {
                            if !std::ptr::addr_of!(TRANSLATION_HWND).read().is_invalid() {
                                if visible {
                                    update_webview_theme(TRANSLATION_HWND);
                                }
                                let _ = ShowWindow(
                                    TRANSLATION_HWND,
                                    if visible { SW_SHOW } else { SW_HIDE },
                                );
                            }
                            // Sync to other webview
                            sync_visibility_to_webviews();

                            // If both windows are now off, hide and reset state (but keep windows alive)
                            if !MIC_VISIBLE.load(Ordering::SeqCst)
                                && !TRANS_VISIBLE.load(Ordering::SeqCst)
                            {
                                REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);
                                crate::api::tts::TTS_MANAGER.stop();
                                IS_ACTIVE = false;
                            } else if visible {
                                // Force update since we suppressed them while hidden
                                let _ = PostMessageW(
                                    Some(TRANSLATION_HWND),
                                    WM_TRANSLATION_UPDATE,
                                    WPARAM(0),
                                    LPARAM(0),
                                );
                            }
                        }
                    } else if body == "startGroupDrag" {
                        // Start group drag - nothing special needed, just mark drag started
                        // The actual movement is handled by groupDragMove
                    } else if body.starts_with("groupDragMove:") {
                        // Move both windows together by delta
                        let coords = &body[14..];
                        if let Some((dx_str, dy_str)) = coords.split_once(',') {
                            if let (Ok(dx), Ok(dy)) = (dx_str.parse::<i32>(), dy_str.parse::<i32>())
                            {
                                unsafe {
                                    // Move realtime window
                                    if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                                        let mut rect = RECT::default();
                                        let _ = GetWindowRect(REALTIME_HWND, &mut rect);
                                        let _ = SetWindowPos(
                                            REALTIME_HWND,
                                            None,
                                            rect.left + dx,
                                            rect.top + dy,
                                            0,
                                            0,
                                            SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
                                        );
                                    }

                                    // Move translation window
                                    if !std::ptr::addr_of!(TRANSLATION_HWND).read().is_invalid() {
                                        let mut rect = RECT::default();
                                        let _ = GetWindowRect(TRANSLATION_HWND, &mut rect);
                                        let _ = SetWindowPos(
                                            TRANSLATION_HWND,
                                            None,
                                            rect.left + dx,
                                            rect.top + dy,
                                            0,
                                            0,
                                            SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
                                        );
                                    }
                                }
                            }
                        }
                    } else if body.starts_with("copyText:") {
                        // Copy text to clipboard via UI thread
                        let text = body[9..].to_string();
                        let boxed = Box::new(text);
                        let ptr = Box::into_raw(boxed);
                        unsafe {
                            let _ = PostMessageW(
                                Some(hwnd_for_ipc),
                                WM_COPY_TEXT,
                                WPARAM(0),
                                LPARAM(ptr as isize),
                            );
                        }
                    } else if body == "close" {
                        unsafe {
                            let _ =
                                PostMessageW(Some(hwnd_for_ipc), WM_CLOSE, WPARAM(0), LPARAM(0));
                        }
                    } else if body == "saveResize" {
                        unsafe {
                            let mut rect = RECT::default();
                            let _ = GetWindowRect(hwnd_for_ipc, &mut rect);
                            let w = rect.right - rect.left;
                            let h = rect.bottom - rect.top;

                            let mut app = APP.lock().unwrap();
                            if hwnd_for_ipc == REALTIME_HWND {
                                app.config.realtime_transcription_size = (w, h);
                            } else {
                                app.config.realtime_translation_size = (w, h);
                            }
                            crate::config::save_config(&app.config);
                        }
                    } else if body.starts_with("fontSize:") {
                        // Font size change - store for future use
                        if let Ok(size) = body[9..].parse::<u32>() {
                            let mut app = APP.lock().unwrap();
                            app.config.realtime_font_size = size;
                            crate::config::save_config(&app.config);
                        }
                    } else if body.starts_with("audioSource:") {
                        // Audio source change
                        let source = body[12..].to_string();
                        if let Ok(mut new_source) = NEW_AUDIO_SOURCE.lock() {
                            *new_source = source.clone();
                        }

                        if source == "mic" {
                            // Clear app selection when switching to mic
                            SELECTED_APP_PID.store(0, Ordering::SeqCst);
                            if let Ok(mut name) = SELECTED_APP_NAME.lock() {
                                name.clear();
                            }
                        } else if source == "device" {
                            // Check if TTS is enabled - if so, show app selection popup
                            let tts_enabled = REALTIME_TTS_ENABLED.load(Ordering::SeqCst);
                            if tts_enabled {
                                // Show app selection popup for user to choose which app to capture
                                show_app_selection_popup();
                            } else {
                                // TTS is off, use normal device loopback (clear any app selection)
                                SELECTED_APP_PID.store(0, Ordering::SeqCst);
                                if let Ok(mut name) = SELECTED_APP_NAME.lock() {
                                    name.clear();
                                }
                            }
                        }

                        // Save to config
                        {
                            let mut app = APP.lock().unwrap();
                            app.config.realtime_audio_source = source;
                            crate::config::save_config(&app.config);
                        }
                        AUDIO_SOURCE_CHANGE.store(true, Ordering::SeqCst);
                    } else if body.starts_with("language:") {
                        // Target language change - signal update
                        let lang = body[9..].to_string();
                        if let Ok(mut new_lang) = NEW_TARGET_LANGUAGE.lock() {
                            *new_lang = lang.clone();
                        }

                        // Save to config
                        {
                            let mut app = APP.lock().unwrap();
                            app.config.realtime_target_language = lang;
                            crate::config::save_config(&app.config);
                        }
                        LANGUAGE_CHANGE.store(true, Ordering::SeqCst);
                    } else if body.starts_with("translationModel:") {
                        // Translation model change - signal update
                        let model = body[17..].to_string();
                        if let Ok(mut new_model) = NEW_TRANSLATION_MODEL.lock() {
                            *new_model = model.clone();
                        }

                        // Save to config
                        {
                            let mut app = APP.lock().unwrap();
                            app.config.realtime_translation_model = model;
                            crate::config::save_config(&app.config);
                        }
                        TRANSLATION_MODEL_CHANGE.store(true, Ordering::SeqCst);
                    } else if body.starts_with("transcriptionModel:") {
                        // Transcription model change
                        let model = body[19..].to_string();
                        if let Ok(mut new_model) = NEW_TRANSCRIPTION_MODEL.lock() {
                            *new_model = model.clone();
                        }
                        {
                            let mut app = APP.lock().unwrap();
                            app.config.realtime_transcription_model = model;
                            crate::config::save_config(&app.config);
                        }
                        TRANSCRIPTION_MODEL_CHANGE.store(true, Ordering::SeqCst);
                    } else if body.starts_with("resize:") {
                        // Resize window by delta
                        let coords = &body[7..];
                        if let Some((dx_str, dy_str)) = coords.split_once(',') {
                            if let (Ok(dx), Ok(dy)) = (dx_str.parse::<i32>(), dy_str.parse::<i32>())
                            {
                                unsafe {
                                    let mut rect = RECT::default();
                                    let _ = GetWindowRect(hwnd_for_ipc, &mut rect);
                                    let new_width = (rect.right - rect.left + dx).max(200);
                                    let new_height = (rect.bottom - rect.top + dy).max(100);
                                    let _ = SetWindowPos(
                                        hwnd_for_ipc,
                                        None,
                                        rect.left,
                                        rect.top,
                                        new_width,
                                        new_height,
                                        SWP_NOZORDER | SWP_NOACTIVATE,
                                    );
                                }
                            }
                        }
                    } else if body.starts_with("toggleMic:") {
                        // Toggle transcription window visibility
                        let visible = &body[10..] == "1";
                        MIC_VISIBLE.store(visible, Ordering::SeqCst);
                        unsafe {
                            if !std::ptr::addr_of!(REALTIME_HWND).read().is_invalid() {
                                let _ = ShowWindow(
                                    REALTIME_HWND,
                                    if visible { SW_SHOW } else { SW_HIDE },
                                );
                            }
                            // Sync to other webview
                            sync_visibility_to_webviews();

                            // If both windows are now off, hide and reset state (but keep windows alive)
                            if !MIC_VISIBLE.load(Ordering::SeqCst)
                                && !TRANS_VISIBLE.load(Ordering::SeqCst)
                            {
                                REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);
                                crate::api::tts::TTS_MANAGER.stop();
                                IS_ACTIVE = false;
                            } else if visible {
                                // Force update since we suppressed them while hidden
                                let _ = PostMessageW(
                                    Some(REALTIME_HWND),
                                    WM_REALTIME_UPDATE,
                                    WPARAM(0),
                                    LPARAM(0),
                                );
                            }
                        }
                    } else if body.starts_with("toggleTrans:") {
                        // Toggle translation window visibility
                        let visible = &body[12..] == "1";
                        TRANS_VISIBLE.store(visible, Ordering::SeqCst);

                        // Stop TTS when translation window is hidden
                        if !visible {
                            crate::api::tts::TTS_MANAGER.stop();
                        }

                        unsafe {
                            if !std::ptr::addr_of!(TRANSLATION_HWND).read().is_invalid() {
                                let _ = ShowWindow(
                                    TRANSLATION_HWND,
                                    if visible { SW_SHOW } else { SW_HIDE },
                                );
                            }
                            // Sync to other webview
                            sync_visibility_to_webviews();

                            // If both windows are now off, hide and reset state (but keep windows alive)
                            if !MIC_VISIBLE.load(Ordering::SeqCst)
                                && !TRANS_VISIBLE.load(Ordering::SeqCst)
                            {
                                REALTIME_STOP_SIGNAL.store(true, Ordering::SeqCst);
                                crate::api::tts::TTS_MANAGER.stop();
                                IS_ACTIVE = false;
                            } else if visible {
                                // Force update since we suppressed them while hidden
                                let _ = PostMessageW(
                                    Some(TRANSLATION_HWND),
                                    WM_TRANSLATION_UPDATE,
                                    WPARAM(0),
                                    LPARAM(0),
                                );
                            }
                        }
                    } else if body.starts_with("ttsEnabled:") {
                        // TTS toggle for realtime translations
                        let enabled = &body[11..] == "1";
                        REALTIME_TTS_ENABLED.store(enabled, Ordering::SeqCst);

                        // Reset spoken length when disabling so we start fresh next time
                        if !enabled {
                            // IMMEDIATELY stop TTS (cut off mid-sentence to prevent capture)
                            crate::api::tts::TTS_MANAGER.stop();

                            // Close app selection popup if open
                            let popup_hwnd_val = APP_SELECTION_HWND.load(Ordering::SeqCst);
                            if popup_hwnd_val != 0 {
                                let popup_hwnd = windows::Win32::Foundation::HWND(
                                    popup_hwnd_val as *mut std::ffi::c_void,
                                );
                                let _ = unsafe {
                                    windows::Win32::UI::WindowsAndMessaging::PostMessageW(
                                        Some(popup_hwnd),
                                        windows::Win32::UI::WindowsAndMessaging::WM_CLOSE,
                                        windows::Win32::Foundation::WPARAM(0),
                                        windows::Win32::Foundation::LPARAM(0),
                                    )
                                };
                                APP_SELECTION_HWND.store(0, Ordering::SeqCst);
                            }

                            LAST_SPOKEN_LENGTH.store(0, Ordering::SeqCst);
                            // Clear any queued translations
                            if let Ok(mut queue) = COMMITTED_TRANSLATION_QUEUE.lock() {
                                queue.clear();
                            }

                            // Clear app selection (but do NOT restart audio capture -
                            // that only happens when an app is explicitly selected)
                            SELECTED_APP_PID.store(0, Ordering::SeqCst);
                            if let Ok(mut name) = SELECTED_APP_NAME.lock() {
                                name.clear();
                            }
                        } else {
                            // TTS enabled - if in device mode, show app selection popup
                            // Note: We DON'T change audio mode here - only when user selects an app
                            let current_source = {
                                let app = APP.lock().unwrap();
                                app.config.realtime_audio_source.clone()
                            };
                            if current_source == "device" {
                                // Show app selection popup (no audio change yet - happens when app is selected)
                                show_app_selection_popup();
                            }
                        }
                    } else if body.starts_with("ttsSpeed:") {
                        // TTS playback speed adjustment (50-200, where 100 = 1.0x)
                        if let Ok(speed) = body[9..].parse::<u32>() {
                            REALTIME_TTS_SPEED.store(speed, Ordering::SeqCst);
                            // Turn off auto-speed when user manually adjusts slider
                            REALTIME_TTS_AUTO_SPEED.store(false, Ordering::SeqCst);
                        }
                    } else if body.starts_with("ttsAutoSpeed:") {
                        // TTS auto-speed toggle
                        let enabled = &body[13..] == "1";
                        REALTIME_TTS_AUTO_SPEED.store(enabled, Ordering::SeqCst);
                    } else if body == "cancelDownload" {
                        // Cancel Parakeet download and revert to Gemini
                        crate::api::realtime_audio::cancel_download_and_revert_to_gemini();
                    }
                })
                .build_as_child(&wrapper)
        });
        crate::log_info!(
            "[Realtime] Build finished. Releasing lock. Status: {}",
            if build_res.is_ok() { "OK" } else { "ERR" }
        );
        build_res
    };

    if let Ok(webview) = result {
        crate::log_info!("[Realtime] WebView success for HWND: {:?}", hwnd);
        REALTIME_WEBVIEWS.with(|wvs| {
            wvs.borrow_mut().insert(hwnd_key, webview);
        });
    } else if let Err(e) = result {
        crate::log_info!(
            "[Realtime] WebView FAILED for HWND: {:?}, Error: {:?}",
            hwnd,
            e
        );
    }
}

pub fn destroy_realtime_webview(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;
    REALTIME_WEBVIEWS.with(|wvs| {
        wvs.borrow_mut().remove(&hwnd_key);
    });
}

/// Sync visibility toggle state to all webviews
pub fn sync_visibility_to_webviews() {
    let mic_vis = MIC_VISIBLE.load(Ordering::SeqCst);
    let trans_vis = TRANS_VISIBLE.load(Ordering::SeqCst);
    let script = format!(
        "if(window.setVisibility) window.setVisibility({}, {});",
        mic_vis, trans_vis
    );

    REALTIME_WEBVIEWS.with(|wvs| {
        for webview in wvs.borrow().values() {
            let _ = webview.evaluate_script(&script);
        }
    });
}

pub fn update_webview_text(hwnd: HWND, old_text: &str, new_text: &str) {
    let hwnd_key = hwnd.0 as isize;

    // Escape the text for JavaScript
    fn escape_js(text: &str) -> String {
        text.replace('\\', "\\\\")
            .replace('\'', "\\'")
            .replace('\n', "\\n")
            .replace('\r', "")
    }

    let escaped_old = escape_js(old_text);
    let escaped_new = escape_js(new_text);

    let script = format!("window.updateText('{}', '{}');", escaped_old, escaped_new);

    REALTIME_WEBVIEWS.with(|wvs| {
        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
            let _ = webview.evaluate_script(&script);
        }
    });
}

/// Clear/reset the WebView text to initial "Đang chờ nói..." state
pub fn clear_webview_text(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;
    let script = "if(window.clearText) window.clearText();";

    REALTIME_WEBVIEWS.with(|wvs| {
        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
            let _ = webview.evaluate_script(script);
        }
    });
}

use super::app_selection::show_app_selection_popup;

pub fn update_webview_theme(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    let is_dark = if let Ok(app) = crate::APP.lock() {
        match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        }
    } else {
        true
    };

    let font_size = if let Ok(app) = crate::APP.lock() {
        app.config.realtime_font_size
    } else {
        24
    };

    // Determine glow color based on whether this is a translation window
    let is_translation = unsafe { hwnd == TRANSLATION_HWND };
    let glow_color = if is_translation { "#ff9633" } else { "#00c8ff" };

    let css = format!(
        "{}{}",
        crate::overlay::html_components::css_main::get(glow_color, font_size, is_dark),
        crate::overlay::html_components::css_modals::get(is_dark)
    );
    let css_escaped = css.replace("`", "\\`");

    let script = format!(
        r#"
        if (document.getElementById('main-style')) {{
            document.getElementById('main-style').innerHTML = `{}`;
        }}
        "#,
        css_escaped
    );

    REALTIME_WEBVIEWS.with(|wvs| {
        if let Some(webview) = wvs.borrow().get(&hwnd_key) {
            let _ = webview.evaluate_script(&script);
        }
    });
}
</file>

<file path="src/overlay/result/event_handler/click_actions.rs">
use std::mem::size_of;
use windows::Win32::Foundation::*;
use windows::Win32::UI::Input::KeyboardAndMouse::ReleaseCapture;
use windows::Win32::UI::WindowsAndMessaging::*;

use windows::core::PCWSTR;
use windows::Win32::Graphics::Gdi::InvalidateRect;
use windows::Win32::UI::Input::KeyboardAndMouse::{TrackMouseEvent, TME_LEAVE, TRACKMOUSEEVENT};

use super::misc::WM_CREATE_WEBVIEW;

use crate::overlay::result::state::{InteractionMode, WINDOW_STATES};
use crate::overlay::result::{button_canvas, markdown_view};
use crate::overlay::utils::to_wstring;

pub unsafe fn handle_lbutton_up(hwnd: HWND) -> LRESULT {
    let _ = ReleaseCapture();
    button_canvas::set_drag_mode(false); // Disable unclipped drag mode
    let mut perform_click = false;
    let mut is_copy_click = false;
    let mut is_edit_click = false;
    let mut is_undo_click = false;
    let mut is_redo_click = false;
    let mut is_markdown_click = false;
    let mut is_back_click = false;
    let mut is_forward_click = false;
    let mut is_download_click = false;
    let mut is_speaker_click = false;
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            let was_resizing = matches!(state.interaction_mode, InteractionMode::Resizing(_));
            state.interaction_mode = InteractionMode::None;
            if was_resizing && state.is_markdown_mode {
                markdown_view::fit_font_to_window(hwnd);
            }
            if !state.has_moved_significantly {
                perform_click = true;
                is_copy_click = state.on_copy_btn;
                is_edit_click = state.on_edit_btn;
                is_undo_click = state.on_undo_btn;
                is_redo_click = state.on_redo_btn;
                is_markdown_click = state.on_markdown_btn;
                is_back_click = state.on_back_btn;
                is_forward_click = state.on_forward_btn;
                is_download_click = state.on_download_btn;
                is_speaker_click = state.on_speaker_btn;
            }
        }
    }

    if perform_click {
        if is_back_click {
            markdown_view::go_back(hwnd);
        } else if is_forward_click {
            markdown_view::go_forward(hwnd);
        } else if is_undo_click {
            let mut prev_text = None;

            let mut is_markdown = false;
            let mut is_hovered = false;
            {
                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                    if let Some(last) = state.text_history.pop() {
                        // Save current text to redo history before replacing
                        let current_text_for_redo = state.full_text.clone();
                        prev_text = Some(last.clone());
                        state.full_text = last;
                        // Push current text to redo stack
                        if !current_text_for_redo.is_empty() {
                            state.redo_history.push(current_text_for_redo);
                        }
                    }
                    is_markdown = state.is_markdown_mode;
                    is_hovered = state.is_hovered;
                }
            }
            if let Some(txt) = prev_text {
                let wide_text = to_wstring(&txt);
                let _ = SetWindowTextW(hwnd, PCWSTR(wide_text.as_ptr()));
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.font_cache_dirty = true;
                        // Reset browsing state since content changed
                        state.is_browsing = false;
                    }
                }

                // Update markdown WebView if in markdown mode
                if is_markdown {
                    markdown_view::create_markdown_webview(hwnd, &txt, is_hovered);
                }

                let _ = InvalidateRect(Some(hwnd), None, false);
            }
        } else if is_redo_click {
            // Redo: pop from redo_history, push current to text_history
            let mut next_text = None;

            let mut is_markdown = false;
            let mut is_hovered = false;
            {
                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                    if let Some(redo_text) = state.redo_history.pop() {
                        // Save current text to undo history before replacing
                        let current_text_for_undo = state.full_text.clone();
                        next_text = Some(redo_text.clone());
                        state.full_text = redo_text;
                        // Push current text back to undo stack
                        if !current_text_for_undo.is_empty() {
                            state.text_history.push(current_text_for_undo);
                        }
                    }
                    is_markdown = state.is_markdown_mode;
                    is_hovered = state.is_hovered;
                }
            }
            if let Some(txt) = next_text {
                let wide_text = to_wstring(&txt);
                let _ = SetWindowTextW(hwnd, PCWSTR(wide_text.as_ptr()));
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.font_cache_dirty = true;
                        // Reset browsing state since content changed
                        state.is_browsing = false;
                    }
                }

                // Update markdown WebView if in markdown mode
                if is_markdown {
                    markdown_view::create_markdown_webview(hwnd, &txt, is_hovered);
                }

                let _ = InvalidateRect(Some(hwnd), None, false);
            }
        } else if is_edit_click {
            crate::overlay::result::trigger_edit(hwnd);
        } else if is_copy_click {
            let text_len = GetWindowTextLengthW(hwnd) + 1;
            let mut buf = vec![0u16; text_len as usize];
            GetWindowTextW(hwnd, &mut buf);
            let text = String::from_utf16_lossy(&buf[..text_len as usize - 1]).to_string();
            crate::overlay::utils::copy_to_clipboard(&text, hwnd);
            {
                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                    state.copy_success = true;
                }
            }
            SetTimer(Some(hwnd), 1, 1500, None);
        } else if is_markdown_click {
            // Only allow markdown toggle when NOT refining AND NOT streaming
            let can_toggle = {
                let states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get(&(hwnd.0 as isize)) {
                    !state.is_refining && !state.is_streaming_active
                } else {
                    false
                }
            };

            if can_toggle {
                // Toggle markdown mode
                let (toggle_on, _full_text) = {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.is_markdown_mode = !state.is_markdown_mode;
                        (state.is_markdown_mode, state.full_text.clone())
                    } else {
                        (false, String::new())
                    }
                };

                if toggle_on {
                    // Switch TO Markdown:
                    // window.rs now creates window without WS_CLIPCHILDREN by default

                    // DEFER WebView creation to after this handler returns
                    let _ = PostMessageW(Some(hwnd), WM_CREATE_WEBVIEW, WPARAM(0), LPARAM(0));
                    SetTimer(Some(hwnd), 2, 30, None);
                } else {
                    // Switch TO Plain Text:
                    // 1. Destroy the WebView completely
                    markdown_view::destroy_markdown_webview(hwnd);

                    // 2. Add WS_CLIPCHILDREN back
                    unsafe {
                        // Force style update (WS_CLIPCHILDREN is permanently off)
                        let _ = SetWindowPos(
                            hwnd,
                            Some(HWND::default()),
                            0,
                            0,
                            0,
                            0,
                            SWP_FRAMECHANGED
                                | SWP_NOMOVE
                                | SWP_NOSIZE
                                | SWP_NOZORDER
                                | SWP_NOACTIVATE,
                        );
                    }

                    // 3. Cleanup timers and restore event tracking
                    let _ = KillTimer(Some(hwnd), 2);

                    let mut tme = TRACKMOUSEEVENT {
                        cbSize: size_of::<TRACKMOUSEEVENT>() as u32,
                        dwFlags: TME_LEAVE,
                        hwndTrack: hwnd,
                        dwHoverTime: 0,
                    };
                    let _ = TrackMouseEvent(&mut tme);
                }
                let _ = InvalidateRect(Some(hwnd), None, false);
            }
        } else if is_download_click {
            // Download as HTML file
            let full_text = {
                let states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get(&(hwnd.0 as isize)) {
                    state.full_text.clone()
                } else {
                    String::new()
                }
            };

            if !full_text.is_empty() {
                // Call save_html_file which opens the file save dialog
                markdown_view::save_html_file(&full_text);
            }
        } else if is_speaker_click {
            // TTS - speak the result text
            let (full_text, current_tts_id, is_loading) = {
                let states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get(&(hwnd.0 as isize)) {
                    (
                        state.full_text.clone(),
                        state.tts_request_id,
                        state.tts_loading,
                    )
                } else {
                    (String::new(), 0, false)
                }
            };

            // Don't allow clicks while loading
            if is_loading {
                // Ignore click during loading state
            } else if current_tts_id != 0
                && crate::api::tts::TTS_MANAGER.is_speaking(current_tts_id)
            {
                // Currently speaking (blue button) - stop immediately
                crate::api::tts::TTS_MANAGER.stop();
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.tts_request_id = 0;
                        state.tts_loading = false;
                    }
                }
            } else if !full_text.is_empty() {
                // Start new speech - enter loading state first
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.tts_loading = true;
                    }
                }
                let _ = InvalidateRect(Some(hwnd), None, false); // Redraw to show loading

                let request_id = crate::api::tts::TTS_MANAGER.speak(&full_text, hwnd.0 as isize);
                {
                    let mut states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                        state.tts_request_id = request_id;
                        // Keep tts_loading = true until audio starts playing
                    }
                }
            }
            let _ = InvalidateRect(Some(hwnd), None, false);
        } else {
            // Clicking "x" (or outside buttons) -> Close window
            let linked_hwnd = {
                let states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get(&(hwnd.0 as isize)) {
                    state.linked_window
                } else {
                    None
                }
            };
            if let Some(linked) = linked_hwnd {
                if IsWindow(Some(linked)).as_bool() {
                    let _ = PostMessageW(Some(linked), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
            }
            let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
        }
    }
    LRESULT(0)
}

pub unsafe fn handle_rbutton_up(hwnd: HWND) -> LRESULT {
    let _ = ReleaseCapture();
    button_canvas::set_drag_mode(false); // Disable unclipped drag mode
    let mut close_group = false;

    let mut fit_targets = Vec::new();
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            match &state.interaction_mode {
                InteractionMode::DraggingGroup(snapshot)
                | InteractionMode::ResizingGroup(snapshot, _) => {
                    if state.has_moved_significantly {
                        fit_targets = snapshot.iter().map(|(h, _)| *h).collect();
                    } else {
                        close_group = true;
                    }
                }
                InteractionMode::None => {
                    close_group = true;
                }
                _ => {}
            }
            state.interaction_mode = InteractionMode::None;
        }
    }

    if close_group {
        let group = crate::overlay::result::state::get_window_group(hwnd);
        for (h, _) in group {
            if IsWindow(Some(h)).as_bool() {
                let _ = PostMessageW(Some(h), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
    } else {
        // Post cursor refresh just in case, though the canvas fix should handle it natively
        unsafe {
            let _ = PostMessageW(
                Some(hwnd),
                WM_SETCURSOR,
                WPARAM(hwnd.0 as usize),
                LPARAM(0x02000001),
            );
        }

        // Trigger font fitting for all windows in the group
        for h in fit_targets {
            let is_markdown = {
                let states = WINDOW_STATES.lock().unwrap();
                states
                    .get(&(h.0 as isize))
                    .map(|s| s.is_markdown_mode)
                    .unwrap_or(false)
            };
            if is_markdown {
                // Post message to target window to ensure it runs on correct thread for WebView access
                let _ = PostMessageW(
                    Some(h),
                    super::misc::WM_RESIZE_MARKDOWN,
                    WPARAM(0),
                    LPARAM(0),
                );
            }
        }
    }
    LRESULT(0)
}

pub unsafe fn handle_mbutton_up(hwnd: HWND) -> LRESULT {
    let _ = ReleaseCapture();
    button_canvas::set_drag_mode(false); // Disable unclipped drag mode

    let mut close_all = false;
    let mut fit_targets = Vec::new();
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            match &state.interaction_mode {
                InteractionMode::DraggingGroup(snapshot)
                | InteractionMode::ResizingGroup(snapshot, _) => {
                    if state.has_moved_significantly {
                        fit_targets = snapshot.iter().map(|(h, _)| *h).collect();
                    } else {
                        close_all = true;
                    }
                }
                InteractionMode::None => {
                    close_all = true;
                }
                _ => {}
            }
            state.interaction_mode = InteractionMode::None;
        }
    }

    if close_all {
        let mut targets = Vec::new();
        {
            if let Ok(states) = WINDOW_STATES.lock() {
                for (&hwnd_int, _) in states.iter() {
                    targets.push(HWND(hwnd_int as *mut std::ffi::c_void));
                }
            }
        }

        for target in targets {
            if IsWindow(Some(target)).as_bool() {
                let _ = PostMessageW(Some(target), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
    } else {
        // Post cursor refresh
        unsafe {
            let _ = PostMessageW(
                Some(hwnd),
                WM_SETCURSOR,
                WPARAM(hwnd.0 as usize),
                LPARAM(0x02000001),
            );
        }

        // Trigger font fitting for ALL windows
        for h in fit_targets {
            let is_markdown = {
                let states = WINDOW_STATES.lock().unwrap();
                states
                    .get(&(h.0 as isize))
                    .map(|s| s.is_markdown_mode)
                    .unwrap_or(false)
            };
            if is_markdown {
                // Post message to target window to ensure it runs on correct thread for WebView access
                let _ = PostMessageW(
                    Some(h),
                    super::misc::WM_RESIZE_MARKDOWN,
                    WPARAM(0),
                    LPARAM(0),
                );
            }
        }
    }
    LRESULT(0)
}
</file>

<file path="src/overlay/result/event_handler/mouse_input.rs">
use std::mem::size_of;
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;

use crate::overlay::result::button_canvas;
use crate::overlay::result::layout::{
    get_copy_btn_rect, get_download_btn_rect, get_edit_btn_rect, get_markdown_btn_rect,
    get_redo_btn_rect, get_resize_edge, get_speaker_btn_rect, get_undo_btn_rect,
    should_show_buttons,
};
use crate::overlay::result::markdown_view;
use crate::overlay::result::state::{InteractionMode, ResizeEdge, WINDOW_STATES};

pub unsafe fn handle_set_cursor(hwnd: HWND) -> LRESULT {
    let mut cursor_id = PCWSTR(std::ptr::null());
    let mut rect = RECT::default();
    let _ = GetClientRect(hwnd, &mut rect);

    let mut pt = POINT::default();
    let _ = GetCursorPos(&mut pt);
    let _ = ScreenToClient(hwnd, &mut pt);

    let is_over_edit = false;
    let mut is_streaming_active = false;
    {
        let states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get(&(hwnd.0 as isize)) {
            is_streaming_active = state.is_streaming_active;
        }
    }

    if is_over_edit {
        SetCursor(Some(LoadCursorW(None, IDC_IBEAM).unwrap()));
        return LRESULT(1);
    }

    let edge = get_resize_edge(rect.right, rect.bottom, pt.x, pt.y);

    match edge {
        ResizeEdge::Top | ResizeEdge::Bottom => cursor_id = IDC_SIZENS,
        ResizeEdge::Left | ResizeEdge::Right => cursor_id = IDC_SIZEWE,
        ResizeEdge::TopLeft | ResizeEdge::BottomRight => cursor_id = IDC_SIZENWSE,
        ResizeEdge::TopRight | ResizeEdge::BottomLeft => cursor_id = IDC_SIZENESW,
        ResizeEdge::None => {
            // Only show hand cursor on buttons if overlay is large enough AND not streaming
            if !is_streaming_active && should_show_buttons(rect.right, rect.bottom) {
                let copy_rect = get_copy_btn_rect(rect.right, rect.bottom);
                let edit_rect = get_edit_btn_rect(rect.right, rect.bottom);
                let undo_rect = get_undo_btn_rect(rect.right, rect.bottom);

                let on_copy = pt.x >= copy_rect.left
                    && pt.x <= copy_rect.right
                    && pt.y >= copy_rect.top
                    && pt.y <= copy_rect.bottom;
                let on_edit = pt.x >= edit_rect.left
                    && pt.x <= edit_rect.right
                    && pt.y >= edit_rect.top
                    && pt.y <= edit_rect.bottom;

                let mut has_history = false;
                let mut is_browsing = false;
                {
                    let states = WINDOW_STATES.lock().unwrap();
                    if let Some(state) = states.get(&(hwnd.0 as isize)) {
                        has_history = !state.text_history.is_empty();
                        is_browsing = state.is_browsing;
                    }
                }

                // Manual calc for Back button rect
                let btn_size = 28;
                let margin = 12;
                let threshold_h = btn_size + (margin * 2);
                let cy = if rect.bottom < threshold_h {
                    (rect.bottom as f32) / 2.0
                } else {
                    (rect.bottom - margin - btn_size / 2) as f32
                };
                let cx_back = (margin + btn_size / 2) as i32;
                let cy_back = cy as i32;
                let back_rect = RECT {
                    left: cx_back - 14,
                    top: cy_back - 14,
                    right: cx_back + 14,
                    bottom: cy_back + 14,
                };

                let on_back = is_browsing
                    && pt.x >= back_rect.left
                    && pt.x <= back_rect.right
                    && pt.y >= back_rect.top
                    && pt.y <= back_rect.bottom;

                let on_undo = has_history
                    && pt.x >= undo_rect.left
                    && pt.x <= undo_rect.right
                    && pt.y >= undo_rect.top
                    && pt.y <= undo_rect.bottom;

                let md_rect = get_markdown_btn_rect(rect.right, rect.bottom);
                let on_md = pt.x >= md_rect.left
                    && pt.x <= md_rect.right
                    && pt.y >= md_rect.top
                    && pt.y <= md_rect.bottom;

                let dl_rect = get_download_btn_rect(rect.right, rect.bottom);
                let on_dl = pt.x >= dl_rect.left
                    && pt.x <= dl_rect.right
                    && pt.y >= dl_rect.top
                    && pt.y <= dl_rect.bottom;

                let speaker_rect = get_speaker_btn_rect(rect.right, rect.bottom);
                let on_speaker = pt.x >= speaker_rect.left
                    && pt.x <= speaker_rect.right
                    && pt.y >= speaker_rect.top
                    && pt.y <= speaker_rect.bottom;

                if on_copy || on_edit || on_undo || on_md || on_back || on_dl || on_speaker {
                    cursor_id = IDC_HAND;
                }
            }
        }
    }

    if !cursor_id.0.is_null() {
        SetCursor(Some(LoadCursorW(None, cursor_id).unwrap()));
        LRESULT(1)
    } else {
        // Hide system cursor when over window body to let procedural broom be the visual
        SetCursor(None);
        LRESULT(1)
    }
}

pub unsafe fn handle_lbutton_down(hwnd: HWND, lparam: LPARAM) -> LRESULT {
    let x = (lparam.0 & 0xFFFF) as i16 as i32;
    let y = ((lparam.0 >> 16) & 0xFFFF) as i16 as i32;
    let mut rect = RECT::default();
    let _ = GetClientRect(hwnd, &mut rect);
    let width = rect.right;
    let height = rect.bottom;
    let edge = get_resize_edge(width, height, x, y);
    let mut window_rect = RECT::default();
    let _ = GetWindowRect(hwnd, &mut window_rect);
    let mut screen_pt = POINT::default();
    let _ = GetCursorPos(&mut screen_pt);

    let mut states = WINDOW_STATES.lock().unwrap();
    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
        state.drag_start_mouse = screen_pt;
        state.drag_start_window_rect = window_rect;
        state.has_moved_significantly = false;
        if edge != ResizeEdge::None {
            state.interaction_mode = InteractionMode::Resizing(edge);
        } else {
            state.interaction_mode = InteractionMode::DraggingWindow;
        }
    }
    let is_markdown = if let Some(state) = states.get(&(hwnd.0 as isize)) {
        state.is_markdown_mode
    } else {
        false
    };
    SetCapture(hwnd);
    if is_markdown {
        button_canvas::set_drag_mode(true); // Enable unclipped drag mode for smooth UI
    }
    LRESULT(0)
}

pub unsafe fn handle_rbutton_down(hwnd: HWND, lparam: LPARAM) -> LRESULT {
    let x = (lparam.0 & 0xFFFF) as i16 as i32;
    let y = ((lparam.0 >> 16) & 0xFFFF) as i16 as i32;
    let mut rect = RECT::default();
    let _ = GetClientRect(hwnd, &mut rect);
    let edge = get_resize_edge(rect.right, rect.bottom, x, y);

    let mut screen_pt = POINT::default();
    let _ = GetCursorPos(&mut screen_pt);

    let group = crate::overlay::result::state::get_window_group(hwnd);
    let group_snapshot: Vec<(HWND, RECT)> = group
        .into_iter()
        .map(|(h, _)| {
            let mut r = RECT::default();
            let _ = GetWindowRect(h, &mut r);
            (h, r)
        })
        .collect();

    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            state.drag_start_mouse = screen_pt;
            state.drag_start_window_rect = {
                let mut r = RECT::default();
                let _ = GetWindowRect(hwnd, &mut r);
                r
            };
            state.has_moved_significantly = false;
            if edge != ResizeEdge::None {
                state.interaction_mode = InteractionMode::ResizingGroup(group_snapshot, edge);
            } else {
                state.interaction_mode = InteractionMode::DraggingGroup(group_snapshot);
            }
        }
    }

    SetCapture(hwnd);
    button_canvas::set_drag_mode(true); // Enable unclipped drag mode for smooth UI
    LRESULT(0)
}

pub unsafe fn handle_mbutton_down(hwnd: HWND, lparam: LPARAM) -> LRESULT {
    let x = (lparam.0 & 0xFFFF) as i16 as i32;
    let y = ((lparam.0 >> 16) & 0xFFFF) as i16 as i32;
    let mut rect = RECT::default();
    let _ = GetClientRect(hwnd, &mut rect);
    let edge = get_resize_edge(rect.right, rect.bottom, x, y);

    let mut screen_pt = POINT::default();
    let _ = GetCursorPos(&mut screen_pt);

    let mut targets = Vec::new();
    {
        let states = WINDOW_STATES.lock().unwrap();
        for &hwnd_int in states.keys() {
            let h = HWND(hwnd_int as *mut std::ffi::c_void);
            let mut r = RECT::default();
            if GetWindowRect(h, &mut r).is_ok() {
                targets.push((h, r));
            }
        }
    }

    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            state.drag_start_mouse = screen_pt;
            state.drag_start_window_rect = {
                let mut r = RECT::default();
                let _ = GetWindowRect(hwnd, &mut r);
                r
            };
            state.has_moved_significantly = false;
            if edge != ResizeEdge::None {
                state.interaction_mode = InteractionMode::ResizingGroup(targets, edge);
            } else {
                state.interaction_mode = InteractionMode::DraggingGroup(targets);
            }
        }
    }

    SetCapture(hwnd);
    button_canvas::set_drag_mode(true);
    LRESULT(0)
}

pub unsafe fn handle_mouse_move(hwnd: HWND, lparam: LPARAM) -> LRESULT {
    let x = (lparam.0 & 0xFFFF) as i16 as f32;
    let y = ((lparam.0 >> 16) & 0xFFFF) as i16 as f32;
    let mut rect = RECT::default();
    let _ = GetClientRect(hwnd, &mut rect);
    let hover_edge = get_resize_edge(rect.right, rect.bottom, x as i32, y as i32);

    // Defer group moves to avoid deadlocks (holding lock while calling SetWindowPos on other windows)
    let mut group_moves = Vec::new();

    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
            state.current_resize_edge = hover_edge;
            let dx = x - state.physics.x;
            let drag_impulse = if matches!(
                &state.interaction_mode,
                InteractionMode::DraggingWindow | InteractionMode::DraggingGroup(_)
            ) {
                0.0
            } else {
                (dx * 1.5).clamp(-20.0, 20.0)
            };
            state.physics.tilt_velocity -= drag_impulse * 0.2;
            state.physics.current_tilt = state.physics.current_tilt.clamp(-22.5, 22.5);
            state.physics.x = x;
            state.physics.y = y;

            // Only process button hover states if overlay is large enough AND not streaming
            if !state.is_streaming_active && should_show_buttons(rect.right, rect.bottom) {
                let copy_rect = get_copy_btn_rect(rect.right, rect.bottom);
                let edit_rect = get_edit_btn_rect(rect.right, rect.bottom);
                let undo_rect = get_undo_btn_rect(rect.right, rect.bottom);
                let padding = 4;
                state.on_copy_btn = x as i32 >= copy_rect.left - padding
                    && x as i32 <= copy_rect.right + padding
                    && y as i32 >= copy_rect.top - padding
                    && y as i32 <= copy_rect.bottom + padding;
                state.on_edit_btn = x as i32 >= edit_rect.left - padding
                    && x as i32 <= edit_rect.right + padding
                    && y as i32 >= edit_rect.top - padding
                    && y as i32 <= edit_rect.bottom + padding;
                if !state.text_history.is_empty() && !state.is_browsing {
                    state.on_undo_btn = x as i32 >= undo_rect.left - padding
                        && x as i32 <= undo_rect.right + padding
                        && y as i32 >= undo_rect.top - padding
                        && y as i32 <= undo_rect.bottom + padding;
                } else {
                    state.on_undo_btn = false;
                }

                // Redo button hover state
                let redo_rect = get_redo_btn_rect(rect.right, rect.bottom);
                if !state.redo_history.is_empty() && !state.is_browsing {
                    state.on_redo_btn = x as i32 >= redo_rect.left - padding
                        && x as i32 <= redo_rect.right + padding
                        && y as i32 >= redo_rect.top - padding
                        && y as i32 <= redo_rect.bottom + padding;
                } else {
                    state.on_redo_btn = false;
                }

                // Calc Back and Forward Button state (only when browsing)
                if state.is_browsing {
                    let btn_size = 28;
                    let margin = 12;
                    let threshold_h = btn_size + (margin * 2);
                    let cy = if rect.bottom < threshold_h {
                        (rect.bottom as f32) / 2.0
                    } else {
                        (rect.bottom - margin - btn_size / 2) as f32
                    };

                    // Back button (left side)
                    let cx_back = (margin + btn_size / 2) as i32;
                    let cy_back = cy as i32;
                    let l = cx_back - 14 - padding;
                    let r = cx_back + 14 + padding;
                    let t = cy_back - 14 - padding;
                    let b = cy_back + 14 + padding;
                    state.on_back_btn =
                        x as i32 >= l && x as i32 <= r && y as i32 >= t && y as i32 <= b;

                    // Forward button (right side)
                    if state.navigation_depth < state.max_navigation_depth {
                        let cx_forward = (rect.right - margin - btn_size / 2) as i32;
                        let lf = cx_forward - 14 - padding;
                        let rf = cx_forward + 14 + padding;
                        state.on_forward_btn =
                            x as i32 >= lf && x as i32 <= rf && y as i32 >= t && y as i32 <= b;
                    } else {
                        state.on_forward_btn = false;
                    }

                    // Disable all result UI button hovers when browsing
                    state.on_copy_btn = false;
                    state.on_edit_btn = false;
                    state.on_markdown_btn = false;
                    state.on_download_btn = false;
                } else {
                    state.on_back_btn = false;
                    state.on_forward_btn = false;

                    let md_rect = get_markdown_btn_rect(rect.right, rect.bottom);
                    let padding = 4;
                    state.on_markdown_btn = x as i32 >= md_rect.left - padding
                        && x as i32 <= md_rect.right + padding
                        && y as i32 >= md_rect.top - padding
                        && y as i32 <= md_rect.bottom + padding;

                    let dl_rect = get_download_btn_rect(rect.right, rect.bottom);
                    state.on_download_btn = x as i32 >= dl_rect.left - padding
                        && x as i32 <= dl_rect.right + padding
                        && y as i32 >= dl_rect.top - padding
                        && y as i32 <= dl_rect.bottom + padding;

                    let speaker_rect = get_speaker_btn_rect(rect.right, rect.bottom);
                    state.on_speaker_btn = x as i32 >= speaker_rect.left - padding
                        && x as i32 <= speaker_rect.right + padding
                        && y as i32 >= speaker_rect.top - padding
                        && y as i32 <= speaker_rect.bottom + padding;
                }
            } else {
                // Overlay too small - clear all button hover states
                state.on_copy_btn = false;
                state.on_edit_btn = false;
                state.on_undo_btn = false;
                state.on_redo_btn = false;
                state.on_markdown_btn = false;
                state.on_download_btn = false;
                state.on_back_btn = false;
                state.on_forward_btn = false;
                state.on_speaker_btn = false;
            }

            // In markdown mode, let the Timer handle is_hovered state to ensure it syncs with WebView resize
            let handle_hover_in_mousemove = !state.is_markdown_mode;

            if handle_hover_in_mousemove && !state.is_hovered {
                state.is_hovered = true;
                let mut tme = TRACKMOUSEEVENT {
                    cbSize: size_of::<TRACKMOUSEEVENT>() as u32,
                    dwFlags: TME_LEAVE,
                    hwndTrack: hwnd,
                    dwHoverTime: 0,
                };
                let _ = TrackMouseEvent(&mut tme);
                // Note: WebView resize is now handled by Timer 2 to avoid race conditions
            }

            match &state.interaction_mode {
                InteractionMode::DraggingWindow => {
                    let mut curr_pt = POINT::default();
                    let _ = GetCursorPos(&mut curr_pt);
                    let dx = curr_pt.x - state.drag_start_mouse.x;
                    let dy = curr_pt.y - state.drag_start_mouse.y;
                    if dx.abs() > 3 || dy.abs() > 3 {
                        state.has_moved_significantly = true;
                    }
                    let new_x = state.drag_start_window_rect.left + dx;
                    let new_y = state.drag_start_window_rect.top + dy;
                    let _ = SetWindowPos(
                        hwnd,
                        Some(HWND::default()),
                        new_x,
                        new_y,
                        0,
                        0,
                        SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
                    );
                    button_canvas::update_window_position(hwnd);
                }
                InteractionMode::DraggingGroup(snapshot) => {
                    let mut curr_pt = POINT::default();
                    let _ = GetCursorPos(&mut curr_pt);
                    let dx = curr_pt.x - state.drag_start_mouse.x;
                    let dy = curr_pt.y - state.drag_start_mouse.y;
                    if dx.abs() > 3 || dy.abs() > 3 {
                        state.has_moved_significantly = true;
                    }

                    for (h, start_rect) in snapshot {
                        let new_x = start_rect.left + dx;
                        let new_y = start_rect.top + dy;
                        group_moves.push((
                            *h,
                            new_x,
                            new_y,
                            start_rect.right - start_rect.left,
                            start_rect.bottom - start_rect.top,
                        ));
                    }
                }
                InteractionMode::Resizing(edge) => {
                    state.has_moved_significantly = true;
                    let mut curr_pt = POINT::default();
                    let _ = GetCursorPos(&mut curr_pt);
                    let dx = curr_pt.x - state.drag_start_mouse.x;
                    let dy = curr_pt.y - state.drag_start_mouse.y;
                    let mut new_rect = state.drag_start_window_rect;
                    let min_w = super::MIN_WINDOW_WIDTH;
                    let min_h = super::MIN_WINDOW_HEIGHT;

                    match edge {
                        ResizeEdge::Right | ResizeEdge::TopRight | ResizeEdge::BottomRight => {
                            new_rect.right = (state.drag_start_window_rect.right + dx)
                                .max(state.drag_start_window_rect.left + min_w);
                        }
                        ResizeEdge::Left | ResizeEdge::TopLeft | ResizeEdge::BottomLeft => {
                            new_rect.left = (state.drag_start_window_rect.left + dx)
                                .min(state.drag_start_window_rect.right - min_w);
                        }
                        _ => {}
                    }
                    match edge {
                        ResizeEdge::Bottom | ResizeEdge::BottomRight | ResizeEdge::BottomLeft => {
                            new_rect.bottom = (state.drag_start_window_rect.bottom + dy)
                                .max(state.drag_start_window_rect.top + min_h);
                        }
                        ResizeEdge::Top | ResizeEdge::TopLeft | ResizeEdge::TopRight => {
                            new_rect.top = (state.drag_start_window_rect.top + dy)
                                .min(state.drag_start_window_rect.bottom - min_h);
                        }
                        _ => {}
                    }
                    let w = new_rect.right - new_rect.left;
                    let h = new_rect.bottom - new_rect.top;
                    let _ = SetWindowPos(
                        hwnd,
                        Some(HWND::default()),
                        new_rect.left,
                        new_rect.top,
                        w,
                        h,
                        SWP_NOZORDER | SWP_NOACTIVATE,
                    );

                    // Resize markdown webview if in markdown mode
                    if state.is_markdown_mode {
                        markdown_view::resize_markdown_webview(hwnd, state.is_hovered);
                    }

                    button_canvas::update_window_position(hwnd);
                }
                InteractionMode::ResizingGroup(snapshot, edge) => {
                    state.has_moved_significantly = true;
                    let mut curr_pt = POINT::default();
                    let _ = GetCursorPos(&mut curr_pt);
                    let dx = curr_pt.x - state.drag_start_mouse.x;
                    let dy = curr_pt.y - state.drag_start_mouse.y;

                    let min_w = super::MIN_WINDOW_WIDTH;
                    let min_h = super::MIN_WINDOW_HEIGHT;

                    for (h, start_rect) in snapshot {
                        let mut new_rect = *start_rect;
                        match edge {
                            ResizeEdge::Right | ResizeEdge::TopRight | ResizeEdge::BottomRight => {
                                new_rect.right =
                                    (start_rect.right + dx).max(start_rect.left + min_w);
                            }
                            ResizeEdge::Left | ResizeEdge::TopLeft | ResizeEdge::BottomLeft => {
                                new_rect.left =
                                    (start_rect.left + dx).min(start_rect.right - min_w);
                            }
                            _ => {}
                        }
                        match edge {
                            ResizeEdge::Bottom
                            | ResizeEdge::BottomRight
                            | ResizeEdge::BottomLeft => {
                                new_rect.bottom =
                                    (start_rect.bottom + dy).max(start_rect.top + min_h);
                            }
                            ResizeEdge::Top | ResizeEdge::TopLeft | ResizeEdge::TopRight => {
                                new_rect.top = (start_rect.top + dy).min(start_rect.bottom - min_h);
                            }
                            _ => {}
                        }
                        group_moves.push((
                            *h,
                            new_rect.left,
                            new_rect.top,
                            new_rect.right - new_rect.left,
                            new_rect.bottom - new_rect.top,
                        ));
                    }
                }
                _ => {}
            }
            let _ = InvalidateRect(Some(hwnd), None, false);
        }
    } // Lock released

    // Execute deferred group moves using DeferWindowPos for performance
    if !group_moves.is_empty() {
        unsafe {
            if let Ok(mut hdwp) = BeginDeferWindowPos(group_moves.len() as i32) {
                for (h, x, y, w, h_val) in group_moves {
                    hdwp = DeferWindowPos(
                        hdwp,
                        h,
                        None,
                        x,
                        y,
                        w,
                        h_val,
                        SWP_NOZORDER | SWP_NOACTIVATE,
                    )
                    .unwrap_or(hdwp);
                    button_canvas::update_window_position_direct(h, x, y, w, h_val);
                }
                let _ = EndDeferWindowPos(hdwp);
                button_canvas::update_canvas();
            }
        }
    }

    LRESULT(0)
}

pub unsafe fn handle_mouse_leave(hwnd: HWND) -> LRESULT {
    // Check if cursor is actually outside the window (not just moved to a child window like WebView)
    let mut states = WINDOW_STATES.lock().unwrap();
    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
        // Clear button states
        state.on_copy_btn = false;
        state.on_edit_btn = false;
        state.on_undo_btn = false;
        state.on_redo_btn = false;
        state.on_markdown_btn = false;
        state.on_download_btn = false;
        state.on_back_btn = false;
        state.on_forward_btn = false;
        state.on_speaker_btn = false;
        state.current_resize_edge = ResizeEdge::None;

        // For plain text mode, also clear hover state here
        // (markdown mode uses Timer 2 for this since WebView steals focus)
        if !state.is_markdown_mode {
            state.is_hovered = false;
        }

        let _ = InvalidateRect(Some(hwnd), None, false);
    }
    LRESULT(0)
}
</file>

<file path="src/overlay/result/mod.rs">
pub mod button_canvas;
mod event_handler;
pub mod layout;
mod logic;
pub mod markdown_view;
pub mod paint;
pub mod state;
mod window;

pub use state::{close_windows_with_token, link_windows, RefineContext, WindowType, WINDOW_STATES};
pub use window::{create_result_window, get_chain_color, update_window_text};

// Trigger functions for button canvas IPC
use windows::Win32::Foundation::{HWND, LPARAM, WPARAM};
use windows::Win32::UI::WindowsAndMessaging::{PostMessageW, WM_CLOSE};

// Helper to check if any window is currently refining/editing
pub fn is_any_refine_active() -> bool {
    let states = WINDOW_STATES.lock().unwrap();
    states.values().any(|s| s.is_editing)
}

// Helper to get the parent HWND of the active refine session
pub fn get_active_refine_parent() -> Option<HWND> {
    let states = WINDOW_STATES.lock().unwrap();
    states
        .iter()
        .find(|(_, s)| s.is_editing)
        .map(|(hwnd, _)| HWND(*hwnd as *mut std::ffi::c_void))
}

// Helper to update refine text
pub fn set_refine_text(hwnd: HWND, text: &str, is_insert: bool) {
    button_canvas::send_refine_text_update(hwnd, text, is_insert);

    // Only update internal state if overwriting (for consistency)
    if !is_insert {
        let hwnd_key = hwnd.0 as isize;
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            state.input_text = text.to_string();
        }
    }
}

/// Trigger copy action on a result window
pub fn trigger_copy(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    // Get text and copy to clipboard
    let text = {
        let states = WINDOW_STATES.lock().unwrap();
        states
            .get(&hwnd_key)
            .map(|s| s.full_text.clone())
            .unwrap_or_default()
    };

    if !text.is_empty() {
        crate::overlay::utils::copy_to_clipboard(&text, hwnd);

        // Set copy success flag
        {
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&hwnd_key) {
                state.copy_success = true;
            }
        }

        // Update canvas to show success state
        button_canvas::update_window_position(hwnd);

        // Reset success flag after delay
        let hwnd_val = hwnd.0 as usize;
        std::thread::spawn(move || {
            std::thread::sleep(std::time::Duration::from_millis(1500));
            {
                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(hwnd_val as isize)) {
                    state.copy_success = false;
                }
            }
            // Update canvas after dropping lock
            button_canvas::update_window_position(HWND(hwnd_val as *mut std::ffi::c_void));
        });
    }
}

/// Trigger undo action on a result window
pub fn trigger_undo(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    let (prev_text, is_markdown) = {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            if let Some(last) = state.text_history.pop() {
                let current = state.full_text.clone();
                state.redo_history.push(current);
                state.full_text = last.clone();
                (Some(last), state.is_markdown_mode)
            } else {
                (None, false)
            }
        } else {
            (None, false)
        }
    };

    if let Some(txt) = prev_text {
        // Update window text
        let wide_text = crate::overlay::utils::to_wstring(&txt);
        unsafe {
            let _ = windows::Win32::UI::WindowsAndMessaging::SetWindowTextW(
                hwnd,
                windows::core::PCWSTR(wide_text.as_ptr()),
            );
        }

        if is_markdown {
            unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    event_handler::misc::WM_CREATE_WEBVIEW,
                    WPARAM(0),
                    LPARAM(0),
                );
            }
        }

        // Update canvas
        button_canvas::update_window_position(hwnd);
    }
}

/// Trigger redo action on a result window
pub fn trigger_redo(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    let (next_text, is_markdown) = {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            if let Some(redo) = state.redo_history.pop() {
                let current = state.full_text.clone();
                state.text_history.push(current);
                state.full_text = redo.clone();
                (Some(redo), state.is_markdown_mode)
            } else {
                (None, false)
            }
        } else {
            (None, false)
        }
    };

    if let Some(txt) = next_text {
        let wide_text = crate::overlay::utils::to_wstring(&txt);
        unsafe {
            let _ = windows::Win32::UI::WindowsAndMessaging::SetWindowTextW(
                hwnd,
                windows::core::PCWSTR(wide_text.as_ptr()),
            );
        }

        if is_markdown {
            unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    event_handler::misc::WM_CREATE_WEBVIEW,
                    WPARAM(0),
                    LPARAM(0),
                );
            }
        }

        button_canvas::update_window_position(hwnd);
    }
}

/// Trigger edit/refine action
pub fn trigger_edit(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            state.is_editing = !state.is_editing;
            if state.is_editing {
                state.input_text.clear();
            }
        }
    }

    // Update button canvas to reflect changes (show/hide refine bar)
    button_canvas::update_window_position(hwnd);

    // Resize markdown view if needed (to make space? actually refine bar is floating now?)
    // If refine bar is in button canvas, it floats NEXT to the window or below it.
    // So we DON'T need to resize the markdown window anymore!
    // But previously we did.
    // If we want it to "join" the button canvas as a bar UNDER the result, it floats outside.
    // So we don't resize the window.
}

pub fn trigger_refine_submit(hwnd: HWND, text: &str) {
    if text.trim().is_empty() {
        return;
    }

    let hwnd_key = hwnd.0 as isize;

    // Save to history
    crate::overlay::input_history::add_to_history(text);

    let mut should_trigger_refine = false;
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            let text_to_refine = state.full_text.clone();
            state.text_history.push(text_to_refine.clone());
            // Clear redo history when new action is performed
            state.redo_history.clear();

            // Set input_text for the prompt logic
            state.input_text = text_to_refine; // The prompt logic uses this as "previous text" if not empty??

            // WAIT, logic in timer_tasks was:
            // if text_to_refine.trim().is_empty() && !preset_prompt.is_empty() { (user_input, preset_prompt) } else { (text_to_refine, user_input) }
            // user_input was the text from refine input.
            // text_to_refine came from state.full_text.

            // So:
            // state.input_text should store the PREVIOUS full text (context).
            // But timer_tasks logic is confusingly named.

            // Let's set a NEW state field or reuse one.
            // We have `state.input_text`.
            // In timer_tasks:
            // state.input_text = text_to_refine.clone();
            // user_input = input_text; (from poll)

            // We need to pass `user_input` (the refine prompt) to the logic.
            // `state.input_text` seems to be used for something else?
            // "NEW: Input text currently being refined/processed" comments says so.

            // I'll add `pending_refine_prompt` to WindowState?
            // Or reuse `pending_text`? No `pending_text` is for output.

            // Let's use `preset_prompt` ??? No.

            // Re-check timer_tasks logic:
            // 341: let (final_prev_text, final_user_prompt) = ...
            // 345: (text_to_refine, user_input)

            // text_to_refine is what we are refining (the current content).
            // user_input is what we typed.

            // So I need to store `user_input` in state so timer_tasks can pick it up.
            // Or I can spawn the thread directly here?
            // But timer_tasks has the logic.

            // Let's just modify `state` to trigger `timer_tasks` logic.
            // `trigger_refine` boolean in timer_tasks is local.

            // I will implement the logic HERE instead of relying on `timer_tasks` to pick it up.
            // It makes more sense.

            state.full_text = String::new(); // Clear output for streaming
            state.pending_text = Some(String::new());

            // We need to store context for the refinement.
            // Let's put the typed text into `state.preset_prompt` TEMPORARILY?
            // No, that's hacky.

            // I'll add a `refine_prompt` field to WindowState if needed, or pass it to a helper.
            // Actually, `state.input_text` WAS storing `text_to_refine`.
            // The `user_input` was local in `timer_tasks`.

            // I will update WindowState to receive the prompt.
            // But wait, `timer_tasks.rs` has the `TYPE MODE PROMPT LOGIC` block (lines 318+).
            // It checks `if trigger_refine && !user_input.empty()`.

            // I'll move that logic into a public function `start_refinement(hwnd, prompt, context_text)` in `logic.rs` or `mod.rs`
            // and call it from here.
            should_trigger_refine = true;
        }
    }

    if should_trigger_refine {
        // Need to invoke the refinement logic.
        // I will implement `start_refinement` in this file below and call it.
        start_refinement(hwnd, text);
    }

    // Hide UI
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            state.is_editing = false;
            state.is_refining = true;
            state.is_streaming_active = true;
            state.was_streaming_active = true;
        }
    }
    button_canvas::update_window_position(hwnd);
}

pub fn trigger_refine_cancel(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;
    {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            state.is_editing = false;
        }
    }
    button_canvas::update_window_position(hwnd);
}

// Logic extracted from timer_tasks (simplified)
fn start_refinement(hwnd: HWND, user_prompt: &str) {
    let hwnd_key = hwnd.0 as isize;
    let (context_data, model_id, provider, streaming, preset_prompt, prev_text) = {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(s) = states.get_mut(&hwnd_key) {
            let prev = s.full_text.clone();
            // Setup state for processing
            // s.input_text = prev.clone(); // Removed: Don't pollute input UI state with context
            (
                s.context_data.clone(),
                s.model_id.clone(),
                s.provider.clone(),
                s.streaming_enabled,
                s.preset_prompt.clone(),
                prev,
            )
        } else {
            return;
        }
    };

    let user_input = user_prompt.to_string();

    // Logic for what is prompt and what is context
    let (final_prev_text, final_user_prompt) =
        if prev_text.trim().is_empty() && !preset_prompt.is_empty() {
            // If no text to refine, use user input as text and preset as prompt?
            // Logic copied from timer_tasks:
            // (user_input, preset_prompt)
            (user_input, preset_prompt)
        } else {
            (prev_text, user_input)
        };

    let hwnd_val = hwnd.0 as usize;
    std::thread::spawn(move || {
        let capture_hwnd = HWND(hwnd_val as *mut std::ffi::c_void);

        let (groq_key, gemini_key) = {
            let app = crate::APP.lock().unwrap();
            (
                app.config.api_key.clone(),
                app.config.gemini_api_key.clone(),
            )
        };

        let mut acc_text = String::new();
        let mut first_chunk = true;

        let result = crate::api::refine_text_streaming(
            &groq_key,
            &gemini_key,
            context_data,
            final_prev_text,
            final_user_prompt,
            &model_id,
            &provider,
            streaming,
            {
                let app = crate::APP.lock().unwrap();
                &app.config.ui_language.clone()
            },
            move |chunk| {
                // Check cancellation token? refined_text_streaming should handle it if passed.
                // But here we rely on the callback.

                let mut states = WINDOW_STATES.lock().unwrap();
                if let Some(state) = states.get_mut(&(capture_hwnd.0 as isize)) {
                    if first_chunk {
                        state.is_refining = false; // Stop animation loop??
                                                   // In timer_tasks: state.is_refining = false;
                        first_chunk = false;
                    }

                    // Handle WIPE_SIGNAL
                    if chunk.starts_with(crate::api::WIPE_SIGNAL) {
                        acc_text.clear();
                        acc_text.push_str(&chunk[crate::api::WIPE_SIGNAL.len()..]);
                    } else {
                        acc_text.push_str(chunk);
                    }
                    state.pending_text = Some(acc_text.clone());
                    state.full_text = acc_text.clone();
                }
            },
        );

        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&(capture_hwnd.0 as isize)) {
            state.is_refining = false;
            state.is_streaming_active = false;
            match result {
                Ok(final_text) => {
                    state.full_text = final_text.clone();
                    state.pending_text = Some(final_text);
                }
                Err(e) => {
                    let (lang, model_full_name) = {
                        let app = crate::APP.lock().unwrap();
                        let full_name = crate::model_config::get_model_by_id(&model_id)
                            .map(|m| m.full_name)
                            .unwrap_or_else(|| model_id.to_string());
                        (app.config.ui_language.clone(), full_name)
                    };
                    let err_msg = crate::overlay::utils::get_error_message(
                        &e.to_string(),
                        &lang,
                        Some(&model_full_name),
                    );
                    state.pending_text = Some(err_msg.clone());
                    state.full_text = err_msg;
                }
            }
        }
    });
}

/// Trigger markdown toggle (switch back to plain text)
pub fn trigger_markdown_toggle(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    // Check if we can toggle
    let can_toggle = {
        let states = WINDOW_STATES.lock().unwrap();
        states
            .get(&hwnd_key)
            .map(|s| !s.is_refining && !s.is_streaming_active)
            .unwrap_or(false)
    };

    if !can_toggle {
        return;
    }

    // Toggle the mode in state
    let is_now_markdown = {
        let mut states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            state.is_markdown_mode = !state.is_markdown_mode;
            state.is_markdown_mode
        } else {
            return;
        }
    };

    // Use message passing to update UI on the correct thread
    unsafe {
        if is_now_markdown {
            let _ = PostMessageW(
                Some(hwnd),
                event_handler::misc::WM_CREATE_WEBVIEW,
                WPARAM(0),
                LPARAM(0),
            );
        } else {
            // Switching BACK to plain text
            // We must manually update the window text because the optimized streaming path skipped it!
            let full_text = {
                let states = WINDOW_STATES.lock().unwrap();
                states
                    .get(&hwnd_key)
                    .map(|s| s.full_text.clone())
                    .unwrap_or_default()
            };
            let wide_text = crate::overlay::utils::to_wstring(&full_text);
            let _ = windows::Win32::UI::WindowsAndMessaging::SetWindowTextW(
                hwnd,
                windows::core::PCWSTR(wide_text.as_ptr()),
            );

            let _ = PostMessageW(
                Some(hwnd),
                event_handler::misc::WM_HIDE_MARKDOWN,
                WPARAM(0),
                LPARAM(0),
            );
        }
    }

    // Update canvas to reflect the new state (e.g., active icon state)
    button_canvas::update_window_position(hwnd);
}

/// Trigger speaker/TTS
pub fn trigger_speaker(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    let (full_text, current_tts_id, is_loading) = {
        let states = WINDOW_STATES.lock().unwrap();
        states
            .get(&hwnd_key)
            .map(|s| (s.full_text.clone(), s.tts_request_id, s.tts_loading))
            .unwrap_or_default()
    };

    if is_loading {
        return; // Ignore during loading
    }

    if current_tts_id != 0 && crate::api::tts::TTS_MANAGER.is_speaking(current_tts_id) {
        // Stop speaking
        crate::api::tts::TTS_MANAGER.stop();
        {
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&hwnd_key) {
                state.tts_request_id = 0;
                state.tts_loading = false;
            }
        }
    } else if !full_text.is_empty() {
        // Start speaking
        {
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&hwnd_key) {
                state.tts_loading = true;
            }
        }

        let request_id = crate::api::tts::TTS_MANAGER.speak(&full_text, hwnd_key);
        {
            let mut states = WINDOW_STATES.lock().unwrap();
            if let Some(state) = states.get_mut(&hwnd_key) {
                state.tts_request_id = request_id;
            }
        }
    }

    button_canvas::update_window_position(hwnd);
}

/// Trigger close all windows
pub fn trigger_close_all() {
    let targets: Vec<HWND> = {
        let states = WINDOW_STATES.lock().unwrap();
        states
            .keys()
            .map(|&k| HWND(k as *mut std::ffi::c_void))
            .collect()
    };

    for hwnd in targets {
        unsafe {
            if windows::Win32::UI::WindowsAndMessaging::IsWindow(Some(hwnd)).as_bool() {
                let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
            }
        }
    }
}

/// Trigger drag window (move by delta)
pub fn trigger_drag_window(hwnd: HWND, dx: i32, dy: i32) {
    unsafe {
        let mut rect = windows::Win32::Foundation::RECT::default();
        if windows::Win32::UI::WindowsAndMessaging::GetWindowRect(hwnd, &mut rect).is_ok() {
            let (nx, ny) = (rect.left + dx, rect.top + dy);
            let (nw, nh) = (rect.right - rect.left, rect.bottom - rect.top);

            let _ = windows::Win32::UI::WindowsAndMessaging::SetWindowPos(
                hwnd,
                None,
                nx,
                ny,
                0,
                0,
                windows::Win32::UI::WindowsAndMessaging::SWP_NOSIZE
                    | windows::Win32::UI::WindowsAndMessaging::SWP_NOZORDER
                    | windows::Win32::UI::WindowsAndMessaging::SWP_NOACTIVATE,
            );

            // Update canvas with new position WITHOUT calling GetWindowRect again
            button_canvas::update_window_position_direct(hwnd, nx, ny, nw, nh);
        }
    }
}
</file>

<file path="src/overlay/result/state.rs">
use std::collections::HashMap;
use std::sync::{
    atomic::{AtomicBool, Ordering},
    Arc, Mutex,
};
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::HBITMAP;

// --- DYNAMIC PARTICLES ---
pub struct DustParticle {
    pub x: f32,
    pub y: f32,
    pub vx: f32,
    pub vy: f32,
    pub life: f32, // 1.0 to 0.0
    pub size: f32,
    pub color: u32,
}

#[derive(Clone, Copy, PartialEq)]
pub enum AnimationMode {
    Idle, // Normal mouse movement
}

#[derive(Clone, Copy, PartialEq, Debug)]
pub enum ResizeEdge {
    None,
    Left,
    Right,
    Top,
    Bottom,
    TopLeft,
    TopRight,
    BottomLeft,
    BottomRight,
}

#[derive(Clone, PartialEq)]
pub enum InteractionMode {
    None,
    DraggingWindow,
    DraggingGroup(Vec<(HWND, RECT)>),
    Resizing(ResizeEdge),
    ResizingGroup(Vec<(HWND, RECT)>, ResizeEdge),
}

pub struct CursorPhysics {
    pub x: f32,
    pub y: f32,

    // Spring Physics
    pub current_tilt: f32,  // Current angle in degrees
    pub tilt_velocity: f32, // Angular velocity

    // Deformation
    pub squish_factor: f32, // 1.0 = normal, 0.5 = flat
    pub bristle_bend: f32,  // Lag of bristles

    // Logic
    pub mode: AnimationMode,

    pub particles: Vec<DustParticle>,

    // Clean up
    pub initialized: bool,
    pub needs_cleanup_repaint: bool, // Flag to trigger one final repaint when entering DragOut
}

impl Default for CursorPhysics {
    fn default() -> Self {
        Self {
            x: 0.0,
            y: 0.0,
            current_tilt: 0.0,
            tilt_velocity: 0.0,
            squish_factor: 1.0,
            bristle_bend: 0.0,
            mode: AnimationMode::Idle,

            particles: Vec::new(),
            initialized: false,
            needs_cleanup_repaint: false,
        }
    }
}

// Context for Refinement
#[derive(Clone)]
pub enum RefineContext {
    None,
    Image(Vec<u8>), // PNG Bytes
    Audio(Vec<u8>), // WAV Bytes
}

pub struct WindowState {
    pub is_hovered: bool,
    pub on_copy_btn: bool,
    pub copy_success: bool,
    pub on_edit_btn: bool,
    pub on_undo_btn: bool,
    pub on_redo_btn: bool, // Redo button hover state

    // Edit Mode
    pub is_editing: bool,            // Is the edit box open?
    pub context_data: RefineContext, // Data needed for API call
    pub full_text: String,           // Current full text content

    // Text History for Undo/Redo
    pub text_history: Vec<String>, // Stack of previous text states (for Undo)
    pub redo_history: Vec<String>, // Stack of undone text states (for Redo)

    // Refinement State
    pub is_refining: bool,
    pub animation_offset: f32,

    // Streaming state - true when actively receiving chunks (buttons hidden during streaming)
    pub is_streaming_active: bool,
    // Tracks previous streaming state to detect when streaming ends (for flush logic)
    pub was_streaming_active: bool,

    // Metadata for Refinement/Processing
    pub model_id: String,
    pub provider: String,
    pub streaming_enabled: bool,

    // NEW: Preset Prompt for "Type" mode logic
    pub preset_prompt: String,
    // NEW: Input text currently being refined/processed
    pub input_text: String,

    pub bg_color: u32,
    pub linked_window: Option<HWND>,
    pub physics: CursorPhysics,

    // --- INTERACTION STATE ---
    pub interaction_mode: InteractionMode,
    pub current_resize_edge: ResizeEdge, // Track edge hover state for painting
    pub drag_start_mouse: POINT,
    pub drag_start_window_rect: RECT,
    pub has_moved_significantly: bool, // To distinguish click vs drag

    // --- CACHING & THROTTLING ---
    pub font_cache_dirty: bool,
    pub cached_font_size: i32,
    pub content_bitmap: HBITMAP,
    pub last_w: i32,
    pub last_h: i32,

    // Handle pending updates to avoid flooding Paint
    pub pending_text: Option<String>,

    // Timestamp for throttling text updates (in milliseconds)
    pub last_text_update_time: u32,

    // Resize debounce: timestamp of last resize to skip expensive font calculations during active resize
    pub last_resize_time: u32,

    // Font recalc throttling: timestamp of last font recalculation (for 200ms streaming throttle)
    pub last_font_calc_time: u32,

    pub last_webview_update_time: u32,

    // BACKGROUND CACHING
    pub bg_bitmap: HBITMAP,
    pub bg_w: i32,
    pub bg_h: i32,

    // Graphics mode for refining animation (standard vs minimal)
    pub graphics_mode: String,

    // Cancellation token - set to true when window is destroyed to stop ongoing chains
    pub cancellation_token: Option<Arc<AtomicBool>>,

    // Markdown mode state
    pub is_markdown_mode: bool,      // True when showing markdown view
    pub is_markdown_streaming: bool, // True when using markdown_stream render mode (uses streaming update)
    pub on_markdown_btn: bool,       // Hover state for markdown button

    // Web Browsing State
    pub is_browsing: bool, // True when user has navigated away from initial content
    pub navigation_depth: usize, // How many pages deep from initial content (0 = at result)
    pub max_navigation_depth: usize, // Max depth reached (to know if forward is possible)
    pub on_back_btn: bool, // Hover state for back button
    pub on_forward_btn: bool, // Hover state for forward button

    // Download HTML button state
    pub on_download_btn: bool, // Hover state for download HTML button

    // Speaker/TTS button state
    pub on_speaker_btn: bool, // Hover state for speaker button
    pub tts_request_id: u64,  // Active TTS request ID (0 = not speaking)
    pub tts_loading: bool,    // True when TTS is loading/connecting (shows spinner)
    pub opacity_percent: u8,  // Transparency level (0-100)
}

// SAFETY: Raw pointers are not Send/Sync, but we only use them within the main thread
// This is safe because all access is synchronized via WINDOW_STATES mutex
unsafe impl Send for WindowState {}
unsafe impl Sync for WindowState {}

lazy_static::lazy_static! {
    pub static ref WINDOW_STATES: Mutex<HashMap<isize, WindowState>> = Mutex::new(HashMap::new());
}

pub enum WindowType {
    Primary,
    // Note: Secondary and SecondaryExplicit were removed as dead code
}

pub fn link_windows(hwnd1: HWND, hwnd2: HWND) {
    let mut states = WINDOW_STATES.lock().unwrap();
    if let Some(s1) = states.get_mut(&(hwnd1.0 as isize)) {
        s1.linked_window = Some(hwnd2);
    }
    if let Some(s2) = states.get_mut(&(hwnd2.0 as isize)) {
        s2.linked_window = Some(hwnd1);
    }
}

use windows::Win32::UI::WindowsAndMessaging::{IsWindow, PostMessageW, WM_CLOSE};

/// Close all windows that share the same cancellation token
/// Used in continuous input mode to destroy previous result overlays before spawning new ones
pub fn close_windows_with_token(token: &Arc<AtomicBool>) {
    // Signal the token to stop any ongoing processing
    token.store(true, Ordering::SeqCst);

    // Collect HWNDs that share this token
    let mut to_close = Vec::new();
    {
        let states = WINDOW_STATES.lock().unwrap();
        for (&h_val, state) in states.iter() {
            if let Some(ref t) = state.cancellation_token {
                if Arc::ptr_eq(token, t) {
                    to_close.push(HWND(h_val as *mut std::ffi::c_void));
                }
            }
        }
    }

    // Close them
    for hwnd in to_close {
        unsafe {
            if IsWindow(Some(hwnd)).as_bool() {
                // HIDE IMMEDIATELY so collision detection (which uses IsWindowVisible)
                // will ignore these windows even if they take a moment to be destroyed.
                let _ = windows::Win32::UI::WindowsAndMessaging::ShowWindow(
                    hwnd,
                    windows::Win32::UI::WindowsAndMessaging::SW_HIDE,
                );

                let _ = PostMessageW(
                    Some(hwnd),
                    WM_CLOSE,
                    windows::Win32::Foundation::WPARAM(0),
                    windows::Win32::Foundation::LPARAM(0),
                );
            }
        }
    }
}

/// Get a group of windows that should be moved together (linked or share same token)
pub fn get_window_group(hwnd: HWND) -> Vec<(HWND, RECT)> {
    let mut group = Vec::new();
    let mut token_to_match = None;

    {
        let states = WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get(&(hwnd.0 as isize)) {
            token_to_match = state.cancellation_token.clone();
        }

        // Strategy 1: Cancellation Token (Group Identity)
        if let Some(token) = token_to_match {
            for (&h_val, s) in states.iter() {
                if let Some(ref t) = s.cancellation_token {
                    if std::sync::Arc::ptr_eq(&token, t) {
                        let h = HWND(h_val as *mut std::ffi::c_void);
                        let mut r = RECT::default();
                        unsafe {
                            let _ =
                                windows::Win32::UI::WindowsAndMessaging::GetWindowRect(h, &mut r);
                        }
                        group.push((h, r));
                    }
                }
            }
        }

        // Strategy 2: Linked Window Chain (Fallback/Augment)
        if group.len() <= 1 {
            group.clear();
            let mut visited = std::collections::HashSet::new();
            let mut queue = std::collections::VecDeque::new();

            queue.push_back(hwnd);
            visited.insert(hwnd.0);

            while let Some(current) = queue.pop_front() {
                let mut r = RECT::default();
                unsafe {
                    let _ = windows::Win32::UI::WindowsAndMessaging::GetWindowRect(current, &mut r);
                }
                group.push((current, r));

                if let Some(s) = states.get(&(current.0 as isize)) {
                    if let Some(linked) = s.linked_window {
                        if states.contains_key(&(linked.0 as isize)) && !visited.contains(&linked.0)
                        {
                            visited.insert(linked.0);
                            queue.push_back(linked);
                        }
                    }
                }
            }
        }
    }
    group
}

/// Set the interaction mode for a specific window
pub fn set_window_interaction_mode(hwnd: HWND, mode: InteractionMode) {
    let mut states = WINDOW_STATES.lock().unwrap();
    if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
        state.interaction_mode = mode;
    }
}
</file>

<file path="screen-record/src/components/Timeline.tsx">
import React, { useState } from 'react';
import { VideoSegment, ZoomKeyframe } from '@/types/video';

// Helper function to format time
function formatTime(seconds: number): string {
  const minutes = Math.floor(seconds / 60);
  const remainingSeconds = Math.floor(seconds % 60);
  return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
}

// Helper function to calculate keyframe range
const getKeyframeRange = (
  keyframes: ZoomKeyframe[],
  index: number
): { rangeStart: number; rangeEnd: number } => {
  const keyframe = keyframes[index];
  const prevKeyframe = index > 0 ? keyframes[index - 1] : null;
  const rangeStart =
    prevKeyframe && keyframe.time - prevKeyframe.time <= 1.0
      ? prevKeyframe.time
      : Math.max(0, keyframe.time - 1.0);
  return { rangeStart, rangeEnd: keyframe.time };
};

interface TimelineProps {
  duration: number;
  currentTime: number;
  segment: VideoSegment | null;
  thumbnails: string[];
  timelineRef: React.RefObject<HTMLDivElement>;
  videoRef: React.RefObject<HTMLVideoElement>;
  editingKeyframeId: number | null;
  editingTextId: string | null;
  setCurrentTime: (time: number) => void;
  setEditingKeyframeId: (id: number | null) => void;
  setEditingTextId: (id: string | null) => void;
  setActivePanel: (panel: 'zoom' | 'background' | 'cursor' | 'text') => void;
  setSegment: (segment: VideoSegment | null) => void;
  onSeek?: (time: number) => void;
}

const TimeMarkers: React.FC<{ duration: number }> = ({ duration }) => (
  <div className="absolute left-0 right-0 bottom-[-24px] flex justify-between text-xs text-[#d7dadc] z-40 pointer-events-none px-1">
    {Array.from({ length: 11 }).map((_, i) => {
      const time = (duration * i) / 10;
      return (
        <div key={i} className="flex flex-col items-center">
          <span className="mb-1">{formatTime(time)}</span>
          <div className="h-2 w-0.5 bg-[#d7dadc]/20" />
        </div>
      );
    })}
  </div>
);

const VideoTrack: React.FC<{ segment: VideoSegment; duration: number; thumbnails: string[] }> = ({
  segment,
  duration,
  thumbnails
}) => (
  <div className="absolute inset-0">
    {/* Background track */}
    <div className="absolute inset-0 bg-[#272729] rounded-lg overflow-hidden">
      {/* Thumbnails */}
      <div className="absolute inset-0 flex gap-[2px]">
        {thumbnails.map((thumbnail, index) => (
          <div
            key={index}
            className="h-full flex-shrink-0"
            style={{
              width: `calc(${100 / thumbnails.length}% - 2px)`,
              backgroundImage: `url(${thumbnail})`,
              backgroundSize: 'cover',
              backgroundPosition: 'center',
              opacity: 0.5
            }}
          />
        ))}
      </div>
    </div>

    {/* Trimmed sections */}
    <div
      className="absolute inset-y-0 left-0 bg-black/50 rounded-l-lg"
      style={{ width: `${(segment.trimStart / duration) * 100}%` }}
    />
    <div
      className="absolute inset-y-0 right-0 bg-black/50 rounded-r-lg"
      style={{ width: `${((duration - segment.trimEnd) / duration) * 100}%` }}
    />

    {/* Active section */}
    <div
      className="absolute inset-y-0 bg-white/2 border border-white/20"
      style={{
        left: `${(segment.trimStart / duration) * 100}%`,
        right: `${((duration - segment.trimEnd) / duration) * 100}%`
      }}
    />
  </div>
);

const ZoomKeyframes: React.FC<{
  segment: VideoSegment;
  duration: number;
  editingKeyframeId: number | null;
  onKeyframeClick: (time: number, index: number) => void;
  onKeyframeDragStart: (index: number) => void;
}> = ({ segment, duration, editingKeyframeId, onKeyframeClick, onKeyframeDragStart }) => (
  <div className="absolute inset-x-0 h-full">
    {segment.zoomKeyframes.map((keyframe, index) => {
      const active = editingKeyframeId === index;
      const { rangeStart, rangeEnd } = getKeyframeRange(segment.zoomKeyframes, index);

      return (
        <div key={index}>
          {/* Gradient background for zoom range */}
          <div
            className={`absolute h-full cursor-pointer transition-colors border-r border-[#0079d3] ${active ? "opacity-100" : "opacity-80"
              }`}
            style={{
              left: `${(rangeStart / duration) * 100}%`,
              width: `${((rangeEnd - rangeStart) / duration) * 100}%`,
              zIndex: 20,
              background: `linear-gradient(90deg, rgba(0, 121, 211, 0.1) 0%, rgba(0, 121, 211, ${0.1 + (keyframe.zoomFactor - 1) * 0.3
                }) 100%)`
            }}
          />
          {/* Keyframe marker with label */}
          <div
            className="absolute cursor-pointer group"
            style={{
              left: `${(keyframe.time / duration) * 100}%`,
              transform: "translateX(-50%)",
              top: "-40px",
              height: "64px"
            }}
            onClick={(e) => {
              e.stopPropagation();
              onKeyframeClick(keyframe.time, index);
            }}
            onMouseDown={(e) => {
              e.stopPropagation();
              onKeyframeDragStart(index);
            }}
          >
            <div className="relative flex flex-col items-center">
              <div
                className={`px-2 py-1 mb-1 rounded-full text-xs font-medium whitespace-nowrap ${active ? "bg-[#0079d3] text-white" : "bg-[#0079d3]/20 text-[#0079d3]"
                  }`}
              >
                {Math.round((keyframe.zoomFactor - 1) * 100)}%
              </div>
              <div
                className={`w-3 h-3 bg-[#0079d3] rounded-full hover:scale-125 transition-transform ${active ? "ring-2 ring-white" : ""
                  }`}
              />
              <div className="w-[1px] h-10 bg-[#0079d3]/30 group-hover:bg-[#0079d3]/50" />
            </div>
          </div>
        </div>
      );
    })}
  </div>
);

const ZoomInfluenceTrack: React.FC<{
  segment: VideoSegment;
  duration: number;
  onUpdatePoints: (points: { time: number; value: number }[]) => void;
}> = ({ segment, duration, onUpdatePoints }) => {
  const points = segment.zoomInfluencePoints || [];
  const draggingIdxRef = React.useRef<number | null>(null);
  const pointsRef = React.useRef(points);
  pointsRef.current = points;

  const [hoveredIdx, setHoveredIdx] = useState<number | null>(null);

  // Handle Point Deletion
  React.useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      if ((e.key === 'Delete' || e.key === 'Backspace') && hoveredIdx !== null) {
        // Don't delete start/end anchors if they are the only ones left (length 2)
        // But actually we force start/end to exist. User can't delete index 0 or length-1
        // unless we want to allow re-creating them? 
        // Requirement: "start and end handle must be able to be adjusted... not generating new handle" indicates anchors are permanent.
        if (hoveredIdx === 0 || hoveredIdx === points.length - 1) {
          if (points.length === 2) {
            onUpdatePoints([]);
          }
          return;
        }

        const newPoints = [...points];
        newPoints.splice(hoveredIdx, 1);
        onUpdatePoints(newPoints);
        setHoveredIdx(null);
      }
    };
    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [hoveredIdx, points, onUpdatePoints]);

  // Generate SVG Path
  const generatePath = () => {
    if (points.length === 0) return `M 0 10 L 100 10`;

    // We visualize based on current points state (even if unsorted during drag for instant feedback)
    // But curve generator expects sorted inputs to draw correctly left-to-right?
    // Actually, if points are unsorted, drawing lines between them in array-order might be messy.
    // So for visualization, we MUST sort a copy.
    const sortedPoints = [...points].sort((a, b) => a.time - b.time);

    let d = "";
    // Sample 100 points
    const steps = 100;
    for (let i = 0; i <= steps; i++) {
      const t = (i / steps) * duration;

      // Inline getValueAt logic with sortedPoints
      let v = 1.0;
      const idx = sortedPoints.findIndex(p => p.time >= t);
      if (idx === -1) v = sortedPoints[sortedPoints.length - 1].value;
      else if (idx === 0) v = sortedPoints[0].value;
      else {
        const p1 = sortedPoints[idx - 1];
        const p2 = sortedPoints[idx];
        const ratio = (t - p1.time) / (p2.time - p1.time);
        const cosT = (1 - Math.cos(ratio * Math.PI)) / 2;
        v = p1.value * (1 - cosT) + p2.value * cosT;
      }

      const y = 8 + (1 - v) * 32;
      const x = i;
      d += `${i === 0 ? 'M' : 'L'} ${x} ${y} `;
    }
    return d;
  };

  const handleMouseDown = (e: React.MouseEvent<HTMLDivElement>) => {
    const rect = e.currentTarget.getBoundingClientRect();
    const clickX = e.clientX - rect.left;
    const clickY = e.clientY - rect.top;

    const time = (clickX / rect.width) * duration;
    let val = 1 - (clickY - 8) / 32;
    val = Math.max(0, Math.min(1, val));

    const hitThresholdX = 14;
    let newPoints = [...points];

    let activeIdx = newPoints.findIndex(p => {
      const px = (p.time / duration) * rect.width;
      const py = 8 + (1 - p.value) * 32;
      return Math.abs(px - clickX) < hitThresholdX && Math.abs(py - clickY) < hitThresholdX;
    });

    if (activeIdx !== -1) {
      e.stopPropagation();
    }

    if (activeIdx === -1) {
      const sorted = [...newPoints].sort((a, b) => a.time - b.time);

      let expectedV = 1.0;

      if (sorted.length > 0) {
        const idx = sorted.findIndex(p => p.time >= time);
        if (idx === -1) expectedV = sorted[sorted.length - 1].value;
        else if (idx === 0) expectedV = sorted[0].value;
        else {
          const p1 = sorted[idx - 1];
          const p2 = sorted[idx];
          const ratio = (time - p1.time) / (p2.time - p1.time);
          const cosT = (1 - Math.cos(ratio * Math.PI)) / 2;
          expectedV = p1.value * (1 - cosT) + p2.value * cosT;
        }
      }

      const expectedY = 8 + (1 - expectedV) * 32;

      if (Math.abs(clickY - expectedY) > 10 && newPoints.length > 0) {
        return;
      }

      e.stopPropagation();

      if (newPoints.length === 0) {
        newPoints.push({ time: 0, value: 1 });
        newPoints.push({ time: duration, value: 1 });
      }

      const p = { time, value: expectedV };
      newPoints.push(p);
      newPoints.sort((a, b) => a.time - b.time);
      activeIdx = newPoints.indexOf(p);
      onUpdatePoints(newPoints);
    }

    draggingIdxRef.current = activeIdx;

    const mm = (me: MouseEvent) => {
      if (draggingIdxRef.current === null) return;

      const mx = me.clientX - rect.left;
      const my = me.clientY - rect.top;

      let t = (mx / rect.width) * duration;
      t = Math.max(0, Math.min(duration, t));

      let v = 1 - (my - 8) / 32;
      v = Math.max(0, Math.min(1, v));

      const next = [...pointsRef.current];
      if (draggingIdxRef.current !== null && next[draggingIdxRef.current]) {
        // Lock start/end time
        if (draggingIdxRef.current === 0) t = 0;
        if (draggingIdxRef.current === next.length - 1 && next.length > 1) t = duration;

        next[draggingIdxRef.current] = { time: t, value: v };
        onUpdatePoints(next);
      }
    };

    const mu = () => {
      window.removeEventListener('mousemove', mm);
      window.removeEventListener('mouseup', mu);
      draggingIdxRef.current = null;
      // Final sort to keep consistency
      const sorted = [...pointsRef.current].sort((a, b) => a.time - b.time);
      onUpdatePoints(sorted);
    };

    window.addEventListener('mousemove', mm);
    window.addEventListener('mouseup', mu);
  };

  return (
    <div
      className="absolute inset-x-0 top-0 h-12 z-20 pointer-events-auto"
      onMouseDown={handleMouseDown}
    >
      <svg className="w-full h-full overflow-visible" preserveAspectRatio="none" viewBox="0 0 100 48">
        {/* Guide Lines */}
        <line x1="0" y1="8" x2="100" y2="8" stroke="rgba(255,255,255,0.1)" vectorEffect="non-scaling-stroke" />
        <line x1="0" y1="40" x2="100" y2="40" stroke="rgba(255,255,255,0.1)" vectorEffect="non-scaling-stroke" />

        <path d={generatePath()} fill="none" stroke="#4ade80" strokeWidth="2" vectorEffect="non-scaling-stroke" />
      </svg>
      {points.map((p, i) => (
        <div
          key={i}
          className={`absolute w-3 h-3 bg-white border-2 border-[#4ade80] rounded-full transform -translate-x-1/2 -translate-y-1/2 cursor-pointer transition-transform shadow-sm ${hoveredIdx === i ? 'scale-125 ring-2 ring-red-500/50' : 'hover:scale-125'
            }`}
          style={{
            left: `${(p.time / duration) * 100}%`,
            top: `${8 + (1 - p.value) * 32}px`
          }}
          onMouseEnter={() => setHoveredIdx(i)}
          onMouseLeave={() => setHoveredIdx(null)}
          onMouseDown={(e) => {
            e.stopPropagation();
            draggingIdxRef.current = i;

            const rect = e.currentTarget.parentElement!.getBoundingClientRect();

            const mm = (me: MouseEvent) => {
              const mx = me.clientX - rect.left;
              const my = me.clientY - rect.top;

              let t = (mx / rect.width) * duration;
              t = Math.max(0, Math.min(duration, t));

              if (i === 0) t = 0;
              if (i === pointsRef.current.length - 1 && pointsRef.current.length > 1) t = duration;

              let v = 1 - (my - 8) / 32;
              v = Math.max(0, Math.min(1, v));

              const next = [...pointsRef.current];
              if (draggingIdxRef.current !== null && next[draggingIdxRef.current]) {
                next[draggingIdxRef.current] = { time: t, value: v };
                onUpdatePoints(next);
              }
            };

            const mu = () => {
              window.removeEventListener('mousemove', mm);
              window.removeEventListener('mouseup', mu);
              draggingIdxRef.current = null;
              const sorted = [...pointsRef.current].sort((a, b) => a.time - b.time);
              onUpdatePoints(sorted);
            };

            window.addEventListener('mousemove', mm);
            window.addEventListener('mouseup', mu);
          }}
        />
      ))}
    </div>
  );
};

const TrimHandles: React.FC<{
  segment: VideoSegment;
  duration: number;
  onTrimDragStart: (type: 'start' | 'end') => void;
}> = ({ segment, duration, onTrimDragStart }) => (
  <>
    <div
      className="absolute -top-2 -bottom-2 w-4 cursor-col-resize z-30 group"
      style={{ left: `calc(${(segment.trimStart / duration) * 100}% - 8px)` }}
      onMouseDown={() => onTrimDragStart('start')}
    >
      <div className="absolute inset-y-0 w-2 bg-white/80 group-hover:bg-[#0079d3] group-hover:w-2.5 transition-all rounded-full left-1/2 transform -translate-x-1/2" />
      <div className="absolute inset-y-2 left-1/2 transform -translate-x-1/2 flex flex-col justify-center gap-1">
        <div className="w-0.5 h-1 bg-black/40 rounded-full" />
        <div className="w-0.5 h-1 bg-black/40 rounded-full" />
      </div>
    </div>

    <div
      className="absolute -top-2 -bottom-2 w-4 cursor-col-resize z-30 group"
      style={{ left: `calc(${(segment.trimEnd / duration) * 100}% - 8px)` }}
      onMouseDown={() => onTrimDragStart('end')}
    >
      <div className="absolute inset-y-0 w-2 bg-white/80 group-hover:bg-[#0079d3] group-hover:w-2.5 transition-all rounded-full left-1/2 transform -translate-x-1/2" />
      <div className="absolute inset-y-2 left-1/2 transform -translate-x-1/2 flex flex-col justify-center gap-1">
        <div className="w-0.5 h-1 bg-black/40 rounded-full" />
        <div className="w-0.5 h-1 bg-black/40 rounded-full" />
      </div>
    </div>
  </>
);

const Playhead: React.FC<{ currentTime: number; duration: number }> = ({ currentTime, duration }) => (
  <div
    className="absolute top-0 bottom-[-24px] flex flex-col items-center pointer-events-none z-50"
    style={{
      left: `${(currentTime / duration) * 100}%`,
      transform: 'translateX(-50%)'
    }}
  >
    <div className="w-4 h-3 bg-red-500 rounded-t" />
    <div className="w-0.5 flex-1 bg-red-500" />
  </div>
);

const TextTrack: React.FC<{
  segment: VideoSegment;
  duration: number;
  editingTextId: string | null;
  isDraggingTextStart: boolean;
  isDraggingTextEnd: boolean;
  onTextClick: (id: string) => void;
  onHandleDragStart: (id: string, type: 'start' | 'end' | 'body', offset?: number) => void;
}> = ({ segment, duration, editingTextId, isDraggingTextStart, isDraggingTextEnd, onTextClick, onHandleDragStart }) => (
  <div className="absolute inset-x-0 bottom-14 h-8 bg-[#272729] rounded-lg z-30">
    {segment.textSegments?.map((text) => (
      <div
        key={text.id}
        onMouseDown={(e) => {
          e.stopPropagation();
          const rect = e.currentTarget.parentElement!.getBoundingClientRect();
          const clickX = e.clientX - rect.left;
          const clickTime = (clickX / rect.width) * duration;
          onHandleDragStart(text.id, 'body', clickTime - text.startTime);
        }}
        onClick={(e) => {
          e.stopPropagation();
          // Prevent click when dragging
          if (!isDraggingTextStart && !isDraggingTextEnd) {
            onTextClick(text.id);
          }
        }}
        className={`absolute h-full cursor-move group ${editingTextId === text.id ? 'bg-[#0079d3]/40 ring-1 ring-[#0079d3]' : 'bg-[#0079d3]/20 hover:bg-[#0079d3]/25'
          }`}
        style={{
          left: `${(text.startTime / duration) * 100}%`,
          width: `${((text.endTime - text.startTime) / duration) * 100}%`
        }}
      >
        <div className="absolute inset-y-0 flex items-center justify-center w-full">
          <div className="px-2 truncate text-xs font-medium text-[#d7dadc]">
            {text.text}
          </div>
        </div>
        {/* Drag handles */}
        <div
          className="absolute inset-y-0 left-0 w-1 cursor-ew-resize group-hover:bg-[#0079d3]"
          onMouseDown={(e) => {
            e.stopPropagation();
            onHandleDragStart(text.id, 'start');
          }}
        />
        <div
          className="absolute inset-y-0 right-0 w-1 cursor-ew-resize group-hover:bg-[#0079d3]"
          onMouseDown={(e) => {
            e.stopPropagation();
            onHandleDragStart(text.id, 'end');
          }}
        />
      </div>
    ))}
  </div>
);

export const Timeline: React.FC<TimelineProps> = ({
  duration,
  currentTime,
  segment,
  thumbnails,
  timelineRef,
  videoRef,
  editingKeyframeId,
  editingTextId,
  setCurrentTime,
  setEditingKeyframeId,
  setEditingTextId,
  setActivePanel,
  setSegment,
  onSeek
}) => {
  const [isDraggingTrimStart, setIsDraggingTrimStart] = useState(false);
  const [isDraggingTrimEnd, setIsDraggingTrimEnd] = useState(false);
  const [isDraggingTextStart, setIsDraggingTextStart] = useState(false);
  const [isDraggingTextEnd, setIsDraggingTextEnd] = useState(false);
  const [isDraggingTextBody, setIsDraggingTextBody] = useState(false);
  const [textDragOffset, setTextDragOffset] = useState(0);
  const [draggingTextId, setDraggingTextId] = useState<string | null>(null);
  const [isDraggingZoom, setIsDraggingZoom] = useState(false);
  const [draggingZoomIdx, setDraggingZoomIdx] = useState<number | null>(null);
  const [isDraggingSeek, setIsDraggingSeek] = useState(false);

  const handleSeek = (clientX: number) => {
    const timeline = timelineRef.current;
    if (!timeline || !segment) return;

    const rect = timeline.getBoundingClientRect();
    const x = Math.max(0, Math.min(clientX - rect.left, rect.width));
    const time = (x / rect.width) * duration;

    // Use controller's seek method to properly sync video and audio
    if (onSeek) {
      onSeek(time);
    } else if (videoRef.current && Math.abs(videoRef.current.currentTime - time) > 0.05) {
      // Fallback to direct video manipulation
      videoRef.current.currentTime = time;
      setCurrentTime(time);
    }
  };

  const handleZoomDragStart = (index: number) => {
    setIsDraggingZoom(true);
    setDraggingZoomIdx(index);
    setEditingKeyframeId(index);
    setActivePanel("zoom");
  };

  const handleZoomDrag = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!isDraggingZoom || draggingZoomIdx === null || !segment) return;

    const timeline = timelineRef.current;
    if (!timeline) return;

    const rect = timeline.getBoundingClientRect();
    const x = Math.max(0, Math.min(e.clientX - rect.left, rect.width));
    const newTime = (x / rect.width) * duration;

    // Check bounds against neighbors
    const prevKeyframe = draggingZoomIdx > 0 ? segment.zoomKeyframes[draggingZoomIdx - 1] : null;
    const nextKeyframe = draggingZoomIdx < segment.zoomKeyframes.length - 1 ? segment.zoomKeyframes[draggingZoomIdx + 1] : null;

    let finalTime = newTime;
    if (prevKeyframe && finalTime <= prevKeyframe.time + 0.1) finalTime = prevKeyframe.time + 0.1;
    if (nextKeyframe && finalTime >= nextKeyframe.time - 0.1) finalTime = nextKeyframe.time - 0.1;

    setSegment({
      ...segment,
      zoomKeyframes: segment.zoomKeyframes.map((kf, i) =>
        i === draggingZoomIdx ? { ...kf, time: finalTime } : kf
      )
    });

    if (videoRef.current) {
      videoRef.current.currentTime = finalTime;
      setCurrentTime(finalTime);
    }
  };





  const handleTrimDragStart = (type: 'start' | 'end') => {
    if (type === 'start') setIsDraggingTrimStart(true);
    else setIsDraggingTrimEnd(true);
  };

  const handleTrimDrag = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!isDraggingTrimStart && !isDraggingTrimEnd) return;

    const timeline = timelineRef.current;
    if (!timeline || !segment) return;

    const rect = timeline.getBoundingClientRect();
    const x = Math.max(0, Math.min(e.clientX - rect.left, rect.width));
    const percent = x / rect.width;
    const newTime = percent * duration;

    if (isDraggingTrimStart) {
      const newTrimStart = Math.min(newTime, segment.trimEnd - 0.1);
      setSegment({
        ...segment,
        trimStart: Math.max(0, newTrimStart)
      });
      if (videoRef.current) {
        videoRef.current.currentTime = newTime;
      }
    }

    if (isDraggingTrimEnd) {
      const newTrimEnd = Math.max(newTime, segment.trimStart + 0.1);
      setSegment({
        ...segment,
        trimEnd: Math.min(duration, newTrimEnd)
      });
      if (videoRef.current) {
        videoRef.current.currentTime = newTime;
      }
    }
  };

  const handleTrimDragEnd = () => {
    setIsDraggingTrimStart(false);
    setIsDraggingTrimEnd(false);
  };

  const handleTextDrag = (e: React.MouseEvent<HTMLDivElement>) => {
    if (!isDraggingTextStart && !isDraggingTextEnd && !isDraggingTextBody || !draggingTextId || !segment) return;

    const timeline = timelineRef.current;
    if (!timeline) return;

    const rect = timeline.getBoundingClientRect();
    const x = Math.max(0, Math.min(e.clientX - rect.left, rect.width));
    const newTime = (x / rect.width) * duration;

    setSegment({
      ...segment,
      textSegments: segment.textSegments.map(text => {
        if (text.id !== draggingTextId) return text;

        if (isDraggingTextStart) {
          return {
            ...text,
            startTime: Math.min(Math.max(0, newTime), text.endTime - 0.1)
          };
        } else if (isDraggingTextEnd) {
          return {
            ...text,
            endTime: Math.max(Math.min(duration, newTime), text.startTime + 0.1)
          };
        } else if (isDraggingTextBody) {
          const currentDuration = text.endTime - text.startTime;
          let newStart = newTime - textDragOffset;

          // Clamp to stay within timeline bounds
          if (newStart < 0) newStart = 0;
          if (newStart + currentDuration > duration) newStart = duration - currentDuration;

          return {
            ...text,
            startTime: newStart,
            endTime: newStart + currentDuration
          };
        }
        return text;
      })
    });
  };

  return (
    <div className="relative h-48">
      <div
        ref={timelineRef}
        className="h-32 bg-[#1a1a1b] rounded-lg cursor-pointer relative mt-12"
        onMouseDown={(e) => {
          if (isDraggingTrimStart || isDraggingTrimEnd || isDraggingTextStart || isDraggingTextEnd || isDraggingTextBody || isDraggingZoom) return;
          setIsDraggingSeek(true);
          handleSeek(e.clientX);
        }}
        onMouseMove={(e) => {
          handleTrimDrag(e);
          handleTextDrag(e);
          handleZoomDrag(e);
          if (isDraggingSeek) {
            handleSeek(e.clientX);
          }
        }}
        onMouseUp={() => {
          handleTrimDragEnd();
          setIsDraggingTextStart(false);
          setIsDraggingTextEnd(false);
          setIsDraggingTextBody(false);
          setIsDraggingZoom(false);
          setDraggingZoomIdx(null);
          setDraggingTextId(null);
          setIsDraggingSeek(false);
        }}
        onMouseLeave={() => {
          handleTrimDragEnd();
          setIsDraggingTextStart(false);
          setIsDraggingTextEnd(false);
          setIsDraggingTextBody(false);
          setIsDraggingZoom(false);
          setDraggingZoomIdx(null);
          setDraggingTextId(null);
          setIsDraggingSeek(false);
        }}


      >
        <TimeMarkers duration={duration} />
        {segment && (
          <>
            {/* Render Influence Track on top of video track if path exists meaning Smart Zoom is ON */}
            {segment.smoothMotionPath && segment.smoothMotionPath.length > 0 && (
              <ZoomInfluenceTrack
                segment={segment}
                duration={duration}
                onUpdatePoints={(points) => {
                  const newSegment = { ...segment!, zoomInfluencePoints: points };
                  if (points.length === 0) {
                    newSegment.smoothMotionPath = [];
                  }
                  setSegment(newSegment);
                }}
              />
            )}

            {/* Base track with thumbnails */}
            <div className="absolute inset-x-0 bottom-0 h-12">
              <VideoTrack
                segment={segment}
                duration={duration}
                thumbnails={thumbnails}
              />

              <div className="absolute inset-0">
                <ZoomKeyframes
                  segment={segment}
                  duration={duration}
                  editingKeyframeId={editingKeyframeId}
                  onKeyframeClick={(time, index) => {
                    if (videoRef.current) {
                      videoRef.current.currentTime = time;
                      setCurrentTime(time);
                      setEditingKeyframeId(index);
                      setActivePanel("zoom");
                    }
                  }}
                  onKeyframeDragStart={handleZoomDragStart}
                />
              </div>

              {/* Trim handles */}
              <TrimHandles
                segment={segment}
                duration={duration}
                onTrimDragStart={handleTrimDragStart}
              />
            </div>

            {/* Text track */}
            <TextTrack
              segment={segment}
              duration={duration}
              editingTextId={editingTextId}
              isDraggingTextStart={isDraggingTextStart}
              isDraggingTextEnd={isDraggingTextEnd}
              onTextClick={(id) => {
                setEditingTextId(id);
                setActivePanel('text');
              }}
              onHandleDragStart={(id, type, offset) => {
                setDraggingTextId(id);
                if (type === 'start') setIsDraggingTextStart(true);
                else if (type === 'end') setIsDraggingTextEnd(true);
                else if (type === 'body') {
                  setIsDraggingTextBody(true);
                  if (offset !== undefined) setTextDragOffset(offset);
                }
              }}
            />
          </>
        )}

        {/* Playhead */}
        <Playhead
          currentTime={currentTime}
          duration={duration}
        />
      </div>

      {/* Duration display */}
      <div className="absolute bottom-0 left-1/2 transform -translate-x-1/2 text-sm text-[#818384]">
        {segment ? formatTime(segment.trimEnd - segment.trimStart) : formatTime(duration)}
      </div>
    </div>
  );
};
</file>

<file path="screen-record/src/lib/projectManager.ts">
import { Project } from '@/types/video';

class ProjectManager {
  private readonly STORAGE_KEY = 'screen-demo-projects';
  private limit = 50;

  setLimit(newLimit: number) {
    this.limit = newLimit;
    this.pruneProjects();
  }

  getLimit(): number {
    return this.limit;
  }

  private async pruneProjects() {
    const projects = await this.getProjects();
    if (projects.length > this.limit) {
      const projectsToDelete = projects.splice(this.limit);
      for (const p of projectsToDelete) {
        await this.deleteVideoBlob(p.id);
        await this.deleteAudioBlob(p.id);
      }
      localStorage.setItem(this.STORAGE_KEY, JSON.stringify(projects));
    }
  }

  async saveProject(project: Omit<Project, 'id' | 'createdAt' | 'lastModified'>): Promise<Project> {
    const projects = await this.getProjects();

    const newProject: Project = {
      ...project,
      id: crypto.randomUUID(),
      createdAt: Date.now(),
      lastModified: Date.now(),
    };

    // Store video blob separately using IndexedDB
    await this.saveVideoBlob(newProject.id, newProject.videoBlob);
    if (newProject.audioBlob) {
      await this.saveAudioBlob(newProject.id, newProject.audioBlob);
    }

    // Store project metadata without the blob in localStorage
    const projectMeta = { ...newProject };
    delete (projectMeta as any).videoBlob;
    delete (projectMeta as any).audioBlob;

    projects.unshift(projectMeta);

    // Limit projects
    if (projects.length > this.limit) {
      const projectsToDelete = projects.splice(this.limit);
      for (const p of projectsToDelete) {
        await this.deleteVideoBlob(p.id);
        await this.deleteAudioBlob(p.id);
      }
    }

    localStorage.setItem(this.STORAGE_KEY, JSON.stringify(projects));

    return newProject;
  }

  async getProjects(): Promise<Omit<Project, 'videoBlob' | 'audioBlob'>[]> {
    const projectsJson = localStorage.getItem(this.STORAGE_KEY);
    return projectsJson ? JSON.parse(projectsJson) : [];
  }

  async loadProject(id: string): Promise<Project | null> {
    const projects = await this.getProjects();
    const project = projects.find(p => p.id === id);

    if (!project) return null;

    // Load video blob from IndexedDB
    const videoBlob = await this.loadVideoBlob(id);
    if (!videoBlob) return null;

    const audioBlob = await this.loadAudioBlob(id);

    return { ...project, videoBlob, audioBlob: audioBlob || undefined };
  }

  async deleteProject(id: string): Promise<void> {
    const projects = await this.getProjects();
    const filteredProjects = projects.filter(p => p.id !== id);
    localStorage.setItem(this.STORAGE_KEY, JSON.stringify(filteredProjects));

    // Delete video blob from IndexedDB
    await this.deleteVideoBlob(id);
    await this.deleteAudioBlob(id);
  }

  async updateProject(id: string, updates: Partial<Omit<Project, 'id' | 'createdAt' | 'lastModified'>>): Promise<void> {
    const projects = await this.getProjects();
    const projectIndex = projects.findIndex(p => p.id === id);

    if (projectIndex === -1) return;

    // Store video blob if updated
    if (updates.videoBlob) {
      await this.saveVideoBlob(id, updates.videoBlob);
    }

    if (updates.audioBlob) {
      await this.saveAudioBlob(id, updates.audioBlob);
    }

    // Update project metadata
    const updatedProject = {
      ...projects[projectIndex],
      ...updates,
      lastModified: Date.now()
    };
    delete (updatedProject as any).videoBlob;
    delete (updatedProject as any).audioBlob;

    projects[projectIndex] = updatedProject;
    localStorage.setItem(this.STORAGE_KEY, JSON.stringify(projects));
  }

  // IndexedDB helpers for video blob storage
  private async saveVideoBlob(id: string, blob: Blob): Promise<void> {
    const db = await this.openDB();
    const tx = db.transaction('videos', 'readwrite');
    const store = tx.objectStore('videos');
    await store.put(blob, id);
  }

  private async loadVideoBlob(id: string): Promise<Blob | null> {
    const db = await this.openDB();
    const tx = db.transaction('videos', 'readonly');
    const store = tx.objectStore('videos');

    return new Promise((resolve, reject) => {
      const request = store.get(id);
      request.onerror = () => reject(request.error);
      request.onsuccess = () => resolve(request.result as Blob);
    });
  }

  private async deleteVideoBlob(id: string): Promise<void> {
    const db = await this.openDB();
    const tx = db.transaction('videos', 'readwrite');
    const store = tx.objectStore('videos');
    await store.delete(id);
  }

  private async openDB(): Promise<IDBDatabase> {
    return new Promise((resolve, reject) => {
      const request = indexedDB.open('ScreenDemoDB', 2);

      request.onerror = () => reject(request.error);
      request.onsuccess = () => resolve(request.result);

      request.onupgradeneeded = (event) => {
        const db = (event.target as IDBOpenDBRequest).result;
        if (!db.objectStoreNames.contains('videos')) {
          db.createObjectStore('videos');
        }
        if (!db.objectStoreNames.contains('audio')) {
          db.createObjectStore('audio');
        }
      };
    });
  }
  // Audio blob storage helpers
  private async saveAudioBlob(id: string, blob: Blob): Promise<void> {
    const db = await this.openDB();
    const tx = db.transaction('audio', 'readwrite');
    const store = tx.objectStore('audio');
    await store.put(blob, id);
  }

  private async loadAudioBlob(id: string): Promise<Blob | null> {
    const db = await this.openDB();
    const tx = db.transaction('audio', 'readonly');
    const store = tx.objectStore('audio');

    return new Promise((resolve) => {
      const request = store.get(id);
      request.onerror = () => resolve(null);
      request.onsuccess = () => resolve(request.result as Blob);
    });
  }

  private async deleteAudioBlob(id: string): Promise<void> {
    const db = await this.openDB();
    const tx = db.transaction('audio', 'readwrite');
    const store = tx.objectStore('audio');
    await store.delete(id);
  }
}

export const projectManager = new ProjectManager();
</file>

<file path="src/gui/app/types.rs">
use crate::config::Config;
use crate::gui::settings_ui::node_graph::ChainNode;
use crate::gui::settings_ui::ViewMode;
use crate::updater::{UpdateStatus, Updater};
use auto_launch::AutoLaunch;
use eframe::egui;
use egui_snarl::Snarl;
use std::sync::atomic::AtomicBool;
use std::sync::mpsc::Receiver;
use std::sync::{Arc, Mutex};
use tray_icon::{
    menu::{CheckMenuItem, Menu, MenuEvent, MenuItem},
    TrayIcon, TrayIconEvent,
};

pub const MOD_ALT: u32 = 0x0001;
pub const MOD_CONTROL: u32 = 0x0002;
pub const MOD_SHIFT: u32 = 0x0004;
pub const MOD_WIN: u32 = 0x0008;

lazy_static::lazy_static! {
    pub static ref RESTORE_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
}

pub enum UserEvent {
    Tray(TrayIconEvent),
    Menu(MenuEvent),
}

pub struct SettingsApp {
    pub(crate) config: Config,
    pub(crate) app_state_ref: Arc<Mutex<crate::AppState>>,
    pub(crate) search_query: String,
    pub(crate) tray_icon: Option<TrayIcon>,
    pub(crate) _tray_menu: Menu,

    pub(crate) tray_settings_item: MenuItem, // Store for dynamic i18n update
    pub(crate) tray_quit_item: MenuItem,     // Store for dynamic i18n update
    pub(crate) tray_favorite_bubble_item: CheckMenuItem, // Store for favorite bubble toggle
    pub(crate) last_ui_language: String,     // Track language to detect changes
    pub(crate) tray_retry_timer: f64,        // Timer for lazy tray icon creation
    pub(crate) event_rx: Receiver<UserEvent>,
    pub(crate) is_quitting: bool,
    pub(crate) run_at_startup: bool,
    pub(crate) auto_launcher: Option<AutoLaunch>,
    pub(crate) show_api_key: bool,
    pub(crate) show_gemini_api_key: bool,
    pub(crate) show_openrouter_api_key: bool,
    pub(crate) show_cerebras_api_key: bool,
    pub(crate) icon_dark: Option<egui::TextureHandle>,
    pub(crate) icon_light: Option<egui::TextureHandle>,

    pub(crate) view_mode: ViewMode,
    pub(crate) recording_hotkey_for_preset: Option<usize>,
    pub(crate) hotkey_conflict_msg: Option<String>,
    pub(crate) recording_sr_hotkey: bool,
    pub(crate) splash: Option<crate::gui::splash::SplashScreen>,
    pub(crate) fade_in_start: Option<f64>,

    // 0 = Init/Offscreen, 1 = Move Sent, 2 = Visible Sent
    pub(crate) startup_stage: u8,

    pub(crate) cached_monitors: Vec<String>,
    pub(crate) cached_audio_devices: Arc<Mutex<Vec<(String, String)>>>,

    pub(crate) updater: Option<Updater>,
    pub(crate) update_rx: Receiver<UpdateStatus>,
    pub(crate) update_status: UpdateStatus,

    // --- NEW FIELDS ---
    pub(crate) current_admin_state: bool, // Track runtime admin status
    pub(crate) last_effective_theme_dark: bool, // Effective dark mode (considering System/Dark/Light)
    pub(crate) last_system_theme_dark: bool,    // Track Windows system theme for icon switching
    pub(crate) theme_check_timer: f64,          // Timer for polling system theme
    // ------------------

    // --- TIP UI STATE ---
    pub(crate) current_tip_idx: usize,
    pub(crate) tip_timer: f64, // Time when the current tip started showing
    pub(crate) tip_fade_state: f32, // 0.0 (Invisible) -> 1.0 (Visible)
    pub(crate) tip_is_fading_in: bool,
    pub(crate) show_tips_modal: bool,
    pub(crate) rng_seed: u32,

    // --- NODE GRAPH STATE ---
    pub(crate) snarl: Option<Snarl<ChainNode>>,
    pub(crate) last_edited_preset_idx: Option<usize>,
    // ------------------------

    // --- USAGE MODAL STATE ---
    pub(crate) show_usage_modal: bool,
    // --- DROP OVERLAY STATE ---
    pub(crate) drop_overlay_fade: f32,
    // --- TTS SETTINGS MODAL STATE ---
    pub(crate) show_tts_modal: bool,
    pub(crate) show_tools_modal: bool,
    // --------------------

    // --- FAVORITE BUBBLE STATE TRACKING ---
    pub(crate) last_bubble_enabled: bool,
    pub(crate) last_has_favorites: bool,
    // --------------------------------------

    // --- DOWNLOAD MANAGER ---
    pub(crate) download_manager: crate::gui::settings_ui::download_manager::DownloadManager,

    // --- ARGUMENT HANDLING ---
    pub(crate) pending_file_path: Option<std::path::PathBuf>,
}
</file>

<file path="src/gui/settings_ui/download_manager/detection.rs">
use super::types::CookieBrowser;
use std::collections::HashSet;
#[cfg(windows)]
use std::os::windows::process::CommandExt;
use std::path::PathBuf;
use std::process::Command;

pub fn detect_installed_browsers() -> Vec<CookieBrowser> {
    let mut found = vec![CookieBrowser::None];
    let mut found_set = HashSet::new();
    found_set.insert(CookieBrowser::None);

    let add_if_new = |browser: CookieBrowser,
                      f_list: &mut Vec<CookieBrowser>,
                      f_set: &mut HashSet<CookieBrowser>| {
        if !f_set.contains(&browser) {
            f_set.insert(browser.clone());
            f_list.push(browser);
        }
    };

    // Map Browser -> Executable Name(s) to query in Registry "App Paths"
    let registry_targets = [
        (CookieBrowser::Chrome, "chrome.exe"),
        (CookieBrowser::Firefox, "firefox.exe"),
        (CookieBrowser::Edge, "msedge.exe"),
        (CookieBrowser::Brave, "brave.exe"),
        (CookieBrowser::Opera, "opera.exe"), // or launcher.exe
        (CookieBrowser::Vivaldi, "vivaldi.exe"),
        (CookieBrowser::Chromium, "chromium.exe"),
        (CookieBrowser::Whale, "whale.exe"),
    ];

    // 1. Scan "App Paths" (HKLM and HKCU) - Most robust way to find installed apps by exe name
    for (browser, exe_name) in &registry_targets {
        // Check HKLM
        let hklm_exists = check_registry_key("HKLM", exe_name);
        if hklm_exists {
            add_if_new(browser.clone(), &mut found, &mut found_set);
            continue;
        }
        // Check HKCU
        let hkcu_exists = check_registry_key("HKCU", exe_name);
        if hkcu_exists {
            add_if_new(browser.clone(), &mut found, &mut found_set);
        }
    }

    // 2. Scan StartMenuInternet (Existing Logic - Good for defaults)
    let mut cmd = Command::new("reg");
    cmd.args(&["query", "HKLM\\SOFTWARE\\Clients\\StartMenuInternet"]);
    #[cfg(windows)]
    cmd.creation_flags(0x08000000);

    let output = cmd.output();

    if let Ok(out) = output {
        let stdout = String::from_utf8_lossy(&out.stdout);
        for line in stdout.lines() {
            let lower = line.to_lowercase();
            if lower.contains("chrome") {
                add_if_new(CookieBrowser::Chrome, &mut found, &mut found_set);
            } else if lower.contains("firefox") {
                add_if_new(CookieBrowser::Firefox, &mut found, &mut found_set);
            } else if lower.contains("edge") {
                add_if_new(CookieBrowser::Edge, &mut found, &mut found_set);
            } else if lower.contains("brave") {
                add_if_new(CookieBrowser::Brave, &mut found, &mut found_set);
            } else if lower.contains("opera") {
                add_if_new(CookieBrowser::Opera, &mut found, &mut found_set);
            } else if lower.contains("vivaldi") {
                add_if_new(CookieBrowser::Vivaldi, &mut found, &mut found_set);
            } else if lower.contains("chromium") {
                add_if_new(CookieBrowser::Chromium, &mut found, &mut found_set);
            } else if lower.contains("whale") {
                add_if_new(CookieBrowser::Whale, &mut found, &mut found_set);
            }
        }
    }

    // 3. Fallback to common file paths (Manual Fallback)
    let mut check_exe = |browser: CookieBrowser, paths: &[&str]| {
        if found_set.contains(&browser) {
            return;
        }
        for sub_path in paths {
            let roots = [
                std::env::var("ProgramFiles").ok(),
                std::env::var("ProgramFiles(x86)").ok(),
                std::env::var("LocalAppData").ok(),
            ];
            for root in roots.iter().flatten() {
                if PathBuf::from(root).join(sub_path).exists() {
                    add_if_new(browser.clone(), &mut found, &mut found_set);
                    return;
                }
            }
        }
    };

    check_exe(
        CookieBrowser::Chrome,
        &["Google\\Chrome\\Application\\chrome.exe"],
    );
    check_exe(CookieBrowser::Firefox, &["Mozilla Firefox\\firefox.exe"]);
    check_exe(
        CookieBrowser::Edge,
        &["Microsoft\\Edge\\Application\\msedge.exe"],
    );
    check_exe(
        CookieBrowser::Brave,
        &["BraveSoftware\\Brave-Browser\\Application\\brave.exe"],
    );
    check_exe(
        CookieBrowser::Opera,
        &["Opera\\launcher.exe", "Programs\\Opera\\launcher.exe"],
    );
    check_exe(
        CookieBrowser::Vivaldi,
        &["Vivaldi\\Application\\vivaldi.exe"],
    );

    found
}

fn check_registry_key(root: &str, exe_name: &str) -> bool {
    let key = format!(
        "{}\\Software\\Microsoft\\Windows\\CurrentVersion\\App Paths\\{}",
        root, exe_name
    );
    // We just check if the key exists by querying the default value
    let mut cmd = Command::new("reg");
    cmd.args(&["query", &key, "/ve"]); // /ve queries "Default" matches
    #[cfg(windows)]
    cmd.creation_flags(0x08000000);

    let output = cmd.output();

    match output {
        Ok(o) => o.status.success(),
        Err(_) => false,
    }
}
</file>

<file path="src/gui/settings_ui/download_manager/mod.rs">
pub mod detection;
pub mod persistence;
pub mod run;
pub mod types;
pub mod ui;
pub mod utils;

pub use self::types::{CookieBrowser, DownloadState, DownloadType, InstallStatus, UpdateStatus};
use std::path::PathBuf;
use std::sync::atomic::AtomicBool;
use std::sync::{Arc, Mutex};

pub struct DownloadManager {
    pub show_window: bool,
    pub ffmpeg_status: Arc<Mutex<InstallStatus>>,
    pub ytdlp_status: Arc<Mutex<InstallStatus>>,
    pub ffmpeg_update_status: Arc<Mutex<UpdateStatus>>,
    pub ytdlp_update_status: Arc<Mutex<UpdateStatus>>,
    pub ffmpeg_version: Arc<Mutex<Option<String>>>,
    pub ytdlp_version: Arc<Mutex<Option<String>>>,
    pub is_checking_updates: Arc<AtomicBool>,
    pub logs: Arc<Mutex<Vec<String>>>,
    pub bin_dir: PathBuf,

    // Downloader State
    pub input_url: String,
    pub download_state: Arc<Mutex<DownloadState>>,

    // Config
    pub custom_download_path: Option<PathBuf>,
    pub cancel_flag: Arc<AtomicBool>,

    // Advanced Options
    pub use_metadata: bool,
    pub use_sponsorblock: bool,
    pub use_subtitles: Arc<Mutex<bool>>,
    pub use_playlist: bool,
    pub cookie_browser: CookieBrowser,
    pub available_browsers: Vec<CookieBrowser>,

    // Analysis State
    pub available_formats: Arc<Mutex<Vec<String>>>, // e.g. "1080p", "720p"
    pub selected_format: Option<String>,
    pub available_subs_manual: Arc<Mutex<Vec<String>>>, // From 'subtitles'
    pub download_type: DownloadType,
    pub selected_subtitle: Option<String>,
    pub is_analyzing: Arc<Mutex<bool>>,
    pub last_url_analyzed: String,
    pub analysis_error: Arc<Mutex<Option<String>>>,
    pub last_input_change: f64, // timestamp
    pub initial_focus_set: bool,
    pub show_error_log: bool,
}

impl DownloadManager {
    pub fn new() -> Self {
        let bin_dir = dirs::data_local_dir()
            .unwrap_or(PathBuf::from("."))
            .join("screen-goated-toolbox")
            .join("bin");

        let available_browsers = detection::detect_installed_browsers();

        // Load Config
        let config = persistence::load_config();

        // Determine initial browser: Config > First Detected > None
        // But only if config browser is still available or None?
        // For simplicity, prefer config. If config is default (None) and we have browsers, maybe default to detected?
        // Actually, load_config() returns Default (None) if file missing.
        // Logic:
        // 1. If config file existed and loaded, respect it (even if strictly None).
        // 2. If config file missing (default), try auto-detect.
        // To implement (2), we check if config path exists *inside* load_config, but here we just get a struct.
        // Let's refine `load_config` or just check: if `cookie_browser` is None, we *might* want to auto-select,
        // UNLESS user explicitly set it to None.
        // But if user explicitly saved "None", how do we know?
        // Maybe just trust config. If it's the first run, persistent file doesn't exist.
        // We can check if file exists in `new`.

        let config_exists = persistence::get_config_path().exists();
        let default_browser = if config_exists {
            config.cookie_browser.clone()
        } else {
            CookieBrowser::None
        };

        let manager = Self {
            show_window: false,
            ffmpeg_status: Arc::new(Mutex::new(InstallStatus::Checking)),
            ytdlp_status: Arc::new(Mutex::new(InstallStatus::Checking)),
            ffmpeg_update_status: Arc::new(Mutex::new(UpdateStatus::Idle)),
            ytdlp_update_status: Arc::new(Mutex::new(UpdateStatus::Idle)),
            ffmpeg_version: Arc::new(Mutex::new(None)),
            ytdlp_version: Arc::new(Mutex::new(None)),
            is_checking_updates: Arc::new(AtomicBool::new(false)),
            logs: Arc::new(Mutex::new(Vec::new())),
            bin_dir: bin_dir.clone(),
            input_url: String::new(),
            download_state: Arc::new(Mutex::new(DownloadState::Idle)),
            custom_download_path: config.custom_download_path,
            cancel_flag: Arc::new(AtomicBool::new(false)),
            use_metadata: config.use_metadata,
            use_sponsorblock: config.use_sponsorblock,
            use_subtitles: Arc::new(Mutex::new(config.use_subtitles)),
            use_playlist: config.use_playlist,
            cookie_browser: default_browser,
            available_browsers,

            available_formats: Arc::new(Mutex::new(Vec::new())),
            selected_format: None,
            available_subs_manual: Arc::new(Mutex::new(Vec::new())),
            download_type: config.download_type,
            selected_subtitle: config.selected_subtitle,
            is_analyzing: Arc::new(Mutex::new(false)),
            last_url_analyzed: String::new(),
            analysis_error: Arc::new(Mutex::new(None)),
            last_input_change: 0.0,
            initial_focus_set: false,
            show_error_log: false,
        };

        manager.check_status();
        manager
    }

    pub fn save_settings(&self) {
        let config = persistence::DownloadManagerConfig {
            custom_download_path: self.custom_download_path.clone(),
            use_metadata: self.use_metadata,
            use_sponsorblock: self.use_sponsorblock,
            use_subtitles: *self.use_subtitles.lock().unwrap(),
            use_playlist: self.use_playlist,
            cookie_browser: self.cookie_browser.clone(),
            download_type: self.download_type.clone(),
            selected_subtitle: self.selected_subtitle.clone(),
        };
        persistence::save_config(&config);
    }
}
</file>

<file path="src/gui/settings_ui/download_manager/ui.rs">
use super::types::{CookieBrowser, DownloadState, DownloadType, InstallStatus};
use crate::gui::locale::LocaleText;
use eframe::egui;
use std::path::PathBuf;

use super::DownloadManager;

impl DownloadManager {
    pub fn render(&mut self, ctx: &egui::Context, text: &LocaleText) {
        if !self.show_window {
            self.initial_focus_set = false;
            return;
        }

        let mut open = true;
        egui::Window::new(text.download_feature_title)
            .open(&mut open)
            .collapsible(false)
            .resizable(false)
            .default_width(400.0)
            .pivot(egui::Align2::CENTER_CENTER)
            .default_pos(ctx.input(|i| i.viewport_rect()).center())
            .show(ctx, |ui| {
                // Dependency Check
                let ffmpeg_ok = matches!(
                    *self.ffmpeg_status.lock().unwrap(),
                    InstallStatus::Installed
                );
                let ytdlp_ok =
                    matches!(*self.ytdlp_status.lock().unwrap(), InstallStatus::Installed);

                if !ffmpeg_ok || !ytdlp_ok {
                    ui.label(text.download_deps_missing);

                    // yt-dlp section
                    ui.group(|ui| {
                        ui.horizontal(|ui| {
                            ui.label(text.download_deps_ytdlp);
                            let status = self.ytdlp_status.lock().unwrap().clone();
                            match status {
                                InstallStatus::Checking => {
                                    ui.spinner();
                                }
                                InstallStatus::Missing | InstallStatus::Error(_) => {
                                    if ui.button(text.download_deps_download_btn).clicked() {
                                        self.start_download_ytdlp();
                                    }
                                    if let InstallStatus::Error(e) = status {
                                        ui.colored_label(egui::Color32::RED, e);
                                    }
                                }
                                InstallStatus::Downloading(p) => {
                                    ui.label(format!("{:.0}%", p * 100.0));
                                    ui.add(egui::ProgressBar::new(p).desired_width(120.0));
                                    if ui.button(text.download_cancel_btn).clicked() {
                                        self.cancel_download();
                                    }
                                }
                                InstallStatus::Extracting => {
                                    ui.label(text.download_status_extracting);
                                    ui.spinner();
                                    if ui.button(text.download_cancel_btn).clicked() {
                                        self.cancel_download();
                                    }
                                }
                                InstallStatus::Installed => {
                                    ui.label(text.download_status_ready);
                                }
                            }
                        });
                    });

                    // ffmpeg section
                    ui.group(|ui| {
                        ui.horizontal(|ui| {
                            ui.label(text.download_deps_ffmpeg);
                            let status = self.ffmpeg_status.lock().unwrap().clone();
                            match status {
                                InstallStatus::Checking => {
                                    ui.spinner();
                                }
                                InstallStatus::Missing | InstallStatus::Error(_) => {
                                    if ui.button(text.download_deps_download_btn).clicked() {
                                        self.start_download_ffmpeg();
                                    }
                                    if let InstallStatus::Error(e) = status {
                                        ui.colored_label(egui::Color32::RED, e);
                                    }
                                }
                                InstallStatus::Downloading(p) => {
                                    ui.label(format!("{:.0}%", p * 100.0));
                                    ui.add(egui::ProgressBar::new(p).desired_width(120.0));
                                    if ui.button(text.download_cancel_btn).clicked() {
                                        self.cancel_download();
                                    }
                                }
                                InstallStatus::Extracting => {
                                    ui.label(text.download_status_extracting);
                                    ui.spinner();
                                    if ui.button(text.download_cancel_btn).clicked() {
                                        self.cancel_download();
                                    }
                                }
                                InstallStatus::Installed => {
                                    ui.label(text.download_status_ready);
                                }
                            }
                        });
                    });
                } else {
                    // MAIN DOWNLOADER UI - COMPACT & NO SCROLLBAR
                    // Use a Frame with inner margin to keep things tidy but maximize space
                    egui::Frame::default().inner_margin(8.0).show(ui, |ui| {
                        // --- FOLDER & SETTINGS ---
                        ui.horizontal(|ui| {
                            // Compact Path:  📂 ...\Downloads  [⚙]
                            ui.label(egui::RichText::new("📂").size(14.0));

                            let current_path =
                                self.custom_download_path.clone().unwrap_or_else(|| {
                                    dirs::download_dir().unwrap_or(PathBuf::from("."))
                                });
                            let path_str = current_path
                                .file_name()
                                .and_then(|n| n.to_str())
                                .unwrap_or("...");

                            // Truncate if too long (visual only)
                            ui.label(
                                egui::RichText::new(format!("...\\{}", path_str))
                                    .strong()
                                    .color(ctx.style().visuals.weak_text_color()),
                            );

                            ui.with_layout(
                                egui::Layout::right_to_left(egui::Align::Center),
                                |ui| {
                                    ui.menu_button("⚙", |ui| {
                                        if ui.button(text.download_change_folder_btn).clicked() {
                                            self.change_download_folder();
                                            ui.close();
                                        }

                                        ui.separator();

                                        // Delete Dependencies
                                        let (ytdlp_size, ffmpeg_size) = self.get_dependency_sizes();
                                        let del_btn_text = text
                                            .download_delete_deps_btn
                                            .replacen("{}", &ytdlp_size, 1)
                                            .replacen("{}", &ffmpeg_size, 1);

                                        if ui
                                            .button(
                                                egui::RichText::new(del_btn_text)
                                                    .color(egui::Color32::RED),
                                            )
                                            .clicked()
                                        {
                                            self.delete_dependencies();
                                            ui.close();
                                        }
                                    });
                                },
                            );
                        });

                        ui.add_space(8.0);

                        // --- URL INPUT ---
                        // Compact Label + Input
                        ui.label(egui::RichText::new(text.download_url_label).strong());
                        let response = ui.add(
                            egui::TextEdit::singleline(&mut self.input_url)
                                .hint_text("https://youtube.com/watch?v=...")
                                .desired_width(f32::INFINITY),
                        );

                        // Focus on first open
                        if !self.initial_focus_set {
                            response.request_focus();
                            self.initial_focus_set = true;
                        }

                        if response.changed() {
                            self.last_input_change = ctx.input(|i| i.time);
                            self.available_formats.lock().unwrap().clear();
                            self.selected_format = None;
                        }

                        // Auto-analyze Logic
                        let time_since_edit = ctx.input(|i| i.time) - self.last_input_change;
                        let is_analyzing = *self.is_analyzing.lock().unwrap();
                        let url_changed = self.input_url.trim() != self.last_url_analyzed;

                        // Trigger analysis
                        if time_since_edit > 0.8
                            && url_changed
                            && !self.input_url.trim().is_empty()
                            && !is_analyzing
                        {
                            self.start_analysis();
                        }

                        ui.add_space(8.0);

                        // --- FORMAT & QUALITY (ONE LINE) ---
                        // [Radio Video] [Radio Audio] | [Quality: Best v] (or Spinner)
                        ui.horizontal(|ui| {
                            ui.label(egui::RichText::new(text.download_format_label).strong());
                            if ui
                                .radio_value(&mut self.download_type, DownloadType::Video, "Video")
                                .changed()
                            {
                                self.save_settings();
                            }
                            if ui
                                .radio_value(&mut self.download_type, DownloadType::Audio, "Audio")
                                .changed()
                            {
                                self.save_settings();
                            }

                            // Spacer
                            ui.add_space(10.0);

                            // Quality UI
                            if self.download_type == DownloadType::Video {
                                let formats = self.available_formats.lock().unwrap().clone();
                                let error = self.analysis_error.lock().unwrap().clone();

                                if is_analyzing {
                                    ui.spinner();
                                    ui.label(
                                        egui::RichText::new(text.download_scanning_label)
                                            .italics()
                                            .size(11.0),
                                    );
                                } else if !formats.is_empty() {
                                    ui.label(text.download_quality_label_text);
                                    let best_text = text.download_quality_best.to_string();
                                    let current_val = self
                                        .selected_format
                                        .clone()
                                        .unwrap_or_else(|| best_text.clone());

                                    egui::ComboBox::from_id_salt("quality_combo")
                                        .selected_text(&current_val)
                                        .width(100.0) // Keep it compact
                                        .show_ui(ui, |ui| {
                                            ui.selectable_value(
                                                &mut self.selected_format,
                                                None,
                                                &best_text,
                                            );
                                            for fmt in formats {
                                                ui.selectable_value(
                                                    &mut self.selected_format,
                                                    Some(fmt.clone()),
                                                    &fmt,
                                                );
                                            }
                                        });

                                    // Subtitle Selection
                                    {
                                        let use_sub = *self.use_subtitles.lock().unwrap();
                                        if use_sub {
                                            let manual_subs =
                                                self.available_subs_manual.lock().unwrap().clone();

                                            if !manual_subs.is_empty() {
                                                ui.add_space(8.0);
                                                ui.label(text.download_subtitle_label);
                                                let auto_text =
                                                    text.download_subtitle_auto.to_string();
                                                let current_sub = self
                                                    .selected_subtitle
                                                    .clone()
                                                    .unwrap_or_else(|| auto_text.clone());

                                                egui::ComboBox::from_id_salt("subtitle_combo")
                                                    .selected_text(&current_sub)
                                                    .width(70.0)
                                                    .show_ui(ui, |ui| {
                                                        ui.label(
                                                            egui::RichText::new(
                                                                text.download_subs_found_header,
                                                            )
                                                            .small()
                                                            .weak(),
                                                        );
                                                        ui.separator();

                                                        if ui
                                                            .selectable_value(
                                                                &mut self.selected_subtitle,
                                                                None,
                                                                &auto_text,
                                                            )
                                                            .clicked()
                                                        {
                                                            self.save_settings();
                                                        }

                                                        for sub in manual_subs {
                                                            if ui
                                                                .selectable_label(
                                                                    self.selected_subtitle
                                                                        == Some(sub.clone()),
                                                                    &sub,
                                                                )
                                                                .clicked()
                                                            {
                                                                self.selected_subtitle =
                                                                    Some(sub.clone());
                                                                self.save_settings();
                                                            }
                                                        }
                                                    });
                                            } else {
                                                // No manual subs found
                                                ui.add_space(8.0);
                                                ui.colored_label(
                                                    egui::Color32::GRAY,
                                                    egui::RichText::new(
                                                        text.download_subs_none_found,
                                                    )
                                                    .small()
                                                    .italics(),
                                                );
                                            }
                                        }
                                    }
                                } else if let Some(_) = error {
                                    // Error will be shown in status, just show generic fail here or nothing to keep compact
                                    ui.colored_label(egui::Color32::RED, "❌");
                                }
                            }
                        });

                        ui.add_space(8.0);

                        // --- ADVANCED OPTIONS (Compact) ---
                        ui.collapsing(
                            egui::RichText::new(text.download_advanced_header).strong(),
                            |ui| {
                                egui::Grid::new("adv_options_grid")
                                    .num_columns(2)
                                    .spacing([10.0, 4.0])
                                    .show(ui, |ui| {
                                        if ui
                                            .checkbox(
                                                &mut self.use_metadata,
                                                text.download_opt_metadata,
                                            )
                                            .changed()
                                        {
                                            self.save_settings();
                                        }
                                        if ui
                                            .checkbox(
                                                &mut self.use_sponsorblock,
                                                text.download_opt_sponsorblock,
                                            )
                                            .changed()
                                        {
                                            self.save_settings();
                                        }
                                        ui.end_row();

                                        {
                                            let mut use_sub = self.use_subtitles.lock().unwrap();
                                            if ui
                                                .checkbox(&mut use_sub, text.download_opt_subtitles)
                                                .changed()
                                            {
                                                drop(use_sub);
                                                self.save_settings();
                                            }
                                        }
                                        if ui
                                            .checkbox(
                                                &mut self.use_playlist,
                                                text.download_opt_playlist,
                                            )
                                            .changed()
                                        {
                                            self.save_settings();
                                        }
                                        ui.end_row();
                                    });

                                ui.add_space(4.0);
                                ui.horizontal(|ui| {
                                    ui.label(text.download_opt_cookies);
                                    egui::ComboBox::from_id_salt("cookie_browser_combo")
                                        .selected_text(match &self.cookie_browser {
                                            CookieBrowser::None => {
                                                text.download_no_cookie_option.to_string()
                                            }
                                            other => other.to_string(),
                                        })
                                        .width(140.0)
                                        .show_ui(ui, |ui| {
                                            for browser in &self.available_browsers {
                                                let label = match browser {
                                                    CookieBrowser::None => {
                                                        text.download_no_cookie_option.to_string()
                                                    }
                                                    other => other.to_string(),
                                                };
                                                if ui
                                                    .selectable_value(
                                                        &mut self.cookie_browser,
                                                        browser.clone(),
                                                        label,
                                                    )
                                                    .changed()
                                                {
                                                    self.save_settings();
                                                }
                                            }
                                        });
                                });
                            },
                        );

                        ui.add_space(15.0);

                        // --- ACTION AREA ---
                        // Define common button logic
                        let state = self.download_state.lock().unwrap().clone();
                        let is_analyzing = *self.is_analyzing.lock().unwrap();

                        let (btn_text, btn_color) = if is_analyzing {
                            (
                                text.download_scan_ignore_btn,
                                egui::Color32::from_rgb(200, 100, 0),
                            )
                        } else {
                            (
                                text.download_start_btn,
                                egui::Color32::from_rgb(0, 100, 200),
                            )
                        };

                        let draw_download_btn = |ui: &mut egui::Ui| {
                            let btn = egui::Button::new(
                                egui::RichText::new(btn_text)
                                    .heading()
                                    .color(egui::Color32::WHITE),
                            )
                            .min_size(egui::vec2(ui.available_width(), 36.0)) // Slightly smaller height
                            .fill(btn_color);
                            ui.add(btn).clicked()
                        };

                        match &state {
                            DownloadState::Idle | DownloadState::Error(_) => {
                                if draw_download_btn(ui) {
                                    if !self.input_url.is_empty() {
                                        // Reset logs on new start
                                        self.logs.lock().unwrap().clear();
                                        self.show_error_log = false;
                                        self.start_media_download(
                                            text.download_progress_info_fmt.to_string(),
                                        );
                                    }
                                }
                                if let DownloadState::Error(err) = &state {
                                    ui.add_space(5.0);
                                    ui.label(
                                        egui::RichText::new(format!(
                                            "{} {}",
                                            text.download_status_error, err
                                        ))
                                        .color(egui::Color32::RED)
                                        .small(),
                                    );

                                    // Toggle Log Button
                                    let btn_text = if self.show_error_log {
                                        text.download_hide_log_btn
                                    } else {
                                        text.download_show_log_btn
                                    };

                                    if ui
                                        .button(egui::RichText::new(btn_text).size(10.0))
                                        .clicked()
                                    {
                                        self.show_error_log = !self.show_error_log;
                                    }

                                    // Show Log Area
                                    if self.show_error_log {
                                        ui.add_space(4.0);
                                        egui::Frame::group(ui.style())
                                            .fill(if ctx.style().visuals.dark_mode {
                                                egui::Color32::from_black_alpha(100)
                                            } else {
                                                egui::Color32::from_gray(240)
                                            })
                                            .show(ui, |ui| {
                                                let logs = self.logs.lock().unwrap();
                                                let mut full_log_str = logs.join("\n");
                                                egui::ScrollArea::vertical()
                                                    .max_height(120.0)
                                                    .show(ui, |ui| {
                                                        ui.add(
                                                            egui::TextEdit::multiline(
                                                                &mut full_log_str,
                                                            )
                                                            .font(egui::FontId::monospace(10.0))
                                                            .desired_width(f32::INFINITY)
                                                            .interactive(true)
                                                            .lock_focus(false),
                                                        );
                                                    });
                                            });
                                    }
                                }
                            }
                            DownloadState::Finished(path, _msg) => {
                                // "Finished" View
                                ui.vertical_centered(|ui| {
                                    let success_color = if ctx.style().visuals.dark_mode {
                                        egui::Color32::GREEN
                                    } else {
                                        egui::Color32::from_rgb(0, 128, 0)
                                    };

                                    ui.label(
                                        egui::RichText::new(text.download_status_finished)
                                            .color(success_color)
                                            .heading(),
                                    );

                                    // Compact file info
                                    if let Some(name) = path.file_name() {
                                        let display_name = name
                                            .to_string_lossy()
                                            .replace("\u{29F8}", "/") // Big Solidus
                                            .replace("\u{FF0F}", "/") // Fullwidth Solidus
                                            .replace("\u{FF1A}", ":") // Fullwidth Colon
                                            .replace("\u{FF1F}", "?") // Fullwidth Question Mark
                                            .replace("\u{FF0A}", "*") // Fullwidth Asterisk
                                            .replace("\u{FF1C}", "<") // Fullwidth Less-Than
                                            .replace("\u{FF1E}", ">") // Fullwidth Greater-Than
                                            .replace("\u{FF5C}", "|") // Fullwidth Vertical Line
                                            .replace("\u{FF02}", "\""); // Fullwidth Quotation Mark
                                        ui.label(egui::RichText::new(display_name).small());
                                    }

                                    ui.add_space(4.0);
                                    ui.horizontal(|ui| {
                                        let enabled = path.components().next().is_some();
                                        if ui
                                            .add_enabled(
                                                enabled,
                                                egui::Button::new(text.download_open_file_btn),
                                            )
                                            .clicked()
                                        {
                                            let _ = open::that(&path);
                                        }
                                        if ui
                                            .add_enabled(
                                                enabled,
                                                egui::Button::new(text.download_open_folder_btn),
                                            )
                                            .clicked()
                                        {
                                            if let Some(parent) = path.parent() {
                                                let _ = open::that(parent);
                                            } else {
                                                let _ = open::that(&path);
                                            }
                                        }
                                    });

                                    ui.add_space(8.0);
                                });

                                // Consistent Download Button at bottom
                                if draw_download_btn(ui) {
                                    if !self.input_url.is_empty() {
                                        self.start_media_download(
                                            text.download_progress_info_fmt.to_string(),
                                        );
                                    }
                                }
                            }
                            DownloadState::Downloading(progress, msg) => {
                                ui.vertical_centered(|ui| {
                                    ui.add_space(10.0);
                                    if msg == "Starting..." {
                                        ui.label(text.download_status_starting);
                                    } else {
                                        let clean_msg =
                                            msg.replace("[download]", "").trim().to_string();
                                        ui.label(egui::RichText::new(clean_msg).small());
                                    }
                                    ui.add_space(5.0);
                                    ui.add(egui::ProgressBar::new(*progress).animate(true));
                                });
                            }
                        }
                    });
                }
            });

        self.show_window = open;
    }
}
</file>

<file path="src/gui/settings_ui/sidebar.rs">
use super::ViewMode;
use crate::config::{Config, Preset};
use crate::gui::icons::{draw_icon_static, icon_button_sized, Icon};
use crate::gui::locale::LocaleText;
use eframe::egui;

/// Get localized preset name for default presets (public for reuse in other modules)
pub fn get_localized_preset_name(preset_id: &str, lang_code: &str) -> String {
    // Special handling for 101 preset to ensure it matches
    if preset_id == "preset_101_on_this" {
        return match lang_code {
            "vi" => "Tất tần tật".to_string(),
            "ko" => "이것의 모든 것".to_string(),
            _ => "101 on this".to_string(),
        };
    }

    match (preset_id, lang_code) {
        // Vietnamese
        ("preset_translate", "vi") => "Dịch vùng".to_string(),
        ("preset_extract_retranslate", "vi") => "Dịch vùng (CHUẨN)".to_string(),
        ("preset_translate_auto_paste", "vi") => "Dịch vùng (Tự dán)".to_string(),
        ("preset_translate_retranslate", "vi") => "Dịch vùng+Dịch lại".to_string(),
        ("preset_extract_retrans_retrans", "vi") => "D.vùng (CHUẨN)+D.lại".to_string(),
        ("preset_ocr", "vi") => "Lấy text từ ảnh".to_string(),
        ("preset_quick_screenshot", "vi") => "Chụp MH nhanh".to_string(),
        ("preset_quick_screenshot", "ko") => "빠른 스크린샷".to_string(),
        ("preset_quick_screenshot", _) => "Quick screenshot".to_string(),
        ("preset_ocr_read", "vi") => "Đọc vùng này".to_string(),
        ("preset_summarize", "vi") => "Tóm tắt vùng".to_string(),
        ("preset_desc", "vi") => "Mô tả ảnh".to_string(),
        ("preset_ask_image", "vi") => "Hỏi về ảnh".to_string(),
        ("preset_translate_select", "vi") => "Dịch".to_string(),
        ("preset_translate_arena", "vi") => "Dịch (Arena)".to_string(),
        ("preset_read_aloud", "vi") => "Đọc to".to_string(),
        ("preset_trans_retrans_select", "vi") => "Dịch+ Dịch lại".to_string(),
        ("preset_select_translate_replace", "vi") => "Dịch và Thay".to_string(),
        ("preset_fix_grammar", "vi") => "Sửa ngữ pháp".to_string(),
        ("preset_rephrase", "vi") => "Viết lại".to_string(),
        ("preset_make_formal", "vi") => "Chuyên nghiệp hóa".to_string(),
        ("preset_explain", "vi") => "Giải thích".to_string(),
        ("preset_ask_text", "vi") => "Hỏi về text...".to_string(),
        ("preset_edit_as_follows", "vi") => "Sửa như sau:".to_string(),
        ("preset_extract_table", "vi") => "Trích bảng".to_string(),
        ("preset_qr_scanner", "vi") => "Quét mã QR".to_string(),
        ("preset_trans_retrans_typing", "vi") => "Dịch+Dịch lại (Tự gõ)".to_string(),
        ("preset_ask_ai", "vi") => "Hỏi AI".to_string(),
        ("preset_internet_search", "vi") => "Tìm kiếm internet".to_string(),
        ("preset_make_game", "vi") => "Tạo con game".to_string(),
        ("preset_transcribe", "vi") => "Lời nói thành văn".to_string(),
        ("preset_fix_pronunciation", "vi") => "Chỉnh phát âm".to_string(),
        ("preset_study_language", "vi") => "Học ngoại ngữ".to_string(),
        ("preset_transcribe_retranslate", "vi") => "Trả lời ng.nc.ngoài 1".to_string(),
        ("preset_quicker_foreigner_reply", "vi") => "Trả lời ng.nc.ngoài 2".to_string(),
        ("preset_fact_check", "vi") => "Kiểm chứng thông tin".to_string(),
        ("preset_omniscient_god", "vi") => "Thần Trí tuệ".to_string(),
        // Moved from below to ensure priority/cleanliness
        ("preset_realtime_audio_translate", "vi") => "Dịch cabin".to_string(),
        ("preset_quick_ai_question", "vi") => "Hỏi nhanh AI".to_string(),
        ("preset_voice_search", "vi") => "Nói để search".to_string(),
        ("preset_hang_image", "vi") => "Treo ảnh".to_string(),
        ("preset_hang_text", "vi") => "Treo text".to_string(),
        ("preset_quick_note", "vi") => "Note nhanh".to_string(),
        ("preset_quick_record", "vi") => "Thu âm nhanh".to_string(),
        ("preset_record_device", "vi") => "Thu âm máy".to_string(),
        ("preset_continuous_writing_online", "vi") => "Viết liên tục".to_string(),
        ("preset_transcribe_english_offline", "vi") => "Chép lời TA".to_string(),
        // MASTER presets - Vietnamese
        ("preset_image_master", "vi") => "Ảnh MASTER".to_string(),
        ("preset_text_select_master", "vi") => "Bôi MASTER".to_string(),
        ("preset_text_type_master", "vi") => "Gõ MASTER".to_string(),
        ("preset_audio_mic_master", "vi") => "Mic MASTER".to_string(),
        ("preset_audio_device_master", "vi") => "Tiếng MASTER".to_string(),

        // Korean
        ("preset_translate", "ko") => "영역 번역".to_string(),
        ("preset_extract_retranslate", "ko") => "영역 번역 (정확)".to_string(),
        ("preset_translate_auto_paste", "ko") => "영역 번역 (자동 붙.)".to_string(),
        ("preset_translate_retranslate", "ko") => "영역 번역+재번역".to_string(),
        ("preset_extract_retrans_retrans", "ko") => "영.번역 (정확)+재번역".to_string(),
        ("preset_ocr", "ko") => "텍스트 추출".to_string(),
        ("preset_ocr_read", "ko") => "영역 읽기".to_string(),
        ("preset_summarize", "ko") => "영역 요약".to_string(),
        ("preset_desc", "ko") => "이미지 설명".to_string(),
        ("preset_ask_image", "ko") => "이미지 질문".to_string(),
        ("preset_translate_select", "ko") => "번역 (선택 텍스트)".to_string(),
        ("preset_translate_arena", "ko") => "번역 (아레나)".to_string(),
        ("preset_read_aloud", "ko") => "크게 읽기".to_string(),
        ("preset_trans_retrans_select", "ko") => "번역+재번역 (선택)".to_string(),
        ("preset_select_translate_replace", "ko") => "선택-번역-교체".to_string(),
        ("preset_fix_grammar", "ko") => "문법 수정".to_string(),
        ("preset_rephrase", "ko") => "다시 쓰기".to_string(),
        ("preset_make_formal", "ko") => "공식적으로".to_string(),
        ("preset_explain", "ko") => "설명".to_string(),
        ("preset_ask_text", "ko") => "텍스트 질문...".to_string(),
        ("preset_edit_as_follows", "ko") => "다음과 같이 수정:".to_string(),
        ("preset_extract_table", "ko") => "표 추출".to_string(),
        ("preset_qr_scanner", "ko") => "QR 스캔".to_string(),
        ("preset_trans_retrans_typing", "ko") => "번역+재번역 (입력)".to_string(),
        ("preset_ask_ai", "ko") => "AI 질문".to_string(),
        ("preset_internet_search", "ko") => "인터넷 검색".to_string(),
        ("preset_make_game", "ko") => "게임 만들기".to_string(),
        ("preset_transcribe", "ko") => "음성 받아쓰기".to_string(),
        ("preset_fix_pronunciation", "ko") => "발음 교정".to_string(),
        ("preset_study_language", "ko") => "언어 학습".to_string(),
        ("preset_transcribe_retranslate", "ko") => "빠른 외국인 답변 1".to_string(),
        ("preset_quicker_foreigner_reply", "ko") => "빠른 외국인 답변 2".to_string(),
        ("preset_fact_check", "ko") => "정보 확인".to_string(),
        ("preset_omniscient_god", "ko") => "전지전능한 신".to_string(),

        ("preset_realtime_audio_translate", "ko") => "실시간 음성 번역".to_string(),
        ("preset_quick_ai_question", "ko") => "빠른 AI 질문".to_string(),
        ("preset_voice_search", "ko") => "음성 검색".to_string(),
        ("preset_hang_image", "ko") => "이미지 오버레이".to_string(),
        ("preset_hang_text", "ko") => "텍스트 오버레이".to_string(),
        ("preset_quick_note", "ko") => "빠른 메모".to_string(),
        ("preset_quick_record", "ko") => "빠른 녹음".to_string(),
        ("preset_record_device", "ko") => "시스템 녹음".to_string(),
        ("preset_continuous_writing_online", "ko") => "연속 입력".to_string(),
        ("preset_transcribe_english_offline", "ko") => "영어 받아쓰기".to_string(),
        // MASTER presets - Korean
        ("preset_image_master", "ko") => "이미지 마스터".to_string(),
        ("preset_text_select_master", "ko") => "선택 마스터".to_string(),
        ("preset_text_type_master", "ko") => "입력 마스터".to_string(),
        ("preset_audio_mic_master", "ko") => "마이크 마스터".to_string(),
        ("preset_audio_device_master", "ko") => "사운드 마스터".to_string(),

        // English (default)
        ("preset_translate", _) => "Translate region".to_string(),
        ("preset_extract_retranslate", _) => "Trans reg (ACCURATE)".to_string(),
        ("preset_translate_auto_paste", _) => "Trans reg (Auto paste)".to_string(),
        ("preset_translate_retranslate", _) => "Trans reg+Retrans".to_string(),
        ("preset_extract_retrans_retrans", _) => "Trans (ACC)+Retrans".to_string(),
        ("preset_ocr", _) => "Extract text".to_string(),
        ("preset_ocr_read", _) => "Read this region".to_string(),
        ("preset_summarize", _) => "Summarize region".to_string(),
        ("preset_desc", _) => "Describe image".to_string(),
        ("preset_ask_image", _) => "Ask about image".to_string(),
        ("preset_translate_select", _) => "Trans (Select text)".to_string(),
        ("preset_translate_arena", _) => "Trans (Arena)".to_string(),
        ("preset_read_aloud", _) => "Read aloud".to_string(),
        ("preset_trans_retrans_select", _) => "Trans+Retrans (Select)".to_string(),
        ("preset_select_translate_replace", _) => "Select-Trans-Replace".to_string(),
        ("preset_fix_grammar", _) => "Fix Grammar".to_string(),
        ("preset_rephrase", _) => "Rephrase".to_string(),
        ("preset_make_formal", _) => "Make Formal".to_string(),
        ("preset_explain", _) => "Explain".to_string(),
        ("preset_ask_text", _) => "Ask about text...".to_string(),
        ("preset_edit_as_follows", _) => "Edit as follows:".to_string(),
        ("preset_extract_table", _) => "Extract Table".to_string(),
        ("preset_qr_scanner", _) => "QR Scanner".to_string(),
        ("preset_trans_retrans_typing", _) => "Trans+Retrans (Type)".to_string(),
        ("preset_ask_ai", _) => "Ask AI".to_string(),
        ("preset_internet_search", _) => "Internet Search".to_string(),
        ("preset_make_game", _) => "Make a Game".to_string(),
        ("preset_transcribe", _) => "Transcribe speech".to_string(),
        ("preset_fix_pronunciation", _) => "Fix pronunciation".to_string(),
        ("preset_study_language", _) => "Study language".to_string(),
        ("preset_transcribe_retranslate", _) => "Quick 4NR reply 1".to_string(),
        ("preset_quicker_foreigner_reply", _) => "Quick 4NR reply 2".to_string(),
        ("preset_fact_check", _) => "Fact Check".to_string(),
        ("preset_omniscient_god", _) => "Omniscient God".to_string(),
        ("preset_realtime_audio_translate", _) => "Live Translate".to_string(),
        ("preset_quick_ai_question", _) => "Quick AI Question".to_string(),
        ("preset_voice_search", _) => "Voice Search".to_string(),
        ("preset_hang_image", _) => "Image Overlay".to_string(),
        ("preset_hang_text", _) => "Text Overlay".to_string(),
        ("preset_quick_note", _) => "Quick Note".to_string(),
        ("preset_quick_record", _) => "Quick Record".to_string(),
        ("preset_record_device", _) => "Device Record".to_string(),
        ("preset_continuous_writing_online", _) => "Continuous Writing".to_string(),
        ("preset_transcribe_english_offline", _) => "Transcribe English".to_string(),

        // MASTER presets - English (default)
        ("preset_image_master", _) => "Image MASTER".to_string(),
        ("preset_text_select_master", _) => "Select MASTER".to_string(),
        ("preset_text_type_master", _) => "Type MASTER".to_string(),
        ("preset_audio_mic_master", _) => "Mic MASTER".to_string(),
        ("preset_audio_device_master", _) => "Sound MASTER".to_string(),

        // Fallback: return original ID without "preset_" prefix
        _ => preset_id
            .strip_prefix("preset_")
            .unwrap_or(preset_id)
            .replace('_', " "),
    }
}

pub fn render_sidebar(
    ui: &mut egui::Ui,
    config: &mut Config,
    view_mode: &mut ViewMode,
    text: &LocaleText,
) -> bool {
    let mut changed = false;
    let mut preset_to_add_type = None;
    let mut preset_idx_to_select: Option<usize> = None;
    let mut preset_idx_to_delete = None;
    let mut preset_idx_to_clone = None;
    let mut preset_idx_to_toggle_favorite = None;
    let mut preset_swap_request = None;

    // Get currently dragging item index from memory (if any)
    let dragging_idx_id = egui::Id::new("sidebar_drag_source");
    let dragging_source_idx: Option<usize> = ui.memory(|mem| mem.data.get_temp(dragging_idx_id));

    let mut image_indices = Vec::new();
    let mut text_indices = Vec::new();
    let mut audio_video_indices = Vec::new();

    for (i, p) in config.presets.iter().enumerate() {
        match p.preset_type.as_str() {
            "image" => image_indices.push(i),
            "text" => text_indices.push(i),
            "audio" | "video" => audio_video_indices.push(i),
            _ => image_indices.push(i),
        }
    }

    // Audio/Video indices are not sorted by type to allow user reordering.
    // They will appear in the order they are defined in config.presets.

    let current_view_mode = view_mode.clone();
    // Use actual grid width from previous frame for Global Settings position
    thread_local! {
        static GRID_WIDTH: std::cell::Cell<f32> = const { std::cell::Cell::new(0.0) };
    }

    // --- Presets Grid ---
    // Use stable ID based on preset count and IDs (not names - those change during typing)
    let preset_hash: u64 = config
        .presets
        .iter()
        .fold(config.presets.len() as u64, |acc, p| {
            acc.wrapping_mul(31).wrapping_add(
                p.id.bytes()
                    .fold(0u64, |h, b| h.wrapping_mul(31).wrapping_add(b as u64)),
            )
        });
    let grid_id = egui::Id::new("presets_grid").with(preset_hash);

    let grid_response = egui::Grid::new(grid_id)
        .num_columns(6)
        .spacing([8.0, 4.0])
        .min_col_width(67.0)
        .show(ui, |ui| {
            // ROW 1: Add Buttons
            let is_dark = ui.visuals().dark_mode;
            let img_bg = if is_dark {
                egui::Color32::from_rgb(45, 85, 140)
            } else {
                egui::Color32::from_rgb(100, 150, 220)
            };
            let txt_bg = if is_dark {
                egui::Color32::from_rgb(45, 120, 80)
            } else {
                egui::Color32::from_rgb(90, 180, 120)
            };
            let aud_bg = if is_dark {
                egui::Color32::from_rgb(150, 95, 40)
            } else {
                egui::Color32::from_rgb(220, 160, 80)
            };

            // Image
            ui.add(
                egui::Button::new(
                    egui::RichText::new(text.add_image_preset_btn)
                        .color(egui::Color32::WHITE)
                        .strong(),
                )
                .fill(img_bg)
                .corner_radius(12.0),
            )
            .clicked()
            .then(|| preset_to_add_type = Some("image"));
            ui.label("");

            // Text
            ui.add(
                egui::Button::new(
                    egui::RichText::new(text.add_text_preset_btn)
                        .color(egui::Color32::WHITE)
                        .strong(),
                )
                .fill(txt_bg)
                .corner_radius(12.0),
            )
            .clicked()
            .then(|| preset_to_add_type = Some("text"));
            ui.label("");

            // Audio
            ui.add(
                egui::Button::new(
                    egui::RichText::new(text.add_audio_preset_btn)
                        .color(egui::Color32::WHITE)
                        .strong(),
                )
                .fill(aud_bg)
                .corner_radius(12.0),
            )
            .clicked()
            .then(|| preset_to_add_type = Some("audio"));
            ui.label("");
            ui.end_row();

            // ROW 2+: Preset Items
            let max_len = image_indices
                .len()
                .max(text_indices.len())
                .max(audio_video_indices.len());
            for i in 0..max_len {
                // Column 1&2: Image
                if let Some(&idx) = image_indices.get(i) {
                    render_preset_item_parts(
                        ui,
                        &config.presets,
                        idx,
                        dragging_source_idx,
                        &current_view_mode,
                        &mut preset_idx_to_select,
                        &mut preset_idx_to_delete,
                        &mut preset_idx_to_clone,
                        &mut preset_idx_to_toggle_favorite,
                        &mut preset_swap_request,
                        &config.ui_language,
                    );
                } else {
                    ui.label("");
                    ui.label("");
                }

                // Column 3&4: Text
                if let Some(&idx) = text_indices.get(i) {
                    render_preset_item_parts(
                        ui,
                        &config.presets,
                        idx,
                        dragging_source_idx,
                        &current_view_mode,
                        &mut preset_idx_to_select,
                        &mut preset_idx_to_delete,
                        &mut preset_idx_to_clone,
                        &mut preset_idx_to_toggle_favorite,
                        &mut preset_swap_request,
                        &config.ui_language,
                    );
                } else {
                    ui.label("");
                    ui.label("");
                }

                // Column 5&6: Audio
                if let Some(&idx) = audio_video_indices.get(i) {
                    render_preset_item_parts(
                        ui,
                        &config.presets,
                        idx,
                        dragging_source_idx,
                        &current_view_mode,
                        &mut preset_idx_to_select,
                        &mut preset_idx_to_delete,
                        &mut preset_idx_to_clone,
                        &mut preset_idx_to_toggle_favorite,
                        &mut preset_swap_request,
                        &config.ui_language,
                    );
                } else {
                    ui.label("");
                    ui.label("");
                }

                ui.end_row();
            }
        });

    // Update cached grid width for next frame
    GRID_WIDTH.with(|w| w.set(grid_response.response.rect.width()));

    if let Some(idx) = preset_idx_to_select {
        *view_mode = ViewMode::Preset(idx);
    }

    if let Some(idx) = preset_idx_to_toggle_favorite {
        if let Some(preset) = config.presets.get_mut(idx) {
            preset.is_favorite = !preset.is_favorite;
            changed = true;
            crate::overlay::favorite_bubble::update_favorites_panel();
            crate::overlay::favorite_bubble::trigger_blink_animation();
        }
    }

    if let Some(idx) = preset_idx_to_clone {
        let mut new_preset = config.presets[idx].clone();
        new_preset.id = format!(
            "{:x}",
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_nanos()
        );
        let base_name = if config.presets[idx].id.starts_with("preset_") {
            get_localized_preset_name(&config.presets[idx].id, &config.ui_language)
        } else {
            new_preset.name.clone()
        };
        let mut new_name = format!("{} Copy", base_name);
        let mut counter = 1;
        while config.presets.iter().any(|p| p.name == new_name) {
            new_name = format!("{} Copy {}", base_name, counter);
            counter += 1;
        }
        new_preset.name = new_name;
        new_preset.hotkeys.clear();
        config.presets.push(new_preset);
        *view_mode = ViewMode::Preset(config.presets.len() - 1);
        changed = true;
    }

    if let Some((idx_a, idx_b)) = preset_swap_request {
        // Swap presets
        config.presets.swap(idx_a, idx_b);
        // If currently selecting one of them, update view_mode
        if let ViewMode::Preset(current) = view_mode {
            if *current == idx_a {
                *view_mode = ViewMode::Preset(idx_b);
            } else if *current == idx_b {
                *view_mode = ViewMode::Preset(idx_a);
            }
        }
        changed = true;
    }

    if let Some(type_str) = preset_to_add_type {
        let mut new_preset = Preset::default();
        if type_str == "text" {
            new_preset.preset_type = "text".to_string();
            new_preset.name = format!("Text {}", config.presets.len() + 1);
            new_preset.text_input_mode = "select".to_string();
            if let Some(block) = new_preset.blocks.first_mut() {
                block.block_type = "text".to_string();
                block.model = "text_accurate_kimi".to_string();
                block.prompt = "Translate this text.".to_string();
            }
        } else if type_str == "audio" {
            new_preset.preset_type = "audio".to_string();
            new_preset.name = format!("Audio {}", config.presets.len() + 1);
            new_preset.audio_source = "mic".to_string();
            if let Some(block) = new_preset.blocks.first_mut() {
                block.block_type = "audio".to_string();
                block.model = "whisper-fast".to_string();
            }
        } else {
            new_preset.name = format!("Image {}", config.presets.len() + 1);
        }
        config.presets.push(new_preset);
        *view_mode = ViewMode::Preset(config.presets.len() - 1);
        changed = true;
    }

    if let Some(idx) = preset_idx_to_delete {
        config.presets.remove(idx);
        if let ViewMode::Preset(curr) = *view_mode {
            if curr >= idx && curr > 0 {
                *view_mode = ViewMode::Preset(curr - 1);
            } else if config.presets.is_empty() {
                *view_mode = ViewMode::Global;
            } else {
                *view_mode = ViewMode::Preset(0);
            }
        }
        changed = true;
    }

    changed
}

fn render_preset_item_parts(
    ui: &mut egui::Ui,
    presets: &[Preset],
    idx: usize,
    dragging_source_idx: Option<usize>,
    current_view_mode: &ViewMode,
    preset_idx_to_select: &mut Option<usize>,
    preset_idx_to_delete: &mut Option<usize>,
    preset_idx_to_clone: &mut Option<usize>,
    preset_idx_to_toggle_favorite: &mut Option<usize>,
    preset_swap_request: &mut Option<(usize, usize)>,
    lang: &str,
) {
    let preset = &presets[idx];
    let display_name = if preset.id.starts_with("preset_") {
        get_localized_preset_name(&preset.id, lang)
    } else {
        preset.name.clone()
    };
    let is_selected = matches!(current_view_mode, ViewMode::Preset(i) if *i == idx);
    let has_hotkey = !preset.hotkeys.is_empty();

    let icon_type = match preset.preset_type.as_str() {
        "audio" => {
            if preset.audio_processing_mode == "realtime" {
                Icon::Realtime
            } else if preset.audio_source == "device" {
                Icon::Speaker
            } else {
                Icon::Microphone
            }
        }
        "video" => Icon::Image,
        "text" => {
            if preset.text_input_mode == "select" {
                Icon::TextSelect
            } else {
                Icon::Text
            }
        }
        _ => Icon::Image,
    };

    // --- Column X: Content ---
    ui.horizontal(|ui| {
        ui.set_min_height(22.0);
        ui.spacing_mut().item_spacing.x = 4.0;
        if has_hotkey && !preset.is_upcoming {
            let rect = ui.available_rect_before_wrap();
            let is_dark = ui.visuals().dark_mode;
            let bg_color = if is_dark {
                egui::Color32::from_rgba_unmultiplied(40, 150, 130, 70)
            } else {
                egui::Color32::from_rgb(200, 235, 220)
            };
            ui.painter().rect_filled(rect, 4.0, bg_color);
        }
        if preset.is_upcoming {
            ui.add_enabled_ui(false, |ui| {
                draw_icon_static(ui, icon_type, Some(14.0));
                let _ = ui.selectable_label(is_selected, &display_name);
            });
        } else {
            draw_icon_static(ui, icon_type, Some(14.0));
            // Make the label draggable.
            // SelectableLabel by default captures clicks. We want to also capture drags.
            let label_response = ui.selectable_label(is_selected, &display_name);
            let response = ui.interact(label_response.rect, label_response.id, egui::Sense::drag());

            if label_response.clicked() {
                *preset_idx_to_select = Some(idx);
            }

            // Drag Source Logic
            let dragging_id = egui::Id::new("sidebar_drag_source");
            if response.drag_started() {
                ui.memory_mut(|mem| mem.data.insert_temp(dragging_id, idx));
            }
            if response.dragged() {
                ui.ctx().set_cursor_icon(egui::CursorIcon::Grabbing);
            }
            if response.drag_stopped() {
                // Clear state when drag stops
                ui.memory_mut(|mem| mem.data.remove::<usize>(dragging_id));
            }

            // Drop Target Logic
            // If dragging, and we are not the source, and hovered, and released
            if let Some(source_idx) = dragging_source_idx {
                if source_idx != idx && response.hovered() && ui.input(|i| i.pointer.any_released())
                {
                    // Check if they are in the same column group
                    let source_preset = &presets[source_idx];
                    // Target is `preset`

                    let get_group = |p: &Preset| -> u8 {
                        match p.preset_type.as_str() {
                            "text" => 1,
                            "audio" | "video" => 2,
                            _ => 0, // Image or default
                        }
                    };

                    if get_group(source_preset) == get_group(preset) {
                        *preset_swap_request = Some((source_idx, idx));
                    }
                }
            }
        }
    });

    // --- Column X+1: Actions ---
    // Use horizontal layout (not right_to_left) to prevent column expansion
    ui.horizontal(|ui| {
        ui.spacing_mut().item_spacing.x = 0.0;
        if !preset.is_upcoming {
            // Drag handle removed - label is now draggable

            if icon_button_sized(ui, Icon::CopySmall, 22.0).clicked() {
                *preset_idx_to_clone = Some(idx);
            }
            let star_icon = if preset.is_favorite {
                Icon::StarFilled
            } else {
                Icon::Star
            };
            if icon_button_sized(ui, star_icon, 22.0).clicked() {
                *preset_idx_to_toggle_favorite = Some(idx);
            }
            if presets.len() > 1 {
                if icon_button_sized(ui, Icon::Delete, 22.0).clicked() {
                    *preset_idx_to_delete = Some(idx);
                }
            }
        }
    });
}
</file>

<file path="src/overlay/prompt_dj/mod.rs">
use raw_window_handle::{
    HandleError, HasWindowHandle, RawWindowHandle, Win32WindowHandle, WindowHandle,
};
use std::borrow::Cow;
use std::num::NonZeroIsize;
use std::sync::{Arc, Once};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE, DWMWCP_ROUND,
};
use windows::Win32::Graphics::Gdi::HBRUSH;
use windows::Win32::Media::Audio::{
    eMultimedia, eRender, IAudioSessionControl2, IAudioSessionManager2, IMMDeviceEnumerator,
    ISimpleAudioVolume, MMDeviceEnumerator,
};
use windows::Win32::System::Com::{
    CoCreateInstance, CoInitializeEx, CLSCTX_ALL, COINIT_APARTMENTTHREADED,
};
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::System::Threading::GetCurrentProcessId;
use windows::Win32::UI::Input::KeyboardAndMouse::{ReleaseCapture, SetFocus};
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebViewBuilder};

use crate::win_types::SendHwnd;

static REGISTER_PDJ_CLASS: Once = Once::new();
static mut PDJ_HWND: SendHwnd = SendHwnd(HWND(std::ptr::null_mut()));
static mut IS_WARMED_UP: bool = false;
static mut IS_INITIALIZING: bool = false;
const WM_APP_SHOW: u32 = WM_USER + 101;
const WM_APP_UPDATE_SETTINGS: u32 = WM_USER + 102;

// Thread-local storage for WebView
thread_local! {
    static PDJ_WEBVIEW: std::cell::RefCell<Option<Arc<wry::WebView>>> = std::cell::RefCell::new(None);
    static PDJ_WEB_CONTEXT: std::cell::RefCell<Option<WebContext>> = std::cell::RefCell::new(None);
}

// Assets
const INDEX_HTML: &[u8] = include_bytes!("dist/index.html");
const ASSET_INDEX_JS: &[u8] = include_bytes!("dist/assets/index.js");
const ASSET_INDEX_CSS: &[u8] = include_bytes!("dist/assets/index.css");
const ASSET_CUBIC_JS: &[u8] = include_bytes!("dist/assets/cubic.js");
const ASSET_MORPH_JS: &[u8] = include_bytes!("dist/assets/morph-fixed.js");
const ASSET_ROUNDED_JS: &[u8] = include_bytes!("dist/assets/roundedPolygon.js");
const ASSET_UTILS_JS: &[u8] = include_bytes!("dist/assets/utils.js");

lazy_static::lazy_static! {
    static ref CHILD_PIDS: std::sync::Mutex<Vec<u32>> = std::sync::Mutex::new(Vec::new());
}

fn update_child_pids() {
    let current_pid = unsafe { GetCurrentProcessId() };

    // Use wmic to get all processes (PID, PPID) - fast and standard
    #[cfg(windows)]
    use std::os::windows::process::CommandExt;

    let mut cmd = std::process::Command::new("wmic");
    cmd.args(&["process", "get", "ProcessId,ParentProcessId", "/format:csv"]);

    // CREATE_NO_WINDOW = 0x08000000 - prevents console window flash
    #[cfg(windows)]
    cmd.creation_flags(0x08000000);

    let output = cmd.output();

    if let Ok(o) = output {
        if let Ok(s) = String::from_utf8(o.stdout) {
            let mut tree = std::collections::HashMap::new();

            // Parse CSV output
            for line in s.lines() {
                if line.trim().is_empty() {
                    continue;
                }
                let parts: Vec<&str> = line.split(',').collect();
                // Format is: Node, ParentProcessId, ProcessId (usually)
                // But wmic csv header is: Node,ParentProcessId,ProcessId
                if parts.len() >= 3 {
                    if let (Ok(ppid), Ok(pid)) = (
                        parts[1].trim().parse::<u32>(),
                        parts[2].trim().parse::<u32>(),
                    ) {
                        tree.entry(ppid).or_insert_with(Vec::new).push(pid);
                    }
                }
            }

            // Find all descendants recursively
            let mut descendants = Vec::new();
            let mut queue = vec![current_pid];
            let mut visited = std::collections::HashSet::new();
            visited.insert(current_pid);

            while let Some(pid) = queue.pop() {
                if let Some(children) = tree.get(&pid) {
                    for &child in children {
                        if visited.insert(child) {
                            descendants.push(child);
                            queue.push(child);
                        }
                    }
                }
            }

            if let Ok(mut lock) = CHILD_PIDS.lock() {
                *lock = descendants;
            }
        }
    }
}

unsafe fn set_app_volume(volume: f32) -> Result<()> {
    // Access cache
    let current_pid = GetCurrentProcessId();
    let child_pids = CHILD_PIDS.lock().unwrap_or_else(|e| e.into_inner()).clone();

    // We try to initialize COM, but ignore error if already initialized
    let _ = CoInitializeEx(None, COINIT_APARTMENTTHREADED);

    let device_enumerator: IMMDeviceEnumerator =
        CoCreateInstance(&MMDeviceEnumerator, None, CLSCTX_ALL)?;

    let device = device_enumerator.GetDefaultAudioEndpoint(eRender, eMultimedia)?;
    let session_manager: IAudioSessionManager2 = device.Activate(CLSCTX_ALL, None)?;
    let session_enumerator = session_manager.GetSessionEnumerator()?;
    let count = session_enumerator.GetCount()?;

    for i in 0..count {
        if let Ok(session_control) = session_enumerator.GetSession(i) {
            if let Ok(session_control2) = session_control.cast::<IAudioSessionControl2>() {
                if let Ok(pid) = session_control2.GetProcessId() {
                    // Match Main Process OR known Children
                    if pid == current_pid || child_pids.contains(&pid) {
                        if let Ok(simple_volume) = session_control.cast::<ISimpleAudioVolume>() {
                            let _ = simple_volume.SetMasterVolume(volume, std::ptr::null());
                        }
                    }
                }
            }
        }
    }
    Ok(())
}

unsafe extern "system" fn pdj_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_SHOW => {
            // Update lang and theme if needed
            let (api_key, lang, theme_mode) = {
                let app = crate::APP.lock().unwrap();
                (
                    app.config.gemini_api_key.clone(),
                    app.config.ui_language.clone(),
                    app.config.theme_mode.clone(),
                )
            };

            let theme_str = match theme_mode {
                crate::config::ThemeMode::Dark => "dark",
                crate::config::ThemeMode::Light => "light",
                crate::config::ThemeMode::System => {
                    if crate::gui::utils::is_system_in_dark_mode() {
                        "dark"
                    } else {
                        "light"
                    }
                }
            };

            // Update window icon based on theme
            let is_dark = theme_str == "dark";
            crate::gui::utils::set_window_icon(hwnd, is_dark);

            PDJ_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let script = format!(
                        r#"
                        if (window.postMessage) {{
                            window.postMessage({{ type: 'pm-dj-set-api-key', apiKey: '{}', lang: '{}' }}, '*');
                            window.postMessage({{ type: 'pm-dj-set-theme', theme: '{}' }}, '*');
                        }}
                        "#,
                        api_key, lang, theme_str
                    );
                    let _ = webview.evaluate_script(&script);
                }
            });

            let _ = ShowWindow(hwnd, SW_SHOW);
            let _ = SetForegroundWindow(hwnd);
            let _ = SetFocus(Some(hwnd));
            LRESULT(0)
        }
        WM_APP_UPDATE_SETTINGS => {
            // Update lang and theme immediately even if hidden
            let (api_key, lang, theme_mode) = {
                let app = crate::APP.lock().unwrap();
                (
                    app.config.gemini_api_key.clone(),
                    app.config.ui_language.clone(),
                    app.config.theme_mode.clone(),
                )
            };

            let theme_str = match theme_mode {
                crate::config::ThemeMode::Dark => "dark",
                crate::config::ThemeMode::Light => "light",
                crate::config::ThemeMode::System => {
                    if crate::gui::utils::is_system_in_dark_mode() {
                        "dark"
                    } else {
                        "light"
                    }
                }
            };

            let is_dark = theme_str == "dark";
            crate::gui::utils::set_window_icon(hwnd, is_dark);

            PDJ_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let script = format!(
                        r#"
                        if (window.postMessage) {{
                            window.postMessage({{ type: 'pm-dj-set-api-key', apiKey: '{}', lang: '{}' }}, '*');
                            window.postMessage({{ type: 'pm-dj-set-theme', theme: '{}' }}, '*');
                        }}
                        "#,
                        api_key, lang, theme_str
                    );
                    let _ = webview.evaluate_script(&script);
                }
            });
            LRESULT(0)
        }
        WM_CLOSE => {
            PDJ_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let _ = webview
                        .evaluate_script("window.postMessage({ type: 'pm-dj-stop-audio' }, '*')");
                }
            });
            let _ = ShowWindow(hwnd, SW_HIDE);
            LRESULT(0)
        }
        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }
        WM_ERASEBKGND => LRESULT(1),
        WM_NCCALCSIZE => {
            if wparam.0 != 0 {
                LRESULT(0)
            } else {
                DefWindowProcW(hwnd, msg, wparam, lparam)
            }
        }
        WM_SIZE => {
            PDJ_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let mut r = RECT::default();
                    let _ = GetClientRect(hwnd, &mut r);
                    let width = r.right - r.left;
                    let height = r.bottom - r.top;
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                            0, 0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            width as u32,
                            height as u32,
                        )),
                    });
                }
            });
            LRESULT(0)
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

// Wrapper for HWND
struct HwndWrapper(HWND);

impl HasWindowHandle for HwndWrapper {
    fn window_handle(&self) -> std::result::Result<WindowHandle<'_>, HandleError> {
        let hwnd = self.0 .0 as isize;
        if hwnd == 0 {
            return Err(HandleError::Unavailable);
        }
        if let Some(non_zero) = NonZeroIsize::new(hwnd) {
            let mut handle = Win32WindowHandle::new(non_zero);
            handle.hinstance = None;
            let raw = RawWindowHandle::Win32(handle);
            Ok(unsafe { WindowHandle::borrow_raw(raw) })
        } else {
            Err(HandleError::Unavailable)
        }
    }
}

fn wnd_http_response(
    status: u16,
    content_type: &str,
    body: Cow<'static, [u8]>,
) -> wry::http::Response<Cow<'static, [u8]>> {
    wry::http::Response::builder()
        .status(status)
        .header("Content-Type", content_type)
        .header("Access-Control-Allow-Origin", "*")
        .body(body)
        .unwrap_or_else(|_| {
            wry::http::Response::builder()
                .status(500)
                .body(Cow::Borrowed(b"Internal Error".as_slice()))
                .unwrap()
        })
}

pub fn show_prompt_dj() {
    unsafe {
        // Initialize on-demand if not warmed up
        if !IS_WARMED_UP {
            if !IS_INITIALIZING {
                IS_INITIALIZING = true;
                std::thread::spawn(|| {
                    internal_create_pdj_loop();
                });
            }

            // Polling thread to auto-show once ready
            std::thread::spawn(|| {
                // Poll for 10 seconds (100 * 100ms)
                for _ in 0..100 {
                    std::thread::sleep(std::time::Duration::from_millis(100));
                    let hwnd_wrapper = std::ptr::addr_of!(PDJ_HWND).read();
                    if IS_WARMED_UP && !hwnd_wrapper.is_invalid() {
                        let _ =
                            PostMessageW(Some(hwnd_wrapper.0), WM_APP_SHOW, WPARAM(0), LPARAM(0));
                        return;
                    }
                }
            });
            return;
        }

        let hwnd_wrapper = std::ptr::addr_of!(PDJ_HWND).read();
        if !hwnd_wrapper.is_invalid() {
            let _ = PostMessageW(Some(hwnd_wrapper.0), WM_APP_SHOW, WPARAM(0), LPARAM(0));
        }
    }
}

pub fn update_settings() {
    unsafe {
        if !std::ptr::addr_of!(PDJ_HWND).read().is_invalid() {
            let _ = PostMessageW(
                Some(PDJ_HWND.0),
                WM_APP_UPDATE_SETTINGS,
                WPARAM(0),
                LPARAM(0),
            );
        }
    }
}

unsafe fn internal_create_pdj_loop() {
    // 1. Create Window
    let instance = GetModuleHandleW(None).unwrap();
    let class_name = w!("PromptDJ_Class_Persistent");

    REGISTER_PDJ_CLASS.call_once(|| {
        let mut wc = WNDCLASSW::default();
        wc.lpfnWndProc = Some(pdj_wnd_proc);
        wc.hInstance = instance.into();
        wc.lpszClassName = class_name;
        wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
        wc.hbrBackground = HBRUSH(std::ptr::null_mut()); // Transparent background
        let _ = RegisterClassW(&wc);
    });

    let screen_w = GetSystemMetrics(SM_CXSCREEN);
    let screen_h = GetSystemMetrics(SM_CYSCREEN);

    // Adaptive sizing based on screen aspect ratio:
    // - Width: Use 70% of screen width, capped between 1200 and 1600 pixels
    // - Height: Scales inversely with aspect ratio for consistent UI appearance
    //   - At 16:9 (1.78:1): ~72% of screen height → 775px on 1080p
    //   - At 21:9 (2.37:1): ~60% of screen height → 650px on 1080p ultrawide
    let aspect_ratio = screen_w as f64 / screen_h as f64;
    let base_aspect = 16.0 / 9.0; // 1.778
    let height_pct = (0.72 - (aspect_ratio - base_aspect) * 0.20).clamp(0.50, 0.80);

    let width = ((screen_w as f64 * 0.70) as i32).clamp(1200, 1600);
    let height = ((screen_h as f64 * height_pct) as i32).clamp(550, 900);
    let x = (screen_w - width) / 2;
    let y = (screen_h - height) / 2;

    let (api_key, lang, theme_mode) = {
        let app = crate::APP.lock().unwrap();
        (
            app.config.gemini_api_key.clone(),
            app.config.ui_language.clone(),
            app.config.theme_mode.clone(),
        )
    };

    let title_str = crate::gui::locale::LocaleText::get(&lang).prompt_dj_title;
    let title_wide = windows::core::HSTRING::from(title_str);

    let hwnd = CreateWindowExW(
        WS_EX_APPWINDOW,
        class_name,
        PCWSTR(title_wide.as_ptr()),
        WS_POPUP | WS_THICKFRAME | WS_MINIMIZEBOX | WS_SYSMENU, // Start hidden (no WS_VISIBLE)
        x,
        y,
        width,
        height,
        None,
        None,
        Some(instance.into()),
        None,
    )
    .unwrap();

    PDJ_HWND = SendHwnd(hwnd);

    // Enable rounded corners
    let corner_pref = DWMWCP_ROUND;
    let _ = DwmSetWindowAttribute(
        hwnd,
        DWMWA_WINDOW_CORNER_PREFERENCE,
        &corner_pref as *const _ as *const std::ffi::c_void,
        std::mem::size_of_val(&corner_pref) as u32,
    );

    // Set Window Icon
    let is_dark = match theme_mode {
        crate::config::ThemeMode::Dark => true,
        crate::config::ThemeMode::Light => false,
        crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
    };
    crate::gui::utils::set_window_icon(hwnd, is_dark);

    // 2. Create WebView
    let wrapper = HwndWrapper(hwnd);

    let theme_str = match theme_mode {
        crate::config::ThemeMode::Dark => "dark",
        crate::config::ThemeMode::Light => "light",
        crate::config::ThemeMode::System => "dark",
    };

    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    let init_script = format!(
        r#"
        // --- High-Priority Audio Hook ---
        (function() {{
            window._currentVolume = 1.0;
            window._activeMasterGains = [];
            
            const OriginalAC = window.AudioContext || window.webkitAudioContext;
            if (OriginalAC) {{
                const proto = OriginalAC.prototype;
                const desc = Object.getOwnPropertyDescriptor(proto, 'destination');
                if (desc && desc.get) {{
                    Object.defineProperty(proto, 'destination', {{
                        configurable: true,
                        enumerable: true,
                        get: function() {{
                            if (!this._masterGain) {{
                                const realDest = desc.get.call(this);
                                this._masterGain = this.createGain();
                                this._masterGain.gain.value = window._currentVolume;
                                this._masterGain.connect(realDest);
                                window._activeMasterGains.push(this._masterGain);
                            }}
                            return this._masterGain;
                        }}
                    }});
                }}
            }}
        }})();

        window.addEventListener('load', () => {{
            const style = document.createElement('style');
            style.innerHTML = `{}` + `
                body {{
                    margin: 0;
                    padding: 0;
                    font-family: 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif !important;
                    background-color: transparent !important;
                    overflow: hidden;
                }}
                #dj-drag-header {{
                    position: fixed;
                    top: 0;
                    left: 0;
                    width: 100%;
                    height: 32px;
                    background: transparent;
                    z-index: 2147483647;
                    -webkit-app-region: drag; 
                    cursor: grab;
                    pointer-events: auto;
                }}
                #dj-drag-header:active {{
                    cursor: grabbing;
                }}
                #dj-close-btn {{
                    position: absolute;
                    top: 0;
                    right: 0;
                    width: 40px;
                    height: 32px;
                    background: transparent;
                    color: rgba(255,255,255,0.5);
                    border: none;
                    font-family: 'Google Sans Flex', 'Segoe UI', system-ui;
                    font-size: 16px;
                    cursor: pointer;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                    transition: background 0.2s, color 0.2s;
                    -webkit-app-region: no-drag;
                }}
                #dj-close-btn:hover {{
                    background: rgba(255,0,0,0.5);
                    color: white;
                }}
                #dj-min-btn {{
                    position: absolute;
                    top: 0;
                    right: 40px;
                    width: 40px;
                    height: 32px;
                    background: transparent;
                    color: rgba(255,255,255,0.5);
                    border: none;
                    font-family: 'Google Sans Flex', 'Segoe UI', system-ui;
                    font-size: 16px;
                    cursor: pointer;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                    transition: background 0.2s, color 0.2s;
                    -webkit-app-region: no-drag;
                }}
                #dj-min-btn:hover {{
                    background: rgba(255,255,255,0.1);
                    color: white;
                }}
                /* Light theme: keep white text with dark shadow for visibility */
                [data-theme='light'] #dj-close-btn,
                [data-theme='light'] #dj-min-btn {{
                    color: rgba(255,255,255,0.9);
                    text-shadow: 0 1px 3px rgba(0,0,0,0.5), 0 0 6px rgba(0,0,0,0.3);
                }}
            `;
            document.head.appendChild(style);

            const header = document.createElement('div');
            header.id = 'dj-drag-header';
            
            const minBtn = document.createElement('button');
            minBtn.id = 'dj-min-btn';
            minBtn.innerHTML = '—';
            minBtn.onclick = (e) => {{
                e.stopPropagation(); 
                if (window.ipc) window.ipc.postMessage('minimize_window');
            }};
            header.appendChild(minBtn);

            const closeBtn = document.createElement('button');
            closeBtn.id = 'dj-close-btn';
            closeBtn.innerHTML = '✕';
            closeBtn.onclick = (e) => {{
                e.stopPropagation(); 
                window.postMessage({{ type: 'pm-dj-stop-audio' }}, '*');
                if (window.ipc) window.ipc.postMessage('close_window');
            }};
            header.appendChild(closeBtn);

            // --- Volume Slider Removed (moved to PromptDjMidi.ts) ---

            const updateTheme = (theme) => {{
                if (theme === 'light') {{
                    document.documentElement.setAttribute('data-theme', 'light');
                }} else {{
                    document.documentElement.setAttribute('data-theme', 'dark');
                }}
            }};

            window.addEventListener('message', (e) => {{
                if (e.data && e.data.type === 'pm-dj-set-theme') {{
                    updateTheme(e.data.theme);
                }}
            }});
            
            // Hover Logic (Removed Vol Container part)

            document.body.appendChild(header);

            setTimeout(() => {{
                window.postMessage({{ type: 'pm-dj-set-api-key', apiKey: '{}', lang: '{}' }}, '*');
                window.postMessage({{ type: 'pm-dj-set-theme', theme: '{}' }}, '*');
                window.postMessage({{ type: 'pm-dj-set-font', font: 'google-sans-flex' }}, '*');
            }}, 250);
        }});

        "#,
        font_css, api_key, lang, theme_str
    );

    let hwnd_ipc = hwnd;

    PDJ_WEB_CONTEXT.with(|ctx| {
        if ctx.borrow().is_none() {
            let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
            *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
        }
    });

    // Brief delay to ensure window is fully initialized before creating WebView
    std::thread::sleep(std::time::Duration::from_millis(100));

    let webview_result = {
        // LOCK SCOPE: Serialized build to prevent resource contention
        let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
        crate::log_info!("[PromptDJ] Acquired init lock. Building...");

        let build_res = PDJ_WEB_CONTEXT.with(|ctx| {
            let mut ctx_ref = ctx.borrow_mut();
            let mut builder = WebViewBuilder::new_with_web_context(ctx_ref.as_mut().unwrap())
                .with_custom_protocol("promptdj".to_string(), move |_id, request| {
                    let path = request.uri().path();
                    let (content, mime) = if path == "/" || path == "/index.html" {
                        (Cow::Borrowed(INDEX_HTML), "text/html")
                    } else if path.ends_with("index.js") {
                        (Cow::Borrowed(ASSET_INDEX_JS), "application/javascript")
                    } else if path.ends_with("index.css") {
                        (Cow::Borrowed(ASSET_INDEX_CSS), "text/css")
                    } else if path.ends_with("cubic.js") {
                        (Cow::Borrowed(ASSET_CUBIC_JS), "application/javascript")
                    } else if path.ends_with("morph-fixed.js") {
                        (Cow::Borrowed(ASSET_MORPH_JS), "application/javascript")
                    } else if path.ends_with("roundedPolygon.js") {
                        (Cow::Borrowed(ASSET_ROUNDED_JS), "application/javascript")
                    } else if path.ends_with("utils.js") {
                        (Cow::Borrowed(ASSET_UTILS_JS), "application/javascript")
                    } else {
                        return wnd_http_response(
                            404,
                            "text/plain",
                            Cow::Borrowed(b"Not Found".as_slice()),
                        );
                    };
                    wnd_http_response(200, mime, content)
                })
                .with_initialization_script(&init_script)
                .with_ipc_handler(move |msg: wry::http::Request<String>| {
                    let body = msg.body().as_str();
                    if body == "drag_window" {
                        let _ = ReleaseCapture();
                        let _ = SendMessageW(
                            hwnd_ipc,
                            WM_NCLBUTTONDOWN,
                            Some(WPARAM(HTCAPTION as usize)),
                            Some(LPARAM(0)),
                        );
                    } else if body == "minimize_window" {
                        let _ = ShowWindow(hwnd_ipc, SW_MINIMIZE);
                    } else if body == "close_window" {
                        let _ = ShowWindow(hwnd_ipc, SW_HIDE);
                    } else if body.starts_with("set_volume:") {
                        if let Ok(val) = body.trim_start_matches("set_volume:").parse::<f32>() {
                            let _ = set_app_volume(val);
                        }
                    }
                })
                .with_url("promptdj://localhost/index.html");

            builder = crate::overlay::html_components::font_manager::configure_webview(builder);
            builder.build_as_child(&wrapper)
        });
        crate::log_info!(
            "[PromptDJ] Build finished. Status: {}",
            if build_res.is_ok() { "OK" } else { "ERR" }
        );
        build_res
    };

    let webview = match webview_result {
        Ok(wv) => wv,
        Err(e) => {
            eprintln!("Failed to create PromptDJ WebView: {:?}", e);
            // Clean up and exit gracefully
            let _ = DestroyWindow(hwnd);
            PDJ_HWND = SendHwnd::default();
            return;
        }
    };
    let webview_arc = Arc::new(webview);

    // Initial Resize
    let mut r = RECT::default();
    let _ = GetClientRect(hwnd, &mut r);
    let _ = webview_arc.set_bounds(Rect {
        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
            (r.right - r.left) as u32,
            (r.bottom - r.top) as u32,
        )),
    });

    PDJ_WEBVIEW.with(|wv| {
        *wv.borrow_mut() = Some(webview_arc);
    });

    // Mark as warmed up and ready
    IS_WARMED_UP = true;

    // Spawn thread to cache child PIDs for volume control
    std::thread::spawn(|| {
        std::thread::sleep(std::time::Duration::from_secs(2));
        update_child_pids();
    });

    // 3. Message Loop
    let mut msg = MSG::default();
    while GetMessageW(&mut msg, None, 0, 0).as_bool() {
        let _ = TranslateMessage(&msg);
        let _ = DispatchMessageW(&msg);
    }

    PDJ_WEBVIEW.with(|wv| {
        *wv.borrow_mut() = None;
    });
    PDJ_HWND = SendHwnd::default();
    IS_WARMED_UP = false;
    IS_INITIALIZING = false;
}
</file>

<file path="src/overlay/recording.rs">
// use crate::win_types::SendHwnd; // Removed
use crate::APP;
use std::cell::RefCell;
use std::sync::{
    atomic::{AtomicBool, AtomicI32, AtomicIsize, AtomicU32, Ordering},
    Arc, Mutex, Once,
};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmExtendFrameIntoClientArea, DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE,
};
use windows::Win32::System::Com::{CoInitialize, CoUninitialize};
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebView, WebViewBuilder};

// --- GLOBAL SIGNALS (Preserving existing logic usage) ---
lazy_static::lazy_static! {
    pub static ref AUDIO_STOP_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref AUDIO_PAUSE_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref AUDIO_ABORT_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref AUDIO_WARMUP_COMPLETE: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    /// Signal for Gemini Live initialization phase (WebSocket setup)
    pub static ref AUDIO_INITIALIZING: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));

    static ref VISUALIZATION_BUFFER: Mutex<[f32; 40]> = Mutex::new([0.0; 40]);
}

static LAST_SHOW_TIME: std::sync::atomic::AtomicU64 = std::sync::atomic::AtomicU64::new(0);

pub static CURRENT_RMS: AtomicU32 = AtomicU32::new(0);

pub fn update_audio_viz(rms: f32) {
    let bits = rms.to_bits();
    CURRENT_RMS.store(bits, Ordering::Relaxed);
}

// --- STATE MANAGEMENT ---
// 0=Not Created, 1=Hidden/Warmup, 2=Visible/Recording
static RECORDING_STATE: AtomicI32 = AtomicI32::new(0);
static RECORDING_HWND_VAL: AtomicIsize = AtomicIsize::new(0);
static REGISTER_RECORDING_CLASS: Once = Once::new();
static LAST_THEME_IS_DARK: AtomicBool = AtomicBool::new(true);
static CURRENT_RECORDING_HIDDEN: AtomicBool = AtomicBool::new(false);

thread_local! {
    static RECORDING_WEBVIEW: RefCell<Option<WebView>> = RefCell::new(None);
    static RECORDING_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);
}

// --- ADAPTIVE UI SIZE ---
fn get_ui_dimensions() -> (i32, i32) {
    use windows::Win32::UI::WindowsAndMessaging::{GetSystemMetrics, SM_CXSCREEN, SM_CYSCREEN};

    let screen_w = unsafe { GetSystemMetrics(SM_CXSCREEN) };
    let screen_h = unsafe { GetSystemMetrics(SM_CYSCREEN) };

    // Width scales inversely with aspect ratio for consistent UI appearance
    // At 16:9 (1.78:1): 450px width
    // At 21:9 (2.37:1): 375px width (narrower on ultrawide)
    let aspect_ratio = screen_w as f64 / screen_h as f64;
    let base_aspect = 16.0 / 9.0; // 1.778
    let width = (450.0 - (aspect_ratio - base_aspect) * 127.0).clamp(350.0, 500.0) as i32;

    // Height stays constant at 70px
    let height = 70;

    (width, height)
}

const WM_APP_SHOW: u32 = WM_USER + 20;
const WM_APP_HIDE: u32 = WM_USER + 21;
const WM_APP_REAL_SHOW: u32 = WM_USER + 22;
const WM_APP_UPDATE_STATE: u32 = WM_USER + 23;

// --- PUBLIC API ---

pub fn is_recording_overlay_active() -> bool {
    RECORDING_STATE.load(Ordering::SeqCst) == 2
}

pub fn stop_recording_and_submit() {
    // Check if we are already active
    if is_recording_overlay_active() {
        let was_stopped = AUDIO_STOP_SIGNAL.load(Ordering::SeqCst);

        // If already stopped (processing) or aborted, hitting this again should FORCE CLOSE
        if was_stopped {
            AUDIO_ABORT_SIGNAL.store(true, Ordering::SeqCst);
            let hwnd_val = RECORDING_HWND_VAL.load(Ordering::SeqCst);
            if hwnd_val != 0 {
                let hwnd = HWND(hwnd_val as *mut _);
                unsafe {
                    let _ = PostMessageW(Some(hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
                }
            }
        } else {
            // First time: Just stop and let it process
            AUDIO_STOP_SIGNAL.store(true, Ordering::SeqCst);
            // Force update UI to "Processing"
            let hwnd_val = RECORDING_HWND_VAL.load(Ordering::SeqCst);
            if hwnd_val != 0 {
                let hwnd = HWND(hwnd_val as *mut _);
                unsafe {
                    let _ = PostMessageW(Some(hwnd), WM_APP_UPDATE_STATE, WPARAM(0), LPARAM(0));
                }
            }
        }
    }
}

pub fn warmup_recording_overlay() {
    // Transition 0 -> 1
    if RECORDING_STATE
        .compare_exchange(0, 1, Ordering::SeqCst, Ordering::SeqCst)
        .is_ok()
    {
        std::thread::spawn(|| {
            internal_create_recording_window();
        });
    }
}

pub fn show_recording_overlay(preset_idx: usize) {
    // Check current state
    let current = RECORDING_STATE.load(Ordering::SeqCst);

    // If state is 0, warmup hasn't started - trigger it and show notification
    // If state is 0 (not started) or 1 (stuck warming up), trigger recovery and auto-show
    if current == 0 || (current == 1 && RECORDING_HWND_VAL.load(Ordering::SeqCst) == 0) {
        // Reset state if stuck
        if current == 1 {
            RECORDING_STATE.store(0, Ordering::SeqCst);
        }

        // Start warmup
        warmup_recording_overlay();

        // Show loading notification
        let ui_lang = APP.lock().unwrap().config.ui_language.clone();
        let locale = crate::gui::locale::LocaleText::get(&ui_lang);
        crate::overlay::auto_copy_badge::show_notification(locale.recording_loading);

        // Spawn a thread to wait for warmup completion and then trigger show
        std::thread::spawn(move || {
            // Poll for up to 5 seconds
            for _ in 0..50 {
                std::thread::sleep(std::time::Duration::from_millis(100));
                if RECORDING_HWND_VAL.load(Ordering::SeqCst) != 0 {
                    // Ready! Trigger show
                    unsafe {
                        let hwnd = HWND(RECORDING_HWND_VAL.load(Ordering::SeqCst) as *mut _);
                        let _ =
                            PostMessageW(Some(hwnd), WM_APP_SHOW, WPARAM(preset_idx), LPARAM(0));
                    }
                    return;
                }
            }
        });

        return;
    }

    // Wait for HWND to be valid (state is 1 or 2)
    let hwnd_val = RECORDING_HWND_VAL.load(Ordering::SeqCst);

    if hwnd_val != 0 {
        // Reset Signals
        AUDIO_STOP_SIGNAL.store(false, Ordering::SeqCst);
        AUDIO_PAUSE_SIGNAL.store(false, Ordering::SeqCst);
        AUDIO_ABORT_SIGNAL.store(false, Ordering::SeqCst);
        AUDIO_WARMUP_COMPLETE.store(false, Ordering::SeqCst);
        CURRENT_RMS.store(0, Ordering::Relaxed);

        unsafe {
            let _ = PostMessageW(
                Some(HWND(hwnd_val as *mut _)),
                WM_APP_SHOW,
                WPARAM(preset_idx),
                LPARAM(0),
            );
        }
    } else {
        // HWND not ready yet, reset state and try again
        RECORDING_STATE.store(0, Ordering::SeqCst);
        warmup_recording_overlay();

        let ui_lang = APP.lock().unwrap().config.ui_language.clone();
        let locale = crate::gui::locale::LocaleText::get(&ui_lang);
        crate::overlay::auto_copy_badge::show_notification(locale.recording_loading);
    }
}

// --- INTERNAL IMPLEMENTATION ---

struct HwndWrapper(HWND);
unsafe impl Send for HwndWrapper {}
unsafe impl Sync for HwndWrapper {}
impl raw_window_handle::HasWindowHandle for HwndWrapper {
    fn window_handle(
        &self,
    ) -> std::result::Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError>
    {
        let raw = raw_window_handle::Win32WindowHandle::new(
            std::num::NonZeroIsize::new(self.0 .0 as isize).expect("HWND cannot be null"),
        );
        let handle = raw_window_handle::RawWindowHandle::Win32(raw);
        unsafe { Ok(raw_window_handle::WindowHandle::borrow_raw(handle)) }
    }
}

fn internal_create_recording_window() {
    unsafe {
        let coinit = CoInitialize(None); // Required for WebView
        crate::log_info!("[Recording] Loop Start - CoInit: {:?}", coinit);
        let instance = GetModuleHandleW(None).unwrap();
        let class_name = w!("SGT_Recording_Persistent");

        REGISTER_RECORDING_CLASS.call_once(|| {
            let mut wc = WNDCLASSW::default();
            wc.lpfnWndProc = Some(recording_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
            wc.lpszClassName = class_name;
            wc.style = CS_HREDRAW | CS_VREDRAW;
            RegisterClassW(&wc);
        });

        // Get adaptive UI dimensions
        let (ui_width, ui_height) = get_ui_dimensions();

        // Create window OFF-SCREEN initially (-4000, -4000)
        // WS_POPUP | WS_VISIBLE (so WebView renders) but off-screen.
        // Using Layered window for transparency
        let hwnd = CreateWindowExW(
            WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
            class_name,
            w!("SGT Recording Web"),
            WS_POPUP | WS_VISIBLE,
            -4000,
            -4000,
            ui_width,
            ui_height,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap();
        crate::log_info!("[Recording] Window created with HWND: {:?}", hwnd);

        RECORDING_HWND_VAL.store(hwnd.0 as isize, Ordering::SeqCst);

        // Windows 11 Rounded Corners - Disable native rounding to hide native border/shadow
        // We rely on CSS for rounded corners + transparency
        let corner_pref = 1u32; // DWMWCP_DONOTROUND
        let _ = DwmSetWindowAttribute(
            hwnd,
            DWMWA_WINDOW_CORNER_PREFERENCE,
            std::ptr::addr_of!(corner_pref) as *const _,
            std::mem::size_of_val(&corner_pref) as u32,
        );

        // Glass Frame Extension (critical for per-pixel alpha with WebView)
        let margins = MARGINS {
            cxLeftWidth: -1,
            cxRightWidth: -1,
            cyTopHeight: -1,
            cyBottomHeight: -1,
        };
        let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

        // --- WEBVIEW CREATION ---
        let wrapper = HwndWrapper(hwnd);
        let html = generate_html();

        RECORDING_WEB_CONTEXT.with(|ctx| {
            if ctx.borrow().is_none() {
                let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
                *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
            }
        });

        let ipc_hwnd_val = hwnd.0 as usize;
        let webview_res = {
            // LOCK SCOPE: Serialized build to prevent resource contention
            let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
            crate::log_info!("[Recording] Acquired init lock. Building...");

            let build_res = RECORDING_WEB_CONTEXT.with(|ctx| {
                let mut ctx_ref = ctx.borrow_mut();
                let mut builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                    WebViewBuilder::new_with_web_context(web_ctx)
                } else {
                    WebViewBuilder::new()
                };

                builder = crate::overlay::html_components::font_manager::configure_webview(builder);

                // Store HTML in font server and get URL for same-origin font loading
                let page_url =
                    crate::overlay::html_components::font_manager::store_html_page(html.clone())
                        .unwrap_or_else(|| {
                            format!("data:text/html,{}", urlencoding::encode(&html))
                        });

                let (ui_width, ui_height) = get_ui_dimensions();
                builder
                    .with_bounds(Rect {
                        position: wry::dpi::Position::Logical(wry::dpi::LogicalPosition::new(
                            0.0, 0.0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            ui_width as u32,
                            ui_height as u32,
                        )),
                    })
                    .with_transparent(true)
                    .with_background_color((0, 0, 0, 0)) // Fully transparent background
                    .with_url(&page_url)
                    .with_ipc_handler(move |msg: wry::http::Request<String>| {
                        let hwnd = HWND(ipc_hwnd_val as *mut std::ffi::c_void);
                        let body = msg.body().as_str();
                        match body {
                            "pause_toggle" => {
                                let paused = AUDIO_PAUSE_SIGNAL.load(Ordering::SeqCst);
                                AUDIO_PAUSE_SIGNAL.store(!paused, Ordering::SeqCst);
                            }
                            "cancel" | "close" => {
                                AUDIO_ABORT_SIGNAL.store(true, Ordering::SeqCst);
                                AUDIO_STOP_SIGNAL.store(true, Ordering::SeqCst);
                                let _ = PostMessageW(Some(hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
                            }
                            "ready" => {
                                // Handshake: WebView is ready (from resetState), so now we can REAL_SHOW
                                // Kill fallback timer 99
                                let _ = KillTimer(Some(hwnd), 99);
                                // Add a tiny delay to ensure paint catch-up
                                if !CURRENT_RECORDING_HIDDEN.load(Ordering::SeqCst) {
                                    let _ = SetTimer(Some(hwnd), 2, 20, None);
                                }
                            }
                            "drag_window" => {
                                let _ = ReleaseCapture();
                                let _ = PostMessageW(
                                    Some(hwnd),
                                    WM_NCLBUTTONDOWN,
                                    WPARAM(2 as usize), // HTCAPTION = 2
                                    LPARAM(0 as isize),
                                );
                            }
                            _ => {}
                        }
                    })
                    .build(&wrapper)
            });
            crate::log_info!(
                "[Recording] Build finished. Status: {}",
                if build_res.is_ok() { "OK" } else { "ERR" }
            );
            build_res
        };

        if let Ok(wv) = webview_res {
            crate::log_info!("[Recording] WebView success for HWND: {:?}", hwnd);
            RECORDING_WEBVIEW.with(|cell| *cell.borrow_mut() = Some(wv));

            // Setup Global Key Hook for ESC (This needs to be persistent or installed/uninstalled on show/hide)
            // Better to install once and check `is_recording_overlay_active()` inside hook.
            let hook = SetWindowsHookExW(
                WH_KEYBOARD_LL,
                Some(recording_hook_proc),
                Some(GetModuleHandleW(None).unwrap().into()),
                0,
            );

            // Message Loop
            let mut msg = MSG::default();
            while GetMessageW(&mut msg, None, 0, 0).as_bool() {
                let _ = TranslateMessage(&msg);
                let _ = DispatchMessageW(&msg);
            }

            if let Ok(h) = hook {
                let _ = UnhookWindowsHookEx(h);
            }
        }

        // Cleanup on FULL EXIT
        RECORDING_WEBVIEW.with(|cell| *cell.borrow_mut() = None);
        RECORDING_STATE.store(0, Ordering::SeqCst);

        let _ = CoUninitialize();
    }
}

fn start_audio_thread(hwnd: HWND, preset_idx: usize) {
    let (preset, last_active_window) = {
        let app = APP.lock().unwrap();
        (
            app.config.presets[preset_idx].clone(),
            app.last_active_window, // Keep as SendHwnd for safety across threads
        )
    };
    let hwnd_val = hwnd.0 as usize;

    // Check audio streaming modes
    let (use_gemini_live_stream, use_parakeet_stream) = {
        let mut gemini = false;
        let mut parakeet = false;

        for block in &preset.blocks {
            if block.block_type == "audio" {
                if let Some(config) = crate::model_config::get_model_by_id(&block.model) {
                    if config.provider == "gemini-live" {
                        gemini = true;
                    }
                    if config.provider == "parakeet" {
                        parakeet = true;
                    }
                }
            }
        }
        (gemini, parakeet)
    };

    std::thread::spawn(move || {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        let target = last_active_window.map(|h| h.0);

        if use_gemini_live_stream {
            // Use real-time streaming for Gemini Live
            crate::api::record_and_stream_gemini_live(
                preset,
                AUDIO_STOP_SIGNAL.clone(),
                AUDIO_PAUSE_SIGNAL.clone(),
                AUDIO_ABORT_SIGNAL.clone(),
                hwnd,
                target,
            );
        } else if use_parakeet_stream {
            // Use real-time streaming for Parakeet (Local)
            crate::api::audio::record_and_stream_parakeet(
                preset,
                AUDIO_STOP_SIGNAL.clone(),
                AUDIO_PAUSE_SIGNAL.clone(),
                AUDIO_ABORT_SIGNAL.clone(),
                hwnd,
                target,
            );
        } else {
            // Use standard record-then-transcribe flow
            crate::api::record_audio_and_transcribe(
                preset,
                AUDIO_STOP_SIGNAL.clone(),
                AUDIO_PAUSE_SIGNAL.clone(),
                AUDIO_ABORT_SIGNAL.clone(),
                hwnd,
            );
        }
    });
}

unsafe extern "system" fn recording_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_SHOW => {
            // 1. Prepare Content (while still off-screen)
            let preset_idx = wparam.0;

            // Reset JS state
            RECORDING_WEBVIEW.with(|cell| {
                if let Some(wv) = cell.borrow().as_ref() {
                    let _ = wv.evaluate_script("resetState();");
                }
            });

            // 2. Start Audio Logic
            start_audio_thread(hwnd, preset_idx);

            // 3. Mark state as Active (Visible)
            RECORDING_STATE.store(2, Ordering::SeqCst);

            // 4. Check if we should hide the UI
            let is_hidden = {
                let app = APP.lock().unwrap();
                if preset_idx < app.config.presets.len() {
                    app.config.presets[preset_idx].hide_recording_ui
                } else {
                    false
                }
            };
            CURRENT_RECORDING_HIDDEN.store(is_hidden, Ordering::SeqCst);

            // 5. Fallback Timer (99) - If IPC ready signal doesn't come in 500ms, show anyway
            // If hidden, we don't set the show timers.
            if !is_hidden {
                SetTimer(Some(hwnd), 99, 500, None);
            }

            // 5. REMOVED Timer 2 here. We now confirm via IPC "ready" signal to trigger the show.
            // This ensures we never show a blank window on first load.

            // Record Show Time to prevent race with old threads closing
            let now = std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap_or_default()
                .as_millis() as u64;
            LAST_SHOW_TIME.store(now, Ordering::SeqCst);

            LRESULT(0)
        }

        WM_TIMER => {
            if wparam.0 == 2 {
                // REAL SHOW TIMER (from IPC "ready")
                let _ = KillTimer(Some(hwnd), 2);
                let _ = PostMessageW(Some(hwnd), WM_APP_REAL_SHOW, WPARAM(0), LPARAM(0));
            } else if wparam.0 == 99 {
                // FALLBACK TIMER (IPC timed out)
                let _ = KillTimer(Some(hwnd), 99);
                println!("Warning: Recording overlay IPC timed out, forcing show");
                let _ = PostMessageW(Some(hwnd), WM_APP_REAL_SHOW, WPARAM(0), LPARAM(0));
            } else if wparam.0 == 1 {
                // VIZ UPDATE TIMER
                let is_processing = AUDIO_STOP_SIGNAL.load(Ordering::SeqCst);
                let is_paused = AUDIO_PAUSE_SIGNAL.load(Ordering::SeqCst);
                let is_initializing = AUDIO_INITIALIZING.load(Ordering::SeqCst);
                let warming_up = !AUDIO_WARMUP_COMPLETE.load(Ordering::SeqCst);

                let rms_bits = CURRENT_RMS.load(Ordering::Relaxed);
                let rms = f32::from_bits(rms_bits);

                let state_str = if is_processing {
                    "processing"
                } else if is_paused {
                    "paused"
                } else if is_initializing {
                    "initializing"
                } else if warming_up {
                    "warmup"
                } else {
                    "recording"
                };

                let script = format!("updateState('{}', {});", state_str, rms);

                RECORDING_WEBVIEW.with(|cell| {
                    if let Some(wv) = cell.borrow().as_ref() {
                        let _ = wv.evaluate_script(&script);
                    }
                });

                // Check for theme changes
                if let Ok(app) = APP.try_lock() {
                    let current_is_dark = match app.config.theme_mode {
                        crate::config::ThemeMode::Dark => true,
                        crate::config::ThemeMode::Light => false,
                        crate::config::ThemeMode::System => {
                            crate::gui::utils::is_system_in_dark_mode()
                        }
                    };
                    let last_dark = LAST_THEME_IS_DARK.load(Ordering::SeqCst);

                    if current_is_dark != last_dark {
                        LAST_THEME_IS_DARK.store(current_is_dark, Ordering::SeqCst);

                        // Generate new theme colors
                        let (
                            container_bg,
                            container_border,
                            text_color,
                            subtext_color,
                            btn_bg,
                            btn_hover_bg,
                            btn_color,
                            text_shadow,
                        ) = if current_is_dark {
                            (
                                "rgba(18, 18, 18, 0.85)",
                                "rgba(255, 255, 255, 0.1)",
                                "white",
                                "rgba(255, 255, 255, 0.7)",
                                "rgba(255, 255, 255, 0.05)",
                                "rgba(255, 255, 255, 0.15)",
                                "rgba(255, 255, 255, 0.8)",
                                "0 1px 2px rgba(0, 0, 0, 0.3)",
                            )
                        } else {
                            (
                                "rgba(255, 255, 255, 0.92)",
                                "rgba(0, 0, 0, 0.1)",
                                "#222222",
                                "rgba(0, 0, 0, 0.6)",
                                "rgba(0, 0, 0, 0.05)",
                                "rgba(0, 0, 0, 0.1)",
                                "rgba(0, 0, 0, 0.7)",
                                "0 1px 2px rgba(255, 255, 255, 0.3)",
                            )
                        };

                        let theme_script = format!(
                            "if(window.updateTheme) window.updateTheme({}, '{}', '{}', '{}', '{}', '{}', '{}', '{}', '{}');",
                            current_is_dark, container_bg, container_border, text_color, subtext_color, btn_bg, btn_hover_bg, btn_color, text_shadow
                        );

                        RECORDING_WEBVIEW.with(|cell| {
                            if let Some(wv) = cell.borrow().as_ref() {
                                let _ = wv.evaluate_script(&theme_script);
                            }
                        });
                    }
                }
            }
            LRESULT(0)
        }

        WM_APP_REAL_SHOW => {
            if CURRENT_RECORDING_HIDDEN.load(Ordering::SeqCst) {
                return LRESULT(0);
            }
            // Move to Center Screen
            let (ui_width, ui_height) = get_ui_dimensions();
            let screen_x = GetSystemMetrics(SM_CXSCREEN);
            let screen_y = GetSystemMetrics(SM_CYSCREEN);
            let center_x = (screen_x - ui_width) / 2;
            let center_y = (screen_y - ui_height) / 2 + 100;

            let _ = SetWindowPos(
                hwnd,
                Some(HWND_TOPMOST),
                center_x,
                center_y,
                0,
                0,
                SWP_NOSIZE | SWP_NOACTIVATE | SWP_SHOWWINDOW,
            );

            // Set Foreground/Focus
            // let _ = SetForegroundWindow(hwnd);
            // let _ = SetFocus(Some(hwnd));

            // Start Visualization Updates NOW that we are visible and ready
            // Only needing one timer start here
            let _ = SetTimer(Some(hwnd), 1, 16, None);

            // Trigger Fade In - window is now in position
            RECORDING_WEBVIEW.with(|cell| {
                if let Some(wv) = cell.borrow().as_ref() {
                    let _ = wv.evaluate_script(
                        "setTimeout(() => document.body.classList.add('visible'), 50);",
                    );
                }
            });

            LRESULT(0)
        }

        WM_APP_HIDE => {
            // Stop logic
            let _ = KillTimer(Some(hwnd), 1);
            let _ = KillTimer(Some(hwnd), 2);
            let _ = KillTimer(Some(hwnd), 99);

            // Reset opacity immediately so it's ready for next time
            RECORDING_WEBVIEW.with(|cell| {
                if let Some(wv) = cell.borrow().as_ref() {
                    // Use hideState() which DOES NOT trigger 'ready' signal
                    // This prevents the recursion where hide -> reset -> ready -> show -> hide
                    let _ = wv.evaluate_script("hideState();");
                }
            });

            // Move Off-screen
            let _ = SetWindowPos(
                hwnd,
                Some(HWND_TOPMOST),
                -4000,
                -4000,
                0,
                0,
                SWP_NOSIZE | SWP_NOACTIVATE,
            );

            RECORDING_STATE.store(1, Ordering::SeqCst); // Back to Warmup/Hidden

            LRESULT(0)
        }

        WM_APP_UPDATE_STATE => {
            // Just force an immediate update cycle if needed (e.g. for processing state)
            // Timer handles this mostly, but this can be used for instant response
            LRESULT(0)
        }

        WM_CLOSE => {
            // "Close" means Hide in this persistent model
            // LOGIC FIX: Check if this is a 'stale' close from a previous thread
            let is_stop = AUDIO_STOP_SIGNAL.load(Ordering::SeqCst);
            let is_abort = AUDIO_ABORT_SIGNAL.load(Ordering::SeqCst);

            if is_stop || is_abort {
                // User requested stop/abort, so this close is valid
                let _ = PostMessageW(Some(hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
            } else {
                // Natural close (error or finish?)
                // Check if we JUST started. If so, it's likely the old thread dying.
                let now = std::time::SystemTime::now()
                    .duration_since(std::time::UNIX_EPOCH)
                    .unwrap_or_default()
                    .as_millis() as u64;
                let last = LAST_SHOW_TIME.load(Ordering::SeqCst);
                if now > last && (now - last) < 2000 {
                    // Ignore Close during first 2 seconds if not explicitly stopped
                    // This prevents race condition where previous aborted thread sends WM_CLOSE late
                } else {
                    let _ = PostMessageW(Some(hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
                }
            }
            LRESULT(0)
        }

        WM_USER_FULL_CLOSE => {
            let _ = DestroyWindow(hwnd);
            PostQuitMessage(0);
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

unsafe extern "system" fn recording_hook_proc(
    code: i32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    if code == HC_ACTION as i32 {
        let kbd = &*(lparam.0 as *const KBDLLHOOKSTRUCT);
        if wparam.0 == WM_KEYDOWN as usize || wparam.0 == WM_SYSKEYDOWN as usize {
            if kbd.vkCode == VK_ESCAPE.0 as u32 {
                if is_recording_overlay_active() {
                    stop_recording_and_submit();
                    return LRESULT(1);
                }
            }
        }
    }
    CallNextHookEx(None, code, wparam, lparam)
}

const WM_USER_FULL_CLOSE: u32 = WM_USER + 99;

// --- HTML GENERATOR ---
fn generate_html() -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();
    let icon_pause = crate::overlay::html_components::icons::get_icon_svg("pause");
    let icon_play = crate::overlay::html_components::icons::get_icon_svg("play_arrow");
    let icon_close = crate::overlay::html_components::icons::get_icon_svg("close");
    let (text_rec, text_proc, text_wait, text_init, subtext, text_paused, is_dark) = {
        let app = APP.lock().unwrap();
        let lang = app.config.ui_language.as_str();
        let locale = crate::gui::locale::LocaleText::get(lang);
        let is_dark = match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        };
        // Store initial theme state
        LAST_THEME_IS_DARK.store(is_dark, Ordering::SeqCst);
        (
            match lang {
                "vi" => "Đang ghi âm...",
                "ko" => "녹음 중...",
                _ => "Recording...",
            },
            match lang {
                "vi" => "Đang xử lý...",
                "ko" => "처리 중...",
                _ => "Processing...",
            },
            match lang {
                "vi" => "Chuẩn bị...",
                "ko" => "준비 중...",
                _ => "Starting...",
            },
            match lang {
                "vi" => "Đang kết nối...",
                "ko" => "연결 중...",
                _ => "Connecting...",
            },
            locale.recording_subtext,
            locale.recording_paused,
            is_dark,
        )
    };

    // Theme-specific colors
    let (
        container_bg,
        container_border,
        text_color,
        subtext_color,
        btn_bg,
        btn_hover_bg,
        btn_color,
        text_shadow,
    ) = if is_dark {
        // Dark mode
        (
            "rgba(18, 18, 18, 0.85)",
            "rgba(255, 255, 255, 0.1)",
            "white",
            "rgba(255, 255, 255, 0.7)",
            "rgba(255, 255, 255, 0.05)",
            "rgba(255, 255, 255, 0.15)",
            "rgba(255, 255, 255, 0.8)",
            "0 1px 2px rgba(0, 0, 0, 0.3)",
        )
    } else {
        // Light mode
        (
            "rgba(255, 255, 255, 0.92)",
            "rgba(0, 0, 0, 0.1)",
            "#222222",
            "rgba(0, 0, 0, 0.6)",
            "rgba(0, 0, 0, 0.05)",
            "rgba(0, 0, 0, 0.1)",
            "rgba(0, 0, 0, 0.7)",
            "0 1px 2px rgba(255, 255, 255, 0.3)",
        )
    };

    format!(
        r#"
<!DOCTYPE html>
<html>
<head>
<style>
    {font_css}
    
    * {{ box-sizing: border-box; user-select: none; }}
    
    body {{
        margin: 0;
        padding: 0;
        width: 100vw;
        height: 100vh;
        overflow: hidden;
        background: transparent;
        display: flex;
        justify-content: center;
        align-items: center;
        opacity: 0;
        transition: opacity 0.15s ease-out; 
    }}
    
    body.visible {{
        opacity: 1;
    }}

    .container {{
        width: {width}px;
        height: {height}px;
        background: {container_bg};
        backdrop-filter: blur(20px);
        -webkit-backdrop-filter: blur(20px);
        border: 1px solid {container_border};
        border-radius: 50px;
        display: flex;
        flex-direction: row;
        align-items: center;
        justify-content: space-between;
        padding: 0 3px;
        gap: 6px;
        position: relative;
        color: {text_color};
        font-family: 'Google Sans Flex', sans-serif;
    }}

    .text-group {{
        display: flex;
        flex-direction: column;
        align-items: flex-start;
        justify-content: center;
        flex-grow: 1;
        min-width: 0;
        margin-left: 5px;
    }}

    .status-text {{
        font-size: 15px;
        font-weight: 700;
        margin-bottom: 2px;
        text-shadow: {text_shadow};
        font-stretch: expanded;
        white-space: nowrap;
    }}
    
    .sub-text {{
        font-size: 10px;
        color: {subtext_color};
        margin-bottom: 0;
        white-space: nowrap;
        font-family: 'Google Sans Flex', sans-serif;
        font-variation-settings: 'opsz' 14;
    }}

    /* Volume Canvas Styling */
    #volume-canvas {{
        height: 30px;
        width: 100px;
        margin-right: 5px;
    }}

    .btn {{
        position: relative;
        width: 34px; 
        height: 34px;
        border-radius: 50%;
        background: {btn_bg};
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        pointer-events: auto;
        transition: background 0.2s, transform 0.1s;
        color: {btn_color};
        flex-shrink: 0;
        margin: 0 2px;
    }}
    
    .btn:hover {{
        background: {btn_hover_bg};
    }}
    .btn:active {{
        transform: scale(0.95);
    }}

    .btn svg {{
        width: 24px;
        height: 24px;
        fill: currentColor;
        display: block;
    }}
    
    .btn-close svg {{
        width: 36px;
        height: 36px;
    }}
    
    #icon-pause, #icon-play {{
        display: flex;
        align-items: center;
        justify-content: center;
        width: 100%;
        height: 100%;
    }}
    
    .hidden {{ display: none !important; }}

</style>
</head>
<body>
    <div class="container">
        <!-- 1. Play/Pause -->
        <div class="btn btn-pause" onclick="togglePause()" id="btn-pause">
             <div id="icon-pause">{icon_pause}</div>
             <div id="icon-play" class="hidden">{icon_play}</div>
        </div>

        <!-- 2. Text -->
        <div class="text-group">
            <div class="status-text" id="status">{tx_rec}</div>
            <div class="sub-text">{tx_sub}</div>
        </div>
        
        <!-- 3. Waveform -->
        <!-- 3. Waveform (Canvas) -->
        <div style="display: flex; align-items: center;">
            <canvas id="volume-canvas" width="200" height="60" style="width: 100px; height: 30px;"></canvas>
        </div>

        <!-- 4. Close -->
        <div class="btn btn-close" onclick="closeApp()">
            {icon_close}
        </div>
    </div>

    <script>
        // const ipc = window.__TAURI__.ipc; // Removed - not using Tauri here, just Wry

        
        // I18n constants
        const TEXT_REC = "{tx_rec}";
        const TEXT_PROC = "{tx_proc}";
        const TEXT_WAIT = "{tx_wait}";
        const TEXT_INIT = "{tx_init}";
        const TEXT_PAUSED = "{tx_paused}";

        const statusEl = document.getElementById('status');
        const pauseBtn = document.getElementById('btn-pause');
        const iconPause = document.getElementById('icon-pause');
        const iconPlay = document.getElementById('icon-play');
        
        let currentState = "warmup"; 
        
        // --- CANVAS WAVEFORM LOGIC ---
        const volumeCanvas = document.getElementById('volume-canvas');
        const volumeCtx = volumeCanvas ? volumeCanvas.getContext('2d') : null;
        
        const BAR_WIDTH = 8; 
        const BAR_GAP = 6;
        const BAR_SPACING = BAR_WIDTH + BAR_GAP;
        const VISIBLE_BARS = 20; 
        
        const barHeights = new Array(VISIBLE_BARS + 2).fill(6);
        let latestRMS = 0;
        let scrollProgress = 0;
        let lastTime = 0;
        let animationFrame = null;
        
        // Theme state (passed from Rust)
        let isDark = {is_dark};
        
        // Color Schemes for Dark Mode
        const COLORS_DARK = {{
            recording:    ['#00a8e0', '#00c8ff', '#40e0ff'], // Light Cyan
            processing:   ['#00FF00', '#32CD32', '#98FB98'], // Green (unused - rainbow)
            warmup:       ['#FFD700', '#FFA500', '#FFDEAD'], // Gold/Orange
            initializing: ['#9F7AEA', '#805AD5', '#B794F4'], // Purple/Violet
            paused:       ['#888888', '#AAAAAA', '#CCCCCC']  // Grey
        }};
        
        // Color Schemes for Light Mode (darker, more saturated)
        const COLORS_LIGHT = {{
            recording:    ['#0066cc', '#0088dd', '#00aaee'], // Deep Blue
            processing:   ['#00AA00', '#008800', '#006600'], // Dark Green (unused - rainbow)
            warmup:       ['#cc6600', '#dd8800', '#ee9900'], // Dark Orange
            initializing: ['#6B46C1', '#553C9A', '#805AD5'], // Deep Purple
            paused:       ['#666666', '#888888', '#aaaaaa']  // Dark Grey
        }};
        
        let COLORS = isDark ? COLORS_DARK : COLORS_LIGHT;
        let currentColors = COLORS.warmup;

        function updateState(state, rms) {{
            currentState = state;
            latestRMS = rms; 
            
            if (state === 'processing') {{
                 statusEl.innerText = TEXT_PROC;
                 currentColors = COLORS.processing;
                 // Don't reset bars - let them transition smoothly from recording
                 // New DNA-pattern bars will be added as old ones scroll off
                 pauseBtn.style.visibility = 'hidden';
                 pauseBtn.style.pointerEvents = 'none';
            }} else if (state === 'paused') {{
                 statusEl.innerText = TEXT_PAUSED;
                 currentColors = COLORS.paused;
                 // Reset bars to minimal when paused
                 for (let i = 0; i < barHeights.length; i++) barHeights[i] = 6;
                 pauseBtn.style.visibility = 'visible';
                 pauseBtn.style.pointerEvents = 'auto';
                 iconPause.classList.add('hidden');
                 iconPlay.classList.remove('hidden');
            }} else if (state === 'initializing') {{
                 statusEl.innerText = TEXT_INIT;
                 currentColors = COLORS.initializing;
                 // Pulsing bars during initialization
                 for (let i = 0; i < barHeights.length; i++) barHeights[i] = 6;
                 // Hide pause button during initialization
                 pauseBtn.style.visibility = 'hidden';
                 pauseBtn.style.pointerEvents = 'none';
            }} else if (state === 'warmup') {{
                 statusEl.innerText = TEXT_WAIT;
                 currentColors = COLORS.warmup;
                 // Reset bars to minimal when entering warmup to clear lingering full bars
                 for (let i = 0; i < barHeights.length; i++) barHeights[i] = 6;
                 // Hide pause button during warmup
                 pauseBtn.style.visibility = 'hidden';
                 pauseBtn.style.pointerEvents = 'none';
            }} else {{
                 statusEl.innerText = TEXT_REC;
                 currentColors = COLORS.recording;
                 pauseBtn.style.visibility = 'visible';
                 pauseBtn.style.pointerEvents = 'auto';
                 iconPause.classList.remove('hidden');
                 iconPlay.classList.add('hidden');
            }}
        }}

        function drawWaveform(timestamp) {{
            if (!volumeCtx) return;
            
            const dt = lastTime ? (timestamp - lastTime) / 1000 : 0.016;
            lastTime = timestamp;
            
            // Speed: faster for processing to create urgency effect
            const speed = currentState === 'processing' ? 0.06 : 0.15;
            scrollProgress += dt / speed;
            
            // When in processing, apply decay to existing bars for smooth transition
            if (currentState === 'processing') {{
                const decayFactor = 0.95; // Shrink old bars by 5% each frame
                const minHeight = 15;
                for (let i = 0; i < barHeights.length; i++) {{
                    if (barHeights[i] > minHeight) {{
                        barHeights[i] = Math.max(minHeight, barHeights[i] * decayFactor);
                    }}
                }}
            }}
            
            while (scrollProgress >= 1) {{
                scrollProgress -= 1;
                barHeights.shift();
                
                const h = volumeCanvas.height;
                let displayRMS = latestRMS;
                if (currentState === 'processing') {{
                    // DNA-like sine wave pattern for processing
                    displayRMS = 0.12 + 0.2 * Math.abs(Math.sin(timestamp / 120));
                }} else if (currentState === 'initializing') {{
                    // Gentle pulsing wave for initialization
                    displayRMS = 0.08 + 0.12 * Math.abs(Math.sin(timestamp / 300));
                }} else if (currentState === 'paused') {{
                    displayRMS = 0.02; // Tiny dots
                }} else if (currentState === 'warmup') {{
                    displayRMS = 0.02; // Minimal - tiny orange dots
                }}
                
                let v = Math.max(6, Math.min(h - 4, displayRMS * 250 + 6));
                barHeights.push(v);
            }}
            
            const w = volumeCanvas.width;
            const h = volumeCanvas.height;
            volumeCtx.clearRect(0, 0, w, h);
            
            const pixelOffset = scrollProgress * BAR_SPACING;
            
            // For processing: draw each bar with its own rainbow color AND DNA wave height
            // For others: use a single gradient
            if (currentState === 'processing') {{
                const baseHue = (timestamp / 20) % 360; // Slower cycling base
                const wavePhase = timestamp / 200; // Animation phase for wave movement
                
                for (let i = 0; i < barHeights.length; i++) {{
                    // DNA wave: each bar height based on position + time for traveling wave
                    const waveValue = Math.sin((i * 0.4) + wavePhase);
                    const pillHeight = 12 + 35 * Math.abs(waveValue); // Range: 12 to 47
                    
                    const x = i * BAR_SPACING - pixelOffset;
                    const y = (h - pillHeight) / 2;
                    
                    if (x > -BAR_WIDTH && x < w) {{
                        // Each bar gets a different hue
                        const barHue = (baseHue + i * 18) % 360;
                        volumeCtx.fillStyle = `hsl(${{barHue}}, 100%, 55%)`;
                        volumeCtx.beginPath();
                        if (volumeCtx.roundRect) {{
                            volumeCtx.roundRect(x, y, BAR_WIDTH, pillHeight, BAR_WIDTH / 2);
                        }} else {{
                            volumeCtx.rect(x, y, BAR_WIDTH, pillHeight);
                        }}
                        volumeCtx.fill();
                    }}
                }}
            }} else {{
                // Normal gradient for other states
                const grad = volumeCtx.createLinearGradient(0, h, 0, 0);
                grad.addColorStop(0, currentColors[0]);
                grad.addColorStop(0.5, currentColors[1]);
                grad.addColorStop(1, currentColors[2]);
                volumeCtx.fillStyle = grad;
                
                for (let i = 0; i < barHeights.length; i++) {{
                    const pillHeight = barHeights[i];
                    const x = i * BAR_SPACING - pixelOffset;
                    const y = (h - pillHeight) / 2;
                    
                    if (x > -BAR_WIDTH && x < w) {{
                        volumeCtx.beginPath();
                        if (volumeCtx.roundRect) {{
                            volumeCtx.roundRect(x, y, BAR_WIDTH, pillHeight, BAR_WIDTH / 2);
                        }} else {{
                            volumeCtx.rect(x, y, BAR_WIDTH, pillHeight);
                        }}
                        volumeCtx.fill();
                    }}
                }}
            }}
            
            // Apply fading curtain effect on both edges
            const fadeWidth = 30; // Width of the fade zone in canvas pixels
            
            volumeCtx.save();
            volumeCtx.globalCompositeOperation = 'destination-out';
            
            // Left fade (fully transparent at edge -> fully opaque inward)
            const leftGrad = volumeCtx.createLinearGradient(0, 0, fadeWidth, 0);
            leftGrad.addColorStop(0, 'rgba(0, 0, 0, 1)');
            leftGrad.addColorStop(1, 'rgba(0, 0, 0, 0)');
            volumeCtx.fillStyle = leftGrad;
            volumeCtx.fillRect(0, 0, fadeWidth, h);
            
            // Right fade (fully opaque inward -> fully transparent at edge)
            const rightGrad = volumeCtx.createLinearGradient(w - fadeWidth, 0, w, 0);
            rightGrad.addColorStop(0, 'rgba(0, 0, 0, 0)');
            rightGrad.addColorStop(1, 'rgba(0, 0, 0, 1)');
            volumeCtx.fillStyle = rightGrad;
            volumeCtx.fillRect(w - fadeWidth, 0, fadeWidth, h);
            
            volumeCtx.restore();
            
            animationFrame = requestAnimationFrame(drawWaveform);
        }}

        if (!animationFrame) {{
            animationFrame = requestAnimationFrame(drawWaveform);
        }}

        function togglePause() {{
            window.ipc.postMessage('pause_toggle');
        }}
        
        function closeApp() {{
            window.ipc.postMessage('cancel');
        }}
        
        function resetState() {{
            hideState();
            setTimeout(() => {{
                 window.ipc.postMessage('ready');
            }}, 10);
        }}

        const container = document.querySelector('.container');
        container.addEventListener('mousedown', (e) => {{
            if (e.target.closest('.btn')) return;
            window.ipc.postMessage('drag_window');
        }});

        function hideState() {{
            document.body.classList.remove('visible');
        }}
        
        // Dynamic theme update function (called from Rust)
        window.updateTheme = function(newIsDark, containerBg, containerBorder, textColor, subtextColor, btnBg, btnHoverBg, btnColor, textShadow) {{
            isDark = newIsDark;
            COLORS = isDark ? COLORS_DARK : COLORS_LIGHT;
            
            // Update CSS
            const container = document.querySelector('.container');
            container.style.background = containerBg;
            container.style.borderColor = containerBorder;
            container.style.color = textColor;
            
            const subtext = document.querySelector('.sub-text');
            if (subtext) subtext.style.color = subtextColor;
            
            const statusText = document.querySelector('.status-text');
            if (statusText) statusText.style.textShadow = textShadow;
            
            document.querySelectorAll('.btn').forEach(btn => {{
                btn.style.background = btnBg;
                btn.style.color = btnColor;
            }});
            
            // Update current colors based on current state
            if (currentState === 'recording') currentColors = COLORS.recording;
            else if (currentState === 'paused') currentColors = COLORS.paused;
            else if (currentState === 'warmup') currentColors = COLORS.warmup;
            else if (currentState === 'initializing') currentColors = COLORS.initializing;
            else if (currentState === 'processing') currentColors = COLORS.processing;
        }};
    </script>
</body>
</html>
    "#,
        width = get_ui_dimensions().0 - 20,
        height = get_ui_dimensions().1 - 20,
        font_css = font_css,
        tx_rec = text_rec,
        tx_proc = text_proc,
        tx_wait = text_wait,
        tx_init = text_init,
        tx_sub = subtext,
        tx_paused = text_paused,
        icon_pause = icon_pause,
        icon_play = icon_play,
        icon_close = icon_close,
        container_bg = container_bg,
        container_border = container_border,
        text_color = text_color,
        subtext_color = subtext_color,
        btn_bg = btn_bg,
        btn_hover_bg = btn_hover_bg,
        btn_color = btn_color,
        text_shadow = text_shadow,
        is_dark = if is_dark { "true" } else { "false" }
    )
}
</file>

<file path="src/config/config.rs">
//! Main Config struct definition.

use serde::{Deserialize, Serialize};

use crate::config::preset::{get_default_presets, Preset};
use crate::config::types::{
    default_tts_language_conditions, get_system_ui_language, EdgeTtsSettings, Hotkey, ThemeMode,
    TtsLanguageCondition, TtsMethod, DEFAULT_HISTORY_LIMIT, DEFAULT_PROJECTS_LIMIT,
};

// ============================================================================
// SERDE DEFAULT FUNCTIONS
// ============================================================================

fn default_true() -> bool {
    true
}

fn default_history_limit() -> usize {
    DEFAULT_HISTORY_LIMIT
}

fn default_projects_limit() -> usize {
    DEFAULT_PROJECTS_LIMIT
}

fn default_graphics_mode() -> String {
    "standard".to_string()
}

fn default_tts_voice() -> String {
    "Aoede".to_string()
}

fn default_tts_speed() -> String {
    "Fast".to_string()
}

fn default_tts_method() -> TtsMethod {
    TtsMethod::GeminiLive
}

fn default_edge_tts_settings() -> EdgeTtsSettings {
    EdgeTtsSettings::default()
}

fn default_realtime_translation_model() -> String {
    "cerebras-oss".to_string()
}

fn default_realtime_font_size() -> u32 {
    16
}

fn default_realtime_window_size() -> (i32, i32) {
    (500, 180)
}

fn default_realtime_transcription_model() -> String {
    "gemini".to_string()
}

fn default_realtime_target_language() -> String {
    "Vietnamese".to_string()
}

fn default_ollama_base_url() -> String {
    "http://localhost:11434".to_string()
}

// ============================================================================
// CONFIG STRUCT
// ============================================================================

#[derive(Serialize, Deserialize, Clone, Debug)]
pub struct Config {
    // -------------------------------------------------------------------------
    // API Keys
    // -------------------------------------------------------------------------
    /// Groq API key
    pub api_key: String,

    /// Google Gemini API key
    pub gemini_api_key: String,

    /// OpenRouter API key
    #[serde(default)]
    pub openrouter_api_key: String,

    /// Cerebras AI API key
    #[serde(default)]
    pub cerebras_api_key: String,

    // -------------------------------------------------------------------------
    // Presets
    // -------------------------------------------------------------------------
    /// All configured presets
    pub presets: Vec<Preset>,

    /// Index of the currently active preset
    pub active_preset_idx: usize,

    // -------------------------------------------------------------------------
    // UI Settings
    // -------------------------------------------------------------------------
    /// Theme mode: System, Dark, or Light
    #[serde(default)]
    pub theme_mode: ThemeMode,

    /// UI language code: "en", "vi", "ko"
    pub ui_language: String,

    /// Maximum history items to keep
    #[serde(default = "default_history_limit")]
    pub max_history_items: usize,

    /// Maximum screen record projects to keep
    #[serde(default = "default_projects_limit")]
    pub max_screen_record_projects: usize,

    /// Graphics mode: "standard" or "low"
    #[serde(default = "default_graphics_mode")]
    pub graphics_mode: String,

    // -------------------------------------------------------------------------
    // Startup Behavior
    // -------------------------------------------------------------------------
    /// Start minimized to system tray
    #[serde(default)]
    pub start_in_tray: bool,

    /// Request admin privileges on startup
    #[serde(default)]
    pub run_as_admin_on_startup: bool,

    /// Regular startup (registry-based)
    #[serde(default)]
    pub run_at_startup: bool,

    /// The path that is authorized to manage startup entries
    #[serde(default)]
    pub authorized_startup_path: String,

    // -------------------------------------------------------------------------
    // API Provider Toggles
    // -------------------------------------------------------------------------
    /// Enable Groq models
    #[serde(default = "default_true")]
    pub use_groq: bool,

    /// Enable Google Gemini models
    #[serde(default = "default_true")]
    pub use_gemini: bool,

    /// Enable OpenRouter models
    #[serde(default)]
    pub use_openrouter: bool,

    /// Enable Cerebras AI models
    #[serde(default = "default_true")]
    pub use_cerebras: bool,

    /// Enable local Ollama models
    #[serde(default)]
    pub use_ollama: bool,

    // -------------------------------------------------------------------------
    // Ollama Configuration
    // -------------------------------------------------------------------------
    /// Ollama server base URL
    #[serde(default = "default_ollama_base_url")]
    pub ollama_base_url: String,

    /// Ollama model for vision tasks
    #[serde(default)]
    pub ollama_vision_model: String,

    /// Ollama model for text tasks
    #[serde(default)]
    pub ollama_text_model: String,

    // -------------------------------------------------------------------------
    // Realtime Audio Settings
    // -------------------------------------------------------------------------
    /// Model for realtime translation: "cerebras-oss" or "google-gemma"
    #[serde(default = "default_realtime_translation_model")]
    pub realtime_translation_model: String,

    /// Model for realtime transcription: "gemini" or "parakeet"
    #[serde(default = "default_realtime_transcription_model")]
    pub realtime_transcription_model: String,

    /// Font size for realtime overlay
    #[serde(default = "default_realtime_font_size")]
    pub realtime_font_size: u32,

    /// Realtime transcription window size
    #[serde(default = "default_realtime_window_size")]
    pub realtime_transcription_size: (i32, i32),

    /// Realtime translation window size
    #[serde(default = "default_realtime_window_size")]
    pub realtime_translation_size: (i32, i32),

    /// Realtime audio source: "mic" or "device"
    #[serde(default)]
    pub realtime_audio_source: String,

    /// Target language for realtime translation
    #[serde(default = "default_realtime_target_language")]
    pub realtime_target_language: String,

    // -------------------------------------------------------------------------
    // TTS Settings
    // -------------------------------------------------------------------------
    /// TTS method: GeminiLive, GoogleTranslate, or EdgeTTS
    #[serde(default = "default_tts_method")]
    pub tts_method: TtsMethod,

    /// TTS voice name
    #[serde(default = "default_tts_voice")]
    pub tts_voice: String,

    /// TTS speed: "Normal", "Slow", "Fast"
    #[serde(default = "default_tts_speed")]
    pub tts_speed: String,

    /// TTS output device ID
    #[serde(default)]
    pub tts_output_device: String,

    /// Language-specific TTS instructions
    #[serde(default = "default_tts_language_conditions")]
    pub tts_language_conditions: Vec<TtsLanguageCondition>,

    /// Edge TTS specific settings
    #[serde(default = "default_edge_tts_settings")]
    pub edge_tts_settings: EdgeTtsSettings,

    // -------------------------------------------------------------------------
    // Favorite Bubble Settings
    // -------------------------------------------------------------------------
    /// Show floating favorite bubble
    #[serde(default)]
    pub show_favorite_bubble: bool,

    /// Bubble position (physical pixels)
    #[serde(default)]
    pub favorite_bubble_position: Option<(i32, i32)>,

    /// Keep the favorites panel open after selecting a preset
    #[serde(default)]
    pub favorites_keep_open: bool,

    /// Size of the favorite bubble (width/height)
    #[serde(default = "default_bubble_size")]
    pub favorite_bubble_size: u32,

    // -------------------------------------------------------------------------
    // Maintenance Flags
    // -------------------------------------------------------------------------
    /// Clear WebView data on next startup (for MIDI permission reset)
    #[serde(default)]
    pub clear_webview_on_startup: bool,

    /// Global hotkeys for screen recording start/stop
    #[serde(default = "default_screen_record_hotkeys")]
    pub screen_record_hotkeys: Vec<Hotkey>,
}

fn default_screen_record_hotkeys() -> Vec<Hotkey> {
    vec![Hotkey {
        code: 0x7B, // F12
        name: "F12".to_string(),
        modifiers: 0,
    }]
}

// ============================================================================
// CONFIG STRUCT METHODS
// ============================================================================

impl Config {
    /// Checks if a hotkey combination conflicts with any existing hotkeys.
    /// Returns the name of the conflicting item if found.
    pub fn check_hotkey_conflict(
        &self,
        vk: u32,
        mods: u32,
        exclude_preset_idx: Option<usize>,
    ) -> Option<String> {
        // Check global screen record hotkeys
        for h in &self.screen_record_hotkeys {
            if h.code == vk && h.modifiers == mods {
                return Some(format!(
                    "Conflict with global hotkey '{}' (Screen Record)",
                    h.name
                ));
            }
        }

        // Check all presets
        for (idx, preset) in self.presets.iter().enumerate() {
            if Some(idx) == exclude_preset_idx {
                continue;
            }
            for h in &preset.hotkeys {
                if h.code == vk && h.modifiers == mods {
                    return Some(format!(
                        "Conflict with '{}' in preset '{}'",
                        h.name, preset.name
                    ));
                }
            }
        }
        None
    }
}

// ============================================================================
// CONFIG DEFAULT IMPL
// ============================================================================

impl Default for Config {
    fn default() -> Self {
        Self {
            // API Keys
            api_key: String::new(),
            gemini_api_key: String::new(),
            openrouter_api_key: String::new(),
            cerebras_api_key: String::new(),

            // Presets - use the centralized ordered list
            presets: get_default_presets(),
            active_preset_idx: 0,

            // UI Settings
            theme_mode: ThemeMode::System,
            ui_language: get_system_ui_language(),
            max_history_items: DEFAULT_HISTORY_LIMIT,
            max_screen_record_projects: DEFAULT_PROJECTS_LIMIT,
            graphics_mode: "standard".to_string(),

            // Startup
            start_in_tray: false,
            run_as_admin_on_startup: false,
            run_at_startup: false,
            authorized_startup_path: String::new(),

            // API Providers
            use_groq: true,
            use_gemini: true,
            use_openrouter: false,
            use_cerebras: true,
            use_ollama: false,

            // Ollama
            ollama_base_url: "http://localhost:11434".to_string(),
            ollama_vision_model: String::new(),
            ollama_text_model: String::new(),

            // Realtime Audio
            realtime_translation_model: "cerebras-oss".to_string(),
            realtime_transcription_model: "gemini".to_string(),
            realtime_font_size: 16,
            realtime_transcription_size: (500, 180),
            realtime_translation_size: (500, 180),
            realtime_audio_source: "device".to_string(),
            realtime_target_language: "Vietnamese".to_string(),

            // TTS
            tts_method: TtsMethod::GeminiLive,
            tts_voice: "Aoede".to_string(),
            tts_speed: "Fast".to_string(),
            tts_output_device: String::new(),
            tts_language_conditions: default_tts_language_conditions(),
            edge_tts_settings: EdgeTtsSettings::default(),

            // Favorite Bubble
            show_favorite_bubble: false,
            favorite_bubble_position: None,
            favorites_keep_open: false,
            favorite_bubble_size: 40,

            // Maintenance
            clear_webview_on_startup: false,

            // Screen Record
            screen_record_hotkeys: default_screen_record_hotkeys(),
        }
    }
}

fn default_bubble_size() -> u32 {
    40
}
</file>

<file path="src/gui/app.rs">
mod init;
pub mod input_handler;
mod logic;
mod rendering;
mod types;
mod utils;

pub use types::SettingsApp;
pub use utils::{restart_app, signal_restore_window};

use eframe::egui;

impl eframe::App for SettingsApp {
    fn clear_color(&self, _visuals: &egui::Visuals) -> [f32; 4] {
        [0.0, 0.0, 0.0, 0.0]
    }

    fn update(&mut self, ctx: &egui::Context, _frame: &mut eframe::Frame) {
        // Log first update
        static LOGGED_STARTUP: std::sync::atomic::AtomicBool =
            std::sync::atomic::AtomicBool::new(false);
        if !LOGGED_STARTUP.swap(true, std::sync::atomic::Ordering::SeqCst) {
            crate::log_info!("[Main] App Update Start - Main Thread Alive");
        }

        // Handle Dropped Files and Paste FIRST (before any UI consumes events)
        if let Some(path) = self.pending_file_path.take() {
            crate::log_info!("App Update: Found pending file path, triggering process...");
            input_handler::process_file_path(&path);
        }
        input_handler::handle_dropped_files(ctx);
        if !self.download_manager.show_window {
            input_handler::handle_paste(ctx);
        }

        // Updater
        self.check_updater();

        // Theme & Tray
        self.update_theme_and_tray(ctx);

        // Startup Logic
        self.update_startup(ctx);

        // Bubble Sync
        self.update_bubble_sync();

        // Splash
        self.update_splash(ctx);

        // Restore Signal
        self.check_restore_signal(ctx);

        // Hotkey Recording
        self.update_hotkey_recording(ctx);

        // Event Handling
        self.handle_events(ctx);

        // Close Request
        self.handle_close_request(ctx);

        // Tips Logic
        self.update_tips_logic(ctx);

        // --- UI LAYOUT ---
        if self.startup_stage >= 36 {
            // Title Bar (Custom Windows Bar)
            self.render_title_bar(ctx);

            // Footer & Tips Modal
            self.render_footer_and_tips_modal(ctx);

            // Main Layout
            self.render_main_layout(ctx);

            // Window Resizing (Must be last to override cursors at edges)
            self.render_window_resize_handles(ctx);

            // Overlays
            self.render_fade_overlay(ctx);

            // Render Minimal Mode Overlay (Realtime)
            crate::overlay::realtime_egui::render_minimal_overlay(ctx);
        }

        // Render Splash Overlay (Last Last)
        // Note: Splash remains visible during its exit animation, covering the UI.
        if let Some(splash) = &self.splash {
            if splash.paint(ctx, &self.config.theme_mode) {
                let is_currently_dark = ctx.style().visuals.dark_mode;
                self.config.theme_mode = if is_currently_dark {
                    crate::config::ThemeMode::Light
                } else {
                    crate::config::ThemeMode::Dark
                };
                self.save_and_sync();
            }
        }

        // Render Drop Overlay when dragging files (Very Last)
        if self.startup_stage >= 36 {
            self.render_drop_overlay(ctx);
        }
    }

    fn on_exit(&mut self, _gl: Option<&eframe::glow::Context>) {
        self.tray_icon = None;
    }
}
</file>

<file path="src/gui/app/logic.rs">
use super::types::{
    SettingsApp, UserEvent, MOD_ALT, MOD_CONTROL, MOD_SHIFT, MOD_WIN, RESTORE_SIGNAL,
};
use crate::config::{Hotkey, ThemeMode};
use crate::gui::app::utils::simple_rand;
use crate::gui::key_mapping::{egui_key_to_vk, egui_pointer_to_vk};
use crate::gui::locale::LocaleText;
use crate::icon_gen;
use crate::{WINDOW_HEIGHT, WINDOW_WIDTH};
use eframe::egui;
use std::sync::atomic::Ordering;
use tray_icon::{MouseButton, TrayIconBuilder, TrayIconEvent};
use windows::Win32::Foundation::POINT;
use windows::Win32::Graphics::Gdi::{
    GetMonitorInfoW, MonitorFromPoint, MONITORINFO, MONITOR_DEFAULTTONEAREST,
};
use windows::Win32::UI::WindowsAndMessaging::GetCursorPos;

impl SettingsApp {
    pub(crate) fn check_updater(&mut self) {
        while let Ok(status) = self.update_rx.try_recv() {
            // Show popup notification when update is available
            if let crate::updater::UpdateStatus::UpdateAvailable { ref version, .. } = status {
                // Show blue-themed update notification with longer duration
                let ui_lang = self.config.ui_language.clone();
                let locale = crate::gui::locale::LocaleText::get(&ui_lang);
                let notification_text =
                    format!("{} v{}", locale.update_available_notification, version);
                crate::overlay::auto_copy_badge::show_update_notification(&notification_text);
            }
            self.update_status = status;
        }
    }

    pub(crate) fn update_theme_and_tray(&mut self, ctx: &egui::Context) {
        let now = ctx.input(|i| i.time);

        // 1. Check if we need to poll system theme (only if in System mode)
        let mut current_system_dark = self.last_system_theme_dark;

        if now - self.theme_check_timer > 1.0 {
            self.theme_check_timer = now;
            // Always update system state tracker, even if not currently used
            current_system_dark = crate::gui::utils::is_system_in_dark_mode();
            self.last_system_theme_dark = current_system_dark;
        }

        // 2. Calculate Effective Theme
        let effective_dark = match self.config.theme_mode {
            ThemeMode::Dark => true,
            ThemeMode::Light => false,
            ThemeMode::System => current_system_dark,
        };

        // 3. Apply Changes if Effective Theme Changed
        if effective_dark != self.last_effective_theme_dark {
            self.last_effective_theme_dark = effective_dark;

            // A. Update Visuals (egui)
            if effective_dark {
                ctx.set_visuals(egui::Visuals::dark());
            } else {
                ctx.set_visuals(egui::Visuals::light());
            }

            // B. Update Native Icons (Tray & Window) based on Effective Theme
            if let Some(tray) = &mut self.tray_icon {
                let new_icon = icon_gen::get_tray_icon(effective_dark);
                let _ = tray.set_icon(Some(new_icon));
            }
            crate::gui::utils::update_window_icon_native(effective_dark);

            // C. Update Realtime Webviews
            unsafe {
                use crate::api::realtime_audio::WM_THEME_UPDATE;
                use crate::overlay::realtime_webview::state::{REALTIME_HWND, TRANSLATION_HWND};
                use windows::Win32::Foundation::{LPARAM, WPARAM};
                use windows::Win32::UI::WindowsAndMessaging::PostMessageW;

                let realtime_hwnd = std::ptr::addr_of!(REALTIME_HWND).read();
                if !realtime_hwnd.is_invalid() {
                    let _ =
                        PostMessageW(Some(realtime_hwnd), WM_THEME_UPDATE, WPARAM(0), LPARAM(0));
                }
                let translation_hwnd = std::ptr::addr_of!(TRANSLATION_HWND).read();
                if !translation_hwnd.is_invalid() {
                    let _ = PostMessageW(
                        Some(translation_hwnd),
                        WM_THEME_UPDATE,
                        WPARAM(0),
                        LPARAM(0),
                    );
                }

                use crate::overlay::realtime_webview::state::APP_SELECTION_HWND;
                let app_sel_val = APP_SELECTION_HWND.load(std::sync::atomic::Ordering::SeqCst);
                if app_sel_val != 0 {
                    let hwnd =
                        windows::Win32::Foundation::HWND(app_sel_val as *mut std::ffi::c_void);
                    let _ = PostMessageW(Some(hwnd), WM_THEME_UPDATE, WPARAM(0), LPARAM(0));
                }
            }
        }

        // --- TRAY MENU I18N UPDATE ---
        // Update tray menu items when language changes
        if self.config.ui_language != self.last_ui_language {
            self.last_ui_language = self.config.ui_language.clone();
            let new_locale = LocaleText::get(&self.config.ui_language);
            self.tray_settings_item.set_text(new_locale.tray_settings);
            self.tray_quit_item.set_text(new_locale.tray_quit);
        }

        // --- LAZY TRAY ICON RECONCILE ---
        if self.tray_icon.is_none() {
            if now - self.tray_retry_timer > 1.0 {
                self.tray_retry_timer = now;
                let icon = icon_gen::get_tray_icon(self.last_effective_theme_dark);
                if let Ok(tray) = TrayIconBuilder::new()
                    .with_tooltip("Screen Goated Toolbox (nganlinh4)")
                    .with_icon(icon)
                    .build()
                {
                    self.tray_icon = Some(tray);
                }
            }
        }
    }

    pub(crate) fn update_startup(&mut self, ctx: &egui::Context) {
        if self.startup_stage == 0 {
            unsafe {
                let mut cursor_pos = POINT::default();
                let _ = GetCursorPos(&mut cursor_pos);
                let h_monitor = MonitorFromPoint(cursor_pos, MONITOR_DEFAULTTONEAREST);
                let mut mi = MONITORINFO::default();
                mi.cbSize = std::mem::size_of::<MONITORINFO>() as u32;
                let _ = GetMonitorInfoW(h_monitor, &mut mi);

                let work_w = (mi.rcWork.right - mi.rcWork.left) as f32;
                let work_h = (mi.rcWork.bottom - mi.rcWork.top) as f32;
                let work_left = mi.rcWork.left as f32;
                let work_top = mi.rcWork.top as f32;

                let pixels_per_point = ctx.pixels_per_point();
                let win_w_physical = WINDOW_WIDTH * pixels_per_point;
                let win_h_physical = WINDOW_HEIGHT * pixels_per_point;

                let center_x_physical = work_left + (work_w - win_w_physical) / 2.0;
                let center_y_physical = work_top + (work_h - win_h_physical) / 2.0;

                let x_logical = center_x_physical / pixels_per_point;
                let y_logical = center_y_physical / pixels_per_point;

                if !self.config.start_in_tray {
                    ctx.send_viewport_cmd(egui::ViewportCommand::OuterPosition(egui::pos2(
                        x_logical, y_logical,
                    )));
                    ctx.send_viewport_cmd(egui::ViewportCommand::InnerSize(egui::vec2(
                        WINDOW_WIDTH,
                        WINDOW_HEIGHT,
                    )));
                }

                self.startup_stage = 1;
                ctx.request_repaint();
                return;
            }
        } else if self.startup_stage == 1 {
            // --- EARLY INIT: TRULY BEFORE SPLASH ---

            // 1. Start favorite bubble (WebView creation)
            let has_favorites = self.config.presets.iter().any(|p| p.is_favorite);
            if self.config.show_favorite_bubble && has_favorites {
                crate::overlay::favorite_bubble::show_favorite_bubble();
            }

            // 2. Trigger auto-update check (Network/Disk IO)
            if let Some(updater) = &self.updater {
                updater.check_for_updates();
            }

            self.startup_stage = 2;
            ctx.request_repaint();
            return;
        } else if self.startup_stage < 35 {
            // Wait for ~35 frames to let background windows (Bubble/Tray) settle
            self.startup_stage += 1;
            ctx.request_repaint();
            return;
        } else if self.startup_stage == 35 {
            // CRITICAL: Wait for Tray Icon to be ready before starting splash
            // This ensures all shell integration is settled.
            if self.tray_icon.is_none() {
                // If tray failed or is still initializing, keep waiting
                ctx.request_repaint();
                return;
            }

            if self.config.start_in_tray {
                // ENSURE HIDDEN: If starting in tray, we must stay invisible.
                ctx.send_viewport_cmd(egui::ViewportCommand::Visible(false));
            } else {
                // SHOW SPLASH: Create it NOW for perfect t=0 timing.
                if self.splash.is_none() {
                    self.splash = Some(crate::gui::splash::SplashScreen::new(ctx));
                }

                ctx.send_viewport_cmd(egui::ViewportCommand::InnerSize(egui::vec2(
                    WINDOW_WIDTH,
                    WINDOW_HEIGHT,
                )));
                ctx.send_viewport_cmd(egui::ViewportCommand::Visible(true));
            }

            self.startup_stage = 36;
        }
    }

    /// Called exactly once when the splash screen finishes its exit animation.
    fn on_splash_finished(&mut self) {
        // High-prio tasks now done before splash.
    }

    pub(crate) fn update_bubble_sync(&mut self) {
        // --- FAVORITE BUBBLE SYNC (Change-Detection Only) ---
        // Only trigger show/hide when state actually changes to avoid per-frame overhead
        let current_has_favorites = self.config.presets.iter().any(|p| p.is_favorite);
        let current_bubble_enabled = self.config.show_favorite_bubble;

        // Update tray item enabled state (cheap operation)
        self.tray_favorite_bubble_item
            .set_enabled(current_has_favorites);

        // Detect state change
        let state_changed = current_bubble_enabled != self.last_bubble_enabled
            || current_has_favorites != self.last_has_favorites;

        if state_changed {
            self.last_bubble_enabled = current_bubble_enabled;
            self.last_has_favorites = current_has_favorites;

            if current_bubble_enabled && current_has_favorites {
                crate::overlay::favorite_bubble::show_favorite_bubble();
            } else {
                crate::overlay::favorite_bubble::hide_favorite_bubble();
            }
        }
    }

    pub(crate) fn update_splash(&mut self, ctx: &egui::Context) {
        if let Some(splash) = &mut self.splash {
            match splash.update(ctx) {
                crate::gui::splash::SplashStatus::Ongoing => {
                    // Do NOT return here. Continue to render main UI underneath.
                }
                crate::gui::splash::SplashStatus::Finished => {
                    self.splash = None;
                    self.on_splash_finished();
                }
            }
        }
    }

    pub(crate) fn check_restore_signal(&mut self, ctx: &egui::Context) {
        if RESTORE_SIGNAL.swap(false, Ordering::SeqCst) {
            self.restore_window(ctx);
        }
    }

    pub(crate) fn update_tips_logic(&mut self, ctx: &egui::Context) {
        let text = LocaleText::get(&self.config.ui_language);
        let now = ctx.input(|i| i.time);

        // Initialize timer on first run
        if self.tip_timer == 0.0 {
            self.tip_timer = now;
        }

        // Calculate duration based on text length (reading speed ~ 15 chars/sec + 2s base)
        let current_tip = text
            .tips_list
            .get(self.current_tip_idx)
            .unwrap_or(&"")
            .to_string();
        let display_duration = (2.0 + (current_tip.len() as f64 * 0.06)) as f32;
        let fade_duration = 0.5f32;

        let elapsed = (now - self.tip_timer) as f32;

        if self.tip_is_fading_in {
            // Fading In
            self.tip_fade_state = (elapsed / fade_duration as f32).min(1.0);
            if elapsed >= fade_duration {
                self.tip_fade_state = 1.0;
                // Fully visible, wait for duration
                if elapsed >= fade_duration + display_duration {
                    self.tip_is_fading_in = false; // Start fading out
                    self.tip_timer = now; // Reset timer for fade-out
                }
            }
            ctx.request_repaint();
        } else {
            // Fading Out
            self.tip_fade_state = (1.0 - (elapsed / fade_duration as f32)).max(0.0);
            if elapsed >= fade_duration {
                self.tip_fade_state = 0.0;

                // Switch to next random tip
                self.rng_seed = simple_rand(self.rng_seed);
                if !text.tips_list.is_empty() {
                    let next = (self.rng_seed as usize) % text.tips_list.len();
                    // Avoid repeating same tip if possible
                    if next == self.current_tip_idx && text.tips_list.len() > 1 {
                        self.current_tip_idx = (next + 1) % text.tips_list.len();
                    } else {
                        self.current_tip_idx = next;
                    }
                }

                self.tip_timer = now; // Reset timer
                self.tip_is_fading_in = true; // Start fading in
            }
            ctx.request_repaint();
        }
    }

    pub(crate) fn update_hotkey_recording(&mut self, ctx: &egui::Context) {
        if let Some(preset_idx) = self.recording_hotkey_for_preset {
            let mut key_recorded: Option<(u32, u32, String)> = None;
            let mut cancel = false;

            ctx.input(|i| {
                if i.key_pressed(egui::Key::Escape) {
                    cancel = true;
                } else {
                    let mut modifiers_bitmap = 0;
                    if i.modifiers.ctrl {
                        modifiers_bitmap |= MOD_CONTROL;
                    }
                    if i.modifiers.alt {
                        modifiers_bitmap |= MOD_ALT;
                    }
                    if i.modifiers.shift {
                        modifiers_bitmap |= MOD_SHIFT;
                    }
                    if i.modifiers.command {
                        modifiers_bitmap |= MOD_WIN;
                    }

                    // Check Keyboard Events
                    for event in &i.events {
                        if let egui::Event::Key {
                            key, pressed: true, ..
                        } = event
                        {
                            if let Some(vk) = egui_key_to_vk(key) {
                                if !matches!(vk, 16 | 17 | 18 | 91 | 92) {
                                    let key_name =
                                        format!("{:?}", key).trim_start_matches("Key").to_string();
                                    key_recorded = Some((vk, modifiers_bitmap, key_name));
                                }
                            }
                        }
                    }

                    // Check Mouse Events (Middle, Extra1, Extra2)
                    if key_recorded.is_none() {
                        let mouse_buttons = [
                            egui::PointerButton::Middle,
                            egui::PointerButton::Extra1,
                            egui::PointerButton::Extra2,
                        ];

                        for btn in mouse_buttons {
                            if i.pointer.button_pressed(btn) {
                                if let Some(vk) = egui_pointer_to_vk(&btn) {
                                    let name = match btn {
                                        egui::PointerButton::Middle => "Middle Click",
                                        egui::PointerButton::Extra1 => "Mouse Back",
                                        egui::PointerButton::Extra2 => "Mouse Forward",
                                        _ => "Mouse",
                                    }
                                    .to_string();
                                    key_recorded = Some((vk, modifiers_bitmap, name));
                                    break;
                                }
                            }
                        }
                    }
                }
            });

            if cancel {
                self.recording_hotkey_for_preset = None;
                self.hotkey_conflict_msg = None;
            } else if let Some((vk, mods, key_name)) = key_recorded {
                if let Some(msg) = self.check_hotkey_conflict(vk, mods, preset_idx) {
                    self.hotkey_conflict_msg = Some(msg);
                } else {
                    let mut name_parts = Vec::new();
                    if (mods & MOD_CONTROL) != 0 {
                        name_parts.push("Ctrl".to_string());
                    }
                    if (mods & MOD_ALT) != 0 {
                        name_parts.push("Alt".to_string());
                    }
                    if (mods & MOD_SHIFT) != 0 {
                        name_parts.push("Shift".to_string());
                    }
                    if (mods & MOD_WIN) != 0 {
                        name_parts.push("Win".to_string());
                    }
                    name_parts.push(key_name);

                    let new_hotkey = Hotkey {
                        code: vk,
                        modifiers: mods,
                        name: name_parts.join(" + "),
                    };

                    if let Some(preset) = self.config.presets.get_mut(preset_idx) {
                        if !preset
                            .hotkeys
                            .iter()
                            .any(|h| h.code == vk && h.modifiers == mods)
                        {
                            preset.hotkeys.push(new_hotkey);
                            self.save_and_sync();
                        }
                    }
                    self.recording_hotkey_for_preset = None;
                    self.hotkey_conflict_msg = None;
                }
            }
        }
    }

    pub(crate) fn update_sr_hotkey_recording(&mut self, ctx: &egui::Context) {
        if self.recording_sr_hotkey {
            let mut key_recorded: Option<(u32, u32, String)> = None;
            let mut cancel = false;

            ctx.input(|i| {
                if i.key_pressed(egui::Key::Escape) {
                    cancel = true;
                } else {
                    let mut modifiers_bitmap = 0;
                    if i.modifiers.ctrl {
                        modifiers_bitmap |= MOD_CONTROL;
                    }
                    if i.modifiers.alt {
                        modifiers_bitmap |= MOD_ALT;
                    }
                    if i.modifiers.shift {
                        modifiers_bitmap |= MOD_SHIFT;
                    }
                    if i.modifiers.command {
                        modifiers_bitmap |= MOD_WIN;
                    }

                    // Check Keyboard Events
                    for event in &i.events {
                        if let egui::Event::Key {
                            key, pressed: true, ..
                        } = event
                        {
                            if let Some(vk) = egui_key_to_vk(key) {
                                if !matches!(vk, 16 | 17 | 18 | 91 | 92) {
                                    let key_name =
                                        format!("{:?}", key).trim_start_matches("Key").to_string();
                                    key_recorded = Some((vk, modifiers_bitmap, key_name));
                                }
                            }
                        }
                    }

                    // Check Mouse Events
                    if key_recorded.is_none() {
                        let mouse_buttons = [
                            egui::PointerButton::Middle,
                            egui::PointerButton::Extra1,
                            egui::PointerButton::Extra2,
                        ];

                        for btn in mouse_buttons {
                            if i.pointer.button_pressed(btn) {
                                if let Some(vk) = egui_pointer_to_vk(&btn) {
                                    let name = match btn {
                                        egui::PointerButton::Middle => "Middle Click",
                                        egui::PointerButton::Extra1 => "Mouse Back",
                                        egui::PointerButton::Extra2 => "Mouse Forward",
                                        _ => "Mouse",
                                    }
                                    .to_string();
                                    key_recorded = Some((vk, modifiers_bitmap, name));
                                    break;
                                }
                            }
                        }
                    }
                }
            });

            if cancel {
                self.recording_sr_hotkey = false;
            } else if let Some((vk, mods, key_name)) = key_recorded {
                let mut name_parts = Vec::new();
                if (mods & MOD_CONTROL) != 0 {
                    name_parts.push("Ctrl".to_string());
                }
                if (mods & MOD_ALT) != 0 {
                    name_parts.push("Alt".to_string());
                }
                if (mods & MOD_SHIFT) != 0 {
                    name_parts.push("Shift".to_string());
                }
                if (mods & MOD_WIN) != 0 {
                    name_parts.push("Win".to_string());
                }
                name_parts.push(key_name);

                let new_hotkey = Hotkey {
                    code: vk,
                    modifiers: mods,
                    name: name_parts.join(" + "),
                };

                if let Some(msg) = self.config.check_hotkey_conflict(vk, mods, None) {
                    crate::log_info!("Hotkey conflict: {}", msg);
                } else {
                    self.config.screen_record_hotkeys.push(new_hotkey);
                    self.save_and_sync();
                }
                self.recording_sr_hotkey = false;
            }
        }
    }

    pub(crate) fn handle_events(&mut self, ctx: &egui::Context) {
        // --- Event Handling ---
        while let Ok(event) = self.event_rx.try_recv() {
            match event {
                UserEvent::Tray(tray_event) => match tray_event {
                    TrayIconEvent::DoubleClick {
                        button: MouseButton::Left,
                        ..
                    } => {
                        self.restore_window(ctx);
                    }

                    _ => {}
                },
                UserEvent::Menu(menu_event) => {
                    match menu_event.id.0.as_str() {
                        "1002" => {
                            self.restore_window(ctx);
                        }
                        "1003" => {
                            // Toggle favorite bubble
                            self.config.show_favorite_bubble = !self.config.show_favorite_bubble;
                            self.tray_favorite_bubble_item
                                .set_checked(self.config.show_favorite_bubble);
                            self.save_and_sync();

                            // Spawn or dismiss the bubble overlay
                            if self.config.show_favorite_bubble {
                                crate::overlay::favorite_bubble::show_favorite_bubble();
                            } else {
                                crate::overlay::favorite_bubble::hide_favorite_bubble();
                            }
                        }
                        _ => {}
                    }
                }
            }
        }
    }

    pub(crate) fn handle_close_request(&mut self, ctx: &egui::Context) {
        if ctx.input(|i| i.viewport().close_requested()) {
            if !self.is_quitting {
                ctx.send_viewport_cmd(egui::ViewportCommand::CancelClose);
                ctx.send_viewport_cmd(egui::ViewportCommand::Visible(false));
            }
        }
    }
}
</file>

<file path="src/gui/app/rendering.rs">
use super::types::SettingsApp;
use crate::gui::locale::LocaleText;
use crate::gui::settings_ui::node_graph::{blocks_to_snarl, snarl_to_graph};
use crate::gui::settings_ui::{
    render_footer, render_global_settings, render_history_panel, render_preset_editor,
    render_sidebar, ViewMode,
};
use eframe::egui;
use egui::text::{LayoutJob, TextFormat};
use image;

// compile_error!("Find me!");
impl SettingsApp {
    pub(crate) fn render_footer_and_tips_modal(&mut self, ctx: &egui::Context) {
        let text = LocaleText::get(&self.config.ui_language);
        let visuals = ctx.style().visuals.clone();
        let footer_bg = if visuals.dark_mode {
            egui::Color32::from_gray(20)
        } else {
            egui::Color32::from_gray(240)
        };

        // Determine current tip text for footer
        let current_tip = text
            .tips_list
            .get(self.current_tip_idx)
            .unwrap_or(&"")
            .to_string();

        egui::TopBottomPanel::bottom("footer_panel")
            .resizable(false)
            .show_separator_line(false)
            .frame(
                egui::Frame::default()
                    .inner_margin(egui::Margin::symmetric(10, 4))
                    .fill(footer_bg)
                    .corner_radius(egui::CornerRadius {
                        nw: 0,
                        ne: 0,
                        sw: if ctx.input(|i| i.viewport().maximized.unwrap_or(false)) {
                            0
                        } else {
                            12
                        },
                        se: if ctx.input(|i| i.viewport().maximized.unwrap_or(false)) {
                            0
                        } else {
                            12
                        },
                    })
                    .stroke(egui::Stroke::NONE),
            )
            .show(ctx, |ui| {
                render_footer(
                    ui,
                    &text,
                    current_tip.clone(),
                    self.tip_fade_state,
                    &mut self.show_tips_modal,
                );
            });

        // [TIPS POPUP]
        let tips_popup_id = egui::Id::new("tips_popup_modal");

        if self.show_tips_modal {
            // Register this as an open popup so any_popup_open() returns true
            egui::Popup::open_id(ctx, tips_popup_id);

            let tips_list_copy = text.tips_list.clone();
            let tips_title = text.tips_title;

            // Dark semi-transparent backdrop (disabled)
            // let backdrop_layer =
            //     egui::LayerId::new(egui::Order::Middle, egui::Id::new("tips_backdrop"));
            // let backdrop_painter = ctx.layer_painter(backdrop_layer);
            // backdrop_painter.rect_filled(screen_rect, 0.0, egui::Color32::from_black_alpha(120));

            // Popup area centered on screen
            egui::Area::new(tips_popup_id)
                .order(egui::Order::Tooltip) // High priority layer
                .anchor(egui::Align2::CENTER_CENTER, egui::vec2(0.0, 0.0))
                .show(ctx, |ui| {
                    egui::Frame::popup(ui.style())
                        .inner_margin(egui::Margin::same(16))
                        .show(ui, |ui| {
                            ui.set_max_width(1000.0);
                            ui.set_max_height(550.0);

                            // Header with title and close button
                            ui.horizontal(|ui| {
                                ui.heading(tips_title);
                                ui.with_layout(
                                    egui::Layout::right_to_left(egui::Align::Center),
                                    |ui| {
                                        if crate::gui::icons::icon_button(
                                            ui,
                                            crate::gui::icons::Icon::Close,
                                        )
                                        .clicked()
                                        {
                                            self.show_tips_modal = false;
                                        }
                                    },
                                );
                            });
                            ui.separator();
                            ui.add_space(8.0);

                            // Scrollable tips list
                            egui::ScrollArea::vertical()
                                .max_height(400.0)
                                .auto_shrink([false; 2])
                                .show(ui, |ui| {
                                    for (i, tip) in tips_list_copy.iter().enumerate() {
                                        let is_dark_mode = ctx.style().visuals.dark_mode;
                                        let layout_job =
                                            format_tip_with_bold(i + 1, tip, is_dark_mode);
                                        ui.label(layout_job);
                                        if i < tips_list_copy.len() - 1 {
                                            ui.add_space(8.0);
                                            ui.separator();
                                            ui.add_space(8.0);
                                        }
                                    }
                                });
                        });
                });

            // Close on click outside (check if clicked outside the popup area)
            if ctx.input(|i| i.pointer.any_click()) {
                if let Some(pos) = ctx.input(|i| i.pointer.interact_pos()) {
                    // Check if click is on the backdrop (outside popup content)
                    if let Some(layer) = ctx.layer_id_at(pos) {
                        if layer.id == egui::Id::new("tips_backdrop") {
                            self.show_tips_modal = false;
                        }
                    }
                }
            }

            // Close on Escape
            if ctx.input(|i| i.key_pressed(egui::Key::Escape)) {
                self.show_tips_modal = false;
            }
        }

        // Render Download Manager Modal
        self.download_manager.render(ctx, &text);
    }

    pub(crate) fn render_title_bar(&mut self, ctx: &egui::Context) {
        let text = LocaleText::get(&self.config.ui_language);
        let is_dark = ctx.style().visuals.dark_mode;
        let is_maximized = ctx.input(|i| i.viewport().maximized.unwrap_or(false));

        // Match Footer Color
        let bar_bg = if is_dark {
            egui::Color32::from_gray(20)
        } else {
            egui::Color32::from_gray(240)
        };

        egui::TopBottomPanel::top("title_bar")
            .exact_height(40.0)
            .frame(
                egui::Frame::default()
                    .inner_margin(if is_maximized {
                        egui::Margin {
                            left: 8,
                            right: 0,
                            top: 0,
                            bottom: 0,
                        }
                    } else {
                        egui::Margin {
                            left: 8,
                            right: 8,
                            top: 6,
                            bottom: 6,
                        }
                    })
                    .fill(bar_bg)
                    .corner_radius(egui::CornerRadius {
                        nw: if is_maximized { 0 } else { 12 },
                        ne: if is_maximized { 0 } else { 12 },
                        sw: 0,
                        se: 0,
                    })
                    .stroke(egui::Stroke::NONE),
            )
            .show_separator_line(false)
            .show(ctx, |ui| {
                // --- DRAG HANDLE (Whole Bar) ---
                // We use interact instead of allocate_response to avoid pushing content
                let drag_resp =
                    ui.interact(ui.max_rect(), ui.id().with("drag_bar"), egui::Sense::drag());
                if drag_resp.drag_started() {
                    ui.ctx().send_viewport_cmd(egui::ViewportCommand::StartDrag);
                }

                ui.with_layout(egui::Layout::left_to_right(egui::Align::Center), |ui| {
                    ui.spacing_mut().item_spacing.x = 6.0;

                    // --- LEFT SIDE: Sidebar Controls ---
                    // Theme Switcher
                    let (theme_icon, tooltip) = match self.config.theme_mode {
                        crate::config::ThemeMode::Dark => {
                            (crate::gui::icons::Icon::Moon, "Theme: Dark")
                        }
                        crate::config::ThemeMode::Light => {
                            (crate::gui::icons::Icon::Sun, "Theme: Light")
                        }
                        crate::config::ThemeMode::System => {
                            (crate::gui::icons::Icon::Device, "Theme: System (Auto)")
                        }
                    };

                    if crate::gui::icons::icon_button_sized(ui, theme_icon, 18.0)
                        .on_hover_text(tooltip)
                        .clicked()
                    {
                        self.config.theme_mode = match self.config.theme_mode {
                            crate::config::ThemeMode::System => crate::config::ThemeMode::Dark,
                            crate::config::ThemeMode::Dark => crate::config::ThemeMode::Light,
                            crate::config::ThemeMode::Light => crate::config::ThemeMode::System,
                        };
                        self.save_and_sync();
                    }

                    // Language Switcher
                    let original_lang = self.config.ui_language.clone();
                    let lang_flag = match self.config.ui_language.as_str() {
                        "vi" => "🇻🇳",
                        "ko" => "🇰🇷",
                        _ => "🇺🇸",
                    };
                    egui::ComboBox::from_id_salt("title_lang_switch")
                        .width(30.0)
                        .selected_text(lang_flag)
                        .show_ui(ui, |ui| {
                            ui.selectable_value(
                                &mut self.config.ui_language,
                                "en".to_string(),
                                "🇺🇸 English",
                            );
                            ui.selectable_value(
                                &mut self.config.ui_language,
                                "vi".to_string(),
                                "🇻🇳 Tiếng Việt",
                            );
                            ui.selectable_value(
                                &mut self.config.ui_language,
                                "ko".to_string(),
                                "🇰🇷 한국어",
                            );
                        });
                    if original_lang != self.config.ui_language {
                        self.save_and_sync();
                    }

                    // History Button
                    ui.spacing_mut().item_spacing.x = 2.0;
                    crate::gui::icons::draw_icon_static(
                        ui,
                        crate::gui::icons::Icon::History,
                        Some(14.0),
                    );
                    let is_history = matches!(self.view_mode, ViewMode::History);
                    if ui
                        .selectable_label(
                            is_history,
                            egui::RichText::new(text.history_btn).size(13.0),
                        )
                        .clicked()
                    {
                        self.view_mode = ViewMode::History;
                    }

                    ui.spacing_mut().item_spacing.x = 6.0;
                    ui.add_space(2.0);

                    // Chill Corner (PromptDJ)
                    if ui
                        .add(
                            egui::Button::new(
                                egui::RichText::new(format!("🎵 {}", text.prompt_dj_btn))
                                    .color(egui::Color32::WHITE)
                                    .size(12.0),
                            )
                            .fill(egui::Color32::from_rgb(100, 100, 200))
                            .corner_radius(6.0),
                        )
                        .clicked()
                    {
                        crate::overlay::prompt_dj::show_prompt_dj();
                    }

                    // Download Manager
                    if ui
                        .add(
                            egui::Button::new(
                                egui::RichText::new(format!("⬇ {}", text.download_feature_btn))
                                    .color(egui::Color32::WHITE)
                                    .size(12.0),
                            )
                            .fill(egui::Color32::from_rgb(200, 100, 100))
                            .corner_radius(6.0),
                        )
                        .clicked()
                    {
                        self.download_manager.show_window = true;
                    }

                    // Screen Record
                    if ui
                        .add(
                            egui::Button::new(
                                egui::RichText::new(format!("🎥 {}", text.screen_record_btn))
                                    .color(egui::Color32::WHITE)
                                    .size(12.0),
                            )
                            .fill(egui::Color32::from_rgb(60, 140, 100))
                            .corner_radius(6.0),
                        )
                        .clicked()
                    {
                        crate::overlay::screen_record::show_screen_record();
                    }

                    // Help Assistant
                    let help_bg = if is_dark {
                        egui::Color32::from_rgb(80, 60, 120)
                    } else {
                        egui::Color32::from_rgb(180, 160, 220)
                    };
                    if ui
                        .add(
                            egui::Button::new(
                                egui::RichText::new(format!("❓ {}", text.help_assistant_btn))
                                    .color(egui::Color32::WHITE)
                                    .size(12.0),
                            )
                            .fill(help_bg)
                            .corner_radius(6.0),
                        )
                        .on_hover_text(text.help_assistant_title)
                        .clicked()
                    {
                        std::thread::spawn(|| {
                            crate::gui::settings_ui::help_assistant::show_help_input();
                        });
                    }

                    // Global Settings
                    ui.spacing_mut().item_spacing.x = 2.0;
                    crate::gui::icons::draw_icon_static(
                        ui,
                        crate::gui::icons::Icon::Settings,
                        Some(14.0),
                    );
                    let is_global = matches!(self.view_mode, ViewMode::Global);
                    if ui
                        .selectable_label(
                            is_global,
                            egui::RichText::new(text.global_settings).size(13.0),
                        )
                        .clicked()
                    {
                        self.view_mode = ViewMode::Global;
                    }

                    // --- RIGHT SIDE: Window Controls & Branding ---
                    ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                        ui.spacing_mut().item_spacing.x = 0.0;

                        let grid_h = if is_maximized { 40.0 } else { 28.0 };
                        let btn_size = egui::vec2(40.0, grid_h);

                        // Close Button
                        let close_resp = ui.allocate_response(btn_size, egui::Sense::click());
                        if close_resp.clicked() {
                            ui.ctx().send_viewport_cmd(egui::ViewportCommand::Close);
                        }
                        if close_resp.hovered() {
                            ui.painter().rect_filled(
                                close_resp.rect,
                                0.0,
                                egui::Color32::from_rgb(232, 17, 35),
                            );
                        }
                        crate::gui::icons::paint_icon(
                            ui.painter(),
                            close_resp
                                .rect
                                .shrink2(egui::vec2(12.0, if is_maximized { 12.0 } else { 6.0 })),
                            crate::gui::icons::Icon::Close,
                            if close_resp.hovered() {
                                egui::Color32::WHITE
                            } else {
                                if is_dark {
                                    egui::Color32::WHITE
                                } else {
                                    egui::Color32::BLACK
                                }
                            },
                        );

                        // Maximize / Restore
                        let max_resp = ui.allocate_response(btn_size, egui::Sense::click());
                        if max_resp.clicked() {
                            ui.ctx()
                                .send_viewport_cmd(egui::ViewportCommand::Maximized(!is_maximized));
                        }
                        if max_resp.hovered() {
                            ui.painter().rect_filled(
                                max_resp.rect,
                                0.0,
                                if is_dark {
                                    egui::Color32::from_gray(60)
                                } else {
                                    egui::Color32::from_gray(220)
                                },
                            );
                        }
                        let max_icon = if is_maximized {
                            crate::gui::icons::Icon::Restore
                        } else {
                            crate::gui::icons::Icon::Maximize
                        };
                        crate::gui::icons::paint_icon(
                            ui.painter(),
                            max_resp
                                .rect
                                .shrink2(egui::vec2(13.0, if is_maximized { 13.0 } else { 7.0 })),
                            max_icon,
                            if is_dark {
                                egui::Color32::WHITE
                            } else {
                                egui::Color32::BLACK
                            },
                        );

                        // Minimize
                        let min_resp = ui.allocate_response(btn_size, egui::Sense::click());
                        if min_resp.clicked() {
                            ui.ctx()
                                .send_viewport_cmd(egui::ViewportCommand::Minimized(true));
                        }
                        if min_resp.hovered() {
                            ui.painter().rect_filled(
                                min_resp.rect,
                                0.0,
                                if is_dark {
                                    egui::Color32::from_gray(60)
                                } else {
                                    egui::Color32::from_gray(220)
                                },
                            );
                        }
                        crate::gui::icons::paint_icon(
                            ui.painter(),
                            min_resp
                                .rect
                                .shrink2(egui::vec2(13.0, if is_maximized { 13.0 } else { 7.0 })),
                            crate::gui::icons::Icon::Minimize,
                            if is_dark {
                                egui::Color32::WHITE
                            } else {
                                egui::Color32::BLACK
                            },
                        );

                        ui.add_space(8.0);

                        // Title Text
                        let title_text =
                            egui::RichText::new("Screen Goated Toolbox (by nganlinh4)")
                                .strong()
                                .size(13.0)
                                .color(if is_dark {
                                    egui::Color32::WHITE
                                } else {
                                    egui::Color32::BLACK
                                });

                        if ui
                            .add(egui::Label::new(title_text).sense(egui::Sense::click()))
                            .on_hover_cursor(egui::CursorIcon::PointingHand)
                            .clicked()
                        {
                            ui.ctx().open_url(egui::OpenUrl::new_tab(
                                "https://github.com/nganlinh4/screen-goated-toolbox",
                            ));
                        }

                        ui.add_space(6.0);

                        // App Icon
                        let icon_handle = if is_dark {
                            if self.icon_dark.is_none() {
                                let bytes = include_bytes!("../../../assets/app-icon-small.png");
                                if let Ok(image) = image::load_from_memory(bytes) {
                                    let resized = image.resize(
                                        128,
                                        20,
                                        image::imageops::FilterType::Lanczos3,
                                    );
                                    let image_buffer = resized.to_rgba8();
                                    let size =
                                        [image_buffer.width() as _, image_buffer.height() as _];
                                    let pixels = image_buffer.as_raw();
                                    let color_image =
                                        egui::ColorImage::from_rgba_unmultiplied(size, pixels);
                                    let handle = ctx.load_texture(
                                        "app-icon-dark",
                                        color_image,
                                        Default::default(),
                                    );
                                    self.icon_dark = Some(handle);
                                }
                            }
                            self.icon_dark.as_ref()
                        } else {
                            if self.icon_light.is_none() {
                                let bytes =
                                    include_bytes!("../../../assets/app-icon-small-light.png");
                                if let Ok(image) = image::load_from_memory(bytes) {
                                    let resized = image.resize(
                                        128,
                                        20,
                                        image::imageops::FilterType::Lanczos3,
                                    );
                                    let image_buffer = resized.to_rgba8();
                                    let size =
                                        [image_buffer.width() as _, image_buffer.height() as _];
                                    let pixels = image_buffer.as_raw();
                                    let color_image =
                                        egui::ColorImage::from_rgba_unmultiplied(size, pixels);
                                    let handle = ctx.load_texture(
                                        "app-icon-light",
                                        color_image,
                                        Default::default(),
                                    );
                                    self.icon_light = Some(handle);
                                }
                            }
                            self.icon_light.as_ref()
                        };

                        if let Some(texture) = icon_handle {
                            ui.add(egui::Image::new(texture).max_height(20.0));
                        }
                    });
                });
            });
    }

    pub(crate) fn render_main_layout(&mut self, ctx: &egui::Context) {
        let text = LocaleText::get(&self.config.ui_language);
        let _is_dark = ctx.style().visuals.dark_mode;

        egui::CentralPanel::default()
            .frame(
                egui::Frame::NONE
                    .fill(ctx.style().visuals.panel_fill)
                    .corner_radius(egui::CornerRadius {
                        nw: 0,
                        ne: 0,
                        sw: 0, // Footer handles bottom corners now
                        se: 0, // Footer handles bottom corners now
                    }),
            )
            .show(ctx, |ui| {
                let available_width = ui.available_width();
                let left_width = available_width * 0.35;
                let right_width = available_width * 0.65;

                ui.horizontal(|ui| {
                    // Left Sidebar
                    ui.allocate_ui_with_layout(
                        egui::vec2(left_width, ui.available_height()),
                        egui::Layout::top_down(egui::Align::Min),
                        |ui| {
                            // Add Left Margin/Padding for Sidebar
                            egui::Frame::NONE
                                .inner_margin(egui::Margin {
                                    left: 8,
                                    right: 0,
                                    top: 8,
                                    bottom: 0,
                                })
                                .show(ui, |ui| {
                                    if render_sidebar(
                                        ui,
                                        &mut self.config,
                                        &mut self.view_mode,
                                        &text,
                                    ) {
                                        self.save_and_sync();
                                    }
                                    self.update_sr_hotkey_recording(ctx);
                                });
                        },
                    );

                    ui.add_space(10.0);

                    // Right Detail View
                    ui.allocate_ui_with_layout(
                        egui::vec2((right_width - 20.0).max(0.0), ui.available_height()),
                        egui::Layout::top_down(egui::Align::Min),
                        |ui| {
                            match self.view_mode {
                                ViewMode::Global => {
                                    let usage_stats = {
                                        let app = self.app_state_ref.lock().unwrap();
                                        app.model_usage_stats.clone()
                                    };
                                    if render_global_settings(
                                        ui,
                                        &mut self.config,
                                        &mut self.show_api_key,
                                        &mut self.show_gemini_api_key,
                                        &mut self.show_openrouter_api_key,
                                        &mut self.show_cerebras_api_key,
                                        &usage_stats,
                                        &self.updater,
                                        &self.update_status,
                                        &mut self.run_at_startup,
                                        &self.auto_launcher,
                                        self.current_admin_state, // <-- Pass current admin state
                                        &text,
                                        &mut self.show_usage_modal,
                                        &mut self.show_tts_modal,
                                        &mut self.show_tools_modal,
                                        &mut self.download_manager,
                                        &self.cached_audio_devices,
                                        &mut self.recording_sr_hotkey,
                                    ) {
                                        self.save_and_sync();
                                    }
                                }
                                ViewMode::History => {
                                    let history_manager = {
                                        let app = self.app_state_ref.lock().unwrap();
                                        app.history.clone()
                                    };
                                    if render_history_panel(
                                        ui,
                                        &mut self.config,
                                        &history_manager,
                                        &mut self.search_query,
                                        &text,
                                    ) {
                                        self.save_and_sync();
                                    }
                                }
                                ViewMode::Preset(idx) => {
                                    // Sync snarl state if switching presets or first load
                                    if self.last_edited_preset_idx != Some(idx) {
                                        if idx < self.config.presets.len() {
                                            self.snarl = Some(blocks_to_snarl(
                                                &self.config.presets[idx].blocks,
                                                &self.config.presets[idx].block_connections,
                                                &self.config.presets[idx].preset_type,
                                            ));
                                            self.last_edited_preset_idx = Some(idx);
                                        }
                                    }

                                    if let Some(snarl) = &mut self.snarl {
                                        if render_preset_editor(
                                            ui,
                                            &mut self.config,
                                            idx,
                                            &mut self.search_query,
                                            &mut self.cached_monitors,
                                            &mut self.recording_hotkey_for_preset,
                                            &self.hotkey_conflict_msg,
                                            &text,
                                            snarl,
                                        ) {
                                            // Sync back to blocks and connections
                                            if idx < self.config.presets.len() {
                                                let (blocks, connections) = snarl_to_graph(snarl);
                                                self.config.presets[idx].blocks = blocks;
                                                self.config.presets[idx].block_connections =
                                                    connections;
                                            }
                                            self.save_and_sync();
                                        }
                                    }
                                }
                            }
                        },
                    );
                });
            });

        // Help assistant is now handled via TextInput overlay (show_help_input)
        // No egui modal rendering needed
    }

    pub(crate) fn render_window_resize_handles(&self, ctx: &egui::Context) {
        let border = 8.0; // Increased sensitivity
        let corner = 16.0; // Larger corner area

        // Fix recursive lock: Get inner_rect first, release lock, then fallback
        let inner_rect = ctx.input(|i| i.viewport().inner_rect);
        let viewport_rect = inner_rect.unwrap_or_else(|| ctx.viewport_rect());
        let size = viewport_rect.size();

        // Use a single Area for all resize handles to reduce overhead
        // Disable resize when maximized
        if ctx.input(|i| i.viewport().maximized.unwrap_or(false)) {
            return;
        }

        egui::Area::new(egui::Id::new("resize_handles_overlay"))
            .order(egui::Order::Debug)
            .fixed_pos(egui::Pos2::ZERO)
            .show(ctx, |ui| {
                let directions = [
                    // Corners (NorthWest, NorthEast, SouthWest, SouthEast)
                    (
                        egui::Rect::from_min_max(egui::Pos2::ZERO, egui::Pos2::new(corner, corner)),
                        egui::viewport::ResizeDirection::NorthWest,
                        "nw",
                    ),
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(size.x - corner, 0.0),
                            egui::Pos2::new(size.x, corner),
                        ),
                        egui::viewport::ResizeDirection::NorthEast,
                        "ne",
                    ),
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(0.0, size.y - corner),
                            egui::Pos2::new(corner, size.y),
                        ),
                        egui::viewport::ResizeDirection::SouthWest,
                        "sw",
                    ),
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(size.x - corner, size.y - corner),
                            egui::Pos2::new(size.x, size.y),
                        ),
                        egui::viewport::ResizeDirection::SouthEast,
                        "se",
                    ),
                    // Edges (North, South, West, East)
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(corner, 0.0),
                            egui::Pos2::new(size.x - corner, border),
                        ),
                        egui::viewport::ResizeDirection::North,
                        "n",
                    ),
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(corner, size.y - border),
                            egui::Pos2::new(size.x - corner, size.y),
                        ),
                        egui::viewport::ResizeDirection::South,
                        "s",
                    ),
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(0.0, corner),
                            egui::Pos2::new(border, size.y - corner),
                        ),
                        egui::viewport::ResizeDirection::West,
                        "w",
                    ),
                    (
                        egui::Rect::from_min_max(
                            egui::Pos2::new(size.x - border, corner),
                            egui::Pos2::new(size.x, size.y - corner),
                        ),
                        egui::viewport::ResizeDirection::East,
                        "e",
                    ),
                ];

                for (rect, dir, id_suffix) in directions {
                    // Use ui.allocate_rect to reserve space (though in an Area it might not push layout much if fixed,
                    // but interaction is key). ui.interact is better for explicit rects.
                    let response = ui.interact(rect, ui.id().with(id_suffix), egui::Sense::drag());

                    if response.hovered() || response.dragged() {
                        ui.ctx().set_cursor_icon(match dir {
                            egui::viewport::ResizeDirection::North
                            | egui::viewport::ResizeDirection::South => {
                                egui::CursorIcon::ResizeVertical
                            }
                            egui::viewport::ResizeDirection::East
                            | egui::viewport::ResizeDirection::West => {
                                egui::CursorIcon::ResizeHorizontal
                            }
                            egui::viewport::ResizeDirection::NorthWest
                            | egui::viewport::ResizeDirection::SouthEast => {
                                egui::CursorIcon::ResizeNwSe
                            }
                            egui::viewport::ResizeDirection::NorthEast
                            | egui::viewport::ResizeDirection::SouthWest => {
                                egui::CursorIcon::ResizeNeSw
                            }
                        });
                    }

                    if response.drag_started() {
                        ui.ctx()
                            .send_viewport_cmd(egui::ViewportCommand::BeginResize(dir));
                    }
                }
            });
    }

    pub(crate) fn render_fade_overlay(&mut self, ctx: &egui::Context) {
        if let Some(start_time) = self.fade_in_start {
            let elapsed = ctx.input(|i| i.time) - start_time;
            if elapsed < 0.6 {
                let opacity = 1.0 - (elapsed / 0.6) as f32;
                let rect = ctx.input(|i| {
                    i.viewport().inner_rect.unwrap_or(egui::Rect::from_min_size(
                        egui::Pos2::ZERO,
                        egui::Vec2::ZERO,
                    ))
                });
                let painter = ctx.layer_painter(egui::LayerId::new(
                    egui::Order::Foreground,
                    egui::Id::new("fade_overlay"),
                ));
                painter.rect_filled(
                    rect,
                    0.0,
                    eframe::egui::Color32::from_black_alpha((opacity * 255.0) as u8),
                );
                ctx.request_repaint();
            } else {
                self.fade_in_start = None;
            }
        }
    }

    /// Render a drop overlay when files are being dragged over the window
    pub(crate) fn render_drop_overlay(&mut self, ctx: &egui::Context) {
        use super::input_handler::is_files_hovered;
        use crate::gui::locale::LocaleText;

        // --- ANIMATION LOGIC ---
        let delta = ctx.input(|i| i.stable_dt).min(0.1);
        let is_hovered = is_files_hovered(ctx);
        let fade_speed = 8.0_f32;

        if is_hovered {
            self.drop_overlay_fade += fade_speed * delta;
        } else {
            self.drop_overlay_fade -= fade_speed * delta;
        }
        self.drop_overlay_fade = self.drop_overlay_fade.clamp(0.0, 1.0);

        // If completely invisible and not hovered, do nothing
        if self.drop_overlay_fade <= 0.0 {
            return;
        }

        // Keep repainting while animating
        if self.drop_overlay_fade > 0.0 && self.drop_overlay_fade < 1.0 {
            ctx.request_repaint();
        } else if is_hovered {
            ctx.request_repaint(); // Animate bobbing
        }

        // --- RENDER ---
        let text = LocaleText::get(&self.config.ui_language);
        let screen_rect = ctx.available_rect();

        // Overlay layer (Debug order to stay on top)
        let overlay_layer = egui::LayerId::new(egui::Order::Debug, egui::Id::new("drop_overlay"));
        let painter = ctx.layer_painter(overlay_layer);

        // Backdrop with fade
        let max_alpha = 180;
        let alpha = (max_alpha as f32 * self.drop_overlay_fade) as u8;
        let backdrop_color = egui::Color32::from_rgba_unmultiplied(0, 120, 215, alpha);
        painter.rect_filled(screen_rect, 0.0, backdrop_color);

        // Content opacity
        let content_opacity = self.drop_overlay_fade;
        let element_color = egui::Color32::from_white_alpha((255.0_f32 * content_opacity) as u8);

        // Dashed border with pulse
        let inset = 24.0;
        let inner_rect = screen_rect.shrink(inset);
        let time = ctx.input(|i| i.time);
        let pulse = (time * 2.5).sin() as f32 * 0.2_f32 + 0.8_f32;
        let border_alpha = (255.0_f32 * content_opacity * pulse) as u8;
        let border_color = egui::Color32::from_white_alpha(border_alpha);
        let stroke = egui::Stroke::new(3.0, border_color);

        let dash_length = 12.0;
        let gap_length = 8.0;

        // Helper to draw dashed line
        let draw_dashed_line = |p1: egui::Pos2, p2: egui::Pos2| {
            let vec = p2 - p1;
            let len = vec.length();
            let dir = vec / len;
            let count = (len / (dash_length + gap_length)).ceil() as i32;

            for i in 0..count {
                let start = p1 + dir * (i as f32 * (dash_length + gap_length));
                let end = start + dir * dash_length;
                let end = if (end - p1).length() > len { p2 } else { end };
                painter.line_segment([start, end], stroke);
            }
        };

        draw_dashed_line(inner_rect.left_top(), inner_rect.right_top());
        draw_dashed_line(inner_rect.right_top(), inner_rect.right_bottom());
        draw_dashed_line(inner_rect.right_bottom(), inner_rect.left_bottom());
        draw_dashed_line(inner_rect.left_bottom(), inner_rect.left_top());

        // Center content
        let center = screen_rect.center();
        let icon_size = 64.0;

        // Bobbing animation
        let bob_offset = (time * 5.0).sin() as f32 * 4.0_f32;

        // Draw Rounded Document Icon
        let file_width = icon_size * 0.7;
        let file_height = icon_size * 0.9;
        let file_rect = egui::Rect::from_center_size(center, egui::vec2(file_width, file_height));

        painter.rect_stroke(
            file_rect,
            8.0_f32,
            egui::Stroke::new(3.0, element_color),
            egui::StrokeKind::Middle,
        );

        // Draw Arrow (Bobbing inside)
        let arrow_center = center + egui::vec2(0.0, bob_offset);
        let arrow_len = icon_size * 0.4;
        let arrow_start = arrow_center - egui::vec2(0.0, arrow_len * 0.5);
        let arrow_end = arrow_center + egui::vec2(0.0, arrow_len * 0.5);

        let arrow_stroke = egui::Stroke::new(4.0, element_color);
        painter.line_segment([arrow_start, arrow_end], arrow_stroke);

        let arrow_head_size = 10.0;
        painter.line_segment(
            [
                arrow_end,
                arrow_end + egui::vec2(-arrow_head_size, -arrow_head_size),
            ],
            arrow_stroke,
        );
        painter.line_segment(
            [
                arrow_end,
                arrow_end + egui::vec2(arrow_head_size, -arrow_head_size),
            ],
            arrow_stroke,
        );

        // Text below
        let text_offset_y = icon_size * 0.8;
        let text_pos = center + egui::vec2(0.0, text_offset_y);
        let galley = painter.layout_no_wrap(
            text.drop_overlay_text.to_string(),
            egui::FontId::proportional(22.0),
            element_color,
        );
        let text_rect = galley.rect;
        painter.galley(
            text_pos - egui::vec2(text_rect.width() * 0.5, 0.0),
            galley,
            element_color,
        );

        // Request repaint for close animation
        if self.drop_overlay_fade > 0.0 {
            ctx.request_repaint();
        }
    }
}

// Helper function to format tips with bold text using LayoutJob
fn format_tip_with_bold(tip_number: usize, text: &str, is_dark_mode: bool) -> LayoutJob {
    let mut job = LayoutJob::default();
    let number_text = format!("{}. ", tip_number);

    // Color scheme based on theme
    let regular_color = if is_dark_mode {
        egui::Color32::from_rgb(180, 180, 180) // Gray for dark mode
    } else {
        egui::Color32::from_rgb(100, 100, 100) // Darker gray for light mode
    };

    let bold_color = if is_dark_mode {
        egui::Color32::from_rgb(150, 200, 255) // Soft cyan for dark mode
    } else {
        egui::Color32::from_rgb(40, 100, 180) // Dark blue for light mode
    };

    // Create text format for regular text
    let mut text_format = TextFormat::default();
    text_format.font_id = egui::FontId::proportional(13.0);
    text_format.color = regular_color;

    // Append number in regular color
    job.append(&number_text, 0.0, text_format.clone());

    // Parse text for **bold** markers
    let mut current_text = String::new();
    let mut chars = text.chars().peekable();
    let mut is_bold = false;

    while let Some(ch) = chars.next() {
        if ch == '*' && chars.peek() == Some(&'*') {
            // Found ** marker
            chars.next(); // consume second *

            if !current_text.is_empty() {
                // Append accumulated text
                let mut fmt = text_format.clone();
                if is_bold {
                    fmt.color = bold_color;
                }
                job.append(&current_text, 0.0, fmt);
                current_text.clear();
            }

            is_bold = !is_bold;
        } else {
            current_text.push(ch);
        }
    }

    // Append remaining text
    if !current_text.is_empty() {
        let mut fmt = text_format.clone();
        if is_bold {
            fmt.color = bold_color;
        }
        job.append(&current_text, 0.0, fmt);
    }

    job
}
</file>

<file path="src/gui/settings_ui/global/downloaded_tools.rs">
use crate::api::realtime_audio::model_loader::{
    download_parakeet_model, get_parakeet_model_dir, is_model_downloaded,
};
use crate::gui::locale::LocaleText;
use crate::gui::settings_ui::download_manager::{DownloadManager, InstallStatus, UpdateStatus};
use crate::overlay::realtime_webview::state::REALTIME_STATE;
use eframe::egui;
use std::fs;
use std::path::PathBuf;

use std::sync::atomic::AtomicBool;
use std::sync::Arc;
use std::thread;

pub fn render_downloaded_tools_modal(
    ctx: &egui::Context,
    _ui: &mut egui::Ui,
    show_modal: &mut bool,
    download_manager: &mut DownloadManager,
    text: &LocaleText,
) {
    if *show_modal {
        let mut open = true;
        egui::Window::new(text.downloaded_tools_title)
            .open(&mut open)
            .collapsible(false)
            .resizable(false)
            .default_width(500.0)
            .anchor(egui::Align2::CENTER_CENTER, egui::vec2(0.0, 0.0))
            .show(ctx, |ui| {
                ui.add_space(8.0);

                // --- Parakeet ---
                ui.group(|ui| {
                    ui.horizontal(|ui| {
                        ui.label(egui::RichText::new(text.tool_parakeet).strong());
                        ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                            let is_downloading = {
                                if let Ok(state) = REALTIME_STATE.lock() {
                                    state.is_downloading
                                } else {
                                    false
                                }
                            };

                            if is_downloading {
                                let progress = {
                                    if let Ok(state) = REALTIME_STATE.lock() {
                                        state.download_progress
                                    } else {
                                        0.0
                                    }
                                };
                                ui.label(format!("{:.0}%", progress));
                                ui.spinner();
                            } else if is_model_downloaded() {
                                if ui
                                    .button(
                                        egui::RichText::new(text.tool_action_delete)
                                            .color(egui::Color32::RED),
                                    )
                                    .clicked()
                                {
                                    let _ = fs::remove_dir_all(get_parakeet_model_dir());
                                }
                                let size = get_dir_size(get_parakeet_model_dir());
                                ui.label(
                                    egui::RichText::new(
                                        text.tool_status_installed
                                            .replace("{}", &format_size(size)),
                                    )
                                    .color(egui::Color32::from_rgb(34, 139, 34)),
                                );
                            } else {
                                if ui.button(text.tool_action_download).clicked() {
                                    let stop_signal = Arc::new(AtomicBool::new(false));
                                    thread::spawn(move || {
                                        let _ = download_parakeet_model(stop_signal, false);
                                    });
                                }
                                ui.label(
                                    egui::RichText::new(text.tool_status_missing)
                                        .color(egui::Color32::GRAY),
                                );
                            }
                        });
                    });
                    ui.label(text.tool_desc_parakeet);
                });

                ui.add_space(8.0);

                // --- yt-dlp ---
                ui.group(|ui| {
                    let status = download_manager.ytdlp_status.lock().unwrap().clone();
                    ui.horizontal(|ui| {
                        ui.label(egui::RichText::new(text.tool_ytdlp).strong());
                        ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                            match status {
                                InstallStatus::Installed => {
                                    let path = download_manager.bin_dir.join("yt-dlp.exe");
                                    if ui
                                        .button(
                                            egui::RichText::new(text.tool_action_delete)
                                                .color(egui::Color32::RED),
                                        )
                                        .clicked()
                                    {
                                        let _ = fs::remove_file(path);
                                        *download_manager.ytdlp_status.lock().unwrap() =
                                            InstallStatus::Missing;
                                    }

                                    let size = if let Ok(meta) =
                                        fs::metadata(download_manager.bin_dir.join("yt-dlp.exe"))
                                    {
                                        meta.len()
                                    } else {
                                        0
                                    };
                                    ui.label(
                                        egui::RichText::new(
                                            text.tool_status_installed
                                                .replace("{}", &format_size(size)),
                                        )
                                        .color(egui::Color32::from_rgb(34, 139, 34)),
                                    );
                                }
                                InstallStatus::Downloading(p) => {
                                    ui.spinner();
                                    ui.label(format!("{:.0}%", p * 100.0));
                                }
                                InstallStatus::Extracting => {
                                    ui.spinner();
                                    ui.label(text.download_status_extracting);
                                }
                                InstallStatus::Checking => {
                                    ui.spinner();
                                }
                                _ => {
                                    if ui.button(text.tool_action_download).clicked() {
                                        download_manager.start_download_ytdlp();
                                    }
                                    ui.label(
                                        egui::RichText::new(text.tool_status_missing)
                                            .color(egui::Color32::GRAY),
                                    );
                                }
                            }
                        });
                    });

                    ui.horizontal(|ui| {
                        ui.label(text.tool_desc_ytdlp);
                        if matches!(status, InstallStatus::Installed) {
                            ui.with_layout(
                                egui::Layout::right_to_left(egui::Align::Center),
                                |ui| {
                                    // Update Status
                                    let u_status = {
                                        if let Ok(s) = download_manager.ytdlp_update_status.lock() {
                                            s.clone()
                                        } else {
                                            UpdateStatus::Idle
                                        }
                                    };

                                    match u_status {
                                        UpdateStatus::UpdateAvailable(ver) => {
                                            if ui
                                                .button(
                                                    egui::RichText::new(
                                                        text.tool_update_available
                                                            .replace("{}", &ver),
                                                    )
                                                    .color(egui::Color32::from_rgb(255, 165, 0)),
                                                )
                                                .clicked()
                                            {
                                                download_manager.start_download_ytdlp();
                                            }
                                        }
                                        UpdateStatus::Checking => {
                                            ui.spinner();
                                            ui.label(text.tool_update_checking);
                                        }
                                        UpdateStatus::UpToDate => {
                                            if ui
                                                .small_button(text.tool_update_check_again)
                                                .clicked()
                                            {
                                                download_manager.check_updates();
                                            }
                                            ui.label(
                                                egui::RichText::new(text.tool_update_latest)
                                                    .color(egui::Color32::from_rgb(34, 139, 34)),
                                            );
                                        }
                                        UpdateStatus::Error(e) => {
                                            if ui.small_button(text.tool_update_retry).clicked() {
                                                download_manager.check_updates();
                                            }
                                            ui.label(
                                                egui::RichText::new(text.tool_update_error)
                                                    .color(egui::Color32::RED),
                                            )
                                            .on_hover_text(e);
                                        }
                                        UpdateStatus::Idle => {
                                            if ui.small_button(text.tool_update_check_btn).clicked()
                                            {
                                                download_manager.check_updates();
                                            }
                                        }
                                    }

                                    // Version
                                    if let Ok(guard) = download_manager.ytdlp_version.lock() {
                                        if let Some(ver) = &*guard {
                                            ui.label(
                                                egui::RichText::new(format!("v{}", ver))
                                                    .color(egui::Color32::GRAY),
                                            );
                                        }
                                    }
                                },
                            );
                        }
                    });
                });

                ui.add_space(8.0);

                // --- ffmpeg ---
                ui.group(|ui| {
                    let status = download_manager.ffmpeg_status.lock().unwrap().clone();
                    ui.horizontal(|ui| {
                        ui.label(egui::RichText::new(text.tool_ffmpeg).strong());
                        ui.with_layout(egui::Layout::right_to_left(egui::Align::Center), |ui| {
                            match status {
                                InstallStatus::Installed => {
                                    let path = download_manager.bin_dir.join("ffmpeg.exe");
                                    if ui
                                        .button(
                                            egui::RichText::new(text.tool_action_delete)
                                                .color(egui::Color32::RED),
                                        )
                                        .clicked()
                                    {
                                        let _ = fs::remove_file(&path);
                                        let _ = fs::remove_file(
                                            download_manager.bin_dir.join("ffprobe.exe"),
                                        );
                                        *download_manager.ffmpeg_status.lock().unwrap() =
                                            InstallStatus::Missing;
                                    }

                                    let size = if let Ok(meta) = fs::metadata(&path) {
                                        meta.len()
                                    } else {
                                        0
                                    };
                                    ui.label(
                                        egui::RichText::new(
                                            text.tool_status_installed
                                                .replace("{}", &format_size(size)),
                                        )
                                        .color(egui::Color32::from_rgb(34, 139, 34)),
                                    );
                                }
                                InstallStatus::Downloading(p) => {
                                    ui.spinner();
                                    ui.label(format!("{:.0}%", p * 100.0));
                                }
                                InstallStatus::Extracting => {
                                    ui.spinner();
                                    ui.label(text.download_status_extracting);
                                }
                                InstallStatus::Checking => {
                                    ui.spinner();
                                }
                                _ => {
                                    if ui.button(text.tool_action_download).clicked() {
                                        download_manager.start_download_ffmpeg();
                                    }
                                    ui.label(
                                        egui::RichText::new(text.tool_status_missing)
                                            .color(egui::Color32::GRAY),
                                    );
                                }
                            }
                        });
                    });

                    ui.horizontal(|ui| {
                        ui.label(text.tool_desc_ffmpeg);
                        if matches!(status, InstallStatus::Installed) {
                            ui.with_layout(
                                egui::Layout::right_to_left(egui::Align::Center),
                                |ui| {
                                    // Update Status
                                    let u_status = {
                                        if let Ok(s) = download_manager.ffmpeg_update_status.lock()
                                        {
                                            s.clone()
                                        } else {
                                            UpdateStatus::Idle
                                        }
                                    };

                                    match u_status {
                                        UpdateStatus::UpdateAvailable(ver) => {
                                            if ui
                                                .button(
                                                    egui::RichText::new(
                                                        text.tool_update_available
                                                            .replace("{}", &ver),
                                                    )
                                                    .color(egui::Color32::from_rgb(255, 165, 0)),
                                                )
                                                .clicked()
                                            {
                                                download_manager.start_download_ffmpeg();
                                            }
                                        }
                                        UpdateStatus::Checking => {
                                            ui.spinner();
                                            ui.label(text.tool_update_checking);
                                        }
                                        UpdateStatus::UpToDate => {
                                            if ui
                                                .small_button(text.tool_update_check_again)
                                                .clicked()
                                            {
                                                download_manager.check_updates();
                                            }
                                            ui.label(
                                                egui::RichText::new(text.tool_update_latest)
                                                    .color(egui::Color32::from_rgb(34, 139, 34)),
                                            );
                                        }
                                        UpdateStatus::Error(e) => {
                                            if ui.small_button(text.tool_update_retry).clicked() {
                                                download_manager.check_updates();
                                            }
                                            ui.label(
                                                egui::RichText::new(text.tool_update_error)
                                                    .color(egui::Color32::RED),
                                            )
                                            .on_hover_text(e);
                                        }
                                        UpdateStatus::Idle => {
                                            if ui.small_button(text.tool_update_check_btn).clicked()
                                            {
                                                download_manager.check_updates();
                                            }
                                        }
                                    }

                                    // Version
                                    if let Ok(guard) = download_manager.ffmpeg_version.lock() {
                                        if let Some(ver) = &*guard {
                                            ui.label(
                                                egui::RichText::new(format!("v{}", ver))
                                                    .color(egui::Color32::GRAY),
                                            );
                                        }
                                    }
                                },
                            );
                        }
                    });
                });
            });

        *show_modal = open;
    }
}

fn get_dir_size(path: PathBuf) -> u64 {
    let mut total_size = 0;
    if let Ok(entries) = fs::read_dir(path) {
        for entry in entries {
            if let Ok(entry) = entry {
                if let Ok(metadata) = entry.metadata() {
                    if metadata.is_dir() {
                        total_size += get_dir_size(entry.path());
                    } else {
                        total_size += metadata.len();
                    }
                }
            }
        }
    }
    total_size
}

fn format_size(bytes: u64) -> String {
    let mb = bytes as f64 / 1024.0 / 1024.0;
    format!("{:.1} MB", mb)
}
</file>

<file path="src/gui/settings_ui/global/mod.rs">
use super::node_graph::request_node_graph_view_reset;
use crate::config::Config;
use crate::gui::icons::{icon_button, Icon};
use crate::gui::locale::LocaleText;
use crate::updater::{UpdateStatus, Updater};
use auto_launch::AutoLaunch;
use eframe::egui;
use std::collections::HashMap;

mod downloaded_tools;
mod tts_settings;
mod update_section;
mod usage_stats;

use crate::gui::settings_ui::download_manager::DownloadManager;
use downloaded_tools::render_downloaded_tools_modal;
use tts_settings::render_tts_settings_modal;
use update_section::render_update_section_content;
use usage_stats::render_usage_modal;

const API_KEY_FIELD_WIDTH: f32 = 400.0;

pub fn render_global_settings(
    ui: &mut egui::Ui,
    config: &mut Config,
    show_api_key: &mut bool,
    show_gemini_api_key: &mut bool,
    show_openrouter_api_key: &mut bool,
    show_cerebras_api_key: &mut bool,
    usage_stats: &HashMap<String, String>,
    updater: &Option<Updater>,
    update_status: &UpdateStatus,
    run_at_startup: &mut bool,
    auto_launcher: &Option<AutoLaunch>,
    current_admin_state: bool,
    text: &LocaleText,
    show_usage_modal: &mut bool,

    show_tts_modal: &mut bool,
    show_tools_modal: &mut bool,
    download_manager: &mut DownloadManager,
    _cached_audio_devices: &std::sync::Arc<std::sync::Mutex<Vec<(String, String)>>>,
    _recording_sr_hotkey: &mut bool,
) -> bool {
    let mut changed = false;

    let is_dark = ui.visuals().dark_mode;
    let card_bg = if is_dark {
        egui::Color32::from_rgba_unmultiplied(28, 32, 42, 250) // Darker for better text contrast
    } else {
        egui::Color32::from_rgba_unmultiplied(255, 255, 255, 255)
    };
    let card_stroke = if is_dark {
        egui::Stroke::new(1.0, egui::Color32::from_gray(50))
    } else {
        egui::Stroke::new(1.0, egui::Color32::from_gray(210))
    };

    ui.add_space(5.0);

    // === API KEYS CARD ===
    egui::Frame::new()
        .fill(card_bg)
        .stroke(card_stroke)
        .inner_margin(12.0)
        .corner_radius(10.0)
        .show(ui, |ui| {
            // Header row with title and provider checkboxes
            ui.horizontal(|ui| {
                ui.label(
                    egui::RichText::new(text.api_keys_header)
                        .strong()
                        .size(14.0),
                );
                ui.add_space(16.0);

                if ui
                    .checkbox(&mut config.use_groq, text.use_groq_checkbox)
                    .changed()
                {
                    changed = true;
                }
                if ui
                    .checkbox(&mut config.use_cerebras, text.use_cerebras_checkbox)
                    .changed()
                {
                    changed = true;
                }
                if ui
                    .checkbox(&mut config.use_gemini, text.use_gemini_checkbox)
                    .changed()
                {
                    changed = true;
                }
                if ui
                    .checkbox(&mut config.use_openrouter, text.use_openrouter_checkbox)
                    .changed()
                {
                    changed = true;
                }
                if ui.checkbox(&mut config.use_ollama, "Ollama").changed() {
                    changed = true;
                }
            });
            ui.add_space(6.0);

            // Groq API Key (only show if enabled)
            if config.use_groq {
                ui.horizontal(|ui| {
                    ui.label(text.groq_label);
                    if ui.link(text.get_key_link).clicked() {
                        let _ = open::that("https://console.groq.com/keys");
                    }
                });
                ui.horizontal(|ui| {
                    if ui
                        .add(
                            egui::TextEdit::singleline(&mut config.api_key)
                                .id(egui::Id::new("settings_api_key_groq"))
                                .password(!*show_api_key)
                                .desired_width(API_KEY_FIELD_WIDTH),
                        )
                        .changed()
                    {
                        changed = true;
                    }
                    let eye_icon = if *show_api_key {
                        Icon::EyeOpen
                    } else {
                        Icon::EyeClosed
                    };
                    if icon_button(ui, eye_icon).clicked() {
                        *show_api_key = !*show_api_key;
                    }
                });
            }

            // Cerebras API Key (only show if enabled)
            if config.use_cerebras {
                ui.horizontal(|ui| {
                    ui.label(text.cerebras_api_key_label);
                    if ui.link(text.cerebras_get_key_link).clicked() {
                        let _ = open::that("https://cloud.cerebras.ai/");
                    }
                });
                ui.horizontal(|ui| {
                    if ui
                        .add(
                            egui::TextEdit::singleline(&mut config.cerebras_api_key)
                                .id(egui::Id::new("settings_api_key_cerebras"))
                                .password(!*show_cerebras_api_key)
                                .desired_width(API_KEY_FIELD_WIDTH),
                        )
                        .changed()
                    {
                        changed = true;
                    }
                    let eye_icon = if *show_cerebras_api_key {
                        Icon::EyeOpen
                    } else {
                        Icon::EyeClosed
                    };
                    if icon_button(ui, eye_icon).clicked() {
                        *show_cerebras_api_key = !*show_cerebras_api_key;
                    }
                });
            }

            // Gemini API Key (only show if enabled)
            if config.use_gemini {
                ui.horizontal(|ui| {
                    ui.label(text.gemini_api_key_label);
                    if ui.link(text.gemini_get_key_link).clicked() {
                        let _ = open::that("https://aistudio.google.com/app/apikey");
                    }
                });
                ui.horizontal(|ui| {
                    if ui
                        .add(
                            egui::TextEdit::singleline(&mut config.gemini_api_key)
                                .id(egui::Id::new("settings_api_key_gemini"))
                                .password(!*show_gemini_api_key)
                                .desired_width(API_KEY_FIELD_WIDTH),
                        )
                        .changed()
                    {
                        changed = true;
                    }
                    let eye_icon = if *show_gemini_api_key {
                        Icon::EyeOpen
                    } else {
                        Icon::EyeClosed
                    };
                    if icon_button(ui, eye_icon).clicked() {
                        *show_gemini_api_key = !*show_gemini_api_key;
                    }
                });
            }

            // OpenRouter API Key (only show if enabled)
            if config.use_openrouter {
                ui.horizontal(|ui| {
                    ui.label(text.openrouter_api_key_label);
                    if ui.link(text.openrouter_get_key_link).clicked() {
                        let _ = open::that("https://openrouter.ai/settings/keys");
                    }
                });
                ui.horizontal(|ui| {
                    if ui
                        .add(
                            egui::TextEdit::singleline(&mut config.openrouter_api_key)
                                .id(egui::Id::new("settings_api_key_openrouter"))
                                .password(!*show_openrouter_api_key)
                                .desired_width(API_KEY_FIELD_WIDTH),
                        )
                        .changed()
                    {
                        changed = true;
                    }
                    let eye_icon = if *show_openrouter_api_key {
                        Icon::EyeOpen
                    } else {
                        Icon::EyeClosed
                    };
                    if icon_button(ui, eye_icon).clicked() {
                        *show_openrouter_api_key = !*show_openrouter_api_key;
                    }
                });
            }

            // Ollama (Local AI) - only show URL field if enabled
            if config.use_ollama {
                ui.horizontal(|ui| {
                    ui.label("Ollama URL:");
                    if ui.link(text.ollama_url_guide).clicked() {
                        let _ = open::that("https://docs.ollama.com/api/introduction#base-url");
                    }
                });
                ui.horizontal(|ui| {
                    if ui
                        .add(
                            egui::TextEdit::singleline(&mut config.ollama_base_url)
                                .id(egui::Id::new("settings_api_key_ollama_url"))
                                .desired_width(API_KEY_FIELD_WIDTH),
                        )
                        .changed()
                    {
                        changed = true;
                    }
                    // Show status if available
                    if let Some(status) = ui
                        .ctx()
                        .memory(|mem| mem.data.get_temp::<String>(egui::Id::new("ollama_status")))
                    {
                        ui.label(egui::RichText::new(&status).size(11.0));
                    }
                });
            }
        });

    ui.add_space(10.0);

    // === USAGE STATISTICS & TTS SETTINGS BUTTONS ===
    let is_dark = ui.visuals().dark_mode;
    let stats_bg = if is_dark {
        egui::Color32::from_rgb(50, 100, 110) // Teal for dark mode
    } else {
        egui::Color32::from_rgb(90, 160, 170) // Lighter teal for light mode
    };

    ui.horizontal(|ui| {
        if ui
            .add(
                egui::Button::new(
                    egui::RichText::new(format!("📊 {}", text.usage_statistics_title))
                        .color(egui::Color32::WHITE)
                        .strong(),
                )
                .fill(stats_bg)
                .corner_radius(10.0),
            )
            .on_hover_cursor(egui::CursorIcon::PointingHand)
            .on_hover_text(text.usage_statistics_tooltip)
            .clicked()
        {
            *show_usage_modal = true;
        }

        ui.add_space(10.0);

        let tts_bg = if is_dark {
            egui::Color32::from_rgb(100, 80, 120) // Purple for dark mode
        } else {
            egui::Color32::from_rgb(180, 140, 200) // Lighter purple for light mode
        };

        if ui
            .add(
                egui::Button::new(
                    egui::RichText::new(format!("🔊 {}", text.tts_settings_button))
                        .color(egui::Color32::WHITE)
                        .strong(),
                )
                .fill(tts_bg)
                .corner_radius(10.0),
            )
            .on_hover_cursor(egui::CursorIcon::PointingHand)
            .clicked()
        {
            *show_tts_modal = true;
        }

        ui.add_space(10.0);

        let tools_bg = if is_dark {
            egui::Color32::from_rgb(60, 90, 140)
        } else {
            egui::Color32::from_rgb(100, 140, 200)
        };

        if ui
            .add(
                egui::Button::new(
                    egui::RichText::new(format!("📦 {}", text.downloaded_tools_button))
                        .color(egui::Color32::WHITE)
                        .strong(),
                )
                .fill(tools_bg)
                .corner_radius(10.0),
            )
            .on_hover_cursor(egui::CursorIcon::PointingHand)
            .clicked()
        {
            *show_tools_modal = true;
        }
    });

    // === USAGE STATISTICS MODAL ===
    render_usage_modal(
        ui,
        usage_stats,
        text,
        show_usage_modal,
        config.use_groq,
        config.use_gemini,
        config.use_openrouter,
        config.use_ollama,
        config.use_cerebras,
    );

    // === TOOLS MODAL ===
    let ctx = ui.ctx().clone();
    render_downloaded_tools_modal(&ctx, ui, show_tools_modal, download_manager, text);

    // === TTS SETTINGS MODAL ===
    if render_tts_settings_modal(ui, config, text, show_tts_modal) {
        changed = true;
    }

    ui.add_space(10.0);

    // === SOFTWARE UPDATE CARD ===
    egui::Frame::new()
        .fill(card_bg)
        .stroke(card_stroke)
        .inner_margin(12.0)
        .corner_radius(10.0)
        .show(ui, |ui| {
            ui.label(
                egui::RichText::new(text.software_update_header)
                    .strong()
                    .size(14.0),
            );
            ui.add_space(6.0);
            render_update_section_content(ui, updater, update_status, text);
        });

    ui.add_space(10.0);

    // === STARTUP OPTIONS CARD ===
    egui::Frame::new()
        .fill(card_bg)
        .stroke(card_stroke)
        .inner_margin(12.0)
        .corner_radius(10.0)
        .show(ui, |ui| {
            ui.label(
                egui::RichText::new(text.startup_display_header)
                    .strong()
                    .size(14.0),
            );
            ui.add_space(6.0);

            // Main startup toggle
            ui.horizontal(|ui| {
                if let Some(launcher) = auto_launcher {
                    let mut startup_toggle = *run_at_startup;
                    if ui
                        .checkbox(&mut startup_toggle, text.startup_label)
                        .clicked()
                    {
                        if startup_toggle && !(*run_at_startup) {
                            // User is turning it ON - authorize THIS exe as the one allowed to start
                            if let Ok(exe_path) = std::env::current_exe() {
                                if let Some(exe_str) = exe_path.to_str() {
                                    config.authorized_startup_path = exe_str.to_string();
                                }
                            }

                            if config.run_as_admin_on_startup && current_admin_state {
                                if crate::gui::utils::set_admin_startup(true) {
                                    let _ = launcher.disable();
                                    config.run_at_startup = false;
                                    *run_at_startup = true;
                                    changed = true;
                                }
                            } else {
                                std::thread::spawn(|| {
                                    crate::gui::utils::set_admin_startup(false);
                                });
                                let _ = launcher.enable();
                                config.run_at_startup = true;
                                *run_at_startup = true;
                                changed = true;
                            }
                        } else if !startup_toggle && *run_at_startup {
                            // User is turning it OFF
                            std::thread::spawn(|| {
                                crate::gui::utils::set_admin_startup(false);
                            });
                            let _ = launcher.disable();
                            config.run_as_admin_on_startup = false;
                            config.run_at_startup = false;
                            config.start_in_tray = false;
                            *run_at_startup = false;
                            changed = true;
                        }
                    }
                }
            });

            // Admin Mode Sub-option
            if *run_at_startup {
                ui.indent("admin_indent", |ui| {
                    let mut is_admin_mode = config.run_as_admin_on_startup;
                    let checkbox_label = text.admin_startup_on;

                    if current_admin_state {
                        if ui.checkbox(&mut is_admin_mode, checkbox_label).clicked() {
                            if is_admin_mode && !config.run_as_admin_on_startup {
                                // Transitioning to admin mode requires updated authorization
                                if let Ok(exe_path) = std::env::current_exe() {
                                    if let Some(exe_str) = exe_path.to_str() {
                                        config.authorized_startup_path = exe_str.to_string();
                                    }
                                }

                                if crate::gui::utils::set_admin_startup(true) {
                                    config.run_as_admin_on_startup = true;
                                    config.run_at_startup = false;
                                    if let Some(launcher) = auto_launcher {
                                        let _ = launcher.disable();
                                    }
                                    changed = true;
                                }
                            } else if !is_admin_mode && config.run_as_admin_on_startup {
                                // Reverting to standard mode
                                if let Ok(exe_path) = std::env::current_exe() {
                                    if let Some(exe_str) = exe_path.to_str() {
                                        config.authorized_startup_path = exe_str.to_string();
                                    }
                                }

                                std::thread::spawn(|| {
                                    crate::gui::utils::set_admin_startup(false);
                                });
                                config.run_as_admin_on_startup = false;
                                config.run_at_startup = true;
                                if let Some(launcher) = auto_launcher {
                                    let _ = launcher.enable();
                                }
                                changed = true;
                            }
                        }
                    } else {
                        let mut _is_admin_mode_disabled = config.run_as_admin_on_startup;
                        ui.add_enabled_ui(false, |ui| {
                            ui.checkbox(&mut _is_admin_mode_disabled, checkbox_label);
                        });
                        ui.label(
                            egui::RichText::new(text.admin_startup_fail)
                                .size(11.0)
                                .color(egui::Color32::from_rgb(200, 100, 50)),
                        );
                    }

                    if config.run_as_admin_on_startup && current_admin_state {
                        ui.label(
                            egui::RichText::new(text.admin_startup_success)
                                .size(11.0)
                                .color(egui::Color32::from_rgb(34, 139, 34)),
                        );
                    }
                });

                if ui
                    .checkbox(&mut config.start_in_tray, text.start_in_tray_label)
                    .clicked()
                {
                    changed = true;
                }
            }

            ui.add_space(8.0);

            // Graphics Mode + Reset button on same row
            ui.horizontal(|ui| {
                let current_label = match config.ui_language.as_str() {
                    "vi" => {
                        if config.graphics_mode == "minimal" {
                            "Tối giản"
                        } else {
                            "Tiêu chuẩn"
                        }
                    }
                    "ko" => {
                        if config.graphics_mode == "minimal" {
                            "최소"
                        } else {
                            "표준"
                        }
                    }
                    _ => {
                        if config.graphics_mode == "minimal" {
                            "Minimal"
                        } else {
                            "Standard"
                        }
                    }
                };

                egui::ComboBox::from_id_salt("graphics_mode_combo")
                    .selected_text(current_label)
                    .show_ui(ui, |ui| {
                        if ui
                            .selectable_label(
                                config.graphics_mode == "standard",
                                text.graphics_mode_standard,
                            )
                            .clicked()
                        {
                            config.graphics_mode = "standard".to_string();
                            changed = true;
                        }
                        if ui
                            .selectable_label(
                                config.graphics_mode == "minimal",
                                text.graphics_mode_minimal,
                            )
                            .clicked()
                        {
                            config.graphics_mode = "minimal".to_string();
                            changed = true;
                        }
                    });

                // Big gap to simulate right alignment
                ui.add_space(40.0);

                // Force Quit button
                let quite_bg = if is_dark {
                    egui::Color32::from_rgb(120, 40, 40)
                } else {
                    egui::Color32::from_rgb(200, 100, 100)
                };
                if ui
                    .add(
                        egui::Button::new(
                            egui::RichText::new(text.force_quit).color(egui::Color32::WHITE),
                        )
                        .fill(quite_bg)
                        .corner_radius(8.0),
                    )
                    .clicked()
                {
                    std::process::exit(0);
                }

                ui.add_space(10.0);

                // Reset button
                let reset_bg = if is_dark {
                    egui::Color32::from_rgb(120, 60, 60)
                } else {
                    egui::Color32::from_rgb(220, 140, 140)
                };
                if ui
                    .add(
                        egui::Button::new(
                            egui::RichText::new(text.reset_defaults_btn)
                                .color(egui::Color32::WHITE),
                        )
                        .fill(reset_bg)
                        .corner_radius(8.0),
                    )
                    .clicked()
                {
                    let saved_groq_key = config.api_key.clone();
                    let saved_gemini_key = config.gemini_api_key.clone();
                    let saved_openrouter_key = config.openrouter_api_key.clone();
                    let saved_cerebras_key = config.cerebras_api_key.clone();
                    let saved_language = config.ui_language.clone();
                    let saved_use_groq = config.use_groq;
                    let saved_use_gemini = config.use_gemini;
                    let saved_use_openrouter = config.use_openrouter;
                    let saved_use_ollama = config.use_ollama;
                    let saved_use_cerebras = config.use_cerebras;
                    let saved_ollama_base_url = config.ollama_base_url.clone();
                    // Realtime model reset to default (google-gemma)

                    *config = Config::default();

                    config.api_key = saved_groq_key;
                    config.gemini_api_key = saved_gemini_key;
                    config.openrouter_api_key = saved_openrouter_key;
                    config.cerebras_api_key = saved_cerebras_key;
                    config.ui_language = saved_language;
                    config.use_groq = saved_use_groq;
                    config.use_gemini = saved_use_gemini;
                    config.use_openrouter = saved_use_openrouter;
                    config.use_ollama = saved_use_ollama;
                    config.use_cerebras = saved_use_cerebras;
                    config.ollama_base_url = saved_ollama_base_url;
                    // config.realtime_translation_model = saved_realtime_model;
                    request_node_graph_view_reset(ui.ctx());

                    // Also clear WebView data (MIDI permissions, etc.)
                    // Instead of throwing an error if locked, we schedule for next startup and restart immediately.
                    config.clear_webview_on_startup = true;

                    // Save immediately and restart
                    crate::config::save_config(config);
                    crate::gui::app::restart_app();

                    changed = true;
                }
            });
        });

    ui.add_space(10.0);

    ui.add_space(10.0);

    changed
}
</file>

<file path="src/overlay/preset_wheel/window.rs">
// Preset Wheel Window - Persistent Hidden Window for Instant Appearance

use super::html::{generate_css, generate_items_html, get_wheel_template};
use crate::config::Preset;
use crate::APP;
use std::cell::RefCell;
use std::sync::atomic::{AtomicBool, AtomicI32, AtomicIsize, Ordering};
use std::sync::{Mutex, Once};
use windows::core::w;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmExtendFrameIntoClientArea, DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE,
};
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::Com::{CoInitialize, CoUninitialize};
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebView, WebViewBuilder};

static REGISTER_WHEEL_CLASS: Once = Once::new();
static REGISTER_OVERLAY_CLASS: Once = Once::new();

// Custom Messages
const WM_APP_SHOW: u32 = WM_USER + 10;
const WM_APP_HIDE: u32 = WM_USER + 11;
const WM_APP_REAL_SHOW: u32 = WM_USER + 12;

// Large dimensions for wheel window - transparent so no visual impact
// Must fit on common screens (1366x768 minimum)
const WHEEL_WIDTH: i32 = 1200;
const WHEEL_HEIGHT: i32 = 700;

// Result communication
pub static WHEEL_RESULT: AtomicI32 = AtomicI32::new(-1);
pub static WHEEL_ACTIVE: AtomicBool = AtomicBool::new(false);

// Thread-safe handles
static WHEEL_HWND: AtomicIsize = AtomicIsize::new(0);
static OVERLAY_HWND: AtomicIsize = AtomicIsize::new(0);
static IS_WARMING_UP: AtomicBool = AtomicBool::new(false);
static IS_WARMED_UP: AtomicBool = AtomicBool::new(false);

// Shared data
lazy_static::lazy_static! {
    static ref PENDING_ITEMS_HTML: Mutex<String> = Mutex::new(String::new());
    static ref PENDING_DISMISS_LABEL: Mutex<String> = Mutex::new(String::new());
    static ref PENDING_CSS: Mutex<String> = Mutex::new(String::new());
    static ref PENDING_POS: Mutex<(i32, i32)> = Mutex::new((0, 0));
    static ref SELECTED_PRESET: Mutex<Option<usize>> = Mutex::new(None);
}

thread_local! {
    static WHEEL_WEBVIEW: RefCell<Option<WebView>> = RefCell::new(None);
    static WHEEL_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);
}

struct HwndWrapper(HWND);
unsafe impl Send for HwndWrapper {}
unsafe impl Sync for HwndWrapper {}
impl raw_window_handle::HasWindowHandle for HwndWrapper {
    fn window_handle(
        &self,
    ) -> Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError> {
        let raw = raw_window_handle::Win32WindowHandle::new(
            std::num::NonZeroIsize::new(self.0 .0 as isize).expect("HWND cannot be null"),
        );
        let handle = raw_window_handle::RawWindowHandle::Win32(raw);
        unsafe { Ok(raw_window_handle::WindowHandle::borrow_raw(handle)) }
    }
}

pub fn warmup() {
    // Prevent multiple warmup threads from spawning
    if IS_WARMING_UP
        .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
        .is_err()
    {
        return;
    }
    std::thread::spawn(|| {
        internal_create_window_loop();
    });
}

pub fn show_preset_wheel(
    filter_type: &str,
    filter_mode: Option<&str>,
    center_pos: POINT,
) -> Option<usize> {
    // Check if warmed up first
    // Check if warmed up first
    if !IS_WARMED_UP.load(Ordering::SeqCst) {
        // Try to trigger warmup for recovery
        warmup();

        // Show localized message that feature is not ready yet
        let ui_lang = APP.lock().unwrap().config.ui_language.clone();
        let locale = crate::gui::locale::LocaleText::get(&ui_lang);
        crate::overlay::auto_copy_badge::show_notification(locale.preset_wheel_loading);

        // Wait up to 5 seconds for it to become ready
        // Wait up to 5 seconds for it to become ready
        // We use smaller sleep intervals (10ms) with message pumping to keep the UI thread responsive
        // Total wait: 500 * 10ms = 5000ms (5 seconds)
        for _ in 0..500 {
            unsafe {
                let mut msg = MSG::default();
                // Drain message queue to prevent freezing the UI thread (input window)
                while PeekMessageW(&mut msg, None, 0, 0, PM_REMOVE).as_bool() {
                    let _ = TranslateMessage(&msg);
                    DispatchMessageW(&msg);
                }
            }

            std::thread::sleep(std::time::Duration::from_millis(10));
            if IS_WARMED_UP.load(Ordering::SeqCst) {
                // It's ready! Proceed to show logic (fall through)
                break;
            }
        }

        // Check again
        if !IS_WARMED_UP.load(Ordering::SeqCst) {
            return None;
        }
    }

    unsafe {
        WHEEL_RESULT.store(-1, Ordering::SeqCst);
        WHEEL_ACTIVE.store(true, Ordering::SeqCst);
        *SELECTED_PRESET.lock().unwrap() = None;

        let (presets, ui_lang) = {
            let app = APP.lock().unwrap();
            (app.config.presets.clone(), app.config.ui_language.clone())
        };
        let is_dark = crate::overlay::is_dark_mode();

        // Generate themed CSS for injection
        let themed_css = generate_css(is_dark);

        let filtered: Vec<(usize, Preset)> = presets
            .iter()
            .enumerate()
            .filter(|(_, p)| {
                if p.is_master {
                    return false;
                }
                if p.is_upcoming {
                    return false;
                }
                if p.preset_type != filter_type {
                    return false;
                }
                if filter_type == "audio" && p.audio_processing_mode == "realtime" {
                    return false;
                }
                if let Some(mode) = filter_mode {
                    match filter_type {
                        "text" => {
                            if p.text_input_mode != mode {
                                return false;
                            }
                        }
                        "audio" => {
                            if p.audio_source != mode {
                                return false;
                            }
                        }
                        _ => {}
                    }
                }
                true
            })
            .map(|(i, p)| (i, p.clone()))
            .collect();

        if filtered.is_empty() {
            WHEEL_ACTIVE.store(false, Ordering::SeqCst);
            return None;
        }

        let dismiss_label = match ui_lang.as_str() {
            "vi" => "HỦY",
            "ko" => "취소",
            _ => "CANCEL",
        };

        let screen_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
        let screen_y = GetSystemMetrics(SM_YVIRTUALSCREEN);
        let screen_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
        let screen_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);

        let win_x = (center_pos.x - WHEEL_WIDTH / 2)
            .max(screen_x)
            .min(screen_x + screen_w - WHEEL_WIDTH);
        let win_y = (center_pos.y - WHEEL_HEIGHT / 2)
            .max(screen_y)
            .min(screen_y + screen_h - WHEEL_HEIGHT);

        let items_html = generate_items_html(&filtered, &ui_lang);

        *PENDING_ITEMS_HTML.lock().unwrap() = items_html;
        *PENDING_DISMISS_LABEL.lock().unwrap() = dismiss_label.to_string();
        *PENDING_CSS.lock().unwrap() = themed_css;
        *PENDING_POS.lock().unwrap() = (win_x, win_y);

        let hwnd_val = WHEEL_HWND.load(Ordering::SeqCst);
        let wheel_hwnd = HWND(hwnd_val as *mut _);

        if !wheel_hwnd.is_invalid() {
            let _ = PostMessageW(Some(wheel_hwnd), WM_APP_SHOW, WPARAM(0), LPARAM(0));
        }

        let mut msg = MSG::default();
        loop {
            let res = WHEEL_RESULT.load(Ordering::SeqCst);
            if res != -1 {
                break;
            }
            if PeekMessageW(&mut msg, None, 0, 0, PM_REMOVE).as_bool() {
                let _ = TranslateMessage(&msg);
                DispatchMessageW(&msg);
            }
            std::thread::sleep(std::time::Duration::from_millis(5));
        }

        WHEEL_ACTIVE.store(false, Ordering::SeqCst);
        let res = WHEEL_RESULT.load(Ordering::SeqCst);
        if res >= 0 {
            Some(res as usize)
        } else {
            None
        }
    }
}

pub fn dismiss_wheel() {
    unsafe {
        let hwnd_val = WHEEL_HWND.load(Ordering::SeqCst);
        let wheel_hwnd = HWND(hwnd_val as *mut _);
        if !wheel_hwnd.is_invalid() {
            let _ = PostMessageW(Some(wheel_hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
        }
    }
    WHEEL_RESULT.store(-2, Ordering::SeqCst);
}

pub fn is_wheel_active() -> bool {
    WHEEL_ACTIVE.load(Ordering::SeqCst)
}

fn internal_create_window_loop() {
    unsafe {
        // Initialize COM for the thread (Critical for WebView2/Wry)
        let _ = CoInitialize(None);

        let instance = GetModuleHandleW(None).unwrap_or_default();
        let screen_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
        let screen_y = GetSystemMetrics(SM_YVIRTUALSCREEN);
        let screen_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
        let screen_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);

        let overlay_class = w!("SGTWheelOverlayPersistent");
        REGISTER_OVERLAY_CLASS.call_once(|| {
            let wc = WNDCLASSW {
                lpfnWndProc: Some(overlay_wnd_proc),
                hInstance: instance.into(),
                lpszClassName: overlay_class,
                hCursor: LoadCursorW(None, IDC_ARROW).unwrap_or_default(),
                hbrBackground: HBRUSH(std::ptr::null_mut()),
                ..Default::default()
            };
            RegisterClassW(&wc);
        });

        let overlay_hwnd = CreateWindowExW(
            WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED | WS_EX_NOACTIVATE,
            overlay_class,
            w!("WheelOverlay"),
            WS_POPUP,
            screen_x,
            screen_y,
            screen_w,
            screen_h - 1, // Solve taskbar hide issue
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        OVERLAY_HWND.store(overlay_hwnd.0 as isize, Ordering::SeqCst);
        let _ = SetLayeredWindowAttributes(overlay_hwnd, COLORREF(0), 1, LWA_ALPHA);

        let class_name = w!("SGTPresetWheelPersistent");
        REGISTER_WHEEL_CLASS.call_once(|| {
            let wc = WNDCLASSW {
                lpfnWndProc: Some(wheel_wnd_proc),
                hInstance: instance.into(),
                lpszClassName: class_name,
                hCursor: LoadCursorW(None, IDC_ARROW).unwrap_or_default(),
                hbrBackground: HBRUSH(std::ptr::null_mut()),
                ..Default::default()
            };
            RegisterClassW(&wc);
        });

        let hwnd = CreateWindowExW(
            WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
            class_name,
            w!("PresetWheel"),
            WS_POPUP | WS_VISIBLE, // Start visible (offscreen)
            -4000,
            -4000,
            2000, // Dummy width (Large to avoid clipping)
            2000, // Dummy height (Large to avoid clipping)
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        // Windows 11 Rounded Corners - Disable native rounding
        let corner_pref = 1u32; // DWMWCP_DONOTROUND
        let _ = DwmSetWindowAttribute(
            hwnd,
            DWMWA_WINDOW_CORNER_PREFERENCE,
            std::ptr::addr_of!(corner_pref) as *const _,
            std::mem::size_of_val(&corner_pref) as u32,
        );

        // DELAYED STORE: Do not publish WHEEL_HWND yet. Wait until WebView is built.
        // WHEEL_HWND.store(hwnd.0 as isize, Ordering::SeqCst);
        // Use DWM to extend the "glass" frame into the entire client area for transparency
        let margins = MARGINS {
            cxLeftWidth: -1,
            cxRightWidth: -1,
            cyTopHeight: -1,
            cyBottomHeight: -1,
        };
        let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

        let wrapper = HwndWrapper(hwnd);

        WHEEL_WEB_CONTEXT.with(|ctx| {
            if ctx.borrow().is_none() {
                let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
                *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
            }
        });

        let webview_res = {
            // LOCK SCOPE: Serialized build to prevent resource contention
            let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
            crate::log_info!("[PresetWheel] Acquired init lock. Building...");

            let build_res = WHEEL_WEB_CONTEXT.with(|ctx| {
                let mut ctx_ref = ctx.borrow_mut();
                let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                    WebViewBuilder::new_with_web_context(web_ctx)
                } else {
                    WebViewBuilder::new()
                };
                let builder =
                    crate::overlay::html_components::font_manager::configure_webview(builder);

                let template_html = get_wheel_template(true); // Default dark for warmup

                // Store HTML in font server and get URL for same-origin font loading
                let page_url = crate::overlay::html_components::font_manager::store_html_page(
                    template_html.clone(),
                )
                .unwrap_or_else(|| {
                    format!("data:text/html,{}", urlencoding::encode(&template_html))
                });

                builder
                    .with_transparent(true)
                    .with_background_color((0, 0, 0, 0))
                    .with_url(&page_url)
                    .with_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                            0, 0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            WHEEL_WIDTH as u32,
                            WHEEL_HEIGHT as u32,
                        )),
                    })
                    .with_ipc_handler(move |msg: wry::http::Request<String>| {
                        let body = msg.body();
                        if body == "ready_to_show" {
                            let hwnd_val = WHEEL_HWND.load(Ordering::SeqCst);
                            let wheel_hwnd = HWND(hwnd_val as *mut _);
                            if !wheel_hwnd.is_invalid() {
                                let _ = PostMessageW(
                                    Some(wheel_hwnd),
                                    WM_APP_REAL_SHOW,
                                    WPARAM(0),
                                    LPARAM(0),
                                );
                            }
                        } else if body == "dismiss" {
                            let hwnd_val = WHEEL_HWND.load(Ordering::SeqCst);
                            let wheel_hwnd = HWND(hwnd_val as *mut _);
                            if !wheel_hwnd.is_invalid() {
                                let _ = PostMessageW(
                                    Some(wheel_hwnd),
                                    WM_APP_HIDE,
                                    WPARAM(0),
                                    LPARAM(0),
                                );
                            }
                            *SELECTED_PRESET.lock().unwrap() = None;
                            WHEEL_RESULT.store(-2, Ordering::SeqCst);
                        } else if let Some(idx_str) = body.strip_prefix("select:") {
                            if let Ok(idx) = idx_str.parse::<usize>() {
                                let hwnd_val = WHEEL_HWND.load(Ordering::SeqCst);
                                let wheel_hwnd = HWND(hwnd_val as *mut _);
                                if !wheel_hwnd.is_invalid() {
                                    let _ = PostMessageW(
                                        Some(wheel_hwnd),
                                        WM_APP_HIDE,
                                        WPARAM(0),
                                        LPARAM(0),
                                    );
                                }
                                *SELECTED_PRESET.lock().unwrap() = Some(idx);
                                WHEEL_RESULT.store(idx as i32, Ordering::SeqCst);
                            }
                        }
                    })
                    .build(&wrapper)
            });
            crate::log_info!(
                "[PresetWheel] Build finished. Status: {}",
                if build_res.is_ok() { "OK" } else { "ERR" }
            );
            build_res
        };

        if let Ok(wv) = webview_res {
            WHEEL_WEBVIEW.with(|cell| {
                *cell.borrow_mut() = Some(wv);
            });
            let _ = ShowWindow(hwnd, SW_HIDE);

            // Now that WebView is ready, publicize the HWND and mark warmup as done
            WHEEL_HWND.store(hwnd.0 as isize, Ordering::SeqCst);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            IS_WARMED_UP.store(true, Ordering::SeqCst);
        } else {
            // Initialization failed - cleanup and exit
            let _ = DestroyWindow(hwnd);
            let _ = DestroyWindow(overlay_hwnd);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            OVERLAY_HWND.store(0, Ordering::SeqCst);
            WHEEL_HWND.store(0, Ordering::SeqCst);
            let _ = CoUninitialize(); // Cleanup COM
            return;
        }

        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
        }

        WHEEL_WEBVIEW.with(|cell| {
            *cell.borrow_mut() = None;
        });
        WHEEL_HWND.store(0, Ordering::SeqCst);
        OVERLAY_HWND.store(0, Ordering::SeqCst);
        IS_WARMING_UP.store(false, Ordering::SeqCst); // Ensure flag is cleared on exit
        let _ = CoUninitialize(); // Cleanup COM
    }
}

unsafe extern "system" fn overlay_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_LBUTTONDOWN | WM_RBUTTONDOWN => {
            let hwnd_val = WHEEL_HWND.load(Ordering::SeqCst);
            let wheel_hwnd = HWND(hwnd_val as *mut _);
            if !wheel_hwnd.is_invalid() {
                let _ = PostMessageW(Some(wheel_hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
            }
            WHEEL_RESULT.store(-2, Ordering::SeqCst);
            LRESULT(0)
        }
        WM_CLOSE => LRESULT(0),
        WM_ERASEBKGND => LRESULT(1), // Prevent GDI from clearing background to black/white
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

unsafe extern "system" fn wheel_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_SHOW => {
            let items_html = PENDING_ITEMS_HTML.lock().unwrap().clone();
            let dismiss_label = PENDING_DISMISS_LABEL.lock().unwrap().clone();
            let themed_css = PENDING_CSS.lock().unwrap().clone();

            // 1. Ensure Off-screen (-4000, -4000) but VISIBLE
            // Remove calls to SetLayeredWindowAttributes here to prevent black artifacts
            let _ = SetWindowPos(
                hwnd,
                Some(HWND_TOPMOST),
                -4000,
                -4000,
                0,
                0,
                SWP_NOACTIVATE | SWP_NOSIZE | SWP_SHOWWINDOW,
            );

            // Re-apply glass effect to ensure it's active
            let margins = MARGINS {
                cxLeftWidth: -1,
                cxRightWidth: -1,
                cyTopHeight: -1,
                cyBottomHeight: -1,
            };
            let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

            // 2. Inject themed CSS and update content via JS
            WHEEL_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    // Inject themed CSS
                    let css_escaped = themed_css
                        .replace("\\", "\\\\")
                        .replace("`", "\\`")
                        .replace("$", "\\$");
                    let css_script = format!(
                        "document.getElementById('theme-style').textContent = `{}`;",
                        css_escaped
                    );
                    let _ = webview.evaluate_script(&css_script);

                    // Update content
                    let script = format!(
                        "window.updateContent(`{}`, `{}`);",
                        items_html
                            .replace("\\", "\\\\")
                            .replace("`", "\\`")
                            .replace("$", "\\$"),
                        dismiss_label.replace("`", "\\`").replace("$", "\\$")
                    );
                    let _ = webview.evaluate_script(&script);

                    // Force bounds update to ensure WebView syncs with window size
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                            0, 0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            WHEEL_WIDTH as u32,
                            WHEEL_HEIGHT as u32,
                        )),
                    });
                }
            });

            // 3. Fallback timer (150ms) - Increased robustness
            SetTimer(Some(hwnd), 99, 150, None);

            LRESULT(0)
        }

        WM_APP_REAL_SHOW => {
            let _ = KillTimer(Some(hwnd), 99);
            let (target_x, target_y) = *PENDING_POS.lock().unwrap();

            // Show overlay
            let overlay_val = OVERLAY_HWND.load(Ordering::SeqCst);
            let overlay = HWND(overlay_val as *mut _);
            if !overlay.is_invalid() {
                let _ = ShowWindow(overlay, SW_SHOWNOACTIVATE);
                let screen_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
                let screen_y = GetSystemMetrics(SM_YVIRTUALSCREEN);
                let screen_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
                let screen_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);
                let _ = SetWindowPos(
                    overlay,
                    Some(HWND_TOPMOST),
                    screen_x,
                    screen_y,
                    screen_w,
                    screen_h - 1, // Solve taskbar hide issue
                    SWP_NOACTIVATE | SWP_NOMOVE,
                );
            }

            // Move wheel on-screen
            let _ = InvalidateRect(Some(hwnd), None, true);
            let _ = SetWindowPos(
                hwnd,
                Some(HWND_TOPMOST),
                target_x,
                target_y,
                WHEEL_WIDTH + 50,  // Explicit size buffer
                WHEEL_HEIGHT + 50, // Explicit size buffer
                SWP_NOACTIVATE,    // Removed SWP_NOSIZE
            );

            LRESULT(0)
        }

        WM_TIMER => {
            if wparam.0 == 99 {
                let _ = PostMessageW(Some(hwnd), WM_APP_REAL_SHOW, WPARAM(0), LPARAM(0));
            }
            LRESULT(0)
        }

        WM_APP_HIDE => {
            let _ = KillTimer(Some(hwnd), 99);
            let _ = ShowWindow(hwnd, SW_HIDE);
            let overlay_val = OVERLAY_HWND.load(Ordering::SeqCst);
            let overlay = HWND(overlay_val as *mut _);
            if !overlay.is_invalid() {
                let _ = ShowWindow(overlay, SW_HIDE);
            }

            WHEEL_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let _ =
                        webview.evaluate_script("document.getElementById('grid').innerHTML = '';");
                }
            });

            LRESULT(0)
        }

        WM_KEYDOWN => {
            if wparam.0 as u32 == 0x1B {
                let _ = PostMessageW(Some(hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
                WHEEL_RESULT.store(-2, Ordering::SeqCst);
            }
            LRESULT(0)
        }

        // Handle DPI changes to maintain correct size
        WM_DPICHANGED => {
            let rect = &*(lparam.0 as *const RECT);
            let _ = SetWindowPos(
                hwnd,
                None,
                rect.left,
                rect.top,
                rect.right - rect.left,
                rect.bottom - rect.top,
                SWP_NOZORDER | SWP_NOACTIVATE,
            );
            // WebView bounds will be updated on next SHOW or we could enforce it here if active
            // For now, next JS check/show will resync.
            LRESULT(0)
        }

        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/screen_record/engine.rs">
use crate::overlay::screen_record::audio_engine;
use parking_lot::Mutex;
use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use std::mem::zeroed;
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;
use std::time::Instant;
use windows::core::BOOL;
use windows::Win32::Foundation::{LPARAM, POINT, RECT};
use windows::Win32::Graphics::Gdi::{
    EnumDisplayMonitors, GetMonitorInfoW, HDC, HMONITOR, MONITORINFOEXW,
};
use windows::Win32::UI::WindowsAndMessaging::{
    GetCursorInfo, GetCursorPos, LoadCursorW, CURSORINFO, IDC_ARROW, IDC_HAND, IDC_IBEAM,
};
use windows_capture::{
    capture::{Context, GraphicsCaptureApiHandler},
    encoder::{AudioSettingsBuilder, ContainerSettingsBuilder, VideoEncoder, VideoSettingsBuilder},
    frame::Frame,
    graphics_capture_api::InternalCaptureControl,
    monitor::Monitor,
};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MousePosition {
    pub x: i32,
    pub y: i32,
    pub timestamp: f64,
    pub is_clicked: bool,
    pub cursor_type: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MonitorInfo {
    pub id: String,
    pub name: String,
    pub x: i32,
    pub y: i32,
    pub width: u32,
    pub height: u32,
    pub is_primary: bool,
}

lazy_static::lazy_static! {
    pub static ref MOUSE_POSITIONS: Mutex<VecDeque<MousePosition>> = Mutex::new(VecDeque::new());
    pub static ref IS_RECORDING: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref SHOULD_STOP: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref SHOULD_STOP_AUDIO: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref ENCODING_FINISHED: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref AUDIO_ENCODING_FINISHED: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref ENCODER_ACTIVE: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref IS_MOUSE_CLICKED: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    // Track if we already captured the click event (to only record one frame as clicked)
    pub static ref CLICK_CAPTURED: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
}

pub static mut VIDEO_PATH: Option<String> = None;
pub static mut AUDIO_PATH: Option<String> = None;
pub static mut MONITOR_X: i32 = 0;
pub static mut MONITOR_Y: i32 = 0;

pub struct CaptureHandler {
    encoder: Option<VideoEncoder>,
    start: Instant,
    last_mouse_capture: Instant,
    frame_count: u32,
    last_frame_time: Instant,
    dropped_frames: u32,
}

fn get_cursor_type() -> String {
    unsafe {
        let mut cursor_info: CURSORINFO = std::mem::zeroed();
        cursor_info.cbSize = std::mem::size_of::<CURSORINFO>() as u32;

        if GetCursorInfo(&mut cursor_info).is_ok() && cursor_info.flags.0 != 0 {
            let current_handle = cursor_info.hCursor.0;

            let arrow = LoadCursorW(None, IDC_ARROW).unwrap().0;
            let ibeam = LoadCursorW(None, IDC_IBEAM).unwrap().0;
            let hand = LoadCursorW(None, IDC_HAND).unwrap().0;

            if current_handle == arrow {
                "default".to_string()
            } else if current_handle == ibeam {
                "text".to_string()
            } else if current_handle == hand {
                "pointer".to_string()
            } else {
                "other".to_string()
            }
        } else {
            "default".to_string()
        }
    }
}

impl GraphicsCaptureApiHandler for CaptureHandler {
    type Flags = String;
    type Error = Box<dyn std::error::Error + Send + Sync>;

    fn new(ctx: Context<Self::Flags>) -> Result<Self, Self::Error> {
        let monitor_index = ctx.flags.parse::<usize>().unwrap_or(0);

        let monitor = Monitor::from_index(monitor_index + 1)?;
        let mut width = monitor.width()?;
        let mut height = monitor.height()?;

        // Ensure even dimensions for encoding
        if width % 2 != 0 {
            width -= 1;
        }
        if height % 2 != 0 {
            height -= 1;
        }

        let app_data_dir = dirs::data_local_dir()
            .unwrap_or_else(|| std::env::temp_dir())
            .join("screen-goated-toolbox")
            .join("recordings");

        std::fs::create_dir_all(&app_data_dir)?;

        let video_path = app_data_dir.join(format!(
            "recording_{}.mp4",
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_millis()
        ));

        let audio_path = app_data_dir.join(format!(
            "recording_{}.wav",
            std::time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)
                .unwrap()
                .as_millis()
        ));

        unsafe {
            VIDEO_PATH = Some(video_path.to_string_lossy().to_string());
            AUDIO_PATH = Some(audio_path.to_string_lossy().to_string());
        }

        let video_settings = VideoSettingsBuilder::new(width, height)
            .frame_rate(60)
            .bitrate(15_000_000); // 15Mbps

        println!(
            "Initializing VideoEncoder: {}x{} @ 60fps, Monitor Index: {}",
            width, height, monitor_index
        );

        let encoder = VideoEncoder::new(
            video_settings,
            AudioSettingsBuilder::default().disabled(true),
            ContainerSettingsBuilder::default(),
            &video_path,
        )?;

        SHOULD_STOP_AUDIO.store(false, Ordering::SeqCst);
        AUDIO_ENCODING_FINISHED.store(false, Ordering::SeqCst);
        audio_engine::record_audio(
            audio_path.to_string_lossy().to_string(),
            SHOULD_STOP_AUDIO.clone(),
            AUDIO_ENCODING_FINISHED.clone(),
        );

        ENCODER_ACTIVE.store(true, Ordering::SeqCst);
        ENCODING_FINISHED.store(false, Ordering::SeqCst);

        Ok(Self {
            encoder: Some(encoder),
            start: Instant::now(),
            last_mouse_capture: Instant::now(),
            frame_count: 0,
            last_frame_time: Instant::now(),
            dropped_frames: 0,
        })
    }

    fn on_frame_arrived(
        &mut self,
        frame: &mut Frame,
        capture_control: InternalCaptureControl,
    ) -> Result<(), Self::Error> {
        if !ENCODER_ACTIVE.load(Ordering::SeqCst) {
            return Ok(());
        }

        if let Err(e) = self.encoder.as_mut().unwrap().send_frame(frame) {
            eprintln!("Encoder error: {}", e);
        }

        if self.frame_count % 60 == 0 {
            // Debug log every ~1 second
            println!("Captured frame {}", self.frame_count);
        }
        self.frame_count += 1;

        if self.last_mouse_capture.elapsed().as_millis() >= 16 {
            unsafe {
                let mut point = POINT::default();
                if GetCursorPos(&mut point).is_ok() {
                    // Record actual held state - cursor should stay squished while held
                    let is_clicked = IS_MOUSE_CLICKED.load(Ordering::SeqCst);
                    let cursor_type = get_cursor_type();

                    let mouse_pos = MousePosition {
                        x: point.x - MONITOR_X,
                        y: point.y - MONITOR_Y,
                        timestamp: self.start.elapsed().as_secs_f64(),
                        is_clicked,
                        cursor_type,
                    };

                    MOUSE_POSITIONS.lock().push_back(mouse_pos);
                }
            }
            self.last_mouse_capture = Instant::now();
        }

        if SHOULD_STOP.load(Ordering::SeqCst) {
            ENCODER_ACTIVE.store(false, Ordering::SeqCst);
            SHOULD_STOP_AUDIO.store(true, Ordering::SeqCst);
            if let Some(encoder) = self.encoder.take() {
                std::thread::spawn(move || {
                    let _ = encoder.finish();
                    ENCODING_FINISHED.store(true, Ordering::SeqCst);
                });
            }
            capture_control.stop();
        }

        Ok(())
    }

    fn on_closed(&mut self) -> Result<(), Self::Error> {
        Ok(())
    }
}

pub fn get_monitors() -> Vec<MonitorInfo> {
    let mut monitors_vec: Vec<HMONITOR> = Vec::new();
    unsafe {
        let _ = EnumDisplayMonitors(
            None,
            None,
            Some(monitor_enum_proc),
            LPARAM(&mut monitors_vec as *mut _ as isize),
        );

        let mut monitor_infos = Vec::new();
        for (index, &hmonitor) in monitors_vec.iter().enumerate() {
            let mut info: MONITORINFOEXW = zeroed();
            info.monitorInfo.cbSize = std::mem::size_of::<MONITORINFOEXW>() as u32;

            if GetMonitorInfoW(hmonitor, &mut info.monitorInfo as *mut _).as_bool() {
                let rect = info.monitorInfo.rcMonitor;
                monitor_infos.push(MonitorInfo {
                    id: index.to_string(),
                    name: format!("Display {}", index + 1),
                    x: rect.left,
                    y: rect.top,
                    width: (rect.right - rect.left) as u32,
                    height: (rect.bottom - rect.top) as u32,
                    is_primary: info.monitorInfo.dwFlags & 1 == 1,
                });
            }
        }
        monitor_infos
    }
}

pub unsafe extern "system" fn monitor_enum_proc(
    hmonitor: HMONITOR,
    _: HDC,
    _: *mut RECT,
    lparam: LPARAM,
) -> BOOL {
    let monitors = &mut *(lparam.0 as *mut Vec<HMONITOR>);
    monitors.push(hmonitor);
    true.into()
}
</file>

<file path="src/unpack_dlls.rs">
use std::fs;
use std::path::PathBuf;
use windows::Win32::System::LibraryLoader::SetDllDirectoryW;

/// Unpacks embedded DLLs to the local app data directory if they are missing.
/// This avoids cluttering the folder where the EXE is located.
pub fn unpack_dlls() {
    // Determine the path to %LOCALAPPDATA%/screen-goated-toolbox/bin
    let mut bin_dir = dirs::data_local_dir().unwrap_or_else(|| PathBuf::from("."));
    bin_dir.push("screen-goated-toolbox");
    bin_dir.push("bin");

    // Ensure the directory exists
    let _ = fs::create_dir_all(&bin_dir);

    // We embed the DLLs using include_bytes!
    let dlls: &[(&str, &[u8])] = &[
        (
            "vcruntime140.dll",
            include_bytes!("embed_dlls/vcruntime140.dll"),
        ),
        (
            "vcruntime140_1.dll",
            include_bytes!("embed_dlls/vcruntime140_1.dll"),
        ),
        ("msvcp140.dll", include_bytes!("embed_dlls/msvcp140.dll")),
        (
            "msvcp140_1.dll",
            include_bytes!("embed_dlls/msvcp140_1.dll"),
        ),
        ("DirectML.dll", include_bytes!("embed_dlls/DirectML.dll")),
        (
            "onnxruntime.dll",
            include_bytes!("embed_dlls/onnxruntime.dll"),
        ),
    ];

    for (name, bytes) in dlls {
        let path = bin_dir.join(name);
        // Only write if missing to avoid unnecessary disk IO
        if !path.exists() {
            let _ = fs::write(&path, bytes);
        }
    }

    // Tell Windows to look in our private bin directory for DLLs (for the current process)
    unsafe {
        let path_wide: Vec<u16> = bin_dir
            .to_string_lossy()
            .encode_utf16()
            .chain(std::iter::once(0))
            .collect();
        let _ = SetDllDirectoryW(windows::core::PCWSTR(path_wide.as_ptr()));
    }

    // Add to PATH so child processes (like WebView2 helpers) can also find them
    if let Ok(current_path) = std::env::var("PATH") {
        let new_path = format!("{};{}", bin_dir.to_string_lossy(), current_path);
        std::env::set_var("PATH", new_path);
    }

    crate::log_info!("[Unpacker] DLLs verified/unpacked to {:?}", bin_dir);
}
</file>

<file path="screen-record/src/lib/videoController.ts">
import { videoRenderer } from './videoRenderer';
import type { VideoSegment, BackgroundConfig, MousePosition } from '@/types/video';

interface VideoControllerOptions {
  videoRef: HTMLVideoElement;
  audioRef?: HTMLAudioElement;
  canvasRef: HTMLCanvasElement;
  tempCanvasRef: HTMLCanvasElement;
  onTimeUpdate?: (time: number) => void;
  onPlayingChange?: (isPlaying: boolean) => void;
  onVideoReady?: (ready: boolean) => void;
  onError?: (error: string) => void;
  onDurationChange?: (duration: number) => void;
  onMetadataLoaded?: (metadata: { duration: number, width: number, height: number }) => void;
}

interface VideoState {
  isPlaying: boolean;
  isReady: boolean;
  isSeeking: boolean;
  currentTime: number;
  duration: number;
}

interface RenderOptions {
  segment: VideoSegment;
  backgroundConfig: BackgroundConfig;
  mousePositions: MousePosition[];
}


export class VideoController {
  private video: HTMLVideoElement;
  private audio?: HTMLAudioElement;
  private canvas: HTMLCanvasElement;
  private tempCanvas: HTMLCanvasElement;
  private options: VideoControllerOptions;
  private state: VideoState;
  private renderOptions?: RenderOptions;

  constructor(options: VideoControllerOptions) {
    this.video = options.videoRef;
    this.audio = options.audioRef;
    this.canvas = options.canvasRef;
    this.tempCanvas = options.tempCanvasRef;
    this.options = options;

    this.state = {
      isPlaying: false,
      isReady: false,
      isSeeking: false,
      currentTime: 0,
      duration: 0
    };

    this.initializeEventListeners();
  }

  private initializeEventListeners() {
    console.log('[VideoController] Initializing listeners (v2-no-waiting)');
    this.video.addEventListener('loadeddata', this.handleLoadedData);
    this.video.addEventListener('play', this.handlePlay);
    this.video.addEventListener('pause', this.handlePause);
    this.video.addEventListener('timeupdate', this.handleTimeUpdate);
    this.video.addEventListener('seeked', this.handleSeeked);
    this.video.addEventListener('loadedmetadata', this.handleLoadedMetadata);
    this.video.addEventListener('durationchange', this.handleDurationChange);
    this.video.addEventListener('error', this.handleError);
  }

  private handleLoadedData = () => {
    console.log('[VideoController] Video loaded data');
    this.renderFrame();
    this.setReady(true);
  };

  private handlePlay = () => {
    console.log('[VideoController] Play event');
    if (this.audio) {
      this.audio.currentTime = this.video.currentTime;
      this.audio.playbackRate = this.video.playbackRate;
      this.audio.play().catch(e => console.warn('[VideoController] Audio play failed:', e));
    }

    // Ensure animation is running
    if (this.renderOptions) {
      videoRenderer.startAnimation({
        video: this.video,
        canvas: this.canvas,
        tempCanvas: this.tempCanvas,
        segment: this.renderOptions.segment,
        backgroundConfig: this.renderOptions.backgroundConfig,
        mousePositions: this.renderOptions.mousePositions,
        currentTime: this.video.currentTime
      });
    }

    this.setPlaying(true);
  };

  private handlePause = () => {
    console.log('[VideoController] Pause event');
    if (this.audio) {
      this.audio.pause();
    }
    this.setPlaying(false);
    this.renderFrame();
  };

  private handleTimeUpdate = () => {
    if (!this.state.isSeeking) {
      const currentTime = this.video.currentTime;

      // Handle trim bounds
      if (this.renderOptions?.segment) {
        const { trimStart, trimEnd } = this.renderOptions.segment;

        if (currentTime >= trimEnd && !this.video.paused) {
          console.log('[VideoController] Reached trim end', { currentTime, trimStart, trimEnd });
          this.video.pause(); // Triggers handlePause
          return;
        }

        if (currentTime < trimStart) {
          this.video.currentTime = trimStart;
          if (this.audio) this.audio.currentTime = trimStart;
        }
      }

      // Smooth audio sync: only correct if drift > 150ms to avoid audio stutter
      if (this.audio && !this.video.paused) {
        const drift = Math.abs(this.video.currentTime - this.audio.currentTime);
        if (drift > 0.15) {
          this.audio.currentTime = this.video.currentTime;
        }
      }

      this.setCurrentTime(currentTime);
      // Removed renderFrame here - allow animation loop to handle updates during playback
      // If paused, handlePause triggers renderFrame.
      // If playing, startAnimation loop handles it.
    }
  };

  private handleSeeked = () => {
    this.setSeeking(false);
    this.setCurrentTime(this.video.currentTime);
    this.renderFrame();
  };

  private handleLoadedMetadata = () => {
    console.log('Video metadata loaded:', {
      duration: this.video.duration,
      width: this.video.videoWidth,
      height: this.video.videoHeight
    });

    this.options.onMetadataLoaded?.({
      duration: this.video.duration,
      width: this.video.videoWidth,
      height: this.video.videoHeight
    });

    if (this.video.duration !== Infinity) {
      this.setDuration(this.video.duration);
      // Initialize segment if none exists
      if (!this.renderOptions?.segment) {
        this.renderOptions = {
          segment: this.initializeSegment(),
          backgroundConfig: {
            scale: 100,
            borderRadius: 8,
            backgroundType: 'solid'
          },
          mousePositions: []
        };
      }
    }
  };

  private handleDurationChange = () => {
    console.log('[VideoController] Duration changed:', this.video.duration);
    if (this.video.duration !== Infinity) {
      this.setDuration(this.video.duration);

      // Update trimEnd if it was not set correctly or is 0
      if (this.renderOptions?.segment) {
        if (this.renderOptions.segment.trimEnd === 0 || this.renderOptions.segment.trimEnd > this.video.duration) {
          console.log('[VideoController] Updating segment trimEnd to duration:', this.video.duration);
          this.renderOptions.segment.trimEnd = this.video.duration;
        }
      }
    }
  };

  private handleError = (error: ErrorEvent) => {
    console.error('Video error:', error);
    this.options.onError?.(error.message);
  };

  private setPlaying(playing: boolean) {
    this.state.isPlaying = playing;
    this.options.onPlayingChange?.(playing);
  }

  private setReady(ready: boolean) {
    this.state.isReady = ready;
    this.options.onVideoReady?.(ready);
  }

  private setSeeking(seeking: boolean) {
    this.state.isSeeking = seeking;
  }

  private setCurrentTime(time: number) {
    this.state.currentTime = time;
    this.options.onTimeUpdate?.(time);
  }

  private setDuration(duration: number) {
    this.state.duration = duration;
    this.options.onDurationChange?.(duration);
  }

  private renderFrame() {
    if (!this.renderOptions) return;

    const renderContext = {
      video: this.video,
      canvas: this.canvas,
      tempCanvas: this.tempCanvas,
      segment: this.renderOptions.segment,
      backgroundConfig: this.renderOptions.backgroundConfig,
      mousePositions: this.renderOptions.mousePositions,
      currentTime: this.getAdjustedTime(this.video.currentTime)
    };

    // Only draw if video is ready
    if (this.video.readyState >= 2) {
      // Draw even if paused to support live preview when editing
      // but we can skip if the video is at the end and paused
      if (renderContext.video.paused && renderContext.video.currentTime >= renderContext.video.duration) {
        // No animationFrame here, as renderFrame is called manually or by event listeners
        return;
      }
      // Update the active context for the animation loop
      videoRenderer.updateRenderContext(renderContext);
      videoRenderer.drawFrame(renderContext);
    } else {
      // console.log('[VideoController] Skipping frame - video not ready');
    }
  }

  // Public API
  public updateRenderOptions(options: RenderOptions) {
    this.renderOptions = options;
    this.renderFrame();
  }

  public play() {
    // Reset seeking state to ensure play works after seek
    this.setSeeking(false);

    if (!this.state.isReady) {
      console.warn('[VideoController] Play ignored: not ready');
      return;
    }

    if (this.renderOptions?.segment) {
      const { trimStart, trimEnd } = this.renderOptions.segment;
      if (this.video.currentTime >= trimEnd - 0.05) {
        this.video.currentTime = trimStart;
      }
    }

    this.video.play().catch(e => console.warn('[VideoController] Play attempt failed:', e));
  }

  public pause() {
    this.video.pause();
  }

  public seek(time: number) {
    if (!this.state.isReady) return;

    if (this.renderOptions?.segment) {
      const { trimStart, trimEnd } = this.renderOptions.segment;
      time = Math.max(trimStart, Math.min(time, trimEnd));
    }

    this.setSeeking(true);
    this.video.currentTime = time;
    if (this.audio) this.audio.currentTime = time;

    // IMPORTANT: Do NOT call renderFrame() here. 
    // Let the 'seeked' event trigger it to avoid drawing frames mid-seek
    // which can cause artifacts/corruption.
  }

  public togglePlayPause() {
    if (this.video.paused) {
      this.play();
    } else {
      this.pause();
    }
  }

  public setVolume(volume: number) {
    if (this.audio) {
      this.audio.volume = volume;
    }
    this.video.volume = volume;
  }

  public destroy() {
    this.video.removeEventListener('loadeddata', this.handleLoadedData);
    this.video.removeEventListener('play', this.handlePlay);
    this.video.removeEventListener('pause', this.handlePause);
    this.video.removeEventListener('timeupdate', this.handleTimeUpdate);
    this.video.removeEventListener('seeked', this.handleSeeked);
    this.video.removeEventListener('loadedmetadata', this.handleLoadedMetadata);
    this.video.removeEventListener('durationchange', this.handleDurationChange);
    this.video.removeEventListener('error', this.handleError);
  }

  // Getters
  public get isPlaying() { return this.state.isPlaying; }
  public get isReady() { return this.state.isReady; }
  public get isSeeking() { return this.state.isSeeking; }
  public get currentTime() { return this.state.currentTime; }
  public get duration() { return this.state.duration; }

  // Add this new method
  public async loadVideo({ videoBlob, videoUrl, onLoadingProgress }: { videoBlob?: Blob, videoUrl?: string, onLoadingProgress?: (p: number) => void }): Promise<string> {
    try {
      // Reset states
      this.setReady(false);
      this.setSeeking(false);
      this.setPlaying(false);

      // Clear previous video properly to avoid 'Video error' events
      this.video.pause();
      this.video.src = "";
      this.video.load();
      this.video.removeAttribute('src');

      // Clear previous audio
      if (this.audio) {
        this.audio.pause();
        this.audio.src = "";
        this.audio.load();
        this.audio.removeAttribute('src');
      }

      let blob: Blob;

      if (videoBlob) {
        blob = videoBlob;
      } else if (videoUrl) {
        console.log('[VideoController] Fetching video data from:', videoUrl);
        const response = await fetch(videoUrl);
        if (!response.ok) throw new Error('Failed to fetch video');

        const reader = response.body!.getReader();
        const contentLength = +(response.headers.get('Content-Length') ?? 0);
        let receivedLength = 0;
        const chunks = [];

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          chunks.push(value);
          receivedLength += value.length;
          const progress = Math.min(((receivedLength / contentLength) * 100), 100);
          onLoadingProgress?.(progress);
        }

        blob = new Blob(chunks, { type: 'video/mp4' });
      } else {
        throw new Error('No video data provided');
      }

      const objectUrl = URL.createObjectURL(blob);
      await this.handleVideoSourceChange(objectUrl);
      return objectUrl;
    } catch (error) {
      console.error('[VideoController] Failed to load video:', error);
      throw error;
    }
  }

  public async loadAudio({ audioBlob, audioUrl, onLoadingProgress }: { audioBlob?: Blob, audioUrl?: string, onLoadingProgress?: (p: number) => void }): Promise<string> {
    try {
      if (!this.audio) return "";

      let blob: Blob;

      if (audioBlob) {
        blob = audioBlob;
      } else if (audioUrl) {
        console.log('[VideoController] Fetching audio data from:', audioUrl);
        const response = await fetch(audioUrl);
        if (!response.ok) throw new Error('Failed to fetch audio');

        const reader = response.body!.getReader();
        const contentLength = +(response.headers.get('Content-Length') ?? 0);
        let receivedLength = 0;
        const chunks = [];

        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          chunks.push(value);
          receivedLength += value.length;
          const progress = Math.min(((receivedLength / contentLength) * 100), 100);
          onLoadingProgress?.(progress);
        }

        blob = new Blob(chunks, { type: 'audio/wav' });
      } else {
        return "";
      }

      const objectUrl = URL.createObjectURL(blob);
      this.audio.src = objectUrl;
      this.audio.load();

      return objectUrl;
    } catch (error) {
      console.error('[VideoController] Failed to load audio:', error);
      return "";
    }
  }

  // Update existing method to be private
  private async handleVideoSourceChange(videoUrl: string): Promise<void> {
    if (!this.video || !this.canvas) return;

    // Reset states
    this.setReady(false);
    this.setSeeking(false);
    this.setPlaying(false);

    // Reset video element
    this.video.pause();
    this.video.src = "";
    this.video.load();
    this.video.removeAttribute('src');

    return new Promise<void>((resolve) => {
      const handleCanPlayThrough = () => {
        console.log('[VideoController] Video can play through');
        this.video.removeEventListener('canplaythrough', handleCanPlayThrough);

        // Set up canvas
        this.canvas.width = this.video.videoWidth;
        this.canvas.height = this.video.videoHeight;

        const ctx = this.canvas.getContext('2d');
        if (ctx) {
          ctx.imageSmoothingEnabled = true;
          ctx.imageSmoothingQuality = 'high';
        }

        this.setReady(true);
        resolve();
      };

      // Set up video
      this.video.addEventListener('canplaythrough', handleCanPlayThrough);
      this.video.preload = 'auto';
      this.video.src = videoUrl;
      this.video.load(); // Explicitly load the video
    });
  }

  // Add this new method to handle time adjustment
  private getAdjustedTime(time: number): number {
    if (!this.renderOptions?.segment) return time;

    const { trimStart, trimEnd } = this.renderOptions.segment;
    const trimDuration = trimEnd - trimStart;

    // Calculate the relative position within the trimmed section
    const relativeTime = ((time - trimStart) % trimDuration);

    // If time is negative, adjust it to wrap from the end
    const adjustedTime = relativeTime < 0
      ? trimEnd + relativeTime
      : trimStart + relativeTime;

    return adjustedTime;
  }

  // Add new method
  public initializeSegment(): VideoSegment {
    // If duration is available, use it, otherwise use a default safe large number
    // It will be corrected by handleDurationChange later
    const duration = (this.video && this.video.duration !== Infinity && !isNaN(this.video.duration))
      ? this.video.duration
      : 3600;

    const initialSegment: VideoSegment = {
      trimStart: 0,
      trimEnd: duration,
      zoomKeyframes: [],
      textSegments: []
    };
    return initialSegment;
  }

  // Add this new method
  public isAtEnd(): boolean {
    if (!this.renderOptions?.segment) return false;
    const { trimEnd } = this.renderOptions.segment;
    return Math.abs(this.video.currentTime - trimEnd) < 0.1; // Allow 0.1s tolerance
  }
}

export const createVideoController = (options: VideoControllerOptions) => {
  return new VideoController(options);
};
</file>

<file path="screen-record/src/types/video.ts">
export type ExportQuality = 'original' | 'balanced';
export type DimensionPreset = 'original' | '1080p' | '720p';

export interface ZoomKeyframe {
  time: number;
  duration: number;
  zoomFactor: number;
  positionX: number;
  positionY: number;
  easingType: 'linear' | 'easeOut' | 'easeInOut';
}

export interface TextSegment {
  id: string;
  startTime: number;
  endTime: number;
  text: string;
  style: {
    fontSize: number;
    color: string;
    x: number;  // 0-100 percentage
    y: number;  // 0-100 percentage
  };
}

export interface CropRect {
  x: number; // 0-1
  y: number; // 0-1
  width: number; // 0-1
  height: number; // 0-1
}

export interface VideoSegment {
  trimStart: number;
  trimEnd: number;
  zoomKeyframes: ZoomKeyframe[];
  smoothMotionPath?: { time: number; x: number; y: number; zoom: number }[];
  zoomInfluencePoints?: { time: number; value: number }[];
  textSegments: TextSegment[];
  crop?: CropRect;
}

export interface BackgroundConfig {
  scale: number;
  borderRadius: number;
  backgroundType: 'solid' | 'gradient1' | 'gradient2' | 'gradient3' | 'custom';
  shadow?: number;
  cursorScale?: number;
  cursorSmoothness?: number;
  customBackground?: string;
  cropBottom?: number; // 0-100 percentage
  volume?: number; // 0-1
}

export interface MousePosition {
  x: number;
  y: number;
  timestamp: number;
  isClicked?: boolean;
  cursor_type?: string;
}

export interface VideoMetadata {
  total_chunks: number;
  duration: number;
  width: number;
  height: number;
}

export interface ExportOptions {
  quality?: ExportQuality;
  dimensions: DimensionPreset;
  speed: number;
  video?: HTMLVideoElement;
  canvas?: HTMLCanvasElement;
  tempCanvas?: HTMLCanvasElement;
  segment?: VideoSegment;
  backgroundConfig?: BackgroundConfig;
  mousePositions?: MousePosition[];
  onProgress?: (progress: number) => void;
  audio?: HTMLAudioElement;
}

export interface ExportPreset {
  width: number;
  height: number;
  bitrate: number;
  label: string;
}

export interface Project {
  id: string;
  name: string;
  createdAt: number;
  lastModified: number;
  videoBlob: Blob;
  audioBlob?: Blob;
  segment: VideoSegment;
  backgroundConfig: BackgroundConfig;
  mousePositions: MousePosition[];
  thumbnail?: string;
}
</file>

<file path="src/gui/settings_ui/download_manager/run.rs">
use super::types::{CookieBrowser, DownloadState, DownloadType, InstallStatus, UpdateStatus};
use super::utils::{download_file, extract_ffmpeg, log};
use std::fs;
use std::io::{BufRead, BufReader};
use std::path::PathBuf;
use std::sync::atomic::Ordering;
use std::sync::{Arc, Mutex};
use std::thread;

use super::DownloadManager;
#[cfg(windows)]
use std::os::windows::process::CommandExt;

impl DownloadManager {
    pub fn check_status(&self) {
        let bin = self.bin_dir.clone();
        let ffmpeg_s = self.ffmpeg_status.clone();
        let ytdlp_s = self.ytdlp_status.clone();
        let logs = self.logs.clone();

        thread::spawn(move || {
            if !bin.exists() {
                let _ = fs::create_dir_all(&bin);
            }

            // Check yt-dlp
            let ytdlp_path = bin.join("yt-dlp.exe");
            if ytdlp_path.exists() {
                *ytdlp_s.lock().unwrap() = InstallStatus::Installed;
            } else {
                *ytdlp_s.lock().unwrap() = InstallStatus::Missing;
                log(&logs, "yt-dlp missing");
            }

            // Check ffmpeg
            let ffmpeg_path = bin.join("ffmpeg.exe");
            if ffmpeg_path.exists() {
                *ffmpeg_s.lock().unwrap() = InstallStatus::Installed;
            } else {
                *ffmpeg_s.lock().unwrap() = InstallStatus::Missing;
                log(&logs, "ffmpeg missing");
            }

            // Cleanup any partial downloads (.tmp files)
            if let Ok(entries) = fs::read_dir(&bin) {
                for entry in entries.flatten() {
                    let path = entry.path();
                    if path.extension().map_or(false, |ext| ext == "tmp") {
                        let _ = fs::remove_file(&path);
                    }
                }
            }
        });
    }

    pub fn check_updates(&self) {
        if self.is_checking_updates.load(Ordering::Relaxed) {
            return;
        }
        self.is_checking_updates.store(true, Ordering::Relaxed);

        let bin = self.bin_dir.clone();
        let ytdlp_status_store = self.ytdlp_update_status.clone();
        let ffmpeg_status_store = self.ffmpeg_update_status.clone();
        let ytdlp_ver = self.ytdlp_version.clone();
        let ffmpeg_ver = self.ffmpeg_version.clone();
        let logs = self.logs.clone();
        let ytdlp_install = self.ytdlp_status.clone();
        let ffmpeg_install = self.ffmpeg_status.clone();
        let checking_flag = self.is_checking_updates.clone();

        thread::spawn(move || {
            log(&logs, "Checking for updates...");

            // Set Checking
            *ytdlp_status_store.lock().unwrap() = UpdateStatus::Checking;
            *ffmpeg_status_store.lock().unwrap() = UpdateStatus::Checking;

            // 1. Check yt-dlp
            // Only if installed
            let mut check_ytdlp = false;
            {
                let s = ytdlp_install.lock().unwrap();
                if *s == InstallStatus::Installed {
                    check_ytdlp = true;
                } else {
                    *ytdlp_status_store.lock().unwrap() = UpdateStatus::Idle;
                }
            }
            if check_ytdlp {
                let ytdlp_path = bin.join("yt-dlp.exe");
                let output = std::process::Command::new(&ytdlp_path)
                    .arg("--version")
                    .creation_flags(0x08000000) // CREATE_NO_WINDOW
                    .output();

                if let Ok(out) = output {
                    let local_ver = String::from_utf8_lossy(&out.stdout).trim().to_string();
                    *ytdlp_ver.lock().unwrap() = Some(local_ver.clone());

                    // Fetch latest
                    let _resp = ureq::get(
                        "https://github.com/yt-dlp/yt-dlp-nightly-builds/releases/latest",
                    )
                    .header("User-Agent", "Mozilla/5.0")
                    .call();

                    if let Ok(r) = ureq::get(
                        "https://api.github.com/repos/yt-dlp/yt-dlp-nightly-builds/releases/latest",
                    )
                    .header("User-Agent", "ScreenGoatedToolbox")
                    .call()
                    {
                        if let Ok(json_str) = r.into_body().read_to_string() {
                            // Manual JSON parse for "tag_name"
                            if let Some(pos) = json_str.find("\"tag_name\"") {
                                let sub = &json_str[pos..];
                                if let Some(colon) = sub.find(':') {
                                    if let Some(quote1) = sub[colon..].find('"') {
                                        let start = colon + quote1 + 1;
                                        if let Some(quote2) = sub[start..].find('"') {
                                            let remote_ver = &sub[start..start + quote2];
                                            log(
                                                &logs,
                                                format!(
                                                    "yt-dlp: local={}, remote={}",
                                                    local_ver, remote_ver
                                                ),
                                            );
                                            if remote_ver != local_ver && !remote_ver.is_empty() {
                                                *ytdlp_status_store.lock().unwrap() =
                                                    UpdateStatus::UpdateAvailable(
                                                        remote_ver.to_string(),
                                                    );
                                            } else {
                                                *ytdlp_status_store.lock().unwrap() =
                                                    UpdateStatus::UpToDate;
                                            }
                                        }
                                    }
                                }
                            }
                        }
                    }
                }
            }

            // 2. Check ffmpeg
            let mut check_ffmpeg = false;
            {
                let s = ffmpeg_install.lock().unwrap();
                if *s == InstallStatus::Installed {
                    check_ffmpeg = true;
                } else {
                    *ffmpeg_status_store.lock().unwrap() = UpdateStatus::Idle;
                }
            }
            if check_ffmpeg {
                let ffmpeg_path = bin.join("ffmpeg.exe");
                let output = std::process::Command::new(&ffmpeg_path)
                    .arg("-version")
                    .creation_flags(0x08000000)
                    .output();

                if let Ok(out) = output {
                    let stdout = String::from_utf8_lossy(&out.stdout);
                    // Line 1: ffmpeg version 6.1.1-essentials...
                    if let Some(line) = stdout.lines().next() {
                        let parts: Vec<&str> = line.split_whitespace().collect();
                        if parts.len() >= 3 && parts[0] == "ffmpeg" && parts[1] == "version" {
                            let ver_chunk = parts[2]; // 6.1.1-essentials...
                                                      // Extract just the version number (digits and dots)
                            let local_ver: String = ver_chunk
                                .chars()
                                .take_while(|c| c.is_ascii_digit() || *c == '.')
                                .collect();
                            *ffmpeg_ver.lock().unwrap() = Some(local_ver.clone());

                            // Fetch remote
                            if let Ok(r) =
                                ureq::get("https://www.gyan.dev/ffmpeg/builds/release-version")
                                    .header("User-Agent", "ScreenGoatedToolbox")
                                    .call()
                            {
                                if let Ok(remote_ver) = r.into_body().read_to_string() {
                                    let remote_ver = remote_ver.trim();
                                    log(
                                        &logs,
                                        format!(
                                            "ffmpeg: local={}, remote={}",
                                            local_ver, remote_ver
                                        ),
                                    );
                                    if remote_ver != local_ver && !remote_ver.is_empty() {
                                        *ffmpeg_status_store.lock().unwrap() =
                                            UpdateStatus::UpdateAvailable(remote_ver.to_string());
                                    } else {
                                        *ffmpeg_status_store.lock().unwrap() =
                                            UpdateStatus::UpToDate;
                                    }
                                }
                            }
                        }
                    }
                }
            }
            checking_flag.store(false, Ordering::Relaxed);
            log(&logs, "Update check complete.");
        });
    }

    pub fn get_dependency_sizes(&self) -> (String, String) {
        let ytdlp_path = self.bin_dir.join("yt-dlp.exe");
        let ffmpeg_path = self.bin_dir.join("ffmpeg.exe");

        let size_to_string = |path: PathBuf| -> String {
            if let Ok(metadata) = fs::metadata(path) {
                let size_mb = metadata.len() as f64 / 1024.0 / 1024.0;
                format!("{:.1} MB", size_mb)
            } else {
                "0 MB".to_string()
            }
        };

        (size_to_string(ytdlp_path), size_to_string(ffmpeg_path))
    }

    pub fn delete_dependencies(&self) {
        let ytdlp_path = self.bin_dir.join("yt-dlp.exe");
        let ffmpeg_path = self.bin_dir.join("ffmpeg.exe");

        let _ = fs::remove_file(ytdlp_path);
        let _ = fs::remove_file(ffmpeg_path);

        // Reset status
        *self.ytdlp_status.lock().unwrap() = InstallStatus::Missing;
        *self.ffmpeg_status.lock().unwrap() = InstallStatus::Missing;
    }

    pub fn cancel_download(&self) {
        self.cancel_flag.store(true, Ordering::Relaxed);
    }

    pub fn change_download_folder(&mut self) {
        // PowerShell hack to open folder picker
        let mut cmd = std::process::Command::new("powershell");
        cmd.args(&["-Command", "Add-Type -AssemblyName System.Windows.Forms; $f = New-Object System.Windows.Forms.FolderBrowserDialog; $f.ShowDialog() | Out-Null; $f.SelectedPath"]);
        #[cfg(windows)]
        cmd.creation_flags(0x08000000);

        let output = cmd.output();

        if let Ok(out) = output {
            if let Ok(path) = String::from_utf8(out.stdout) {
                let path = path.trim().to_string();
                if !path.is_empty() {
                    self.custom_download_path = Some(PathBuf::from(path));
                    self.save_settings();
                }
            }
        }
    }

    pub fn start_download_ytdlp(&self) {
        let bin = self.bin_dir.clone();
        let status = self.ytdlp_status.clone();
        let update_status = self.ytdlp_update_status.clone();
        let logs = self.logs.clone();
        let cancel = self.cancel_flag.clone();
        // Cannot pass self_clone easily to thread as DownloadManager is not Clone-able or meant to be?
        // Actually DownloadManager is not Clone. But we need to call check_updates.
        // check_updates uses Arc fields. We can separate the check logic or just reset status to Idle and let user check again?
        // Better: Reset status to Checking and spawn a delayed check.

        // Wait, self.check_updates() is on &self. The struct has Arcs.
        // We can't nicely call methods from the thread if we don't own self.
        // But we can reset update_status to Idle.

        let bin_clone = bin.clone();

        // We will need to re-run the check logic manually or extract it.
        // For simplicity: Clear version info and Reset update status to Idle so "Check Update" button appears.
        // Even better: Set it to UpToDate if we trust the download.
        // But version string needs update.
        // Let's just set to Idle, so user clicks "Check Update" or we simulate it.
        // Actually, let's explicitly run the version check part for ytdlp here again.

        let ytdlp_ver_store = self.ytdlp_version.clone();

        {
            let mut s = status.lock().unwrap();
            if matches!(
                *s,
                InstallStatus::Downloading(_) | InstallStatus::Extracting
            ) {
                return;
            }
            *s = InstallStatus::Downloading(0.0);
            cancel.store(false, Ordering::Relaxed);
        }

        thread::spawn(move || {
            let url = "https://github.com/yt-dlp/yt-dlp-nightly-builds/releases/latest/download/yt-dlp.exe";
            log(&logs, format!("Starting download: {}", url));

            match download_file(url, &bin.join("yt-dlp.exe"), &status, &cancel) {
                Ok(_) => {
                    *status.lock().unwrap() = InstallStatus::Installed;
                    log(&logs, "yt-dlp installed successfully");
                    *update_status.lock().unwrap() = UpdateStatus::Idle;

                    // Update version string locally
                    #[cfg(target_os = "windows")]
                    use std::os::windows::process::CommandExt;
                    let output = std::process::Command::new(bin_clone.join("yt-dlp.exe"))
                        .arg("--version")
                        .creation_flags(0x08000000)
                        .output();
                    if let Ok(out) = output {
                        let local_ver = String::from_utf8_lossy(&out.stdout).trim().to_string();
                        *ytdlp_ver_store.lock().unwrap() = Some(local_ver);
                    }
                }
                Err(e) => {
                    *status.lock().unwrap() = InstallStatus::Error(e.clone());
                    log(&logs, format!("yt-dlp error: {}", e));
                }
            }
        });
    }

    pub fn start_download_ffmpeg(&self) {
        let bin = self.bin_dir.clone();
        let status = self.ffmpeg_status.clone();
        let update_status = self.ffmpeg_update_status.clone();
        let logs = self.logs.clone();
        let cancel = self.cancel_flag.clone();
        let app_bin = bin.clone();
        let ffmpeg_ver_store = self.ffmpeg_version.clone();

        {
            let mut s = status.lock().unwrap();
            if matches!(
                *s,
                InstallStatus::Downloading(_) | InstallStatus::Extracting
            ) {
                return;
            }
            *s = InstallStatus::Downloading(0.0);
            cancel.store(false, Ordering::Relaxed);
        }

        thread::spawn(move || {
            let url = "https://www.gyan.dev/ffmpeg/builds/ffmpeg-release-essentials.zip";
            log(&logs, format!("Starting download: {}", url));

            let zip_path = bin.join("ffmpeg.zip");
            match download_file(url, &zip_path, &status, &cancel) {
                Ok(_) => {
                    log(&logs, "Download complete. Extracting...");
                    *status.lock().unwrap() = InstallStatus::Extracting;

                    if cancel.load(Ordering::Relaxed) {
                        *status.lock().unwrap() = InstallStatus::Error("Cancelled".to_string());
                        return;
                    }

                    match extract_ffmpeg(&zip_path, &bin) {
                        Ok(_) => {
                            *status.lock().unwrap() = InstallStatus::Installed;
                            log(&logs, "ffmpeg installed successfully");
                            let _ = fs::remove_file(zip_path); // Cleanup
                            *update_status.lock().unwrap() = UpdateStatus::Idle;

                            // Update version string
                            #[cfg(target_os = "windows")]
                            use std::os::windows::process::CommandExt;
                            let output = std::process::Command::new(app_bin.join("ffmpeg.exe"))
                                .arg("-version")
                                .creation_flags(0x08000000)
                                .output();

                            if let Ok(out) = output {
                                let stdout = String::from_utf8_lossy(&out.stdout);
                                if let Some(line) = stdout.lines().next() {
                                    let parts: Vec<&str> = line.split_whitespace().collect();
                                    if parts.len() >= 3
                                        && parts[0] == "ffmpeg"
                                        && parts[1] == "version"
                                    {
                                        let ver_chunk = parts[2];
                                        let local_ver: String = ver_chunk
                                            .chars()
                                            .take_while(|c| c.is_ascii_digit() || *c == '.')
                                            .collect();
                                        *ffmpeg_ver_store.lock().unwrap() = Some(local_ver);
                                    }
                                }
                            }
                        }
                        Err(e) => {
                            *status.lock().unwrap() = InstallStatus::Error(e.clone());
                            log(&logs, format!("Extract error: {}", e));
                        }
                    }
                }
                Err(e) => {
                    *status.lock().unwrap() = InstallStatus::Error(e.clone());
                    log(&logs, format!("ffmpeg download error: {}", e));
                }
            }
        });
    }

    pub fn start_analysis(&mut self) {
        let url = self.input_url.trim().to_string();
        if url.is_empty() {
            return;
        }

        let bin_dir = self.bin_dir.clone();
        let cookie_browser = self.cookie_browser.clone();
        let formats_clone = self.available_formats.clone();
        let manual_subs_clone = self.available_subs_manual.clone();
        let use_subtitles_clone = self.use_subtitles.clone();
        let is_analyzing = self.is_analyzing.clone();
        let error_clone = self.analysis_error.clone();

        self.last_url_analyzed = url.clone();
        *is_analyzing.lock().unwrap() = true;
        *error_clone.lock().unwrap() = None;

        // Reset analysis-specific choices for new URL
        formats_clone.lock().unwrap().clear();
        manual_subs_clone.lock().unwrap().clear();
        self.selected_format = None;
        self.selected_subtitle = None; // Reset selection

        use super::utils::fetch_video_formats;

        thread::spawn(
            move || match fetch_video_formats(&url, &bin_dir, cookie_browser) {
                Ok((formats, manual, _auto)) => {
                    *formats_clone.lock().unwrap() = formats;
                    *manual_subs_clone.lock().unwrap() = manual.clone();
                    if manual.is_empty() {
                        *use_subtitles_clone.lock().unwrap() = false;
                    }
                    *is_analyzing.lock().unwrap() = false;
                }
                Err(e) => {
                    *error_clone.lock().unwrap() = Some(e);
                    *is_analyzing.lock().unwrap() = false;
                }
            },
        );
    }

    pub fn start_media_download(&self, progress_fmt: String) {
        let url = self.input_url.trim().to_string();
        if url.is_empty() {
            return;
        }

        let bin_dir = self.bin_dir.clone();
        let download_type = self.download_type.clone();
        let state = self.download_state.clone();
        let logs = self.logs.clone();

        // Capture advanced flags
        let use_metadata = self.use_metadata;
        let use_sponsorblock = self.use_sponsorblock;
        let use_subtitles = *self.use_subtitles.lock().unwrap();
        let use_playlist = self.use_playlist;
        let cookie_browser = self.cookie_browser.clone();
        let selected_format = self.selected_format.clone();
        let selected_subtitle = self.selected_subtitle.clone();

        let download_path = self
            .custom_download_path
            .clone()
            .unwrap_or_else(|| dirs::download_dir().unwrap_or(PathBuf::from(".")));

        {
            let mut s = state.lock().unwrap();
            if matches!(*s, DownloadState::Downloading(_, _)) {
                return;
            }
            *s = DownloadState::Downloading(0.0, "Starting...".to_string());
        }

        thread::spawn(move || {
            log(&logs, format!("Processing URL: {}", url));
            let ytdlp_exe = bin_dir.join("yt-dlp.exe");

            let mut args = Vec::new();

            // Force UTF-8 output to correctly capture filenames with non-ASCII characters
            args.push("--encoding".to_string());
            args.push("utf-8".to_string());

            // Point to ffmpeg
            args.push("--ffmpeg-location".to_string());
            args.push(bin_dir.to_string_lossy().to_string());

            // Progress per line for potential parsing
            args.push("--newline".to_string());

            if !use_playlist {
                args.push("--no-playlist".to_string());
            } else {
                args.push("--yes-playlist".to_string());
            }

            if use_metadata {
                args.push("--embed-metadata".to_string());
                args.push("--embed-chapters".to_string());
                args.push("--embed-thumbnail".to_string());
            }

            if use_sponsorblock {
                args.push("--sponsorblock-remove".to_string());
                args.push("all".to_string());
            }

            if use_subtitles {
                args.push("--write-subs".to_string());
                args.push("--sub-langs".to_string());
                if let Some(lang) = selected_subtitle {
                    args.push(lang);
                } else {
                    args.push("en.*,vi.*,ko.*".to_string());
                }
                args.push("--embed-subs".to_string());
            }

            match cookie_browser {
                CookieBrowser::None => {}
                CookieBrowser::Chrome => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("chrome".to_string());
                }
                CookieBrowser::Firefox => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("firefox".to_string());
                }
                CookieBrowser::Edge => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("edge".to_string());
                }
                CookieBrowser::Brave => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("brave".to_string());
                }
                CookieBrowser::Opera => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("opera".to_string());
                }
                CookieBrowser::Vivaldi => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("vivaldi".to_string());
                }
                CookieBrowser::Chromium => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("chromium".to_string());
                }
                CookieBrowser::Whale => {
                    args.push("--cookies-from-browser".to_string());
                    args.push("whale".to_string());
                }
            }

            match download_type {
                DownloadType::Video => {
                    args.push("-f".to_string());
                    if let Some(fmt_str) = selected_format {
                        // fmt_str is like "1080p"
                        let height = fmt_str.trim_end_matches('p');
                        // format: bestvideo[height=1080]+bestaudio/best[height=1080]
                        let selector =
                            format!("bestvideo[height={0}]+bestaudio/best[height={0}]", height);
                        args.push(selector);
                    } else {
                        args.push("bestvideo+bestaudio/best".to_string());
                    }
                    args.push("--merge-output-format".to_string());
                    args.push("mp4".to_string());
                }
                DownloadType::Audio => {
                    args.push("-x".to_string());
                    args.push("--audio-format".to_string());
                    args.push("mp3".to_string());
                    args.push("--audio-quality".to_string());
                    args.push("0".to_string());
                }
            }

            args.push("-o".to_string());
            let out_tmpl = download_path.join("%(title)s.%(ext)s");
            args.push(out_tmpl.to_string_lossy().to_string());

            args.push(url);

            use std::process::{Command, Stdio};

            let mut cmd = Command::new(ytdlp_exe);
            cmd.args(&args);

            cmd.stdout(Stdio::piped());
            cmd.stderr(Stdio::piped());
            #[cfg(target_os = "windows")]
            cmd.creation_flags(0x08000000); // CREATE_NO_WINDOW

            log(&logs, format!("Running: yt-dlp ..."));

            match cmd.spawn() {
                Ok(mut child) => {
                    let stdout = child.stdout.take().expect("Failed to open stdout");
                    let stderr = child.stderr.take().expect("Failed to open stderr");

                    let logs_clone = logs.clone();
                    let state_clone = state.clone();
                    let final_filename = Arc::new(Mutex::new(None));
                    let final_filename_clone = final_filename.clone();
                    let fmt_str = progress_fmt.clone();

                    let stdout_thread = thread::spawn(move || {
                        let reader = BufReader::new(stdout);
                        for line in reader.lines() {
                            if let Ok(l) = line {
                                if l.contains("[download]") && l.contains("%") {
                                    if let Some(start) = l.find("%") {
                                        let substr = &l[..start];
                                        if let Some(space) = substr.rfind(' ') {
                                            if let Ok(p) = substr[space + 1..].parse::<f32>() {
                                                let parts: Vec<&str> =
                                                    l.split_whitespace().collect();

                                                let mut p_val = None;
                                                let mut t_val = None;
                                                let mut s_val = None;
                                                let mut e_val = None;

                                                for (i, part) in parts.iter().enumerate() {
                                                    if part.contains("%") {
                                                        p_val = Some(part.trim_end_matches('%'));
                                                    } else if *part == "of" && i + 1 < parts.len() {
                                                        let val = parts[i + 1];
                                                        if val != "Unknown" && val != "N/A" {
                                                            t_val = Some(val);
                                                        }
                                                    } else if *part == "at" && i + 1 < parts.len() {
                                                        let val = parts[i + 1];
                                                        if val != "Unknown" && val != "N/A" {
                                                            s_val = Some(val);
                                                        }
                                                    } else if *part == "ETA" && i + 1 < parts.len()
                                                    {
                                                        let val = parts[i + 1];
                                                        if val != "Unknown" && val != "N/A" {
                                                            e_val = Some(val);
                                                        }
                                                    }
                                                }

                                                let fmt_segments: Vec<&str> =
                                                    fmt_str.split("{}").collect();
                                                let mut status_msg = String::new();

                                                if let Some(p_str) = p_val {
                                                    if fmt_segments.len() >= 5 {
                                                        status_msg.push_str(fmt_segments[0]);
                                                        status_msg.push_str(p_str);

                                                        if let Some(t) = t_val {
                                                            status_msg.push_str(fmt_segments[1]);
                                                            status_msg.push_str(t);
                                                        } else {
                                                            status_msg.push_str("%");
                                                        }

                                                        if let Some(s) = s_val {
                                                            status_msg.push_str(fmt_segments[2]);
                                                            status_msg.push_str(s);
                                                        }

                                                        if let Some(e) = e_val {
                                                            status_msg.push_str(fmt_segments[3]);
                                                            status_msg.push_str(e);
                                                            status_msg.push_str(fmt_segments[4]);
                                                        }
                                                    } else {
                                                        status_msg = format!("{}%", p_str);
                                                    }
                                                } else {
                                                    status_msg = l.clone();
                                                }

                                                if let Ok(mut s) = state_clone.lock() {
                                                    *s = DownloadState::Downloading(
                                                        p / 100.0,
                                                        status_msg,
                                                    );
                                                }
                                            }
                                        }
                                    }
                                }

                                if l.contains("Merging formats into \"") {
                                    if let Some(start) = l.find("Merging formats into \"") {
                                        let raw_path =
                                            &l[start + "Merging formats into \"".len()..];
                                        let clean_path = raw_path.trim().trim_end_matches('"');
                                        *final_filename_clone.lock().unwrap() =
                                            Some(PathBuf::from(clean_path));
                                    }
                                } else if l.contains("Destination: ") {
                                    if final_filename_clone.lock().unwrap().is_none() {
                                        if let Some(start) = l.find("Destination: ") {
                                            let raw_path = &l[start + "Destination: ".len()..];
                                            let clean_path = raw_path.trim();
                                            // Ignore subtitle files
                                            if !clean_path.ends_with(".vtt")
                                                && !clean_path.ends_with(".srt")
                                                && !clean_path.ends_with(".ass")
                                                && !clean_path.ends_with(".lrc")
                                            {
                                                *final_filename_clone.lock().unwrap() =
                                                    Some(PathBuf::from(clean_path));
                                            }
                                        }
                                    }
                                } else if l.contains(" has already been downloaded") {
                                    // Handle case where video is already there
                                    if final_filename_clone.lock().unwrap().is_none() {
                                        if let Some(end) = l.find(" has already been downloaded") {
                                            // Try to find start after "[download] " or just take from beginning
                                            let start = if let Some(p) = l.find("[download] ") {
                                                p + "[download] ".len()
                                            } else {
                                                0
                                            };
                                            if start < end {
                                                let filename = &l[start..end];
                                                let clean_filename = filename.trim();
                                                if !clean_filename.ends_with(".vtt")
                                                    && !clean_filename.ends_with(".srt")
                                                    && !clean_filename.ends_with(".ass")
                                                    && !clean_filename.ends_with(".lrc")
                                                {
                                                    *final_filename_clone.lock().unwrap() =
                                                        Some(PathBuf::from(clean_filename));
                                                }
                                            }
                                        }
                                    }
                                }
                                if l.contains("[ExtractAudio] Destination: ") {
                                    if let Some(start) = l.find("[ExtractAudio] Destination: ") {
                                        let raw_path =
                                            &l[start + "[ExtractAudio] Destination: ".len()..];
                                        let clean_path = raw_path.trim();
                                        *final_filename_clone.lock().unwrap() =
                                            Some(PathBuf::from(clean_path));
                                    }
                                }
                                log(&logs_clone, l);
                            }
                        }
                    });

                    let logs_clone_err = logs.clone();
                    let stderr_thread = thread::spawn(move || {
                        let reader = BufReader::new(stderr);
                        for line in reader.lines() {
                            if let Ok(l) = line {
                                log(&logs_clone_err, format!("ERR: {}", l));
                            }
                        }
                    });

                    let status = child.wait();
                    let _ = stdout_thread.join();
                    let _ = stderr_thread.join();

                    match status {
                        Ok(exit_status) => {
                            if exit_status.success() {
                                let final_path = final_filename.lock().unwrap().clone();
                                if let Some(path) = final_path {
                                    *state.lock().unwrap() = DownloadState::Finished(
                                        path,
                                        "Download Completed!".to_string(),
                                    );
                                } else {
                                    *state.lock().unwrap() = DownloadState::Finished(
                                        PathBuf::new(),
                                        "Download Completed!".to_string(),
                                    );
                                }
                                log(&logs, "Download Finished Successfully.");
                            } else {
                                *state.lock().unwrap() =
                                    DownloadState::Error(format!("Exit Code: {}", exit_status));
                                log(&logs, "Download Failed.");
                            }
                        }
                        Err(e) => {
                            *state.lock().unwrap() = DownloadState::Error(e.to_string());
                            log(&logs, format!("Wait Error: {}", e));
                        }
                    }
                }
                Err(e) => {
                    *state.lock().unwrap() = DownloadState::Error(e.to_string());
                    log(&logs, format!("Execution Error: {}", e));
                }
            }
        });
    }
}
</file>

<file path="src/overlay/mod.rs">
pub mod auto_copy_badge; // Auto-copy notification badge
pub mod broom_assets;
pub mod continuous_mode; // Continuous mode for image/text presets (hold-to-activate)
pub mod input_history; // Persistent input history for arrow up/down navigation
pub mod paint_utils;
pub mod preset_wheel;
pub mod process;
pub mod prompt_dj;
pub mod recording;
pub mod result;
pub mod screen_record;
mod selection;
pub mod text_input; // NEW MODULE
pub mod text_selection;

use std::sync::atomic::{AtomicBool, Ordering};

static IS_BUSY_WITH_OVERLAY: AtomicBool = AtomicBool::new(false);

pub fn is_busy() -> bool {
    IS_BUSY_WITH_OVERLAY.load(Ordering::SeqCst)
}

pub fn set_is_busy(busy: bool) {
    IS_BUSY_WITH_OVERLAY.store(busy, Ordering::SeqCst);
}

pub mod utils; // MASTER preset wheel
               // realtime_overlay module removed (was old GDI-based, now using realtime_webview)
pub mod favorite_bubble; // Floating bubble for favorite presets
pub mod html_components; // Split HTML components (CSS/JS)
pub mod realtime_egui; // Minimal mode (native egui)
pub mod realtime_html; // HTML generation for realtime overlay
pub mod realtime_webview; // New WebView2-based with smooth scrolling
pub mod tray_popup; // Custom non-blocking tray popup menu

pub use recording::{
    is_recording_overlay_active, show_recording_overlay, stop_recording_and_submit,
};
pub use selection::{is_selection_overlay_active, show_selection_overlay};
pub use text_selection::show_text_selection_tag;
// Use the new WebView2-based realtime overlay
lazy_static::lazy_static! {
    /// Mutex to ensure only one WebView is being initialized at a time globally.
    /// This prevents deadlocks and resource exhaustion during startup warmup loops.
    pub static ref GLOBAL_WEBVIEW_MUTEX: std::sync::Mutex<()> = std::sync::Mutex::new(());
}

// pub use crate::api::realtime_audio::show_realtime_overlay; // REMOVED - Incorrect path
pub use realtime_webview::{
    is_realtime_overlay_active, show_realtime_overlay, stop_realtime_overlay,
};

/// Get a WebView2 data directory path.
/// If subdir is provided, returns a component-specific folder to avoid file-lock contention.
pub fn get_shared_webview_data_dir(subdir: Option<&str>) -> std::path::PathBuf {
    let mut path = dirs::data_local_dir().unwrap_or_else(|| std::path::PathBuf::from("."));
    path.push("SGT");
    path.push("webview_data");
    if let Some(s) = subdir {
        path.push(s);
    }
    // Ensure the directory exists
    let _ = std::fs::create_dir_all(&path);
    path
}

/// Clear WebView permissions (MIDI, etc.) by removing the webview_data directory.
/// The directory will be recreated on next WebView initialization.
/// Returns true if successfully cleared, false otherwise.
///
/// On Windows, this function handles the "directory not empty" error (code 145)
/// that can occur when files are locked by WebView processes. It will retry
/// with delays and attempt per-file deletion as a fallback.
pub fn clear_webview_permissions() -> bool {
    let mut path = dirs::data_local_dir().unwrap_or_else(|| std::path::PathBuf::from("."));
    path.push("SGT");
    path.push("webview_data");

    if !path.exists() {
        // Already clean
        return true;
    }

    // Try up to 3 times with increasing delays
    for attempt in 0..3 {
        if attempt > 0 {
            // Wait before retry (100ms, 500ms)
            std::thread::sleep(std::time::Duration::from_millis(if attempt == 1 {
                100
            } else {
                500
            }));
        }

        match std::fs::remove_dir_all(&path) {
            Ok(_) => {
                println!("WebView data cleared successfully at {:?}", path);
                return true;
            }
            Err(e) => {
                // Check if it's the "directory not empty" error (Windows error 145)
                if e.raw_os_error() == Some(145) {
                    eprintln!(
                        "Attempt {}: Directory not empty, trying per-file deletion...",
                        attempt + 1
                    );
                    // Try to delete files individually first
                    if delete_directory_contents_recursive(&path) {
                        // Now try to remove the empty directory
                        if std::fs::remove_dir(&path).is_ok() {
                            println!("WebView data cleared successfully (per-file) at {:?}", path);
                            return true;
                        }
                    }
                } else if attempt == 2 {
                    eprintln!(
                        "Failed to clear WebView data after {} attempts: {:?}",
                        attempt + 1,
                        e
                    );
                }
            }
        }
    }

    false
}

/// Recursively delete directory contents, ignoring errors for individual locked files.
/// Returns true if at least some cleanup was done.
fn delete_directory_contents_recursive(path: &std::path::Path) -> bool {
    let mut any_deleted = false;

    if let Ok(entries) = std::fs::read_dir(path) {
        for entry in entries.flatten() {
            let entry_path = entry.path();
            if entry_path.is_dir() {
                // Recursively clean subdirectory
                delete_directory_contents_recursive(&entry_path);
                // Try to remove the now-empty directory
                if std::fs::remove_dir(&entry_path).is_ok() {
                    any_deleted = true;
                }
            } else {
                // Try to remove the file
                if std::fs::remove_file(&entry_path).is_ok() {
                    any_deleted = true;
                }
            }
        }
    }

    any_deleted
}
/// Check if we should use dark mode based on config.
/// Uses direct registry check for System theme to avoid crate overhead/crashes.
pub fn is_dark_mode() -> bool {
    let mode = {
        if let Ok(app) = crate::APP.lock() {
            app.config.theme_mode.clone()
        } else {
            crate::config::ThemeMode::Dark
        }
    };

    match mode {
        crate::config::ThemeMode::Dark => true,
        crate::config::ThemeMode::Light => false,
        crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
    }
}
</file>

<file path="src/overlay/tray_popup.rs">
// Tray Popup - Custom non-blocking popup window for tray icon menu
// Replaces native Windows tray context menu to avoid blocking the main UI thread

use crate::APP;
use std::cell::RefCell;
use std::sync::{
    atomic::{AtomicIsize, Ordering},
    Once,
};
use windows::core::w;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE, DWMWCP_ROUND,
};
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebView, WebViewBuilder};

static REGISTER_POPUP_CLASS: Once = Once::new();
static POPUP_HWND: AtomicIsize = AtomicIsize::new(0);
static IGNORE_FOCUS_LOSS_UNTIL: std::sync::atomic::AtomicU64 = std::sync::atomic::AtomicU64::new(0);

// Warmup flag - tracks if the window has been created and is ready for instant display
static IS_WARMED_UP: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);
static IS_WARMING_UP: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);
static WARMUP_START_TIME: std::sync::atomic::AtomicU64 = std::sync::atomic::AtomicU64::new(0);
// Flag to track if WebView has permanently failed to initialize
static WEBVIEW_INIT_FAILED: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);

// Custom window messages
const WM_APP_SHOW: u32 = WM_APP + 1;


thread_local! {
    static POPUP_WEBVIEW: RefCell<Option<WebView>> = RefCell::new(None);
    // Shared WebContext for this thread using common data directory
    static POPUP_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);
}

const BASE_POPUP_WIDTH: i32 = 220;
const BASE_POPUP_HEIGHT: i32 = 152; // Base height at 100% scaling (96 DPI) - includes stop TTS row

/// Get DPI-scaled dimension
fn get_scaled_dimension(base: i32) -> i32 {
    let dpi = unsafe {
        windows::Win32::UI::HiDpi::GetDpiForSystem()
    };
    // Scale: 96 DPI = 100%, 120 DPI = 125%, 144 DPI = 150%, etc.
    // Using 93 instead of 96 provides a small buffer (~3%) to ensure content fits comfortably
    (base * dpi as i32) / 93
}

// HWND wrapper for wry
struct HwndWrapper(HWND);
unsafe impl Send for HwndWrapper {}
unsafe impl Sync for HwndWrapper {}
impl raw_window_handle::HasWindowHandle for HwndWrapper {
    fn window_handle(
        &self,
    ) -> Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError> {
        let raw = raw_window_handle::Win32WindowHandle::new(
            std::num::NonZeroIsize::new(self.0 .0 as isize).expect("HWND cannot be null"),
        );
        let handle = raw_window_handle::RawWindowHandle::Win32(raw);
        unsafe { Ok(raw_window_handle::WindowHandle::borrow_raw(handle)) }
    }
}

/// Show the tray popup at cursor position
pub fn show_tray_popup() {
    unsafe {
        // Fallback to native menu if WebView failed completely
        if WEBVIEW_INIT_FAILED.load(Ordering::SeqCst) {
            show_native_context_menu();
            return;
        }

        // Check if warmed up and window exists
        if !IS_WARMED_UP.load(Ordering::SeqCst) {
            // Not ready yet - trigger warmup and show notification
            warmup_tray_popup();
            
            let ui_lang = APP.lock().unwrap().config.ui_language.clone();
            let locale = crate::gui::locale::LocaleText::get(&ui_lang);
            crate::overlay::auto_copy_badge::show_notification(locale.tray_popup_loading);
            
            // Spawn thread to wait for warmup completion and auto-show
            std::thread::spawn(move || {
                // Poll for 5 seconds (50 * 100ms)
                for _ in 0..50 {
                    std::thread::sleep(std::time::Duration::from_millis(100));
                    // Check if ready
                    let ready = IS_WARMED_UP.load(Ordering::SeqCst) && POPUP_HWND.load(Ordering::SeqCst) != 0;
                    if ready {
                        show_tray_popup();
                        return;
                    }
                }
            });
            return;
        }
        
        let hwnd_val = POPUP_HWND.load(Ordering::SeqCst);
        if hwnd_val == 0 {
            // Should be warmed up but handle missing? Retry warmup
            IS_WARMED_UP.store(false, Ordering::SeqCst);
            warmup_tray_popup();
            return;
        }
        
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        
        // Check if window still valid logic...
        if !IsWindow(Some(hwnd)).as_bool() {
            // Window destroyed
            IS_WARMED_UP.store(false, Ordering::SeqCst);
            POPUP_HWND.store(0, Ordering::SeqCst);
            warmup_tray_popup();
            return;
        }
        
        // Check if already visible
        if IsWindowVisible(hwnd).as_bool() {
            hide_tray_popup();
            return;
        }
        
        // Post message to show
        let _ = PostMessageW(Some(hwnd), WM_APP_SHOW, WPARAM(0), LPARAM(0));
    }
}

/// Hide the tray popup (preserves window for reuse)
pub fn hide_tray_popup() {
    let hwnd_val = POPUP_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe {
            // Just hide - don't destroy. Preserves WebView state for instant redisplay.
            let _ = KillTimer(Some(hwnd), 888);
            let _ = ShowWindow(hwnd, SW_HIDE);
        }
    }
}

/// Warmup the tray popup - creates hidden window with WebView for instant display later
pub fn warmup_tray_popup() {
    // Check if dead stuck (timestamp check)
    unsafe {
        let start_time = WARMUP_START_TIME.load(Ordering::SeqCst);
        let now = windows::Win32::System::SystemInformation::GetTickCount64();
        if start_time > 0 && (now - start_time) > 10000 {
            // Stuck for > 10s - force reset
            IS_WARMED_UP.store(false, Ordering::SeqCst);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            POPUP_HWND.store(0, Ordering::SeqCst);
        }
    }

    // Only allow one warmup thread at a time
    if IS_WARMING_UP
        .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
        .is_err()
    {
        return;
    }

    // Update timestamp
    unsafe {
        WARMUP_START_TIME.store(windows::Win32::System::SystemInformation::GetTickCount64(), Ordering::SeqCst);
    }
    
    std::thread::spawn(|| {
        create_popup_window();
    });
}

/// Check if the tray popup is currently visible
/// Used by warmup logic to defer WebView2 initialization until popup closes
pub fn is_popup_open() -> bool {
    let hwnd_val = POPUP_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe { IsWindowVisible(hwnd).as_bool() }
    } else {
        false
    }
}

fn generate_popup_html() -> String {
    use crate::config::ThemeMode;
    
    let (settings_text, bubble_text, stop_tts_text, quit_text, bubble_checked, is_dark_mode) = if let Ok(app) = APP.lock() {
        let lang = &app.config.ui_language;
        let settings = match lang.as_str() {
            "vi" => "Cài đặt",
            "ko" => "설정",
            _ => "Settings",
        };
        let bubble = match lang.as_str() {
            "vi" => "Hiện bong bóng",
            "ko" => "즐겨찾기 버블",
            _ => "Favorite Bubble",
        };
        let stop_tts = match lang.as_str() {
            "vi" => "Dừng đọc",
            "ko" => "재생 중인 모든 음성 중지",
            _ => "Stop All Playing TTS",
        };
        let quit = match lang.as_str() {
            "vi" => "Thoát",
            "ko" => "종료",
            _ => "Quit",
        };
        let checked = app.config.show_favorite_bubble;
        
        // Theme detection
        let is_dark = match app.config.theme_mode {
            ThemeMode::Dark => true,
            ThemeMode::Light => false,
            ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        };
        
        (settings, bubble, stop_tts, quit, checked, is_dark)
    } else {
        ("Settings", "Favorite Bubble", "Stop All TTS", "Quit", false, true)
    };

    // Check if TTS has pending audio
    let has_tts_pending = crate::api::tts::TTS_MANAGER.has_pending_audio();

    // Define Colors based on theme
    let (bg_color, text_color, hover_color, border_color, separator_color) = if is_dark_mode {
        ("#2c2c2c", "#ffffff", "#3c3c3c", "#454545", "rgba(255,255,255,0.08)")
    } else {
        ("#f9f9f9", "#1a1a1a", "#eaeaea", "#dcdcdc", "rgba(0,0,0,0.06)")
    };

    let check_mark = if bubble_checked {
        r#"<svg class="check-icon" viewBox="0 0 16 16" fill="currentColor"><path d="M13.86 3.66a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.6 9.03a.75.75 0 1 1 1.06-1.06l2.42 2.42 6.72-6.72a.75.75 0 0 1 1.06 0z"/></svg>"#
    } else {
        ""
    };
    
    let active_class = if bubble_checked {
        "active"
    } else {
        ""
    };

    let stop_tts_disabled_class = if has_tts_pending { "" } else { "disabled" };

    // Get font CSS to preload fonts into WebView2 cache (tray popup warms up first)
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
{font_css}
:root {{
    --bg-color: {bg};
    --text-color: {text};
    --hover-bg: {hover};
    --border-color: {border};
    --separator-color: {separator};
}}
* {{ margin: 0; padding: 0; box-sizing: border-box; }}
html, body {{
    width: 100%;
    height: 100%;
    overflow: hidden;
    background: var(--bg-color);
    font-family: 'Google Sans Flex', 'Segoe UI Variable Text', 'Segoe UI', system-ui, sans-serif;
    font-variation-settings: 'ROND' 100;
    user-select: none;
    color: var(--text-color);
    border: 1px solid var(--border-color);
    border-radius: 8px;
}}

.container {{
    display: flex;
    flex-direction: column;
    padding: 4px;
}}

.menu-item {{
    display: flex;
    align-items: center;
    padding: 6px 10px;
    border-radius: 4px;
    cursor: default;
    font-size: 13px;
    margin-bottom: 2px;
    background: transparent;
    transition: background 0.1s ease;
    height: 32px;
}}

.menu-item:hover {{
    background: var(--hover-bg);
}}

.icon {{
    display: flex;
    align-items: center;
    justify-content: center;
    width: 16px;
    height: 16px;
    margin-right: 12px;
    opacity: 0.8;
}}

.label {{
    flex: 1;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    padding-bottom: 1px; /* Visual alignment */
}}

.check {{
    width: 16px;
    display: flex;
    align-items: center;
    justify-content: center;
    margin-left: 8px;
}}

.separator {{
    height: 1px;
    background: var(--separator-color);
    margin: 4px 10px;
}}

svg {{
    width: 16px;
    height: 16px;
}}


.bubble-item .label {{
    transition: font-variation-settings 0.4s cubic-bezier(0.33, 1, 0.68, 1);
    font-variation-settings: 'wght' 400, 'wdth' 100, 'ROND' 100;
}}
.bubble-item.active .label {{
    font-variation-settings: 'wght' 700, 'wdth' 110, 'ROND' 100;
    color: var(--text-color);
}}

.menu-item.disabled {{
    opacity: 0.4;
    pointer-events: none;
}}
</style>
</head>
<body>
<div class="container">
    <div class="menu-item" onclick="action('settings')">
        <div class="icon">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round">
                <path d="M12.22 2h-.44a2 2 0 0 0-2 2v.18a2 2 0 0 1-1 1.73l-.43.25a2 2 0 0 1-2 0l-.15-.08a2 2 0 0 0-2.73.73l-.22.38a2 2 0 0 0 .73 2.73l.15.1a2 2 0 0 1 1 1.72v.51a2 2 0 0 1-1 1.74l-.15.09a2 2 0 0 0-.73 2.73l.22.38a2 2 0 0 0 2.73.73l.15-.08a2 2 0 0 1 2 0l.43.25a2 2 0 0 1 1 1.73V20a2 2 0 0 0 2 2h.44a2 2 0 0 0 2-2v-.18a2 2 0 0 1 1-1.73l.43-.25a2 2 0 0 1 2 0l.15.08a2 2 0 0 0 2.73-.73l.22-.39a2 2 0 0 0-.73-2.73l-.15-.09a2 2 0 0 1-1-1.74v-.47a2 2 0 0 1 1-1.74l.15-.09a2 2 0 0 0 .73-2.73l-.22-.39a2 2 0 0 0-2.73-.73l-.15.08a2 2 0 0 1-2 0l-.43-.25a2 2 0 0 1-1-1.73V4a2 2 0 0 0-2-2z"></path>
                <circle cx="12" cy="12" r="3"></circle>
            </svg>
        </div>
        <div class="label">{settings}</div>
        <div class="check"></div>
    </div>
    
    <div class="menu-item bubble-item {active_class}" data-state="{active_class}" onclick="action('bubble')">
        <div class="icon">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><polygon points="12 2 15.09 8.26 22 9.27 17 14.14 18.18 21.02 12 17.77 5.82 21.02 7 14.14 2 9.27 8.91 8.26 12 2"/></svg>
        </div>
        <div class="label">{bubble}</div>
        <div class="check" id="bubble-check-container">{check}</div>
    </div>
    
    <div class="menu-item {stop_tts_disabled}" id="stop-tts-item" onclick="action('stop_tts')">
        <div class="icon">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M11 5L6 9H2v6h4l5 4V5z"/><line x1="23" y1="9" x2="17" y2="15"/><line x1="17" y1="9" x2="23" y2="15"/></svg>
        </div>
        <div class="label">{stop_tts}</div>
        <div class="check"></div>
    </div>
    
    <div class="separator"></div>
    
    <div class="menu-item" onclick="action('quit')">
        <div class="icon">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M9 21H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h4"/><polyline points="16 17 21 12 16 7"/><line x1="21" y1="12" x2="9" y2="12"/></svg>
        </div>
        <div class="label">{quit}</div>
        <div class="check"></div>
    </div>
</div>
<script>
window.ignoreBlur = false;
function action(cmd) {{
    if (cmd === 'bubble') {{
        window.ignoreBlur = true;
        setTimeout(function() {{ window.ignoreBlur = false; }}, 1200);
        const el = document.querySelector('.bubble-item');
        if (el) {{
            if (el.classList.contains('active')) {{
                el.classList.remove('active');
            }} else {{
                el.classList.add('active');
            }}
        }}
    }}
    window.ipc.postMessage(cmd);
}}

// Update popup state without reloading (preserves font cache)
window.updatePopupState = function(config) {{
    // Update CSS variables for theme
    document.documentElement.style.setProperty('--bg-color', config.bgColor);
    document.documentElement.style.setProperty('--text-color', config.textColor);
    document.documentElement.style.setProperty('--hover-bg', config.hoverColor);
    document.documentElement.style.setProperty('--border-color', config.borderColor);
    document.documentElement.style.setProperty('--separator-color', config.separatorColor);
    
    // Update bubble active state
    const bubbleItem = document.querySelector('.bubble-item');
    if (bubbleItem) {{
        if (config.bubbleActive) {{
            bubbleItem.classList.add('active');
            document.getElementById('bubble-check-container').innerHTML = '<svg class="check-icon" viewBox="0 0 16 16" fill="currentColor"><path d="M13.86 3.66a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.6 9.03a.75.75 0 1 1 1.06-1.06l2.42 2.42 6.72-6.72a.75.75 0 0 1 1.06 0z"/></svg>';
        }} else {{
            bubbleItem.classList.remove('active');
            document.getElementById('bubble-check-container').innerHTML = '';
        }}
    }}
    
    // Update stop TTS disabled state
    const stopTtsItem = document.getElementById('stop-tts-item');
    if (stopTtsItem) {{
        if (config.ttsDisabled) {{
            stopTtsItem.classList.add('disabled');
        }} else {{
            stopTtsItem.classList.remove('disabled');
        }}
    }}
}};

window.addEventListener('blur', function() {{
    if (window.ignoreBlur) return;
    window.ipc.postMessage('close');
}});
</script>
</body>
</html>"#,
        bg = bg_color,
        text = text_color,
        hover = hover_color,
        border = border_color,
        separator = separator_color,
        settings = settings_text,
        bubble = bubble_text,
        stop_tts = stop_tts_text,
        stop_tts_disabled = stop_tts_disabled_class,
        quit = quit_text,
        check = check_mark
    )
}

/// Generate JavaScript to update popup state without reloading HTML
fn generate_popup_update_script() -> String {
    use crate::config::ThemeMode;
    
    let (bubble_checked, is_dark_mode) = if let Ok(app) = APP.lock() {
        let is_dark = match app.config.theme_mode {
            ThemeMode::Dark => true,
            ThemeMode::Light => false,
            ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        };
        (app.config.show_favorite_bubble, is_dark)
    } else {
        (false, true)
    };

    let has_tts_pending = crate::api::tts::TTS_MANAGER.has_pending_audio();

    let (bg_color, text_color, hover_color, border_color, separator_color) = if is_dark_mode {
        ("#2c2c2c", "#ffffff", "#3c3c3c", "#454545", "rgba(255,255,255,0.08)")
    } else {
        ("#f9f9f9", "#1a1a1a", "#eaeaea", "#dcdcdc", "rgba(0,0,0,0.06)")
    };

    format!(
        r#"window.updatePopupState({{ 
            bgColor: '{}', 
            textColor: '{}', 
            hoverColor: '{}', 
            borderColor: '{}', 
            separatorColor: '{}',
            bubbleActive: {},
            ttsDisabled: {}
        }});"#,
        bg_color,
        text_color,
        hover_color,
        border_color,
        separator_color,
        bubble_checked,
        !has_tts_pending
    )
}

// Cleanup guard removed - window persists for entire app lifetime

/// Creates the popup window and runs its message loop forever.
/// This is called once during warmup - the window is kept alive hidden for reuse.
fn create_popup_window() {
    unsafe {
        // Initialize COM for the thread (Critical for WebView2/Wry)
        let coinit = windows::Win32::System::Com::CoInitialize(None);
        crate::log_info!("[TrayPopup] Loop Start - CoInit: {:?}", coinit);
        
        let instance = GetModuleHandleW(None).unwrap_or_default();
        let class_name = w!("SGTTrayPopup");

        REGISTER_POPUP_CLASS.call_once(|| {
            let wc = WNDCLASSW {
                lpfnWndProc: Some(popup_wnd_proc),
                hInstance: instance.into(),
                lpszClassName: class_name,
                hCursor: LoadCursorW(None, IDC_ARROW).unwrap_or_default(),
                hbrBackground: HBRUSH(std::ptr::null_mut()),
                ..Default::default()
            };
            RegisterClassW(&wc);
        });
        crate::log_info!("[TrayPopup] Class Registered");

        // Get DPI-scaled dimensions
        let popup_height = get_scaled_dimension(BASE_POPUP_HEIGHT);
        let popup_width = get_scaled_dimension(BASE_POPUP_WIDTH);

        // Create hidden off-screen (will be repositioned when shown)
        let hwnd = CreateWindowExW(
            WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED,
            class_name,
            w!("TrayPopup"),
            WS_POPUP,
            -3000,
            -3000,
            popup_width,
            popup_height,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        crate::log_info!("[TrayPopup] Window created with HWND: {:?}", hwnd);

        if hwnd.is_invalid() {
            return;
        }

        POPUP_HWND.store(hwnd.0 as isize, Ordering::SeqCst);

        // Make transparent initially (invisible)
        let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 0, LWA_ALPHA);

        // Round corners
        let corner_pref = DWMWCP_ROUND;
        let _ = DwmSetWindowAttribute(
            hwnd,
            DWMWA_WINDOW_CORNER_PREFERENCE,
            std::ptr::addr_of!(corner_pref) as *const _,
            std::mem::size_of_val(&corner_pref) as u32,
        );

        // Create WebView using shared context for RAM efficiency
        let wrapper = HwndWrapper(hwnd);
        let html = generate_popup_html();

        // Initialize shared WebContext if needed (uses same data dir as other modules)
        POPUP_WEB_CONTEXT.with(|ctx| {
            if ctx.borrow().is_none() {
                // Consolidate all minor overlays to 'common' to share one browser process and keep RAM at ~80MB
                let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
                *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
            }
        });
        
        crate::log_info!("[TrayPopup] Starting WebView initialization...");

        let mut final_webview: Option<WebView> = None;
        
        // Stagger startup to avoid collision
        std::thread::sleep(std::time::Duration::from_millis(250));

        for attempt in 1..=3 {
            let res = {
                // LOCK SCOPE: Only one WebView builds at a time to prevent "Not enough quota"
                let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
                crate::log_info!("[TrayPopup] (Attempt {}) Acquired init lock. Building...", attempt);
                
                let build_res = POPUP_WEB_CONTEXT.with(|ctx| {
                    let mut ctx_ref = ctx.borrow_mut();
                    let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                        WebViewBuilder::new_with_web_context(web_ctx)
                    } else {
                        WebViewBuilder::new()
                    };
                    let builder = crate::overlay::html_components::font_manager::configure_webview(builder);
                    
                    // Store HTML in font server and get URL for same-origin font loading
                    let page_url = crate::overlay::html_components::font_manager::store_html_page(html.clone())
                        .unwrap_or_else(|| format!("data:text/html,{}", urlencoding::encode(&html)));
                    
                    builder
                        .with_bounds(Rect {
                            position: wry::dpi::Position::Logical(wry::dpi::LogicalPosition::new(0.0, 0.0)),
                            size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                                popup_width as u32,
                                popup_height as u32,
                            )),
                        })
                        .with_transparent(true)
                        .with_url(&page_url)
                        .with_ipc_handler(move |msg: wry::http::Request<String>| {
                            let body = msg.body();
                            match body.as_str() {
                                "settings" => {
                                    // Hide popup and restore main window
                                    hide_tray_popup();
                                    crate::gui::signal_restore_window();
                                }
                                "bubble" => {
                                    // Toggle bubble state
                                    let new_state = if let Ok(mut app) = APP.lock() {
                                        app.config.show_favorite_bubble = !app.config.show_favorite_bubble;
                                        let enabled = app.config.show_favorite_bubble;
                                        crate::config::save_config(&app.config);

                                        if enabled {
                                            crate::overlay::favorite_bubble::show_favorite_bubble();
                                            std::thread::spawn(|| {
                                                std::thread::sleep(std::time::Duration::from_millis(150));
                                                crate::overlay::favorite_bubble::trigger_blink_animation();
                                            });
                                        } else {
                                            crate::overlay::favorite_bubble::hide_favorite_bubble();
                                        }
                                        enabled
                                    } else {
                                        false
                                    };

                                    // Update checkmark in popup via JavaScript (keep popup open)
                                    POPUP_WEBVIEW.with(|cell| {
                                        if let Some(webview) = cell.borrow().as_ref() {
                                            let js = format!(
                                                "document.getElementById('bubble-check-container').innerHTML = '{}';",
                                                if new_state { 
                                                    r#"<svg class="check-icon" viewBox="0 0 16 16" fill="currentColor"><path d="M13.86 3.66a.75.75 0 0 1 0 1.06l-7.25 7.25a.75.75 0 0 1-1.06 0L2.6 9.03a.75.75 0 1 1 1.06-1.06l2.42 2.42 6.72-6.72a.75.75 0 0 1 1.06 0z"/></svg>"#
                                                } else { "" }
                                            );
                                            let _ = webview.evaluate_script(&js);
                                        }
                                    });
                                }
                                "stop_tts" => {
                                    // Stop all TTS playback and clear queues
                                    crate::api::tts::TTS_MANAGER.stop();
                                    // Hide popup after action
                                    hide_tray_popup();
                                }
                                "quit" => {
                                    // Hide popup first, then exit
                                    hide_tray_popup();
                                    std::thread::spawn(|| {
                                        std::thread::sleep(std::time::Duration::from_millis(50));
                                        std::process::exit(0);
                                    });
                                }
                                "close" => {
                                    hide_tray_popup();
                                }
                                _ => {}
                            }
                        })
                        .build(&wrapper)
                });
                build_res
            };

            crate::log_info!("[TrayPopup] (Attempt {}) Release lock. Result: {}", attempt, if res.is_ok() { "OK" } else { "ERR" });
    
            match res {
                Ok(wv) => {
                    final_webview = Some(wv);
                    break;
                }
                Err(e) => {
                    crate::log_info!("[TrayPopup] WebView init attempt {} failed: {:?}", attempt, e);
                    std::thread::sleep(std::time::Duration::from_millis(2000));
                }
            }
        }

        if let Some(wv) = final_webview {
            crate::log_info!("[TrayPopup] WebView initialization SUCCESSFUL");
            POPUP_WEBVIEW.with(|cell| {
                *cell.borrow_mut() = Some(wv);
            });

            // Mark as warmed up - ready for instant display
            IS_WARMED_UP.store(true, Ordering::SeqCst);
            IS_WARMING_UP.store(false, Ordering::SeqCst); // Done warming up
            WARMUP_START_TIME.store(0, Ordering::SeqCst);

            // Message loop runs forever to keep window alive
            let mut msg = MSG::default();
            while GetMessageW(&mut msg, None, 0, 0).into() {
                let _ = TranslateMessage(&msg);
                DispatchMessageW(&msg);
            }
        } else {
            crate::log_info!("[TrayPopup] FAILED to initialize WebView after 3 attempts.");
            WEBVIEW_INIT_FAILED.store(true, Ordering::SeqCst);
        }

        // Clean up on thread exit
        IS_WARMED_UP.store(false, Ordering::SeqCst);
        IS_WARMING_UP.store(false, Ordering::SeqCst);
        POPUP_HWND.store(0, Ordering::SeqCst);
        WARMUP_START_TIME.store(0, Ordering::SeqCst);
        POPUP_WEBVIEW.with(|cell| {
            *cell.borrow_mut() = None;
        });
        
        let _ = windows::Win32::System::Com::CoUninitialize();
    }
}

unsafe extern "system" fn popup_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_SHOW => {
            // Reposition window to cursor and show
            let popup_height = get_scaled_dimension(BASE_POPUP_HEIGHT);
            let popup_width = get_scaled_dimension(BASE_POPUP_WIDTH);
            
            let mut pt = POINT::default();
            let _ = GetCursorPos(&mut pt);
            let screen_w = GetSystemMetrics(SM_CXSCREEN);
            let screen_h = GetSystemMetrics(SM_CYSCREEN);

            let popup_x = (pt.x - popup_width / 2).max(0).min(screen_w - popup_width);
            let popup_y = (pt.y - popup_height - 10).max(0).min(screen_h - popup_height);
            
            // Update state via JavaScript (preserves font cache - no reload flash)
            POPUP_WEBVIEW.with(|cell| {
                if let Some(webview) = cell.borrow().as_ref() {
                    let update_script = generate_popup_update_script();
                    let _ = webview.evaluate_script(&update_script);
                }
            });
            
            // Resize WebView to current DPI
            POPUP_WEBVIEW.with(|cell| {
                if let Some(webview) = cell.borrow().as_ref() {
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Logical(wry::dpi::LogicalPosition::new(0.0, 0.0)),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            popup_width as u32,
                            popup_height as u32,
                        )),
                    });
                }
            });
            
            // Reposition and resize window
            let _ = SetWindowPos(hwnd, None, popup_x, popup_y, popup_width, popup_height, SWP_NOZORDER);
            
            // Make fully visible (undo the warmup transparency)
            let _ = SetLayeredWindowAttributes(hwnd, COLORREF(0), 255, LWA_ALPHA);
            
            // Show and focus
            let _ = ShowWindow(hwnd, SW_SHOW);
            let _ = SetForegroundWindow(hwnd);
            
            // Start focus-polling timer
            let _ = SetTimer(Some(hwnd), 888, 100, None);
            
            LRESULT(0)
        }
        
        WM_ACTIVATE => {
            LRESULT(0)
        }

        WM_TIMER => {
            if wparam.0 == 888 {
                // Focus polling: check if we're still the active window
                let fg = GetForegroundWindow();
                let root = GetAncestor(fg, GA_ROOT);
                
                // If focus is on this popup or its children (WebView2), stay open
                if fg == hwnd || root == hwnd {
                    return LRESULT(0);
                }
                
                // Focus is elsewhere - check grace period
                let now = windows::Win32::System::SystemInformation::GetTickCount64();
                if now > IGNORE_FOCUS_LOSS_UNTIL.load(Ordering::SeqCst) {
                    let _ = KillTimer(Some(hwnd), 888);
                    hide_tray_popup();
                }
            }
            LRESULT(0)
        }

        WM_CLOSE => {
            // Just hide - don't destroy. Preserves WebView for instant redisplay.
            let _ = KillTimer(Some(hwnd), 888);
            let _ = ShowWindow(hwnd, SW_HIDE);
            LRESULT(0)
        }

        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

/// Fallback native context menu when WebView fails
unsafe fn show_native_context_menu() {
    use crate::config::ThemeMode;
    use windows::core::{HSTRING, PCWSTR};

    let (settings_text, bubble_text, stop_tts_text, quit_text, bubble_checked, _is_dark) = if let Ok(app) = APP.lock() {
        let lang = &app.config.ui_language;
        let settings = match lang.as_str() {
            "vi" => "Cài đặt",
            "ko" => "설정",
            _ => "Settings",
        };
        let bubble = match lang.as_str() {
            "vi" => "Hiện bong bóng",
            "ko" => "즐겨찾기 버블",
            _ => "Favorite Bubble",
        };
        let stop_tts = match lang.as_str() {
            "vi" => "Dừng đọc",
            "ko" => "재생 중인 모든 음성 중지",
            _ => "Stop All Playing TTS",
        };
        let quit = match lang.as_str() {
            "vi" => "Thoát",
            "ko" => "종료",
            _ => "Quit",
        };
        let checked = app.config.show_favorite_bubble;
        
        let is_dark = match app.config.theme_mode {
            ThemeMode::Dark => true,
            ThemeMode::Light => false,
            ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        };
        
        (settings, bubble, stop_tts, quit, checked, is_dark)
    } else {
        ("Settings", "Favorite Bubble", "Stop All TTS", "Quit", false, true)
    };

    let has_tts_pending = crate::api::tts::TTS_MANAGER.has_pending_audio();

    // Create a dummy window to handle menu messages
    let instance = GetModuleHandleW(None).unwrap_or_default();
    let hwnd = CreateWindowExW(
        WS_EX_TOOLWINDOW,
        w!("STATIC"),
        w!("SGTNativeMenu"),
        WS_POPUP,
        0, 0, 0, 0,
        None, None, Some(instance.into()), None
    ).unwrap_or_default();

    if hwnd.is_invalid() {
        return;
    }

    let _ = SetForegroundWindow(hwnd);

    let hmenu = CreatePopupMenu().unwrap_or_default();

    fn add_item(hmenu: HMENU, id: usize, text: &str, checked: bool, disabled: bool) {
        let mut flags = MF_STRING;
        if checked { flags |= MF_CHECKED; }
        if disabled { flags |= MF_DISABLED | MF_GRAYED; }
        
        let h_text = HSTRING::from(text);
        unsafe {
            let _ = AppendMenuW(hmenu, flags, id, PCWSTR(h_text.as_ptr()));
        }
    }

    add_item(hmenu, 1, settings_text, false, false);
    add_item(hmenu, 2, bubble_text, bubble_checked, false);
    add_item(hmenu, 3, stop_tts_text, false, !has_tts_pending);
    let _ = AppendMenuW(hmenu, MF_SEPARATOR, 0, PCWSTR::null());
    add_item(hmenu, 4, quit_text, false, false);

    let mut pt = POINT::default();
    let _ = GetCursorPos(&mut pt);

    let cmd_id = TrackPopupMenu(
        hmenu,
        TPM_RETURNCMD | TPM_NONOTIFY | TPM_BOTTOMALIGN | TPM_LEFTALIGN,
        pt.x,
        pt.y,
        None,
        hwnd,
        None
    );

    let _ = DestroyMenu(hmenu);
    let _ = DestroyWindow(hwnd);

    match cmd_id.0 as u32 {
        1 => {
            // Settings
             crate::gui::signal_restore_window();
        },
        2 => {
            // Toggle Bubble
            if let Ok(mut app) = APP.lock() {
                app.config.show_favorite_bubble = !app.config.show_favorite_bubble;
                let enabled = app.config.show_favorite_bubble;
                crate::config::save_config(&app.config);

                if enabled {
                    crate::overlay::favorite_bubble::show_favorite_bubble();
                    std::thread::spawn(|| {
                        std::thread::sleep(std::time::Duration::from_millis(150));
                        crate::overlay::favorite_bubble::trigger_blink_animation();
                    });
                } else {
                    crate::overlay::favorite_bubble::hide_favorite_bubble();
                }
            }
        },
        3 => {
            // Stop TTS
            crate::api::tts::TTS_MANAGER.stop();
        },
        4 => {
            // Quit
            std::process::exit(0);
        },
        _ => {}
    }
}
</file>

<file path="src/overlay/result/markdown_view.rs">
use pulldown_cmark::{html, Options, Parser};
use raw_window_handle::{
    HandleError, HasWindowHandle, RawWindowHandle, Win32WindowHandle, WindowHandle,
};
use std::collections::HashMap;
use std::num::NonZeroIsize;
use std::sync::Mutex;
use windows::Win32::Foundation::*;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebViewBuilder};

lazy_static::lazy_static! {
    // Store WebViews per parent window - wrapped in thread-local storage to avoid Send issues
    static ref WEBVIEW_STATES: Mutex<HashMap<isize, bool>> = Mutex::new(HashMap::new());
    // Global flag to indicate WebView2 is ready
    static ref WEBVIEW_READY: Mutex<bool> = Mutex::new(false);
    // Flag to skip next navigation handler call (set before history.back())
    static ref SKIP_NEXT_NAVIGATION: Mutex<HashMap<isize, bool>> = Mutex::new(HashMap::new());
}

// Thread-local storage for WebViews since they're not Send
thread_local! {
    static WEBVIEWS: std::cell::RefCell<std::collections::HashMap<isize, wry::WebView>> = std::cell::RefCell::new(std::collections::HashMap::new());
    // Shared WebContext for all WebViews on this thread - reduces RAM by sharing browser processes
    static SHARED_WEB_CONTEXT: std::cell::RefCell<Option<wry::WebContext>> = std::cell::RefCell::new(None);
}

/// Wrapper for HWND to implement HasWindowHandle
struct HwndWrapper(HWND);

impl HasWindowHandle for HwndWrapper {
    fn window_handle(&self) -> Result<WindowHandle<'_>, HandleError> {
        let hwnd = self.0 .0 as isize;
        if let Some(non_zero) = NonZeroIsize::new(hwnd) {
            let mut handle = Win32WindowHandle::new(non_zero);
            // hinstance is optional, can be null
            handle.hinstance = None;
            let raw = RawWindowHandle::Win32(handle);
            // Safety: the handle is valid for the lifetime of HwndWrapper
            Ok(unsafe { WindowHandle::borrow_raw(raw) })
        } else {
            Err(HandleError::Unavailable)
        }
    }
}

/// Warmup removed as per user request
#[allow(dead_code)]
pub fn warmup() {}

/// Get font CSS for markdown view (uses locally cached fonts)
fn get_font_style() -> String {
    format!(
        "<style>{}</style>",
        crate::overlay::html_components::font_manager::get_font_css()
    )
}

/// CSS styling for the markdown content
const MARKDOWN_CSS: &str = r#"
    :root {
        --bg: transparent;
    }
    * { box-sizing: border-box; }
    
    /* Animation definitions */
    @keyframes shimmer {
        0% { background-position: 100% 0; }
        100% { background-position: -100% 0; }
    }
    
    /* Appearing animation with blur dissolve - matches realtime overlay style */
    @keyframes content-appear {
        from {
            opacity: 0;
            filter: blur(8px);
            -webkit-backdrop-filter: blur(12px);
            backdrop-filter: blur(12px);
            transform: translateY(4px);
        }
        to {
            opacity: 1;
            filter: blur(0);
            -webkit-backdrop-filter: blur(0);
            backdrop-filter: blur(0);
            transform: translateY(0);
        }
    }

    body { 
        font-family: 'Google Sans Flex', 'Segoe UI', -apple-system, sans-serif;
        font-optical-sizing: auto;
        /* wdth 90 for more compact text as requested */
        font-variation-settings: 'wght' 400, 'wdth' 90, 'slnt' 0, 'ROND' 100;
        /* Default size 14px - JavaScript fit_font_to_window handles dynamic scaling for short content */
        font-size: 14px;
        line-height: 1.5; /* Reduced line height for compactness */
        background: var(--bg);
        /* Removed min-height: 100vh to enable proper overflow detection for font scaling */
        color: var(--text-color);
        margin: 0;
        padding: 0; /* Padding now handled by WebView edge margin */
        overflow-x: hidden;
        word-wrap: break-word;
        /* Appearing animation */
        animation: content-appear 0.35s cubic-bezier(0.2, 0, 0.2, 1) forwards;
    }
    
    body > *:first-child { margin-top: 0; }
    
    h1 { 
        font-size: 1.8em; 
        color: var(--primary); 
        margin-top: 0;
        margin-bottom: 12px; /* Reduced from 16px */
        padding: 0px;
        border-radius: 42px;
        backdrop-filter: blur(12px);
        -webkit-backdrop-filter: blur(12px);
        
        font-variation-settings: 'wght' 600, 'wdth' 110, 'slnt' 0, 'ROND' 100;
        text-align: center;
        position: relative;
        overflow: hidden;
    }

    h2 { 
        font-size: 1.4em; 
        color: var(--secondary); 
        /* Removed border-bottom */
        padding-bottom: 4px; 
        margin-top: 1.0em; /* Reduced from 1.2em */
        margin-bottom: 0.5em;
        font-variation-settings: 'wght' 550, 'wdth' 100, 'slnt' 0, 'ROND' 100;
    }

    h3 { 
        font-size: 1.2em; 
        color: var(--h3-color); 
        margin-top: 0.8em; /* Reduced from 1.0em */
        margin-bottom: 0.4em;
        font-variation-settings: 'wght' 500, 'wdth' 100, 'slnt' 0, 'ROND' 100;
    }
    
    h4, h5, h6 { 
        color: var(--h4-color); 
        margin-top: 0.8em;
        margin-bottom: 0.4em;
        font-variation-settings: 'wght' 500, 'wdth' 100, 'slnt' 0, 'ROND' 100;
    }

    p { margin: 0 0; }
    
    /* Interactive Word Styling - COLOR ONLY, preserves font scaling */
    .word {
        display: inline;
        transition: color 0.2s ease, text-shadow 0.2s ease;
        cursor: text;
    }

    /* 1. Center (Hovered) - Bright cyan + glow */
    .word:hover {
        color: var(--primary);
        text-shadow: 0 0 12px var(--shadow-color);
    }

    /* 2. Immediate Neighbors (Distance: 1) - Light cyan */
    .word:hover + .word {
        color: var(--h4-color);
        text-shadow: 0 0 6px var(--shadow-weak);
    }
    .word:has(+ .word:hover) {
        color: var(--h4-color);
        text-shadow: 0 0 6px var(--shadow-weak);
    }

    /* 3. Secondary Neighbors (Distance: 2) - Lighter cyan */
    .word:hover + .word + .word {
        color: var(--h3-color);
    }
    .word:has(+ .word + .word:hover) {
        color: var(--h3-color);
    }

    /* Headers need specific overriding to ensure the fisheye works on top of their base styles */
    h1 .word:hover, h2 .word:hover, h3 .word:hover {
        color: var(--primary);
    }
    
    /* Ensure code blocks remain non-interactive */
    pre .word {
        display: inline;
        transition: none;
    }
    pre .word:hover, 
    pre .word:hover + .word,
    pre .word:has(+ .word:hover) {
        color: inherit;
        text-shadow: none;
    }
    
    pre code { 
        background: transparent; 
        padding: 0; 
        color: var(--code-color);
    }
    
    a { color: var(--link-color); text-decoration: none; transition: all 0.2s; cursor: pointer; }
    a .word { cursor: pointer; } /* Ensure link words show hand cursor */
    a:hover { color: var(--link-hover-color); text-shadow: 0 0 10px var(--link-shadow); text-decoration: none; }
    
    ul, ol { padding-left: 20px; margin: 0 0; }
    li { margin: 2px 0; } /* Reduced from 4px */
    
    table { 
        width: 100%; 
        border-collapse: separate; 
        border-spacing: 0; 
        margin: 12px 0; /* Reduced from 16px */
        border-radius: 8px; 
        overflow: hidden; 
        border: 1px solid var(--border-color); 
        background: var(--table-bg);
    }
    th { 
        background: var(--table-header-bg); 
        padding: 8px 10px; /* Reduced from 10px */
        color: var(--primary); 
        text-align: left;
        font-weight: 600;
        border-bottom: 1px solid var(--border-color);
        font-variation-settings: 'wght' 600, 'wdth' 100, 'slnt' 0, 'ROND' 100;
    }
    td { 
        padding: 6px 10px; /* Reduced from 8px */
        border-top: 1px solid var(--border-color);
    }
    tr:first-child td { border-top: none; }
    tr:hover td { background: var(--glass); }
    
    hr { border: none; height: 1px; background: var(--border-color); margin: 16px 0; } /* Reduced from 24px */
    img { max-width: 100%; border-radius: 8px; box-shadow: 0 4px 12px rgba(0,0,0,0.3); }
    
    /* Streaming chunk animation - blur-dissolve for ONLY new content */
    @keyframes stream-chunk-in {
        from {
            opacity: 0;
            filter: blur(4px);
            transform: translateX(-2px);
        }
        to {
            opacity: 1;
            filter: blur(0);
            transform: translateX(0);
        }
    }
    
    /* Legacy chunk-appear kept for compatibility */
    @keyframes chunk-appear {
        from {
            opacity: 0;
            filter: blur(4px);
        }
        to {
            opacity: 1;
            filter: blur(0);
        }
    }
    
    /* Class for newly streamed text */
    .streaming-new {
        display: inline;
        animation: stream-chunk-in 0.25s ease-out forwards;
    }
    
    /* Smooth transition for all direct body children during updates */
    body > * {
        transition: opacity 0.15s ease-out, filter 0.15s ease-out;
    }
    
    ::-webkit-scrollbar { display: none; }
"#;

use pulldown_cmark::{Event, Tag, TagEnd};

/// Minimal HTML escaping for text content
fn escape_html_text(text: &str) -> String {
    text.replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace("\"", "&quot;")
        .replace("'", "&#39;")
}

/// Check if content is already HTML (rather than Markdown)
fn is_html_content(content: &str) -> bool {
    let trimmed = content.trim();
    // Check for HTML doctype or opening html tag
    trimmed.starts_with("<!DOCTYPE") || 
    trimmed.starts_with("<!doctype") ||
    trimmed.starts_with("<html") ||
    trimmed.starts_with("<HTML") ||
    // Check for common HTML structure patterns
    (trimmed.contains("<html") && trimmed.contains("</html>")) ||
    (trimmed.contains("<head") && trimmed.contains("</head>")) ||
    // Also detect HTML fragments (has script/style but no html wrapper)
    is_html_fragment(content)
}

/// Check if content is an HTML fragment (has HTML-like content but no document wrapper)
/// Examples: <div><style>...</style><script>...</script></div>
fn is_html_fragment(content: &str) -> bool {
    let lower = content.to_lowercase();
    // Has script or style tags but no html/doctype wrapper
    (lower.contains("<script") || lower.contains("<style"))
        && !lower.contains("<!doctype")
        && !lower.contains("<html")
}

/// Wrap an HTML fragment in a proper document structure
/// This ensures WebView2 can properly parse the DOM
fn wrap_html_fragment(fragment: &str) -> String {
    format!(
        r#"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
{}
</body>
</html>"#,
        fragment
    )
}

/// Inject localStorage/sessionStorage polyfill into HTML for WebView2 compatibility
/// WebView2's with_html() runs in a sandboxed context that denies storage access
/// This provides an in-memory fallback so scripts don't crash
fn inject_storage_polyfill(html: &str) -> String {
    // First, wrap HTML fragments in a proper document structure
    // This ensures WebView2 can properly parse the DOM (fixes "null" getElementById errors)
    let html = if is_html_fragment(html) {
        wrap_html_fragment(html)
    } else {
        html.to_string()
    };

    // Polyfill script that provides in-memory storage when real storage is blocked
    let polyfill = r#"<script>
(function() {
    // Check if localStorage is accessible
    try {
        var test = '__storage_test__';
        localStorage.setItem(test, test);
        localStorage.removeItem(test);
        // localStorage works, no polyfill needed
    } catch (e) {
        // localStorage blocked, create in-memory polyfill
        var memoryStorage = {};
        var createStorage = function() {
            return {
                _data: {},
                length: 0,
                getItem: function(key) { return this._data.hasOwnProperty(key) ? this._data[key] : null; },
                setItem: function(key, value) { this._data[key] = String(value); this.length = Object.keys(this._data).length; },
                removeItem: function(key) { delete this._data[key]; this.length = Object.keys(this._data).length; },
                clear: function() { this._data = {}; this.length = 0; },
                key: function(i) { var keys = Object.keys(this._data); return keys[i] || null; }
            };
        };
        try {
            Object.defineProperty(window, 'localStorage', { value: createStorage(), writable: false });
            Object.defineProperty(window, 'sessionStorage', { value: createStorage(), writable: false });
        } catch (e2) {
            // If defineProperty fails, try direct assignment
            window.localStorage = createStorage();
            window.sessionStorage = createStorage();
        }
    }
})();
</script>"#;

    // Find the best place to inject the polyfill (before any other scripts)
    // Priority: after <head>, after <html>, or at the very start
    let lower = html.to_lowercase();

    if let Some(pos) = lower.find("<head>") {
        // Inject right after <head>
        let insert_pos = pos + 6; // length of "<head>"
        let mut result = html[..insert_pos].to_string();
        result.push_str(polyfill);
        result.push_str(&html[insert_pos..]);
        result
    } else if let Some(pos) = lower.find("<head ") {
        // <head with attributes
        if let Some(end) = html[pos..].find('>') {
            let insert_pos = pos + end + 1;
            let mut result = html[..insert_pos].to_string();
            result.push_str(polyfill);
            result.push_str(&html[insert_pos..]);
            result
        } else {
            format!("{}{}", polyfill, html)
        }
    } else if let Some(pos) = lower.find("<html>") {
        let insert_pos = pos + 6;
        let mut result = html[..insert_pos].to_string();
        result.push_str(polyfill);
        result.push_str(&html[insert_pos..]);
        result
    } else if let Some(pos) = lower.find("<html ") {
        if let Some(end) = html[pos..].find('>') {
            let insert_pos = pos + end + 1;
            let mut result = html[..insert_pos].to_string();
            result.push_str(polyfill);
            result.push_str(&html[insert_pos..]);
            result
        } else {
            format!("{}{}", polyfill, html)
        }
    } else {
        // No head or html tag found, prepend polyfill
        format!("{}{}", polyfill, html)
    }
}

/// Inject Grid.js into raw HTML if tables are present
fn inject_gridjs(html: &str) -> String {
    if !html.contains("<table") {
        return html.to_string();
    }

    let (css_url, js_url) = crate::overlay::html_components::grid_js::get_lib_urls();
    let gridjs_head = format!(
        r#"<link href="{}" rel="stylesheet" />
        <script src="{}"></script>
        <style>{}</style>"#,
        css_url,
        js_url,
        crate::overlay::html_components::grid_js::get_css()
    );
    let gridjs_body = format!(
        r#"<script>{}</script>"#,
        crate::overlay::html_components::grid_js::get_init_script()
    );

    let lower = html.to_lowercase();
    let mut result = html.to_string();

    // Inject CSS/JS into <head>
    if let Some(pos) = lower.find("</head>") {
        result.insert_str(pos, &gridjs_head);
    } else if let Some(pos) = lower.find("<body>") {
        result.insert_str(pos, &gridjs_head);
    } else {
        result.insert_str(0, &gridjs_head);
    }

    // Inject init script into <body>
    let lower_updated = result.to_lowercase();
    if let Some(pos) = lower_updated.find("</body>") {
        result.insert_str(pos, &gridjs_body);
    } else {
        result.push_str(&gridjs_body);
    }

    result
}

/// Inject CSS to hide scrollbars while preserving scrolling functionality
fn inject_scrollbar_css(html: &str) -> String {
    let css = "<style>::-webkit-scrollbar { display: none; }</style>";
    let lower = html.to_lowercase();
    let mut result = html.to_string();

    if let Some(pos) = lower.find("</head>") {
        result.insert_str(pos, css);
    } else if let Some(pos) = lower.find("<body>") {
        result.insert_str(pos, css);
    } else {
        result.insert_str(0, css);
    }
    result
}

/// Auto-scaling is now handled purely via CSS clamp() in MARKDOWN_CSS
/// This function is kept as a no-op for compatibility
fn inject_auto_scaling(html: &str) -> String {
    html.to_string()
}

/// Get theme CSS variables based on mode
fn get_theme_css(is_dark: bool) -> String {
    if is_dark {
        r#"
        :root {
            --primary: #4fc3f7; /* Cyan 300 */
            --secondary: #81d4fa; /* Cyan 200 */
            --text-color: white;
            --h3-color: #b3e5fc; /* Cyan 100 */
            --h4-color: #e1f5fe; /* Cyan 50 */
            --code-color: #d4d4d4;
            --link-color: #82b1ff; /* Blue A100 */
            --link-hover-color: #448aff; /* Blue A200 */
            --link-shadow: rgba(68,138,255,0.4);
            --border-color: #333;
            --table-bg: rgba(0,0,0,0.2);
            --table-header-bg: #222;
            --glass: rgba(255, 255, 255, 0.03);
            --shadow-color: rgba(79, 195, 247, 0.6);
            --shadow-weak: rgba(79, 195, 247, 0.3);
            --sort-icon-filter: invert(1) brightness(200%) grayscale(100%);
            --bg: transparent;
        }
        "#
        .to_string()
    } else {
        r#"
        :root {
            --primary: #0288d1; /* Light Blue 700 */
            --secondary: #0277bd; /* Light Blue 800 */
            --text-color: #222;
            --h3-color: #01579b; /* Light Blue 900 */
            --h4-color: #0277bd;
            --code-color: #444;
            --link-color: #1976d2; /* Blue 700 */
            --link-hover-color: #0d47a1; /* Blue 900 */
            --link-shadow: rgba(13, 71, 161, 0.25);
            --border-color: #ddd;
            --table-bg: rgba(255,255,255,0.4);
            --table-header-bg: rgba(240,240,240,0.8);
            --glass: rgba(0, 0, 0, 0.03);
            --shadow-color: rgba(2, 136, 209, 0.4);
            --shadow-weak: rgba(2, 136, 209, 0.2);
            --sort-icon-filter: none;
            --bg: transparent;
        }
        "#
        .to_string()
    }
}

/// Convert markdown text to styled HTML, or pass through raw HTML
pub fn markdown_to_html(
    markdown: &str,
    is_refining: bool,
    preset_prompt: &str,
    input_text: &str,
) -> String {
    let is_dark = crate::overlay::is_dark_mode();
    let theme_css = get_theme_css(is_dark);

    if is_refining && crate::overlay::utils::SHOW_REFINING_CONTEXT_QUOTE {
        let combined = if input_text.is_empty() {
            preset_prompt.to_string()
        } else {
            format!("{}\n\n{}", preset_prompt, input_text)
        };
        let quote = crate::overlay::utils::get_context_quote(&combined);
        return format!(
            r#"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>{}</style>
    {}
    <style>
        {} 
        body {{ 
            display: flex; 
            align-items: center; 
            justify-content: center; 
            text-align: center; 
            height: 100vh; 
            margin: 0; 
            padding: 12px;
            font-style: italic;
            color: #aaa;
            font-size: 16px;
        }}
    </style>
</head>
<body>
    {}
    {}
</body>
</html>"#,
            theme_css,
            get_font_style(),
            MARKDOWN_CSS,
            quote,
            "" // No extra script
        );
    }

    // If input is already HTML, inject localStorage polyfill, Grid.js, and hidden scrollbar styles
    if is_html_content(markdown) {
        let with_storage = inject_storage_polyfill(markdown);
        let with_grid = inject_gridjs(&with_storage);
        return inject_scrollbar_css(&with_grid);
    }

    let mut options = Options::empty();
    options.insert(Options::ENABLE_TABLES);
    options.insert(Options::ENABLE_STRIKETHROUGH);
    options.insert(Options::ENABLE_TASKLISTS);

    let parser = Parser::new_ext(markdown, options);

    // Custom wrapper to enable word-level interaction
    // We map text events to HTML events containing wrapped words
    let mut in_code_block = false;
    let mut in_table = false;

    let wrapped_parser = parser.map(|event| {
        match event {
            Event::Start(Tag::CodeBlock(_)) => {
                in_code_block = true;
                event
            }
            Event::End(TagEnd::CodeBlock) => {
                in_code_block = false;
                event
            }
            Event::Start(Tag::Table(_)) => {
                in_table = true;
                event
            }
            Event::End(TagEnd::Table) => {
                in_table = false;
                event
            }
            Event::Code(_) => {
                // Inline code event - return as is
                event
            }
            Event::Text(text) => {
                if !in_code_block && !in_table {
                    // Split text into words and wrap
                    let mut output = String::with_capacity(text.len() * 2);
                    let escaped = escape_html_text(&text);

                    for (i, part) in escaped.split(' ').enumerate() {
                        if i > 0 {
                            output.push(' ');
                        }
                        if part.trim().is_empty() {
                            output.push_str(part);
                        } else {
                            output.push_str("<span class=\"word\">");
                            output.push_str(part);
                            output.push_str("</span>");
                        }
                    }
                    Event::Html(output.into())
                } else {
                    Event::Text(text)
                }
            }
            Event::SoftBreak => Event::HardBreak,
            _ => event,
        }
    });

    let mut html_output = String::new();
    html::push_html(&mut html_output, wrapped_parser);

    // Grid.js Integration
    let has_table = html_output.contains("<table");
    let gridjs_head = if has_table {
        let (css_url, js_url) = crate::overlay::html_components::grid_js::get_lib_urls();
        format!(
            r#"<link href="{}" rel="stylesheet" />
            <script src="{}"></script>
            <style>{}</style>"#,
            css_url,
            js_url,
            crate::overlay::html_components::grid_js::get_css()
        )
    } else {
        String::new()
    };

    let gridjs_body = if has_table {
        format!(
            r#"<script>{}</script>"#,
            crate::overlay::html_components::grid_js::get_init_script()
        )
    } else {
        String::new()
    };

    let final_html = format!(
        r#"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>{}</style>
    {}
    <style>{}</style>
    {}
</head>
<body>
    {}
    {}
</body>
</html>"#,
        theme_css,
        get_font_style(),
        MARKDOWN_CSS,
        gridjs_head,
        html_output,
        gridjs_body
    );

    inject_auto_scaling(&final_html)
}

/// Create a WebView child window for markdown rendering
/// Must be called from the main thread!
pub fn create_markdown_webview(parent_hwnd: HWND, markdown_text: &str, is_hovered: bool) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;
    let (is_refining, preset_prompt, input_text) = {
        let states = super::state::WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get(&hwnd_key) {
            (
                state.is_refining,
                state.preset_prompt.clone(),
                state.input_text.clone(),
            )
        } else {
            (false, String::new(), String::new())
        }
    };
    create_markdown_webview_ex(
        parent_hwnd,
        markdown_text,
        is_hovered,
        is_refining,
        &preset_prompt,
        &input_text,
    )
}

/// Create a WebView child window for markdown rendering (Internal version, call without lock if possible)
pub fn create_markdown_webview_ex(
    parent_hwnd: HWND,
    markdown_text: &str,
    _is_hovered: bool,
    is_refining: bool,
    preset_prompt: &str,
    input_text: &str,
) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;

    // Check if we already have a webview
    let exists = WEBVIEWS.with(|webviews| webviews.borrow().contains_key(&hwnd_key));

    if exists {
        return update_markdown_content_ex(
            parent_hwnd,
            markdown_text,
            is_refining,
            preset_prompt,
            input_text,
        );
    }

    // Get parent window rect
    let mut rect = RECT::default();
    unsafe {
        let _ = GetClientRect(parent_hwnd, &mut rect);
    }
    crate::log_info!(
        "[Markdown] Creating WebView for Parent HWND: {:?}",
        parent_hwnd
    );

    let html_content = markdown_to_html(markdown_text, is_refining, preset_prompt, input_text);

    let wrapper = HwndWrapper(parent_hwnd);

    // Edge margins: 4px left/right for resize handles, 2px top/bottom
    // 52px at bottom for buttons (btn_size 28 + margin 12 * 2) if hovered
    let margin_x = 4.0;
    let margin_y = 2.0;
    let button_area_height = margin_y;
    let content_width = ((rect.right - rect.left) as f64 - margin_x * 2.0).max(50.0);
    let content_height = ((rect.bottom - rect.top) as f64 - margin_y - button_area_height).max(0.0); // No min height - allow shrink for button bar

    // Create WebView with small margins so resize handles remain accessible
    // Use Physical coordinates since GetClientRect returns physical pixels
    let hwnd_key_for_nav = hwnd_key;

    // html_content is already a full HTML document from markdown_to_html
    let full_html = html_content;

    // Use store_html_page with safe, minimal retry (max 100ms total block)
    let mut page_url = String::new();
    for _ in 0..10 {
        if let Some(url) =
            crate::overlay::html_components::font_manager::store_html_page(full_html.clone())
        {
            page_url = url;
            break;
        }
        std::thread::sleep(std::time::Duration::from_millis(10));
    }

    if page_url.is_empty() {
        crate::log_info!("[Markdown] FAILED to store markdown page in font server!");
        let error_html = "<html><body style='color:white'>Error: Could not connect to internal font server.</body></html>";
        if let Some(url) =
            crate::overlay::html_components::font_manager::store_html_page(error_html.to_string())
        {
            page_url = url;
        } else {
            page_url = format!("data:text/html,{}", urlencoding::encode(&error_html));
        }
    }

    // Use SHARED_WEB_CONTEXT instead of creating a new one every time to keep RAM at 80MB
    let result = {
        // LOCK SCOPE: Serialized build to prevent resource contention
        let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
        crate::log_info!(
            "[Markdown] Acquired init lock. Building for HWND: {:?}...",
            parent_hwnd
        );

        let build_res = SHARED_WEB_CONTEXT.with(|ctx| {
            let mut ctx_ref = ctx.borrow_mut();

            // Initialization check
            if ctx_ref.is_none() {
                let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
                *ctx_ref = Some(wry::WebContext::new(Some(shared_data_dir)));
            }

            let mut builder = WebViewBuilder::new_with_web_context(ctx_ref.as_mut().unwrap())
                .with_bounds(Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                        margin_x as i32,
                        margin_y as i32,
                    )),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                        content_width as u32,
                        content_height as u32,
                    )),
                })
                .with_url(&page_url)
                .with_transparent(true);

            builder = builder.with_navigation_handler(move |url: String| {
                // Check if we should skip this navigation (triggered by history.back())
                let should_skip = {
                    let mut skip_map = SKIP_NEXT_NAVIGATION.lock().unwrap();
                    if skip_map.get(&hwnd_key_for_nav).copied().unwrap_or(false) {
                        skip_map.insert(hwnd_key_for_nav, false);
                        true
                    } else {
                        false
                    }
                };

                if should_skip {
                    // This navigation was from history.back(), don't increment depth
                    return true;
                }

                // Detect when user navigates to an external URL (clicked a link)
                // CRITICAL: Exclude wry internal URLs to prevent counting original content as browsing
                let is_internal = url.contains("wry.localhost")
                    || url.contains("localhost")
                    || url.contains("127.0.0.1")
                    || url.starts_with("data:")
                    || url.starts_with("about:");
                let is_external =
                    (url.starts_with("http://") || url.starts_with("https://")) && !is_internal;

                if is_external {
                    // Update browsing state and increment depth counter
                    if let Ok(mut states) = super::state::WINDOW_STATES.lock() {
                        if let Some(state) = states.get_mut(&hwnd_key_for_nav) {
                            state.is_browsing = true;
                            state.navigation_depth += 1;
                            // For a new navigation (not history back/forward), reset max depth to current depth
                            state.max_navigation_depth = state.navigation_depth;

                            if state.is_editing {
                                state.is_editing = false;
                            }
                        }
                    }
                    crate::overlay::result::button_canvas::update_window_position(HWND(
                        hwnd_key_for_nav as *mut std::ffi::c_void,
                    ));
                } else if is_internal {
                    // If we hit an internal URL, we are likely back at the start (or initial load)
                    // Force reset depth and browsing state to correct any drift
                    if let Ok(mut states) = super::state::WINDOW_STATES.lock() {
                        if let Some(state) = states.get_mut(&hwnd_key_for_nav) {
                            if state.is_browsing {
                                // Only reset if we were browsing - this handles the "Back to Start" drift
                                state.is_browsing = false;
                                state.navigation_depth = 0;
                                state.max_navigation_depth = 0;
                                // Ensure repaint to hide buttons
                                unsafe {
                                    let _ = windows::Win32::Graphics::Gdi::InvalidateRect(
                                        Some(HWND(hwnd_key_for_nav as *mut std::ffi::c_void)),
                                        None,
                                        false,
                                    );
                                }
                                crate::overlay::result::button_canvas::update_window_position(
                                    HWND(hwnd_key_for_nav as *mut std::ffi::c_void),
                                );
                            }
                        }
                    }
                }

                // Allow all navigation
                true
            });

            builder = builder.with_ipc_handler(move |msg: wry::http::Request<String>| {
                // Handle IPC messages from the WebView
                let body = msg.body();

                // Root IPC handler (general markdown actions)
                handle_markdown_ipc(parent_hwnd, body);

                if body.starts_with("opacity:") {
                    if let Ok(opacity_percent) = body["opacity:".len()..].parse::<f32>() {
                        // Opacity comes in as 0-100 from the slider
                        let alpha = ((opacity_percent / 100.0) * 255.0) as u8;
                        unsafe {
                            use windows::Win32::Foundation::COLORREF;
                            use windows::Win32::UI::WindowsAndMessaging::{
                                SetLayeredWindowAttributes, LWA_ALPHA,
                            };
                            // Set the actual WINDOW opacity
                            let _ = SetLayeredWindowAttributes(
                                parent_hwnd,
                                COLORREF(0),
                                alpha,
                                LWA_ALPHA,
                            );
                        }
                    }
                }
            });

            crate::overlay::html_components::font_manager::configure_webview(builder)
                .build_as_child(&wrapper)
        });

        crate::log_info!(
            "[Markdown] Build finished. Releasing lock. Status: {}",
            if build_res.is_ok() { "OK" } else { "ERR" }
        );
        build_res
    };

    match result {
        Ok(webview) => {
            crate::log_info!(
                "[Markdown] WebView success for Parent HWND: {:?}",
                parent_hwnd
            );
            WEBVIEWS.with(|webviews| {
                webviews.borrow_mut().insert(hwnd_key, webview);
            });

            let mut states = WEBVIEW_STATES.lock().unwrap();
            states.insert(hwnd_key, true);
            true
        }
        Err(e) => {
            crate::log_info!(
                "[Markdown] WebView FAILED for Parent HWND: {:?}, Error: {:?}",
                parent_hwnd,
                e
            );
            // WebView creation failed - warmup may not have completed
            false
        }
    }
}

/// Navigate back in browser history
pub fn go_back(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    // Determine if we need to recreate the webview (returning to original content)
    // or just go back in browser history.
    let (returning_to_original, markdown_text, is_hovered) = {
        let mut states = super::state::WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            if state.navigation_depth > 0 {
                state.navigation_depth -= 1;
            }

            // If depth is now 0, we are returning to the starting result content.
            // We recreate the WebView to ensure a clean state and avoid "white screen"
            // issues that happen when document.write is blocked by website CSP.
            if state.navigation_depth == 0 {
                state.is_browsing = false;
                state.max_navigation_depth = 0; // History is reset on recreation
                (true, state.full_text.clone(), state.is_hovered)
            } else {
                (false, String::new(), false)
            }
        } else {
            (false, String::new(), false)
        }
    };

    if returning_to_original {
        // Full recreation of the WebView with the desired content
        create_markdown_webview(parent_hwnd, &markdown_text, is_hovered);

        // Trigger repaint to hide navigation buttons
        unsafe {
            let _ = windows::Win32::Graphics::Gdi::InvalidateRect(Some(parent_hwnd), None, false);
        }
        crate::overlay::result::button_canvas::update_window_position(parent_hwnd);
    } else {
        // Normal browser history back for deeper navigation
        // Set skip flag to prevent navigation_handler from re-incrementing depth
        {
            let mut skip_map = SKIP_NEXT_NAVIGATION.lock().unwrap();
            skip_map.insert(hwnd_key, true);
        }

        WEBVIEWS.with(|webviews| {
            if let Some(webview) = webviews.borrow().get(&hwnd_key) {
                let _ = webview.evaluate_script("history.back();");
            }
        });
        crate::overlay::result::button_canvas::update_window_position(parent_hwnd);
    }
}

/// Navigate forward in browser history
pub fn go_forward(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    // Set skip flag to prevent navigation_handler from incrementing depth
    {
        let mut skip_map = SKIP_NEXT_NAVIGATION.lock().unwrap();
        skip_map.insert(hwnd_key, true);
    }

    // Increment navigation depth since we're going forward
    {
        let mut states = super::state::WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get_mut(&hwnd_key) {
            if state.navigation_depth < state.max_navigation_depth {
                state.navigation_depth += 1;
                state.is_browsing = true;
            } else {
                return; // Cannot go forward
            }
        }
    }

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            let _ = webview.evaluate_script("history.forward();");
        }
    });
    crate::overlay::result::button_canvas::update_window_position(parent_hwnd);
}

/// Update the markdown content in an existing WebView
pub fn update_markdown_content(parent_hwnd: HWND, markdown_text: &str) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;
    let (is_refining, preset_prompt, input_text) = {
        let states = super::state::WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get(&hwnd_key) {
            (
                state.is_refining,
                state.preset_prompt.clone(),
                state.input_text.clone(),
            )
        } else {
            (false, String::new(), String::new())
        }
    };
    update_markdown_content_ex(
        parent_hwnd,
        markdown_text,
        is_refining,
        &preset_prompt,
        &input_text,
    )
}

/// Check if HTML content contains scripts that need full browser capabilities
/// (localStorage, sessionStorage, IndexedDB, etc.)
fn content_needs_recreation(html: &str) -> bool {
    let lower = html.to_lowercase();
    // If content has <script> tags that might use storage APIs, it needs recreation
    // to get a proper origin instead of the sandboxed document.write context
    lower.contains("<script")
        && (lower.contains("localstorage")
            || lower.contains("sessionstorage")
            || lower.contains("indexeddb")
            || lower.contains("const ") // Variable declarations can conflict
            || lower.contains("let ")
            || lower.contains("var "))
}

/// Update the markdown content in an existing WebView (Raw version, does not fetch state)
/// For interactive HTML with scripts: recreates WebView to get proper origin
/// For simple content: uses fast inline update
pub fn update_markdown_content_ex(
    parent_hwnd: HWND,
    markdown_text: &str,
    is_refining: bool,
    preset_prompt: &str,
    input_text: &str,
) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;
    let html = markdown_to_html(markdown_text, is_refining, preset_prompt, input_text);

    // Check if this content has scripts that need full browser capabilities
    // If so, we must recreate the WebView to get proper origin access
    if content_needs_recreation(&html) {
        // Destroy existing WebView and create fresh one
        destroy_markdown_webview(parent_hwnd);

        // Get hover state for sizing
        let is_hovered = {
            if let Ok(states) = super::state::WINDOW_STATES.lock() {
                states.get(&hwnd_key).map(|s| s.is_hovered).unwrap_or(false)
            } else {
                false
            }
        };

        // Recreate WebView with fresh content (will use with_html for proper origin)
        return create_markdown_webview_ex(
            parent_hwnd,
            markdown_text,
            is_hovered,
            is_refining,
            preset_prompt,
            input_text,
        );
    }

    // Fast path for simple content without scripts
    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            // For simple markdown, update body content via DOM manipulation
            // This is safe because we verified there are no conflicting scripts
            let escaped_html = html
                .replace('\\', "\\\\")
                .replace('`', "\\`")
                .replace("${", "\\${");
            let script = format!(
                "document.open(); document.write(`{}`); document.close();",
                escaped_html
            );
            let _ = webview.evaluate_script(&script);
            return true;
        }
        false
    })
}

/// Stream markdown content - optimized for rapid updates during streaming
/// Uses innerHTML instead of document.write to avoid document recreation
/// Call this during streaming, then call update_markdown_content at the end for final render
pub fn stream_markdown_content(parent_hwnd: HWND, markdown_text: &str) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;
    let (is_refining, preset_prompt, input_text) = {
        let states = super::state::WINDOW_STATES.lock().unwrap();
        if let Some(state) = states.get(&hwnd_key) {
            (
                state.is_refining,
                state.preset_prompt.clone(),
                state.input_text.clone(),
            )
        } else {
            (false, String::new(), String::new())
        }
    };

    stream_markdown_content_ex(
        parent_hwnd,
        markdown_text,
        is_refining,
        &preset_prompt,
        &input_text,
    )
}

/// Stream markdown content - internal version for rapid streaming updates
/// Uses innerHTML on body to avoid document recreation overhead
pub fn stream_markdown_content_ex(
    parent_hwnd: HWND,
    markdown_text: &str,
    is_refining: bool,
    preset_prompt: &str,
    input_text: &str,
) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;

    // Check if webview exists
    let exists = WEBVIEWS.with(|webviews| webviews.borrow().contains_key(&hwnd_key));

    if !exists {
        // Create the webview first if it doesn't exist
        return create_markdown_webview_ex(
            parent_hwnd,
            markdown_text,
            false, // is_hovered - during streaming, use compact view
            is_refining,
            preset_prompt,
            input_text,
        );
    }

    // For streaming, we just update the body innerHTML
    // This is much faster than document.write and doesn't recreate the document
    let html = markdown_to_html(markdown_text, is_refining, preset_prompt, input_text);

    // Extract just the body content from the full HTML
    // The HTML structure is: ....<body>CONTENT</body>....
    let body_content = if let Some(body_start) = html.find("<body>") {
        let after_body = &html[body_start + 6..];
        if let Some(body_end) = after_body.find("</body>") {
            &after_body[..body_end]
        } else {
            &html[..] // Fallback to full html
        }
    } else {
        &html[..] // Fallback to full html
    };

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            // Escape for JS template literal
            let escaped_content = body_content
                .replace('\\', "\\\\")
                .replace('`', "\\`")
                .replace("${", "\\${");

            // Animate only NEW .word spans (markdown_to_html wraps words in <span class="word">)
            // Track previous word count, add animation only to new words
            // Animate only NEW .word spans (markdown_to_html wraps words in <span class="word">)
            // Track previous word count, add animation only to new words
            // Animate only NEW .word spans (markdown_to_html wraps words in <span class="word">)
            // Track previous word count, add animation only to new words
            // Animate only NEW .word spans (markdown_to_html wraps words in <span class="word">)
            // Track previous word count, add animation only to new words
            let script = format!(
                r#"(function() {{
    const newContent = `{}`;
    const prevWordCount = window._streamWordCount || 0;
    
    // Update content
    document.body.innerHTML = newContent;
    
    // --- INTEGRATED FONT SIZING (Heuristic Optimized) ---
    var body = document.body;
    var doc = document.documentElement;
    var winH = window.innerHeight;
    var winW = window.innerWidth;
    
    // Detect new session
    var textLen = (body.innerText || body.textContent || '').trim().length;
    var isNewSession = (!window._streamWordCount || window._streamWordCount < 5 || textLen < 50);
    
    // Dynamic Minimum Size
    // If text is short (< 200 chars), we allow shrinking to 6px to fit purely visual content.
    // If text is longer, we enforce 14px floor for readability.
    var minSize = (textLen < 200) ? 6 : 14;
    
    if (isNewSession) {{
         var maxPossible = Math.min(200, winH); 
         
         // Heuristic estimate
         var estimated = Math.sqrt((winW * winH) / (textLen + 1));
         
         var low = Math.max(minSize, Math.floor(estimated * 0.5));
         var high = Math.min(maxPossible, Math.ceil(estimated * 1.5));
         
         if (low > high) low = high;
         
         body.style.fontVariationSettings = "'wght' 400, 'wdth' 90, 'slnt' 0, 'ROND' 100";
         // RESET all spacing properties that might have been ramped up by fit_font_to_window in the previous session
         body.style.letterSpacing = '0px';
         body.style.wordSpacing = '0px';
         body.style.lineHeight = '1.5';
         body.style.paddingTop = '0';
         body.style.paddingBottom = '0';
         var blocks = body.querySelectorAll('p, h1, h2, h3, li, blockquote');
         for (var i = 0; i < blocks.length; i++) {{
             blocks[i].style.marginBottom = '0.5em';
             blocks[i].style.paddingBottom = '0';
         }}
         // Binary search
         var best = low;
         while (low <= high) {{
             var mid = Math.floor((low + high) / 2);
             body.style.fontSize = mid + 'px';
             if (doc.scrollHeight <= (winH + 2)) {{
                 best = mid;
                 low = mid + 1;
             }} else {{
                 high = mid - 1;
             }}
         }}
         // Enforce floor
         if (best < minSize) best = minSize;
         body.style.fontSize = best + 'px';
         
    }} else {{
        // Incrementally adjust font size if overflow occurs
        var hasOverflow = doc.scrollHeight > (winH + 2);
        if (hasOverflow) {{
            var currentSize = parseFloat(body.style.fontSize) || 14;
            if (currentSize > minSize) {{
                // Binary search from minSize to currentSize to find the largest fitting size
                var low = minSize;
                var high = currentSize;
                var best = minSize;
                while (low <= high) {{
                    var mid = Math.floor((low + high) / 2);
                    body.style.fontSize = mid + 'px';
                    if (doc.scrollHeight <= (winH + 2)) {{
                        best = mid;
                        low = mid + 1;
                    }} else {{
                        high = mid - 1;
                    }}
                }}
                body.style.fontSize = best + 'px';
            }}
        }}
    }}
    // ----------------------------
    
    // Get all word spans
    const words = document.querySelectorAll('.word');
    const newWordCount = words.length;
    
    // SKIP animation for the very first chunk (isNewSession)
    if (!isNewSession) {{
        let newWords = [];
        for (let i = prevWordCount; i < newWordCount; i++) {{
            newWords.push(words[i]);
        }}
        
        if (newWords.length > 0) {{
            // Set initial state
            newWords.forEach(w => {{
                w.style.opacity = '0';
                w.style.filter = 'blur(2px)';
            }});
            
            requestAnimationFrame(() => {{
                 newWords.forEach(w => {{
                    w.style.transition = 'opacity 0.35s ease-out, filter 0.35s ease-out';
                    w.style.opacity = '1';
                    w.style.filter = 'blur(0)';
                 }});
            }});
        }}
    }}
    
    window._streamWordCount = newWordCount;
    window.scrollTo({{ top: document.body.scrollHeight, behavior: 'smooth' }});
}})()"#,
                escaped_content
            );
            let _ = webview.evaluate_script(&script);
            return true;
        }
        false
    })
}

/// Reset the stream content tracker (call when streaming ends)
/// This ensures the next streaming session starts fresh
pub fn reset_stream_counter(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            // Reset stream counters only - font will be reset at start of next session
            let _ = webview.evaluate_script(
                "window._streamPrevLen = 0; window._streamPrevContent = ''; window._streamWordCount = 0;"
            );
        }
    });
}

/// Fit font size to window - call after streaming ends or on content update
/// This runs a ONE-TIME font fit calculation (no loops, no observers, safe)
/// Scales font UP if there's unfilled space, scales DOWN if overflow (but never below 8px)
/// Also adjusts font width (wdth) to prevent text wrapping when possible
pub fn fit_font_to_window(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    // Multi-pass font fitting algorithm that guarantees filling the window
    // Uses all available tools: font-size, wdth, letter-spacing, line-height, margins
    // Strategy: First fit content, then fill remaining space with line-height/margins
    let script = r#"
    (function() {
        if (window._sgtFitting) return;
        window._sgtFitting = true;
        
        setTimeout(function() {
            // Skip font fitting for image/audio input adapters - detect by checking for slider-container
            // These have special fixed layouts that shouldn't be affected by auto-scaling
            if (document.querySelector('.slider-container') || document.querySelector('.audio-player')) {
                window._sgtFitting = false;
                return;
            }
            
            var body = document.body;
            var doc = document.documentElement;
            var winH = window.innerHeight;
            var winW = body.clientWidth || window.innerWidth;
            
            // Helper: check if content fits
            function fits() { return doc.scrollHeight <= winH; }
            function getGap() { return winH - doc.scrollHeight; }
            
            // Helper: reset last child margin (used during binary search phases)
            function clearLastMargin() {
                var blocks = body.querySelectorAll('p, h1, h2, h3, li, blockquote');
                if (blocks.length > 0) {
                    blocks[blocks.length - 1].style.marginBottom = '0';
                }
            }
            
            // Get content and length
            var text = body.innerText || body.textContent || '';
            var textLen = text.trim().length;
            
            var isShortContent = textLen < 1500;
            var isTinyContent = textLen < 300;
            
            // Allowed ranges
            var minSize = isShortContent ? 6 : 12; 
            var maxSize = isTinyContent ? 200 : (isShortContent ? 100 : 24);
            
            // ===== PHASE 0: RESET (Start TIGHT like GDI) =====
            body.style.fontVariationSettings = "'wght' 400, 'wdth' 90, 'slnt' 0, 'ROND' 100";
            body.style.letterSpacing = '0px';
            body.style.lineHeight = '1.15'; // Start tight like GDI
            body.style.paddingTop = '0';
            body.style.paddingBottom = '0';
            var resetBlocks = body.querySelectorAll('p, h1, h2, h3, li, blockquote');
            for (var i = 0; i < resetBlocks.length; i++) {
                resetBlocks[i].style.marginBottom = '0.15em'; // Minimal paragraph gap
                resetBlocks[i].style.paddingBottom = '0';
            }
            clearLastMargin();
            
            var startSize = parseFloat(window.getComputedStyle(body).fontSize) || 14;
            
            // ===== PHASE 1: FONT SIZE (with tight line-height) =====
            // Binary search for largest font size that fits
            var low = minSize, high = maxSize, bestSize = startSize;
            while (low <= high) {
                var mid = Math.floor((low + high) / 2);
                body.style.fontSize = mid + 'px';
                clearLastMargin();
                if (fits()) {
                    bestSize = mid;
                    low = mid + 1;
                } else {
                    high = mid - 1;
                }
            }
            body.style.fontSize = bestSize + 'px';
            clearLastMargin();
            
            // ===== PHASE 2: LINE HEIGHT (expand from tight baseline to fill gap) =====
            // Start from tight 1.15, expand up to 2.5 to fill remaining space
            if (fits() && getGap() > 2) {
                var lowLH = 1.15, highLH = 2.5, bestLH = 1.15;
                while (highLH - lowLH > 0.01) {
                    var midLH = (lowLH + highLH) / 2;
                    body.style.lineHeight = midLH;
                    clearLastMargin();
                    if (fits()) {
                        bestLH = midLH;
                        lowLH = midLH;
                    } else {
                        highLH = midLH;
                    }
                }
                body.style.lineHeight = bestLH;
                clearLastMargin();
            }
            
            // ===== PHASE 3: BLOCK MARGINS (Distribute space between paragraphs) =====
            if (fits() && getGap() > 2) {
                var blocks = body.querySelectorAll('p, h1, h2, h3, li, blockquote');
                var numGaps = Math.max(1, blocks.length - 1);
                
                var lowM = 0, highM = 3.0, bestM = 0;
                while (highM - lowM > 0.02) {
                    var midM = (lowM + highM) / 2;
                    for (var i = 0; i < blocks.length - 1; i++) {
                        blocks[i].style.marginBottom = midM + 'em';
                    }
                    if (blocks.length > 0) blocks[blocks.length - 1].style.marginBottom = '0';
                    if (fits()) {
                        bestM = midM;
                        lowM = midM;
                    } else {
                        highM = midM;
                    }
                }
                for (var i = 0; i < blocks.length - 1; i++) {
                    blocks[i].style.marginBottom = bestM + 'em';
                }
                if (blocks.length > 0) blocks[blocks.length - 1].style.marginBottom = '0';
            }
            
            // ===== PHASE 4: FONT SIZE MICRO-ADJUST =====
            // Try bumping font size by 0.5px increments if there's still gap
            if (fits() && getGap() > 5) {
                var currentSize = parseFloat(body.style.fontSize) || bestSize;
                var testSize = currentSize;
                while (testSize < maxSize) {
                    testSize += 0.5;
                    body.style.fontSize = testSize + 'px';
                    clearLastMargin();
                    if (!fits()) {
                        body.style.fontSize = (testSize - 0.5) + 'px';
                        clearLastMargin();
                        break;
                    }
                }
            }
            
            // ===== PHASE 5: LETTER SPACING (Fine-tune horizontal density) =====
            // Expanding letter spacing can cause more wrapping, filling vertical space
            if (fits() && getGap() > 2 && isShortContent) {
                var lowLS = 0, highLS = 20, bestLS = 0;
                while (highLS - lowLS > 0.1) {
                    var midLS = (lowLS + highLS) / 2;
                    body.style.letterSpacing = midLS + 'px';
                    clearLastMargin();
                    if (fits()) {
                        bestLS = midLS;
                        lowLS = midLS;
                    } else {
                        highLS = midLS;
                    }
                }
                body.style.letterSpacing = bestLS + 'px';
                clearLastMargin();
            }
            
            // ===== PHASE 6: FONT WIDTH (wdth) =====
            // Expanding font width can also cause more wrapping
            if (fits() && getGap() > 2 && isShortContent) {
                var lowW = 90, highW = 150, bestW = 90;
                while (lowW <= highW) {
                    var midW = Math.floor((lowW + highW) / 2);
                    body.style.fontVariationSettings = "'wght' 400, 'wdth' " + midW + ", 'slnt' 0, 'ROND' 100";
                    clearLastMargin();
                    if (fits()) {
                        bestW = midW;
                        lowW = midW + 1;
                    } else {
                        highW = midW - 1;
                    }
                }
                body.style.fontVariationSettings = "'wght' 400, 'wdth' " + bestW + ", 'slnt' 0, 'ROND' 100";
                clearLastMargin();
            }
            
            // ===== PHASE 7: HORIZONTAL FILL (for short/single-line content) =====
            // If content is only 1-2 lines tall, stretch to fill horizontal space
            var fontSize = parseFloat(body.style.fontSize) || 14;
            var lineH = parseFloat(body.style.lineHeight) || 1.5;
            var approxLineHeight = fontSize * lineH;
            var isFewLines = doc.scrollHeight < approxLineHeight * 3;
            
            if (fits() && isFewLines) {
                // For very short content, maximize wdth to fill horizontal space
                var lowW = 90, highW = 500, bestW = 90;
                var baseHeight = doc.scrollHeight;
                while (lowW <= highW) {
                    var midW = Math.floor((lowW + highW) / 2);
                    body.style.fontVariationSettings = "'wght' 400, 'wdth' " + midW + ", 'slnt' 0, 'ROND' 100";
                    // Only accept if height doesn't increase (no wrapping)
                    if (doc.scrollHeight <= baseHeight && fits()) {
                        bestW = midW;
                        lowW = midW + 1;
                    } else {
                        highW = midW - 1;
                    }
                }
                body.style.fontVariationSettings = "'wght' 400, 'wdth' " + bestW + ", 'slnt' 0, 'ROND' 100";
                
                // Also stretch letter-spacing if more room
                baseHeight = doc.scrollHeight;
                var lowLS = 0, highLS = 100, bestLS = 0;
                while (highLS - lowLS > 0.5) {
                    var midLS = (lowLS + highLS) / 2;
                    body.style.letterSpacing = midLS + 'px';
                    if (doc.scrollHeight <= baseHeight && fits()) {
                        bestLS = midLS;
                        lowLS = midLS;
                    } else {
                        highLS = midLS;
                    }
                }
                body.style.letterSpacing = bestLS + 'px';
            }
            
            // ===== FINAL: Fill any remaining gap by distributing space =====
            // After all optimizations, if there's still a gap, distribute it via body padding
            var finalGap = winH - doc.scrollHeight;
            if (finalGap > 2) {
                // Distribute gap: more at bottom, some at top for visual balance
                body.style.paddingTop = Math.floor(finalGap * 0.3) + 'px';
                body.style.paddingBottom = Math.floor(finalGap * 0.7) + 'px';
            } else {
                body.style.paddingTop = '0';
                body.style.paddingBottom = '0';
            }
            
            window._sgtFitting = false;
        }, 50);
    })();
    "#;

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            let _ = webview.evaluate_script(script);
        }
    });
}

/// Trigger Grid.js initialization on any tables in the WebView
/// Call this after streaming ends to convert tables to interactive Grid.js tables
pub fn init_gridjs(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            // Trigger the table initialization via the MutationObserver's mechanism
            // The observer watches for DOM changes and schedules initGridJs via window.gridJsTimeout
            // We can simulate this by triggering a DOM change or directly calling the init logic
            let script = r#"
                (function() {
                    if (typeof gridjs === 'undefined') return;
                    
                    var tables = document.querySelectorAll('table:not(.gridjs-table):not([data-processed-table="true"])');
                    for (var i = 0; i < tables.length; i++) {
                        var table = tables[i];
                        if (table.closest('.gridjs-container') || table.closest('.gridjs-injected-wrapper')) continue;
                        
                        table.setAttribute('data-processed-table', 'true');
                        
                        var wrapper = document.createElement('div');
                        wrapper.className = 'gridjs-injected-wrapper';
                        table.parentNode.insertBefore(wrapper, table);
                        
                        try {
                            var grid = new gridjs.Grid({
                                from: table,
                                sort: true,
                                fixedHeader: true,
                                search: false,
                                resizable: false,
                                autoWidth: false,
                                style: {
                                    table: { 'width': '100%' },
                                    td: { 'border': '1px solid #333' },
                                    th: { 'border': '1px solid #333' }
                                },
                                className: {
                                    table: 'gridjs-table-premium',
                                    th: 'gridjs-th-premium',
                                    td: 'gridjs-td-premium'
                                }
                            });
                            grid.on('ready', function() {
                                table.classList.add('gridjs-hidden-source');
                            });
                            grid.render(wrapper);
                        } catch (e) {
                            console.error('Grid.js streaming init error:', e);
                            if(wrapper.parentNode) wrapper.parentNode.removeChild(wrapper);
                        }
                    }
                })();
            "#;
            let _ = webview.evaluate_script(script);
        }
    });
}

/// Resize the WebView to match parent window
/// When hovered: leaves 52px at bottom for buttons
/// When not hovered: expands to full height for clean view
/// When refine input active: starts 44px from top (40px input + 4px gap)
pub fn resize_markdown_webview(parent_hwnd: HWND, _is_hovered: bool) {
    let hwnd_key = parent_hwnd.0 as isize;

    let top_offset = 2.0; // 2px edge margin

    unsafe {
        let mut rect = RECT::default();
        let _ = GetClientRect(parent_hwnd, &mut rect);

        // Edge margins: 4px left/right for resize handles, 2px top/bottom
        let margin_x = 4.0;
        let margin_y = 2.0;
        // Always use margin_y, as buttons are now floating on a separate canvas
        let button_area_height = margin_y;

        let content_width = ((rect.right - rect.left) as f64 - margin_x * 2.0).max(50.0);
        let content_height =
            ((rect.bottom - rect.top) as f64 - top_offset - button_area_height).max(0.0);

        WEBVIEWS.with(|webviews| {
            if let Some(webview) = webviews.borrow().get(&hwnd_key) {
                // Use Physical coordinates since GetClientRect returns physical pixels
                let _ = webview.set_bounds(Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                        margin_x as i32,
                        top_offset as i32,
                    )),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                        content_width as u32,
                        content_height as u32,
                    )),
                });
            }
        });
    }
}

/// Hide the WebView (toggle back to plain text)
pub fn hide_markdown_webview(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            let _ = webview.set_visible(false);
        }
    });
}

/// Show the WebView (toggle to markdown mode)
pub fn show_markdown_webview(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    WEBVIEWS.with(|webviews| {
        if let Some(webview) = webviews.borrow().get(&hwnd_key) {
            let _ = webview.set_visible(true);
        }
    });
}

/// Destroy the WebView when window closes
pub fn destroy_markdown_webview(parent_hwnd: HWND) {
    let hwnd_key = parent_hwnd.0 as isize;

    WEBVIEWS.with(|webviews| {
        webviews.borrow_mut().remove(&hwnd_key);
    });

    let mut states = WEBVIEW_STATES.lock().unwrap();
    states.remove(&hwnd_key);
}

/// Check if markdown webview exists for this window
pub fn has_markdown_webview(parent_hwnd: HWND) -> bool {
    let hwnd_key = parent_hwnd.0 as isize;
    let states = WEBVIEW_STATES.lock().unwrap();
    states.get(&hwnd_key).copied().unwrap_or(false)
}

/// Generate a filename using Cerebras' gpt-oss-120b model
fn generate_filename(content: &str) -> String {
    let default_name = "result.html".to_string();

    // Get API Key
    let cerebras_key = if let Ok(app) = crate::APP.lock() {
        app.config.cerebras_api_key.clone()
    } else {
        return default_name;
    };

    if cerebras_key.is_empty() {
        return default_name;
    }

    // Truncate content to avoid token limits (first 4000 chars should be enough for context)
    let prompt_content = if content.len() > 4000 {
        &content[..4000]
    } else {
        content
    };

    let prompt = format!(
        "Generate a short, kebab-case filename (without extension) for the following content. \
        Do NOT include 'html' in the name. \
        The filename must be descriptive but concise (max 5 words). \
        Output ONLY the filename, nothing else. No markdown, no quotes, no explanations.\n\nContent:\n{}",
        prompt_content
    );

    let payload = serde_json::json!({
        "model": "gpt-oss-120b",
        "messages": [
            { "role": "user", "content": prompt }
        ],
        "temperature": 0.3,
        "max_tokens": 60
    });

    match crate::api::client::UREQ_AGENT
        .post("https://api.cerebras.ai/v1/chat/completions")
        .header("Authorization", &format!("Bearer {}", cerebras_key))
        .send_json(payload)
    {
        Ok(resp) => {
            if let Ok(json) = resp.into_body().read_json::<serde_json::Value>() {
                if let Some(choice) = json
                    .get("choices")
                    .and_then(|c| c.as_array())
                    .and_then(|c| c.first())
                {
                    if let Some(content) = choice
                        .get("message")
                        .and_then(|m| m.get("content"))
                        .and_then(|s| s.as_str())
                    {
                        let mut name = content.trim().to_string();

                        // Clean up quotes/markdown
                        name = name.replace('"', "").replace('\'', "").replace('`', "");

                        // Remove potential .html extension if the model disobeyed
                        if name.to_lowercase().ends_with(".html") {
                            name = name[..name.len() - 5].to_string();
                        }

                        // Remove trailing -html or _html if present to avoid redundancy
                        if name.to_lowercase().ends_with("-html") {
                            name = name[..name.len() - 5].to_string();
                        } else if name.to_lowercase().ends_with("_html") {
                            name = name[..name.len() - 5].to_string();
                        }

                        // Basic validation: remove invalid characters for Windows filenames
                        let invalid_chars = ['<', '>', ':', '"', '/', '\\', '|', '?', '*'];
                        name = name
                            .chars()
                            .filter(|c| !invalid_chars.contains(c))
                            .collect();

                        if name.is_empty() {
                            return default_name;
                        }

                        // Always append .html
                        name.push_str(".html");

                        return name;
                    }
                }
            }
            default_name
        }
        Err(e) => {
            eprintln!("Failed to generate filename: {}", e);
            default_name
        }
    }
}

/// Save the current content as HTML file using Windows File Save dialog
/// Returns true if file was saved successfully
pub fn save_html_file(markdown_text: &str) -> bool {
    use std::ffi::OsStr;
    use std::os::windows::ffi::OsStrExt;
    use windows::core::PCWSTR;
    use windows::Win32::System::Com::{
        CoCreateInstance, CoInitializeEx, CoUninitialize, CLSCTX_ALL, COINIT_APARTMENTTHREADED,
    };
    use windows::Win32::UI::Shell::Common::COMDLG_FILTERSPEC;
    use windows::Win32::UI::Shell::KNOWN_FOLDER_FLAG;
    use windows::Win32::UI::Shell::{
        FOLDERID_Downloads, FileSaveDialog, IFileSaveDialog, IShellItem,
        SHCreateItemFromParsingName, SHGetKnownFolderPath, FOS_OVERWRITEPROMPT,
        FOS_STRICTFILETYPES, SIGDN_FILESYSPATH,
    };

    unsafe {
        // Initialize COM
        let _ = CoInitializeEx(None, COINIT_APARTMENTTHREADED);

        // Create file dialog
        let dialog: IFileSaveDialog = match CoCreateInstance(&FileSaveDialog, None, CLSCTX_ALL) {
            Ok(d) => d,
            Err(_) => {
                CoUninitialize();
                return false;
            }
        };

        // Set file type filter - HTML files
        let filter_name: Vec<u16> = OsStr::new("HTML Files (*.html)")
            .encode_wide()
            .chain(std::iter::once(0))
            .collect();
        let filter_pattern: Vec<u16> = OsStr::new("*.html")
            .encode_wide()
            .chain(std::iter::once(0))
            .collect();

        let file_types = [COMDLG_FILTERSPEC {
            pszName: windows::core::PCWSTR(filter_name.as_ptr()),
            pszSpec: windows::core::PCWSTR(filter_pattern.as_ptr()),
        }];

        let _ = dialog.SetFileTypes(&file_types);
        let _ = dialog.SetFileTypeIndex(1);

        // Set default folder to Downloads
        if let Ok(downloads_path) =
            SHGetKnownFolderPath(&FOLDERID_Downloads, KNOWN_FOLDER_FLAG(0), None)
        {
            if let Ok(folder_item) =
                SHCreateItemFromParsingName::<PCWSTR, _, IShellItem>(PCWSTR(downloads_path.0), None)
            {
                let _ = dialog.SetFolder(&folder_item);
            }
        }

        // Set default extension
        let default_ext: Vec<u16> = OsStr::new("html")
            .encode_wide()
            .chain(std::iter::once(0))
            .collect();
        let _ = dialog.SetDefaultExtension(windows::core::PCWSTR(default_ext.as_ptr()));

        // Set default filename
        let filename = generate_filename(markdown_text);
        let default_name: Vec<u16> = OsStr::new(&filename)
            .encode_wide()
            .chain(std::iter::once(0))
            .collect();
        let _ = dialog.SetFileName(windows::core::PCWSTR(default_name.as_ptr()));

        // Set options
        let _ = dialog.SetOptions(FOS_OVERWRITEPROMPT | FOS_STRICTFILETYPES);

        // Show dialog
        if dialog.Show(None).is_err() {
            CoUninitialize();
            return false; // User cancelled
        }

        // Get result
        let result: windows::Win32::UI::Shell::IShellItem = match dialog.GetResult() {
            Ok(r) => r,
            Err(_) => {
                CoUninitialize();
                return false;
            }
        };

        // Get file path
        let path: windows::core::PWSTR = match result.GetDisplayName(SIGDN_FILESYSPATH) {
            Ok(p) => p,
            Err(_) => {
                CoUninitialize();
                return false;
            }
        };

        // Convert path to String
        let path_str = path.to_string().unwrap_or_default();

        // Free the path memory
        windows::Win32::System::Com::CoTaskMemFree(Some(path.0 as *const _));

        CoUninitialize();

        // Generate HTML content
        let html_content = markdown_to_html(markdown_text, false, "", "");

        // Write to file
        match std::fs::write(&path_str, html_content) {
            Ok(_) => true,
            Err(_) => false,
        }
    }
}

/// Handle IPC messages from markdown WebView
pub fn handle_markdown_ipc(hwnd: HWND, msg: &str) {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(msg) {
        if let Some(action) = json.get("action").and_then(|s| s.as_str()) {
            match action {
                "copy" => {
                    crate::overlay::result::trigger_copy(hwnd);
                }
                "close" | "broom_click" => unsafe {
                    let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                },
                "broom_drag_start" => {
                    unsafe {
                        // Native Window Drag
                        // ReleaseCapture required before SC_MOVE
                        use windows::Win32::UI::Input::KeyboardAndMouse::ReleaseCapture;
                        let _ = ReleaseCapture();
                        let _ = PostMessageW(
                            Some(hwnd),
                            WM_SYSCOMMAND,
                            WPARAM(0xF012), // SC_MOVE (0xF010) + HTCAPTION (2)
                            LPARAM(0),
                        );
                    }
                }
                _ => {}
            }
        }
    }
}
</file>

<file path="src/gui/app/init.rs">
use super::types::{SettingsApp, UserEvent, RESTORE_SIGNAL};
use crate::config::{Config, ThemeMode};
use crate::gui::settings_ui::ViewMode;
use crate::gui::utils::get_monitor_names;
use crate::updater::{UpdateStatus, Updater};
use auto_launch::AutoLaunch;
use eframe::egui;
use std::sync::atomic::Ordering;
use std::sync::mpsc::channel;
use std::sync::{Arc, Mutex};
use tray_icon::{
    menu::{CheckMenuItem, Menu, MenuEvent, MenuItem},
    MouseButton, TrayIconBuilder, TrayIconEvent,
};
use windows::core::*;
use windows::Win32::Foundation::{CloseHandle, WAIT_OBJECT_0};
use windows::Win32::System::Threading::*;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;

impl SettingsApp {
    pub fn new(
        mut config: Config,
        app_state: Arc<Mutex<crate::AppState>>,
        tray_menu: Menu,
        tray_settings_item: MenuItem,
        tray_quit_item: MenuItem,
        tray_favorite_bubble_item: CheckMenuItem,
        ctx: egui::Context,
        pending_file_path: Option<std::path::PathBuf>,
    ) -> Self {
        // Unified app name for both Debug and Release to share the same registry/task spot
        let app_name = "ScreenGoatedToolbox";
        let app_path = std::env::current_exe().unwrap();
        let app_path_str = app_path.to_str().unwrap_or("");
        let args: &[&str] = &[];

        let auto = AutoLaunch::new(app_name, app_path_str, args);

        // Check for current admin state early
        let current_admin_state = if cfg!(target_os = "windows") {
            crate::gui::utils::is_running_as_admin()
        } else {
            false
        };

        // --- STARTUP LOGIC REVAMP v2 (ONLY ONE WINS) ---
        let mut run_at_startup_ui = config.run_at_startup || config.run_as_admin_on_startup;

        // Ensure authorized path is set if startup is enabled
        if run_at_startup_ui && config.authorized_startup_path.is_empty() {
            config.authorized_startup_path = app_path_str.to_string();
        }

        // 1. Initial Sync: If system has it enabled but config doesn't, sync to true (Migration)
        let mut registry_enabled_in_system = false;
        #[cfg(target_os = "windows")]
        {
            use winreg::enums::*;
            use winreg::RegKey;
            let hkcu = RegKey::predef(HKEY_CURRENT_USER);
            if let Ok(key) = hkcu.open_subkey_with_flags(
                "Software\\Microsoft\\Windows\\CurrentVersion\\Run",
                KEY_READ,
            ) {
                if key.get_value::<String, &str>(app_name).is_ok() {
                    registry_enabled_in_system = true;
                }
            }
        }
        if !registry_enabled_in_system && auto.is_enabled().unwrap_or(false) {
            registry_enabled_in_system = true;
        }

        if registry_enabled_in_system && !config.run_at_startup && !config.run_as_admin_on_startup {
            config.run_at_startup = true;
            // Also authorize the path currently in registry if ours is empty
            if config.authorized_startup_path.is_empty() {
                config.authorized_startup_path = app_path_str.to_string();
            }
        }

        let task_exists = crate::gui::utils::is_admin_startup_enabled();
        if task_exists && !config.run_as_admin_on_startup {
            config.run_as_admin_on_startup = true;
            if config.authorized_startup_path.is_empty() {
                config.authorized_startup_path = app_path_str.to_string();
            }
        }

        // 2. Determine if WE are authorized to manage startup
        let is_authorized = if config.authorized_startup_path.is_empty() {
            // No one is authorized? We take it.
            true
        } else if config.authorized_startup_path == app_path_str {
            // We are the chosen one.
            true
        } else {
            // Someone else is authorized. Do they still exist?
            let other_exists = std::path::Path::new(&config.authorized_startup_path).exists();
            if !other_exists {
                // The authorized version is gone (likely an update/rename). We take over.
                true
            } else {
                // The authorized version still exists (likely Debug vs Release co-existing).
                // We stay quiet to avoid "Both starting" or "Hijacking".
                false
            }
        };

        // 3. Apply intent & Auto-fix (ONLY if authorized)
        if is_authorized {
            // Update authorization if it was empty or changed due to "not exists"
            if config.authorized_startup_path != app_path_str
                && (config.run_at_startup || config.run_as_admin_on_startup)
            {
                config.authorized_startup_path = app_path_str.to_string();
            }

            if config.run_as_admin_on_startup {
                run_at_startup_ui = true;
                if !crate::gui::utils::is_admin_startup_pointing_to_current_exe()
                    && current_admin_state
                {
                    crate::gui::utils::set_admin_startup(true);
                }
            } else if config.run_at_startup {
                run_at_startup_ui = true;
                let _ = auto.enable();
            }
        } else {
            // If not authorized, UI state just reflects intent, but we don't repair/fix.
            run_at_startup_ui = config.run_at_startup || config.run_as_admin_on_startup;
        }

        let run_at_startup = run_at_startup_ui;

        let (tx, rx) = channel();

        // Tray thread
        let tx_tray = tx.clone();
        let ctx_tray = ctx.clone();
        std::thread::spawn(move || {
            while let Ok(event) = TrayIconEvent::receiver().recv() {
                match &event {
                    TrayIconEvent::Click {
                        button: MouseButton::Right,
                        ..
                    } => {
                        // Handle right-click directly - show popup even when main window is hidden
                        crate::overlay::tray_popup::show_tray_popup();
                    }
                    _ => {
                        // Other events go through the normal channel
                        let _ = tx_tray.send(UserEvent::Tray(event));
                        ctx_tray.request_repaint();
                    }
                }
            }
        });

        // Restore signal listener
        let ctx_restore = ctx.clone();
        std::thread::spawn(move || loop {
            unsafe {
                match OpenEventW(
                    EVENT_ALL_ACCESS,
                    false,
                    w!("Global\\ScreenGoatedToolboxRestoreEvent"),
                ) {
                    Ok(event_handle) => {
                        let result = WaitForSingleObject(event_handle, INFINITE);
                        if result == WAIT_OBJECT_0 {
                            let class_name = w!("eframe");
                            let mut hwnd = FindWindowW(class_name, None).unwrap_or_default();
                            if hwnd.is_invalid() {
                                let title = w!("Screen Goated Toolbox (SGT by nganlinh4)");
                                hwnd = FindWindowW(None, title).unwrap_or_default();
                            }
                            if !hwnd.is_invalid() {
                                let _ = ShowWindow(hwnd, SW_RESTORE);
                                let _ = ShowWindow(hwnd, SW_SHOW);
                                let _ = SetForegroundWindow(hwnd);
                                let _ = SetFocus(Some(hwnd));
                            }
                            RESTORE_SIGNAL.store(true, Ordering::SeqCst);
                            ctx_restore.request_repaint();
                            let _ = ResetEvent(event_handle);
                        }
                        let _ = CloseHandle(event_handle);
                    }
                    Err(_) => std::thread::sleep(std::time::Duration::from_millis(100)),
                }
            }
        });

        // Menu thread
        let tx_menu = tx.clone();
        let ctx_menu = ctx.clone();
        std::thread::spawn(move || {
            while let Ok(event) = MenuEvent::receiver().recv() {
                match event.id.0.as_str() {
                    "1001" => std::process::exit(0),
                    "1002" => {
                        unsafe {
                            let class_name = w!("eframe");
                            let hwnd = FindWindowW(class_name, None).unwrap_or_default();
                            let hwnd = if hwnd.is_invalid() {
                                let title = w!("Screen Goated Toolbox (SGT by nganlinh4)");
                                FindWindowW(None, title).unwrap_or_default()
                            } else {
                                hwnd
                            };
                            if !hwnd.is_invalid() {
                                let _ = ShowWindow(hwnd, SW_RESTORE);
                                let _ = ShowWindow(hwnd, SW_SHOW);
                                let _ = SetForegroundWindow(hwnd);
                                let _ = SetFocus(Some(hwnd));
                            }
                        }
                        RESTORE_SIGNAL.store(true, Ordering::SeqCst);
                        let _ = tx_menu.send(UserEvent::Menu(event.clone()));
                        ctx_menu.request_repaint();
                    }
                    _ => {
                        let _ = tx_menu.send(UserEvent::Menu(event));
                        ctx_menu.request_repaint();
                    }
                }
            }
        });

        let view_mode = if config.presets.is_empty() {
            ViewMode::Global
        } else {
            ViewMode::Preset(if config.active_preset_idx < config.presets.len() {
                config.active_preset_idx
            } else {
                0
            })
        };

        let cached_monitors = get_monitor_names();
        let (up_tx, up_rx) = channel();

        // --- Init Audio Device Cache ---
        let cached_audio_devices = Arc::new(Mutex::new(Vec::new()));
        let devices_clone = cached_audio_devices.clone();
        // Fetch in background
        std::thread::spawn(move || {
            let devices = crate::api::tts::TtsManager::get_output_devices();
            if let Ok(mut lock) = devices_clone.lock() {
                *lock = devices;
            }
        });

        // Detect initial system theme
        let system_dark = crate::gui::utils::is_system_in_dark_mode();

        // Determine effective initial theme
        let effective_dark = match config.theme_mode {
            ThemeMode::Dark => true,
            ThemeMode::Light => false,
            ThemeMode::System => system_dark,
        };

        let initial_ui_language = config.ui_language.clone(); // Extract before move
        let rng_seed = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_millis() as u32;

        // Initialize tray item state
        tray_favorite_bubble_item.set_checked(config.show_favorite_bubble);

        // Capture bubble state before config is moved
        let initial_bubble_enabled = config.show_favorite_bubble;
        let initial_has_favorites = config.presets.iter().any(|p| p.is_favorite);

        // Create tray icon immediately to avoid splash delay
        let icon = crate::icon_gen::get_tray_icon(effective_dark);
        let tray_icon = match TrayIconBuilder::new()
            .with_tooltip("Screen Goated Toolbox (nganlinh4)")
            .with_icon(icon)
            .build()
        {
            Ok(t) => Some(t),
            Err(_) => None,
        };

        Self {
            config,
            app_state_ref: app_state,
            search_query: String::new(),
            tray_icon, // Created immediately
            _tray_menu: tray_menu,
            tray_settings_item,
            tray_quit_item,
            tray_favorite_bubble_item,
            last_ui_language: initial_ui_language,
            tray_retry_timer: 0.0,
            event_rx: rx,
            is_quitting: false,
            run_at_startup,
            auto_launcher: Some(auto),
            show_api_key: false,
            show_gemini_api_key: false,
            show_openrouter_api_key: false,
            show_cerebras_api_key: false,
            icon_dark: None,
            icon_light: None,
            view_mode,
            recording_hotkey_for_preset: None,
            hotkey_conflict_msg: None,
            recording_sr_hotkey: false,
            splash: None, // DELAYED CREATION to stage 35 for perfect $t=0$ timing
            fade_in_start: None,
            startup_stage: 0,
            cached_monitors,
            cached_audio_devices,
            snarl: None,
            last_edited_preset_idx: None,
            updater: Some(Updater::new(up_tx)),
            update_rx: up_rx,
            update_status: UpdateStatus::Idle,

            // --- NEW FIELD INIT ---
            current_admin_state,
            last_effective_theme_dark: effective_dark,
            last_system_theme_dark: system_dark,
            theme_check_timer: 0.0,
            // ----------------------

            // --- TIP INIT ---
            current_tip_idx: 0,
            tip_timer: 0.0,
            tip_fade_state: 0.0,
            tip_is_fading_in: true,
            show_tips_modal: false,
            rng_seed,
            // ---------------

            // --- USAGE MODAL INIT ---
            show_usage_modal: false,
            drop_overlay_fade: 0.0,
            // --- TTS SETTINGS MODAL INIT ---
            // --- TTS SETTINGS MODAL INIT ---
            show_tts_modal: false,
            // --- TOOLS MODAL INIT ---
            show_tools_modal: false,
            // -----------------------

            // --- FAVORITE BUBBLE STATE INIT ---
            last_bubble_enabled: initial_bubble_enabled,

            last_has_favorites: initial_has_favorites,
            // ----------------------------------

            // --- DOWNLOAD MANAGER INIT ---
            download_manager: crate::gui::settings_ui::download_manager::DownloadManager::new(),
            // -----------------------------

            // --- ARGUMENT HANDLING ---
            pending_file_path,
        }
    }
}
</file>

<file path="src/gui/splash.rs">
use eframe::egui;
use eframe::egui::{Align2, Color32, FontId, Pos2, Rect, Stroke, Vec2};
use std::cmp::Ordering;
use std::f32::consts::PI;

use crate::gui::icons::{paint_icon, Icon};
use crate::{WINDOW_HEIGHT, WINDOW_WIDTH};
use cpal::traits::{DeviceTrait, HostTrait, StreamTrait};
use std::cell::RefCell;
use std::sync::{Arc, Mutex};

// --- CONFIGURATION ---
const ANIMATION_DURATION: f32 = 3.6;
const START_TRANSITION: f32 = 0.8;
const EXIT_DURATION: f32 = 1.6; // Extended for majestic slow-motion reveal

// --- PALETTE ---
const C_VOID: Color32 = Color32::from_rgb(5, 5, 10);
const C_CYAN: Color32 = Color32::from_rgb(0, 255, 240);
const C_MAGENTA: Color32 = Color32::from_rgb(255, 0, 110);
const C_WHITE: Color32 = Color32::from_rgb(240, 245, 255);
const C_SHADOW: Color32 = Color32::from_rgb(20, 20, 30);

// Moon Palette (Textured Pink Moon)
const C_MOON_BASE: Color32 = Color32::from_rgb(230, 60, 120);
const C_MOON_SHADOW: Color32 = Color32::from_rgb(130, 20, 60); // Deep crater shadows
const C_MOON_HIGHLIGHT: Color32 = Color32::from_rgb(255, 180, 220); // Crater rims
const C_MOON_GLOW: Color32 = Color32::from_rgb(255, 0, 100);

// Dark Cloud Palette - REVERTED TO BLACK AESTHETIC
const C_CLOUD_CORE: Color32 = Color32::from_rgb(2, 2, 5); // Almost pure black void

// --- DAY PALETTE ---
const C_SKY_DAY_TOP: Color32 = Color32::from_rgb(100, 180, 255);
const C_DAY_REP: Color32 = Color32::from_rgb(0, 110, 255); // Representative (Vibrant Blue)
const C_DAY_SEC: Color32 = Color32::from_rgb(255, 255, 255); // Secondary (White) - S/T Voxels
const C_DAY_TEXT: Color32 = Color32::from_rgb(255, 120, 0); // Text (Orange) - Title/Loading

const C_SUN_BODY: Color32 = Color32::from_rgb(255, 160, 20);
const C_SUN_FLARE: Color32 = Color32::from_rgb(255, 240, 150);
const C_SUN_GLOW: Color32 = Color32::from_rgb(255, 200, 50);
const C_SUN_HIGHLIGHT: Color32 = Color32::from_rgb(255, 255, 220);

const C_CLOUD_WHITE: Color32 = Color32::from_rgb(255, 255, 255);

// --- MATH UTILS ---
fn smoothstep(edge0: f32, edge1: f32, x: f32) -> f32 {
    let t = ((x - edge0) / (edge1 - edge0)).clamp(0.0, 1.0);
    t * t * (3.0 - 2.0 * t)
}

fn lerp(a: f32, b: f32, t: f32) -> f32 {
    a + (b - a) * t
}

// --- 3D MATH KERNEL ---
#[derive(Clone, Copy, Debug)]
struct Vec3 {
    x: f32,
    y: f32,
    z: f32,
}

impl Vec3 {
    const ZERO: Self = Self {
        x: 0.0,
        y: 0.0,
        z: 0.0,
    };
    fn new(x: f32, y: f32, z: f32) -> Self {
        Self { x, y, z }
    }

    fn add(self, v: Vec3) -> Self {
        Self::new(self.x + v.x, self.y + v.y, self.z + v.z)
    }
    fn sub(self, v: Vec3) -> Self {
        Self::new(self.x - v.x, self.y - v.y, self.z - v.z)
    }
    fn mul(self, s: f32) -> Self {
        Self::new(self.x * s, self.y * s, self.z * s)
    }
    fn len(self) -> f32 {
        (self.x * self.x + self.y * self.y + self.z * self.z).sqrt()
    }
    fn normalize(self) -> Self {
        let l = self.len();
        if l == 0.0 {
            Self::ZERO
        } else {
            self.mul(1.0 / l)
        }
    }
    fn lerp(self, target: Vec3, t: f32) -> Self {
        Self::new(
            lerp(self.x, target.x, t),
            lerp(self.y, target.y, t),
            lerp(self.z, target.z, t),
        )
    }

    fn rotate_x(self, angle: f32) -> Self {
        let (s, c) = angle.sin_cos();
        Self::new(self.x, self.y * c - self.z * s, self.y * s + self.z * c)
    }
    fn rotate_y(self, angle: f32) -> Self {
        let (s, c) = angle.sin_cos();
        Self::new(self.x * c + self.z * s, self.y, -self.x * s + self.z * c)
    }
    fn rotate_z(self, angle: f32) -> Self {
        let (s, c) = angle.sin_cos();
        Self::new(self.x * c - self.y * s, self.x * s + self.y * c, self.z)
    }
}

// --- ATMOSPHERE ENTITIES ---

struct Cloud {
    pos: Vec2,
    velocity: f32,
    scale: f32,
    opacity: f32,
    puffs: Vec<(Vec2, f32)>, // (Offset from center, Radius multiplier)
}

struct Star {
    pos: Vec2, // 0.0-1.0 normalized screen coords
    phase: f32,
    brightness: f32,
    size: f32,
}

// --- MOON ENTITIES ---
struct MoonFeature {
    pos: Vec2, // Normalized on moon disk (-1.0 to 1.0)
    radius: f32,
    is_crater: bool, // if true, draws a depth ring; if false, draws a filled patch (Mare)
}

// --- VOXEL ENTITIES ---
struct Voxel {
    helix_radius: f32,
    helix_angle_offset: f32,
    helix_y: f32,
    target_pos: Vec3,
    pos: Vec3,
    rot: Vec3,
    scale: f32,
    velocity: Vec3,
    color: Color32,
    noise_factor: f32,
    is_debris: bool,
}

// --- AUDIO ENGINE ---
// Shared state between main thread and audio thread
struct SharedAudioState {
    physics_t: f32,
    warp_progress: f32,
    impact_trigger: bool,
    is_dark: bool,
    is_finished: bool,
}

// Internal state used ONLY by the audio thread (no lock needed)
struct RenderState {
    // Proper phase accumulators (0.0 to 1.0, wrap around)
    vox_phase1: f32,
    vox_phase2: f32,
    vox_phase3: f32,
    impact_phase1: f32,
    impact_phase2: f32,
    impact_phase3: f32,
    whoosh_phase: f32,
    // Envelope/state
    noise_state: f32,
    impact_env: f32,
    samples_rendered: u64,
    last_physics_t: f32,
    last_warp_progress: f32,
    last_is_dark: bool,
}

struct SplashAudio {
    _stream: cpal::Stream,
    state: Arc<Mutex<SharedAudioState>>,
}

impl SplashAudio {
    fn new() -> Option<Self> {
        let host = cpal::default_host();
        let device = host.default_output_device()?;
        let config = device.default_output_config().ok()?;

        let state = Arc::new(Mutex::new(SharedAudioState {
            physics_t: 0.0,
            warp_progress: 0.0,
            impact_trigger: false,
            is_dark: false,
            is_finished: false,
        }));

        let state_clone = Arc::clone(&state);
        let sample_rate = u32::from(config.sample_rate()) as f32;
        let channels = config.channels() as usize;

        // Internal rendering state stays in the closure
        let mut r = RenderState {
            vox_phase1: 0.0,
            vox_phase2: 0.0,
            vox_phase3: 0.0,
            impact_phase1: 0.0,
            impact_phase2: 0.0,
            impact_phase3: 0.0,
            whoosh_phase: 0.0,
            noise_state: 0.0,
            impact_env: 0.0,
            samples_rendered: 0,
            last_physics_t: 0.0,
            last_warp_progress: 0.0,
            last_is_dark: false,
        };

        let stream = device
            .build_output_stream(
                &config.into(),
                move |data: &mut [f32], _| {
                    // Try non-blocking lock to avoid audio pops from blocking
                    let (physics_t, warp_progress, is_dark, is_finished, trigger_impact) =
                        if let Ok(mut s_lock) = state_clone.try_lock() {
                            let pt = s_lock.physics_t;
                            let wp = s_lock.warp_progress;
                            let dark = s_lock.is_dark;
                            let fin = s_lock.is_finished;
                            let trigger = s_lock.impact_trigger;
                            if trigger {
                                s_lock.impact_trigger = false;
                            }
                            r.last_physics_t = pt;
                            r.last_warp_progress = wp;
                            r.last_is_dark = dark;
                            (pt, wp, dark, fin, trigger)
                        } else {
                            // Lock busy - use cached values
                            (r.last_physics_t, r.last_warp_progress, r.last_is_dark, false, false)
                        };

                    if is_finished {
                        for x in data.iter_mut() {
                            *x = 0.0;
                        }
                        return;
                    }

                    if trigger_impact {
                        r.impact_env = 1.0;
                    }

                    // Startup fade to prevent initial pop (first ~50ms)
                    let startup_samples = (sample_rate * 0.05) as u64;

                    for frame in data.chunks_mut(channels) {
                        // 0. ENVELOPE (original)
                        let attack = (physics_t / 0.05).min(1.0);
                        let decay = (1.0 - (physics_t - 1.6).max(0.0) / 0.8).max(0.0);
                        let env = attack * decay;

                        // 1. VOXEL SHIMMER (original frequencies/volumes, proper phase)
                        let theme_freq = if is_dark { 110.0 } else { 220.0 };
                        let base_freq = theme_freq + (physics_t * 40.0);
                        let vol_vox = env * 0.03;

                        r.vox_phase1 += base_freq / sample_rate;
                        r.vox_phase2 += (base_freq * 1.5) / sample_rate;
                        r.vox_phase3 += (base_freq * 2.5) / sample_rate;
                        while r.vox_phase1 >= 1.0 { r.vox_phase1 -= 1.0; }
                        while r.vox_phase2 >= 1.0 { r.vox_phase2 -= 1.0; }
                        while r.vox_phase3 >= 1.0 { r.vox_phase3 -= 1.0; }

                        let s1 = (r.vox_phase1 * 2.0 * PI).sin();
                        let s2 = (r.vox_phase2 * 2.0 * PI).sin();
                        let s3 = (r.vox_phase3 * 2.0 * PI).sin();
                        let voxels = (s1 + s2 * 0.5 + s3 * 0.3) * vol_vox;

                        // 2. COSMIC WIND (original)
                        r.noise_state = (r.noise_state * 0.994 + ((r.vox_phase1 * 43758.5453).sin().fract() - 0.5) * 0.012).clamp(-1.0, 1.0);
                        let wind = r.noise_state * 0.012 * env;

                        // 3. ASSEMBLY IMPACT (original frequencies/volumes, proper phase)
                        let mut impact = 0.0;
                        if r.impact_env > 0.0001 {
                            let f_base = 180.0 + r.impact_env * 360.0;
                            r.impact_phase1 += f_base / sample_rate;
                            r.impact_phase2 += (f_base * 2.1) / sample_rate;
                            r.impact_phase3 += (f_base * 3.5) / sample_rate;
                            while r.impact_phase1 >= 1.0 { r.impact_phase1 -= 1.0; }
                            while r.impact_phase2 >= 1.0 { r.impact_phase2 -= 1.0; }
                            while r.impact_phase3 >= 1.0 { r.impact_phase3 -= 1.0; }

                            let h1 = (r.impact_phase1 * 2.0 * PI).sin();
                            let h2 = (r.impact_phase2 * 2.0 * PI).sin();
                            let h3 = (r.impact_phase3 * 2.0 * PI).sin();
                            // Smooth envelope curve (squared for natural decay tail)
                            let smooth_env = r.impact_env * r.impact_env;
                            impact = (h1 + h2 * 0.4 + h3 * 0.2) * smooth_env * 0.05;
                            // Slower decay for longer ring-out (~600ms instead of ~200ms)
                            r.impact_env *= 0.99985;
                        }

                        // 4. WARP WHOOSH (original frequencies/volumes, proper phase)
                        let mut whoosh = 0.0;
                        if warp_progress > 0.0001 {
                            let p = warp_progress;
                            let whoosh_freq = 80.0 + p.powf(1.5) * 4500.0;
                            r.whoosh_phase += whoosh_freq / sample_rate;
                            while r.whoosh_phase >= 1.0 { r.whoosh_phase -= 1.0; }

                            let attack_w = (p / 0.1).min(1.0);
                            let decay_w = (1.0 - (p - 0.15).max(0.0) / 0.7).max(0.0);
                            let whoosh_vol = attack_w * decay_w * 0.07;
                            whoosh = (r.whoosh_phase * 2.0 * PI).sin() * whoosh_vol;
                        }

                        // Apply startup fade
                        let startup_fade = if r.samples_rendered < startup_samples {
                            r.samples_rendered as f32 / startup_samples as f32
                        } else {
                            1.0
                        };
                        r.samples_rendered = r.samples_rendered.saturating_add(1);

                        let mixed = ((voxels + wind + impact + whoosh) * startup_fade).clamp(-1.0, 1.0);
                        for sample in frame.iter_mut() {
                            *sample = mixed;
                        }
                    }
                },
                |err| crate::log_info!("Splash audio stream error: {}", err),
                None,
            )
            .ok()?;

        stream.play().ok()?;
        Some(Self {
            _stream: stream,
            state,
        })
    }
}

pub struct SplashScreen {
    start_time: f64,
    voxels: Vec<Voxel>,
    clouds: Vec<Cloud>,
    stars: Vec<Star>,
    moon_features: Vec<MoonFeature>,
    init_done: bool,
    mouse_influence: Vec2,
    mouse_world_pos: Vec3,
    loading_text: String,
    exit_start_time: Option<f64>,
    is_dark: bool,
    audio: Arc<Mutex<Option<SplashAudio>>>,
    has_played_impact: bool,
    // Pre-allocated buffers for performance (zero allocation in hot path)
    draw_list: RefCell<Vec<(f32, Pos2, f32, Color32, bool, bool)>>,
}

pub enum SplashStatus {
    Ongoing,
    Finished,
}

impl SplashScreen {
    pub fn new(ctx: &egui::Context) -> Self {
        let is_dark = ctx.style().visuals.dark_mode;
        let audio_container = Arc::new(Mutex::new(None));
        let audio_container_clone = audio_container.clone();

        std::thread::spawn(move || {
            if let Some(audio) = SplashAudio::new() {
                if let Ok(mut lock) = audio_container_clone.lock() {
                    *lock = Some(audio);
                }
            }
        });

        let mut slf = Self {
            start_time: ctx.input(|i| i.time),
            voxels: Vec::with_capacity(600),
            clouds: Vec::with_capacity(20),
            stars: Vec::with_capacity(200),
            moon_features: Vec::with_capacity(100),
            init_done: false,
            mouse_influence: Vec2::ZERO,
            mouse_world_pos: Vec3::ZERO,
            loading_text: "TRANSLATING...".to_string(),
            exit_start_time: None,
            is_dark,
            audio: audio_container,
            has_played_impact: false,
            draw_list: RefCell::new(Vec::with_capacity(600)),
        };

        // Immediately init the heavy scene data on creation
        // instead of waiting for the first update frame.
        slf.init_scene();
        slf
    }

    pub fn reset_timer(&mut self, ctx: &egui::Context) {
        self.start_time = ctx.input(|i| i.time);
    }

    fn init_scene(&mut self) {
        let mut rng_state = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .map(|d| d.as_nanos() as u64)
            .unwrap_or(987654321u64);

        let mut rng = || {
            rng_state = rng_state.wrapping_mul(6364136223846793005).wrapping_add(1);
            (rng_state >> 32) as f32 / 4294967295.0
        };

        // --- 1. Init Text Voxels ---
        let s_map = [" ####", "##   ", " ### ", "   ##", "#### "];
        let g_map = [" ####", "##   ", "## ##", "##  #", " ####"];
        let t_map = ["#####", "  #  ", "  #  ", "  #  ", "  #  "];

        let spacing = 14.0;
        let mut total_voxels = 0;

        let mut spawn_letter = |map: &[&str], offset_x: f32, color_theme: Color32| {
            for (y, row) in map.iter().enumerate() {
                for (x, ch) in row.chars().enumerate() {
                    if ch == '#' {
                        total_voxels += 1;
                        let tx = offset_x + (x as f32 * spacing);
                        let ty = (2.0 - y as f32) * spacing;
                        let tz = 0.0;
                        let target = Vec3::new(tx, ty, tz);

                        let strand_idx = total_voxels % 2;
                        let h_y = ((total_voxels as f32 * 3.0) % 240.0) - 120.0;
                        let h_radius = 60.0;
                        let h_angle = (if strand_idx == 0 { 0.0 } else { PI }) + (h_y * 0.05);

                        self.voxels.push(Voxel {
                            helix_radius: h_radius,
                            helix_angle_offset: h_angle,
                            helix_y: h_y,
                            target_pos: target,
                            pos: Vec3::ZERO,
                            rot: Vec3::new(rng() * 6.0, rng() * 6.0, rng() * 6.0),
                            scale: 0.1,
                            velocity: Vec3::ZERO,
                            color: if rng() > 0.85 { C_WHITE } else { color_theme },
                            noise_factor: rng(),
                            is_debris: false,
                        });
                    }
                }
            }
        };

        let c_primary = if self.is_dark { C_MAGENTA } else { C_DAY_REP };
        let c_secondary = if self.is_dark { C_CYAN } else { C_DAY_SEC };

        spawn_letter(&s_map, -120.0, c_secondary);
        spawn_letter(&g_map, -35.0, c_primary);
        spawn_letter(&t_map, 50.0, c_secondary);

        // Debris
        for _ in 0..100 {
            let h_y = (rng() * 300.0) - 150.0;
            let h_radius = 80.0 + rng() * 60.0;
            let h_angle = rng() * PI * 2.0;

            let n = rng();
            // Spread targets in a thick 3D torus/nebula
            let t_y = rng() * 700.0 - 50.0;
            // Diverse depth: Some very close, some very far
            let t_dist = 400.0 + n.powi(2) * 1400.0;
            let target = Vec3::new(h_angle.cos() * t_dist, t_y, h_angle.sin() * t_dist);

            self.voxels.push(Voxel {
                helix_radius: h_radius,
                helix_angle_offset: h_angle,
                helix_y: h_y,
                target_pos: target,
                pos: Vec3::ZERO,
                rot: Vec3::new(rng(), rng(), rng()),
                // Diverse sizes: small dust to larger puffs
                scale: 0.1 + n * 0.5,
                velocity: Vec3::ZERO,
                color: C_SHADOW,
                noise_factor: n,
                is_debris: true,
            });
        }

        // --- 2. Init Stars ---
        for _ in 0..150 {
            self.stars.push(Star {
                pos: Vec2::new(rng(), rng() * 0.85), // Keep mostly top/middle
                phase: rng() * PI * 2.0,
                brightness: 0.3 + rng() * 0.7,
                size: if rng() > 0.95 {
                    1.5 + rng()
                } else {
                    0.8 + rng() * 0.5
                },
            });
        }

        // --- 3. Init Dark Clouds (Volumetric Puffs) ---
        for _ in 0..15 {
            // Fewer total clouds, but more complex
            let mut puffs = Vec::new();
            // Core main puff
            puffs.push((Vec2::ZERO, 1.0));
            // Satellites
            let num_puffs = 5 + (rng() * 4.0) as usize;
            for _ in 0..num_puffs {
                let angle = rng() * PI * 2.0;
                let dist = 15.0 + rng() * 25.0;
                let r_mult = 0.4 + rng() * 0.5;
                puffs.push((
                    Vec2::new(angle.cos() * dist, angle.sin() * dist * 0.6), // Squashed vertically
                    r_mult,
                ));
            }

            self.clouds.push(Cloud {
                pos: Vec2::new(rng() * 1200.0 - 600.0, rng() * 400.0 - 200.0),
                velocity: 5.0 + rng() * 15.0, // Drifting right
                scale: 1.2 + rng() * 1.5,
                opacity: 0.4 + rng() * 0.4,
                puffs,
            });
        }

        // --- 4. Init Moon Features ---
        // Maria (Dark Patches - large, irregular)
        for _ in 0..20 {
            let angle = rng() * PI * 2.0;
            let dist = rng().sqrt() * 0.7; // Bias towards center/middle
            let pos = Vec2::new(angle.cos() * dist, angle.sin() * dist);

            self.moon_features.push(MoonFeature {
                pos,
                radius: 0.15 + rng() * 0.25,
                is_crater: false,
            });
        }

        // Craters (Small, sharp)
        for _ in 0..50 {
            let angle = rng() * PI * 2.0;
            let dist = rng().powf(0.8);
            let pos = Vec2::new(angle.cos() * dist, angle.sin() * dist);

            self.moon_features.push(MoonFeature {
                pos,
                radius: 0.02 + rng() * 0.06,
                is_crater: true,
            });
        }

        self.init_done = true;
    }

    pub fn update(&mut self, ctx: &egui::Context) -> SplashStatus {
        self.is_dark = ctx.style().visuals.dark_mode;

        let now = ctx.input(|i| i.time);
        let dt = ctx.input(|i| i.stable_dt);

        if self.exit_start_time.is_none() {
            let t = (now - self.start_time) as f32;
            if t > ANIMATION_DURATION - 0.5 {
                if ctx.input(|i| i.pointer.any_click()) {
                    // Prevent click on theme switcher from triggering splash exit
                    let is_in_switcher = if let Some(pos) = ctx.input(|i| i.pointer.latest_pos()) {
                        pos.x < 100.0 && pos.y < 60.0
                    } else {
                        false
                    };

                    if !is_in_switcher {
                        self.exit_start_time = Some(now);
                    }
                }
            }
        }

        let t_abs = (now - self.start_time) as f32;
        let physics_t = t_abs.min(ANIMATION_DURATION);

        // --- EXIT LOGIC ---
        let mut warp_progress = 0.0;
        if let Some(exit_start) = self.exit_start_time {
            let dt = (now - exit_start) as f32;
            if dt > EXIT_DURATION {
                if let Ok(mut lock) = self.audio.lock() {
                    if let Some(audio) = lock.as_mut() {
                        if let Ok(mut s) = audio.state.lock() {
                            s.is_finished = true;
                        }
                    }
                }
                return SplashStatus::Finished;
            }
            warp_progress = (dt / EXIT_DURATION).clamp(0.0, 1.0); // Linear global progress, curves applied per-voxel
        }

        // --- UPDATE AUDIO STATE ---
        if let Ok(mut lock) = self.audio.lock() {
            if let Some(audio) = lock.as_mut() {
                if let Ok(mut s) = audio.state.lock() {
                    s.physics_t = physics_t;
                    s.warp_progress = warp_progress;
                    s.is_dark = self.is_dark;

                    // Trigger impact once when assembly is nearly complete
                    if physics_t > 1.6 && !self.has_played_impact {
                        s.impact_trigger = true;
                        drop(s); // release lock before updating self
                        self.has_played_impact = true;
                    }
                }
            }
        }

        ctx.request_repaint();

        // --- UPDATE CLOUDS ---
        let viewport_rect = ctx.input(|i| {
            i.viewport()
                .inner_rect
                .unwrap_or(Rect::from_min_size(Pos2::ZERO, Vec2::ZERO))
        });
        // Fallback to expected size if viewport not ready
        let size = if viewport_rect.width() < 100.0 || viewport_rect.height() < 100.0 {
            Vec2::new(WINDOW_WIDTH, WINDOW_HEIGHT)
        } else {
            viewport_rect.size()
        };
        // Use window-local coords (0,0 origin) for consistency with paint()
        let rect = Rect::from_min_size(Pos2::ZERO, size);
        for cloud in &mut self.clouds {
            cloud.pos.x += cloud.velocity * dt;
            // Wrap around
            if cloud.pos.x > rect.width() / 2.0 + 300.0 {
                cloud.pos.x = -rect.width() / 2.0 - 300.0;
            }
        }

        if let Some(pointer) = ctx.input(|i| i.pointer.hover_pos()) {
            let center = rect.center();
            let tx = (pointer.x - center.x) / center.x;
            let ty = (pointer.y - center.y) / center.y;
            self.mouse_influence.x += (tx - self.mouse_influence.x) * 0.05;
            self.mouse_influence.y += (ty - self.mouse_influence.y) * 0.05;

            let cam_z_offset = warp_progress * 2000.0;
            let cam_dist =
                600.0 + smoothstep(0.0, ANIMATION_DURATION, physics_t) * 100.0 - cam_z_offset;

            let fov = 800.0;
            let mouse_wx = (pointer.x - center.x) * cam_dist / fov;
            let mouse_wy = -(pointer.y - center.y) * cam_dist / fov;
            self.mouse_world_pos = Vec3::new(mouse_wx, mouse_wy, 0.0);
        }

        if self.exit_start_time.is_none() {
            if t_abs < 0.8 {
                self.loading_text = "TRANSLATING...".to_string();
            } else if t_abs < 1.6 {
                self.loading_text = "OCR...".to_string();
            } else if t_abs < 2.4 {
                self.loading_text = "TRANSCRIBING...".to_string();
            } else {
                self.loading_text = "nganlinh4".to_string();
            }
        } else {
            self.loading_text = "READY TO ROCK!".to_string();
        }

        // --- PHYSICS UPDATE (Voxels) ---
        let helix_spin = physics_t * 2.0 + (physics_t * physics_t * 0.2);

        for v in &mut self.voxels {
            let my_start = START_TRANSITION + (v.noise_factor * 0.6);
            let my_end = my_start + 1.0;
            let progress = smoothstep(my_start, my_end, physics_t);

            if progress <= 0.0 {
                let current_h_y = v.helix_y + (physics_t * 2.0 + v.noise_factor * 10.0).sin() * 5.0;
                let current_angle = v.helix_angle_offset + helix_spin;
                let mut current_radius = v.helix_radius * (1.0 + physics_t * 0.1);

                if v.is_debris && physics_t > ANIMATION_DURATION * 0.7 {
                    let flare_start = ANIMATION_DURATION * 0.7;
                    let flare = (physics_t - flare_start).powi(2) * 20.0;
                    current_radius += flare;
                }

                v.pos = Vec3::new(
                    current_angle.cos() * current_radius,
                    current_h_y,
                    current_angle.sin() * current_radius,
                );
                v.rot.y += 0.05;
                v.scale = 0.8;
                v.velocity = Vec3::ZERO;
            } else {
                let current_h_y = v.helix_y + (physics_t * 2.0 + v.noise_factor * 10.0).sin() * 5.0;
                let current_angle = v.helix_angle_offset + helix_spin;

                let mut current_radius = v.helix_radius * (1.0 + physics_t * 0.1);
                if v.is_debris && physics_t > ANIMATION_DURATION * 0.7 {
                    let flare_start = ANIMATION_DURATION * 0.7;
                    let flare = (physics_t - flare_start).powi(2) * 20.0;
                    current_radius += flare;
                }

                let helix_pos = Vec3::new(
                    current_angle.cos() * current_radius,
                    current_h_y,
                    current_angle.sin() * current_radius,
                );
                let mut target_base = v.target_pos;

                // Add slow cosmic drift/orbit to debris targets so they don't look static
                if v.is_debris {
                    let orbit_speed = 0.02 + v.noise_factor * 0.08;
                    target_base = target_base.rotate_y(t_abs * orbit_speed);
                    target_base.y += (t_abs * 0.5 + v.noise_factor * 10.0).sin() * 20.0;
                }

                if warp_progress > 0.0 {
                    // "One by One" Departure:
                    // Stagger start times across the first 75% of the animation.
                    // Each particle moves for only the remaining 25% (0.4s) effectively.
                    let start_threshold = v.noise_factor * 0.75;
                    let move_duration = 0.25;

                    // Normalize progress to this particle's specific window
                    let local_linear =
                        ((warp_progress - start_threshold) / move_duration).clamp(0.0, 1.0);

                    // Cubic ease-in for explosive departure
                    let local_eased = local_linear * local_linear * local_linear;

                    if local_eased > 0.0 {
                        let radial = Vec3::new(v.pos.x, v.pos.y, 0.0).normalize();

                        // Swirl/Curl
                        let curl_angle = local_eased * (v.noise_factor - 0.5) * 6.0;
                        let swirl_vec = radial.rotate_z(curl_angle);

                        // Distance scaling - fast exit
                        let dist_mult = 1200.0;

                        target_base = target_base.add(swirl_vec.mul(local_eased * dist_mult));
                        target_base.z += local_eased * (v.noise_factor - 0.5) * 800.0;
                    }
                }

                let pos = helix_pos.lerp(target_base, progress);

                if progress > 0.9 && !v.is_debris && warp_progress == 0.0 {
                    let to_mouse = pos.sub(self.mouse_world_pos);
                    let dist_sq = to_mouse.x * to_mouse.x + to_mouse.y * to_mouse.y;
                    if dist_sq < 6400.0 {
                        let dist = dist_sq.sqrt();
                        let force = (80.0 - dist) / 80.0;
                        v.velocity = v.velocity.add(to_mouse.normalize().mul(force * 2.0));
                        v.rot.x += to_mouse.y * force * 0.01;
                        v.rot.y -= to_mouse.x * force * 0.01;
                    }
                }

                let displacement = pos.sub(target_base);
                let spring_force = displacement.mul(-0.1);
                v.velocity = v.velocity.add(spring_force);
                v.velocity = v.velocity.mul(0.90);

                v.pos = pos.add(v.velocity);
                v.rot = v.rot.lerp(Vec3::ZERO, 0.1);

                if progress > 0.95 {
                    let impact = (physics_t - my_end).max(0.0);
                    let pulse = (impact * 10.0).sin() * (-3.0 * impact).exp() * 0.5;
                    v.scale = 1.0 + pulse;
                } else {
                    v.scale = lerp(0.8, 1.0, progress);
                }
            }
        }

        SplashStatus::Ongoing
    }

    pub fn paint(&self, ctx: &egui::Context, _theme_mode: &crate::config::ThemeMode) -> bool {
        let mut theme_clicked = false;
        let now = ctx.input(|i| i.time);
        let t = (now - self.start_time) as f32;

        let mut warp_prog = 0.0;
        if let Some(exit_start) = self.exit_start_time {
            let dt = (now - exit_start) as f32;
            warp_prog = (dt / EXIT_DURATION).powi(5);
        }

        // FIX: The viewport's inner_rect returns SCREEN coordinates (window position on screen).
        // However, the layer_painter paints in WINDOW-LOCAL coordinates where (0,0) is top-left of window.
        // We must ALWAYS anchor our rect at (0,0) to ensure consistent positioning regardless of window location.
        let viewport_rect = ctx.input(|i| {
            i.viewport()
                .inner_rect
                .unwrap_or(Rect::from_min_size(Pos2::ZERO, Vec2::ZERO))
        });

        // Use viewport size but ALWAYS anchor at (0,0) for window-local painting
        let size = if viewport_rect.width() < 100.0 || viewport_rect.height() < 100.0 {
            // Fallback during startup before window is fully realized
            Vec2::new(WINDOW_WIDTH, WINDOW_HEIGHT)
        } else {
            viewport_rect.size()
        };
        // CRITICAL: Always use Pos2::ZERO as origin - painter works in window-local coords
        let rect = Rect::from_min_size(Pos2::ZERO, size);

        // --- INTERACTION BLOCKER & DRAG HANDLE ---
        egui::Area::new(egui::Id::new("splash_blocker"))
            .order(egui::Order::Foreground)
            .fixed_pos(Pos2::ZERO)
            .show(ctx, |ui| {
                let resp = ui.allocate_response(
                    size,
                    egui::Sense::click_and_drag().union(egui::Sense::hover()),
                );

                if resp.drag_started() {
                    ui.ctx().send_viewport_cmd(egui::ViewportCommand::StartDrag);
                }
            });

        // Use a Foreground layer to paint ON TOP of the main UI
        let painter = ctx.layer_painter(egui::LayerId::new(
            egui::Order::Foreground,
            egui::Id::new("splash_overlay"),
        ));

        // Center is now correctly at (width/2, height/2) in window-local coords
        let center = rect.center();
        let _center_vec = Vec2::new(center.x, center.y);

        let alpha_fade_in = 0.4;
        let alpha = if t < alpha_fade_in {
            t / alpha_fade_in
        } else {
            1.0
        };
        let master_alpha = alpha.clamp(0.0, 1.0);

        // --- THEME SWITCHER OVERLAY (User can switch theme ABOVE splash) ---
        // Fade out over 0.3s when exit starts
        let switcher_alpha = if let Some(exit_start) = self.exit_start_time {
            let exit_dt = (now - exit_start) as f32;
            (1.0 - exit_dt / 0.3).max(0.0)
        } else {
            1.0
        };

        if master_alpha > 0.1 && switcher_alpha > 0.01 {
            egui::Area::new(egui::Id::new("splash_theme_switcher"))
                .order(egui::Order::Tooltip) // High priority above blocker
                .fixed_pos(Pos2::new(14.0, 11.0))
                .show(ctx, |ui| {
                    let icon = if self.is_dark { Icon::Sun } else { Icon::Moon };

                    // Pulse effect for the button
                    let pulse = (now * 2.0).sin().abs() * 0.2 + 0.8;
                    let btn_bg = if self.is_dark {
                        Color32::from_white_alpha((30.0 * switcher_alpha) as u8)
                    } else {
                        Color32::from_black_alpha((20.0 * switcher_alpha) as u8)
                    };

                    let icon_color = if self.is_dark {
                        Color32::WHITE.linear_multiply(switcher_alpha)
                    } else {
                        Color32::BLACK.linear_multiply(switcher_alpha)
                    };

                    let (rect, resp) =
                        ui.allocate_at_least(Vec2::splat(32.0), egui::Sense::click());

                    // Glass background
                    let fill = if resp.hovered() {
                        btn_bg.linear_multiply(1.5)
                    } else {
                        btn_bg.linear_multiply(pulse as f32)
                    };
                    ui.painter().rect_filled(rect, 8.0, fill);

                    // Seamless cutout for the Moon icon in Day mode
                    // We must override the GLOBAL context style because the icon painter uses painter.ctx().style()
                    let old_panel_fill = ctx.style().visuals.panel_fill;
                    if !self.is_dark {
                        // Also fade the moon cutout color
                        let cutout_color =
                            Color32::from_rgb(109, 174, 235).linear_multiply(switcher_alpha);
                        ctx.style_mut(|s| s.visuals.panel_fill = cutout_color);
                    }

                    // High-quality manual vector icon
                    paint_icon(ui.painter(), rect.shrink(6.0), icon, icon_color);

                    // Restore global style
                    ctx.style_mut(|s| s.visuals.panel_fill = old_panel_fill);

                    // Only allow clicks when fully visible
                    if resp.clicked() && switcher_alpha > 0.9 {
                        theme_clicked = true;
                    }
                });
        }

        // 1. Background
        // Startup: Fade from Solid Black (Night) or White (Day) to Target Color
        // This ensures the Main UI underneath is hidden start-up.
        let mut bg_color = if self.is_dark { C_VOID } else { C_SKY_DAY_TOP };
        if t < 0.5 {
            let t_fade = (t / 0.5).clamp(0.0, 1.0);
            let start_col = if self.is_dark {
                Color32::BLACK
            } else {
                Color32::WHITE
            };
            // Lerp r,g,b
            bg_color = Color32::from_rgb(
                lerp(start_col.r() as f32, bg_color.r() as f32, t_fade) as u8,
                lerp(start_col.g() as f32, bg_color.g() as f32, t_fade) as u8,
                lerp(start_col.b() as f32, bg_color.b() as f32, t_fade) as u8,
            );
        }

        // Exit: Fast fade out of background SKY only (reveals App UI)
        let sky_exit_fade = (1.0 - warp_prog * 4.0).clamp(0.0, 1.0);

        if self.is_dark {
            painter.rect_filled(rect, 12.0, bg_color.linear_multiply(sky_exit_fade));
        } else {
            // Gradient Sky with Rounded Corners
            let c_top = C_SKY_DAY_TOP.linear_multiply(sky_exit_fade);
            // We use a solid rounded rect for Day Mode to ensure the corners are perfectly
            // rounded as requested.
            painter.rect_filled(rect, 12.0, c_top);
        }

        if master_alpha <= 0.05 {
            return theme_clicked;
        }

        // --- LAYER 0: STARS ---
        // Parallax stars
        let star_offset = self.mouse_influence * -10.0;
        let star_time = t * 2.0;

        for (i, star) in self.stars.iter().enumerate() {
            let sx = rect.left() + (star.pos.x * rect.width()) + star_offset.x;
            let sy = rect.top() + (star.pos.y * rect.height()) + star_offset.y;

            // Random Fade Calculation (Decoupled from Sky)
            let rnd = ((i as f32 * 1.618).fract() + (star.pos.x * 10.0).fract()).fract();
            let start = rnd * 0.7; // Spread starts over 0.0 - 0.7
            let dur = 0.2;
            let local_fade = if warp_prog > 0.0 {
                let p = ((warp_prog - start) / dur).clamp(0.0, 1.0);
                1.0 - p
            } else {
                1.0
            };

            // Twinkle
            let twinkle = (star.phase + star_time).sin() * 0.3 + 0.7;
            let star_alpha =
                (star.brightness * twinkle * master_alpha * local_fade).clamp(0.0, 1.0);

            if star_alpha > 0.1 {
                let size = star.size * (1.0 - warp_prog);
                if self.is_dark {
                    painter.circle_filled(
                        Pos2::new(sx, sy),
                        size,
                        C_WHITE.linear_multiply(star_alpha),
                    );
                } else {
                    let day_star_alpha = star_alpha * 0.3;
                    painter.circle_filled(
                        Pos2::new(sx, sy),
                        size,
                        C_WHITE.linear_multiply(day_star_alpha),
                    );
                }
            }
        }

        // --- LAYER 1.5: GOD RAYS (DAY MODE) ---
        if !self.is_dark && master_alpha > 0.1 && warp_prog < 0.9 {
            let sun_pos = center + Vec2::new(0.0, -40.0 * (1.0 - warp_prog));
            let ray_count = 12;
            let ray_rot = t * 0.1;

            let mut mesh = egui::Mesh::default();
            let c1 = Color32::from_white_alpha(55);

            for i in 0..ray_count {
                let angle = (i as f32 / ray_count as f32) * PI * 2.0 + ray_rot;
                let next_angle = ((i as f32 + 0.5) / ray_count as f32) * PI * 2.0 + ray_rot;

                let v_idx = mesh.vertices.len() as u32;
                mesh.vertices.push(egui::epaint::Vertex {
                    pos: sun_pos,
                    uv: Pos2::ZERO,
                    color: Color32::TRANSPARENT,
                });

                let ray_len = 1200.0;
                let p1 = sun_pos + Vec2::new(angle.cos() * ray_len, angle.sin() * ray_len);
                let p2 =
                    sun_pos + Vec2::new(next_angle.cos() * ray_len, next_angle.sin() * ray_len);

                mesh.vertices.push(egui::epaint::Vertex {
                    pos: p1,
                    uv: Pos2::ZERO,
                    color: c1,
                });
                mesh.vertices.push(egui::epaint::Vertex {
                    pos: p2,
                    uv: Pos2::ZERO,
                    color: c1,
                });

                mesh.add_triangle(v_idx, v_idx + 1, v_idx + 2);
            }
            painter.add(mesh);
        }

        // --- LAYER 2: THE REALISTIC PINK MOON ---
        let moon_parallax = self.mouse_influence * -30.0;
        let moon_base_pos = center + Vec2::new(0.0, -40.0) + moon_parallax;
        let moon_rad = 140.0;
        let moon_alpha = master_alpha * (1.0 - warp_prog * 3.0).clamp(0.0, 1.0); // Simple fast fade for main body

        if moon_alpha > 0.01 {
            if self.is_dark {
                let moon_bob = (t * 0.5).sin() * 5.0;
                let final_moon_pos = moon_base_pos + Vec2::new(0.0, moon_bob);

                // 2a. Atmospheric Glow (Softer, layered)
                painter.circle_filled(
                    final_moon_pos,
                    moon_rad * 1.6,
                    C_MOON_GLOW.linear_multiply(0.03 * moon_alpha),
                );
                painter.circle_filled(
                    final_moon_pos,
                    moon_rad * 1.2,
                    C_MOON_GLOW.linear_multiply(0.08 * moon_alpha),
                );

                // 2b. Spherical Shading (Gradient Approximation)
                // Main body
                painter.circle_filled(
                    final_moon_pos,
                    moon_rad,
                    C_MOON_BASE.linear_multiply(moon_alpha),
                );
                // Shadow side (Bottom Right)
                painter.circle_filled(
                    final_moon_pos + Vec2::new(10.0, 10.0),
                    moon_rad * 0.9,
                    Color32::from_black_alpha((50.0 * moon_alpha) as u8),
                );
                // Highlight side (Top Left)
                painter.circle_filled(
                    final_moon_pos - Vec2::new(10.0, 10.0),
                    moon_rad * 0.85,
                    Color32::from_white_alpha((20.0 * moon_alpha) as u8),
                );

                // 2c. Surface Features
                let feature_rot = t * 0.05;

                for feat in &self.moon_features {
                    let fx = feat.pos.x;
                    let fy = feat.pos.y;

                    // Rotation
                    let rot_cos = feature_rot.cos();
                    let rot_sin = feature_rot.sin();
                    let r_x = fx * rot_cos - fy * rot_sin;
                    let r_y = fx * rot_sin + fy * rot_cos;

                    // Sphere Projection (Fake Z)
                    let dist_sq = r_x * r_x + r_y * r_y;
                    if dist_sq > 0.95 {
                        continue;
                    } // Clip edge features

                    let f_pos = final_moon_pos + Vec2::new(r_x * moon_rad, r_y * moon_rad);

                    // Perspective distortion
                    let z_depth = (1.0 - dist_sq).sqrt(); // 1.0 at center, 0.0 at edge
                    let f_radius = feat.radius * moon_rad * (0.5 + 0.5 * z_depth);
                    let f_alpha = moon_alpha * z_depth; // Fade near edges

                    if feat.is_crater {
                        // Crater: Recessed shadowing
                        // Shadow (Top Left inner)
                        painter.circle_filled(
                            f_pos + Vec2::new(-1.0, -1.0),
                            f_radius,
                            C_MOON_SHADOW.linear_multiply(f_alpha * 0.8),
                        );
                        // Highlight (Bottom Right inner)
                        painter.circle_filled(
                            f_pos + Vec2::new(1.0, 1.0),
                            f_radius * 0.9,
                            C_MOON_HIGHLIGHT.linear_multiply(f_alpha * 0.4),
                        );
                    } else {
                        // Maria: Flat dark patches
                        painter.circle_filled(
                            f_pos,
                            f_radius,
                            C_MOON_SHADOW.linear_multiply(f_alpha * 0.3),
                        );
                    }
                }

                // 2d. Rim Light (Top Left)
                // Simulate light hitting the edge of the sphere
                painter.circle_stroke(
                    final_moon_pos - Vec2::new(2.0, 2.0),
                    moon_rad - 1.0,
                    Stroke::new(2.0, C_MOON_HIGHLIGHT.linear_multiply(0.4 * moon_alpha)),
                );
            } else {
                // --- SUN VARIANT ---
                let sun_bob = (t * 0.5).sin() * 5.0;
                let final_sun_pos = moon_base_pos + Vec2::new(0.0, sun_bob);

                // Glow
                painter.circle_filled(
                    final_sun_pos,
                    moon_rad * 2.0,
                    C_SUN_GLOW.linear_multiply(0.1 * moon_alpha),
                );
                painter.circle_filled(
                    final_sun_pos,
                    moon_rad * 1.4,
                    C_SUN_GLOW.linear_multiply(0.2 * moon_alpha),
                );

                // Sun Body
                painter.circle_filled(
                    final_sun_pos,
                    moon_rad,
                    C_SUN_BODY.linear_multiply(moon_alpha),
                );

                // Sun Spots (Reusing moon features)
                let feature_rot = t * 0.08;
                for feat in &self.moon_features {
                    let fx = feat.pos.x;
                    let fy = feat.pos.y;

                    let rot_cos = feature_rot.cos();
                    let rot_sin = feature_rot.sin();
                    let r_x = fx * rot_cos - fy * rot_sin;
                    let r_y = fx * rot_sin + fy * rot_cos;

                    let dist_sq = r_x * r_x + r_y * r_y;
                    if dist_sq > 0.95 {
                        continue;
                    }

                    let f_pos = final_sun_pos + Vec2::new(r_x * moon_rad, r_y * moon_rad);
                    let z_depth = (1.0 - dist_sq).sqrt();
                    let f_radius = feat.radius * moon_rad * (0.5 + 0.5 * z_depth);
                    let f_alpha = moon_alpha * z_depth;

                    if feat.is_crater {
                        // Sunspots (Darker, sharper, smaller)
                        painter.circle_filled(
                            f_pos,
                            f_radius * 0.6, // Smaller than craters
                            Color32::from_rgb(160, 60, 0).linear_multiply(f_alpha * 0.8),
                        );
                    } else {
                        // Hot Flares/Patches (Bright, glowy) - remove dark rims to avoid crater look
                        painter.circle_filled(
                            f_pos,
                            f_radius * 1.5, // Larger soft glow
                            C_SUN_FLARE.linear_multiply(f_alpha * 0.3),
                        );
                        painter.circle_filled(
                            f_pos,
                            f_radius * 0.8,
                            C_WHITE.linear_multiply(f_alpha * 0.5), // Hot center
                        );
                    }
                }

                // Rim Light
                painter.circle_stroke(
                    final_sun_pos,
                    moon_rad - 1.0,
                    Stroke::new(3.0, C_SUN_HIGHLIGHT.linear_multiply(0.5 * moon_alpha)),
                );
            }
        }

        // --- LAYER 3: VOLUMETRIC DARK CLOUDS (BLACK SILHOUETTE) ---
        let cloud_parallax = self.mouse_influence * -15.0;

        // Clip clouds in Day Mode so they don't enter the "Sea" (Stairs)
        // The Sea is composed of lines that start roughly 18px below the horizon (perspective).
        // We extend the clip rect down by 30px to ensure the clouds are drawn behind the top-most dense stairs,
        // eliminating any gap between the sky and the sea.
        let horizon = center.y + 120.0;
        let cloud_painter = if !self.is_dark {
            painter.with_clip_rect(Rect::from_min_max(
                rect.min,
                Pos2::new(rect.max.x, horizon + 30.0),
            ))
        } else {
            painter.clone()
        };

        for (i, cloud) in self.clouds.iter().enumerate() {
            let c_x = center.x + cloud.pos.x + cloud_parallax.x;
            let c_y = center.y + cloud.pos.y + cloud_parallax.y;

            // Random Fade (Decoupled)
            let rnd = (i as f32 * 0.73).fract();
            let start = rnd * 0.6; // Spread over 0.0 - 0.6
            let dur = 0.3;
            let local_fade = if warp_prog > 0.0 {
                let p = ((warp_prog - start) / dur).clamp(0.0, 1.0);
                1.0 - p
            } else {
                1.0
            };

            let cloud_alpha = cloud.opacity * master_alpha * local_fade;

            if cloud_alpha > 0.01 {
                // Pass 1: Dark Core (Deep black shadow)
                for (offset, puff_r_mult) in &cloud.puffs {
                    let p_pos = Pos2::new(c_x, c_y) + (*offset * cloud.scale);
                    let radius = 30.0 * cloud.scale * puff_r_mult;

                    let core_col = if self.is_dark {
                        C_CLOUD_CORE.linear_multiply(cloud_alpha * 0.95)
                    } else {
                        C_CLOUD_WHITE.linear_multiply(cloud_alpha * 0.95)
                    };

                    cloud_painter.circle_filled(
                        p_pos + Vec2::new(2.0, 5.0), // Shadow offset down-right
                        radius,
                        core_col,
                    );
                }

                // Note: Second pass (Main Body with highlight) was intentionally removed
            }
        }

        // --- LAYER 4: RETRO GRID ---
        let render_t = t.min(ANIMATION_DURATION + 5.0);
        let cam_y = 150.0 + (render_t * 30.0) + (warp_prog * 10000.0);
        // horizon is already defined above
        let grid_fade = if warp_prog > 0.0 { 1.0 } else { 1.0 }; // Handled by local_fade now

        if grid_fade > 0.0 {
            // Horizontal lines
            for i in 0..16 {
                // Random Grid Line Fade
                let rnd = (i as f32 * 0.9).sin() * 0.5 + 0.5;
                let start = rnd * 0.5;
                let dur = 0.25;
                let local_fade = if warp_prog > 0.0 {
                    let p = ((warp_prog - start) / dur).clamp(0.0, 1.0);
                    1.0 - p
                } else {
                    1.0
                };

                if local_fade <= 0.0 {
                    continue;
                }

                let z_dist = 1.0 + (i as f32 * 0.5) - ((cam_y * 0.05) % 0.5);
                let perspective = 250.0 / (z_dist - warp_prog * 0.8).max(0.1);
                let y = horizon + perspective * 0.6;

                if y > rect.bottom() || y < horizon {
                    continue;
                }

                let w = rect.width() * (2.5 / z_dist);
                let x1 = center.x - w;
                let x2 = center.x + w;

                // Distance fade + Random Line Fade
                let alpha_grid = (1.0 - (y - horizon) / (rect.bottom() - horizon)).powf(0.5)
                    * master_alpha
                    * 0.5
                    * local_fade;

                let (grid_col, thickness) = if self.is_dark {
                    (C_MAGENTA, 1.5)
                } else {
                    // Day Mode: Thicker Blue "Stairs"
                    (C_DAY_REP, 4.0 * (1.0 - (y - horizon) / rect.height()))
                };

                painter.line_segment(
                    [Pos2::new(x1, y), Pos2::new(x2, y)],
                    Stroke::new(thickness, grid_col.linear_multiply(alpha_grid)),
                );
            }
        }

        // --- LAYER 5: 3D VOXELS (SPHERES) ---
        let physics_t = t.min(ANIMATION_DURATION);
        let fov = 800.0;
        let cam_fly_dist = warp_prog * 2000.0;
        let cam_dist = (600.0 + smoothstep(0.0, 8.0, physics_t) * 100.0) - cam_fly_dist;

        let global_rot = Vec3::new(
            self.mouse_influence.y * 0.2,
            self.mouse_influence.x * 0.2,
            0.0,
        );

        // Light direction highlight offset (Top-Left)
        let light_dir_2d = Vec2::new(-0.4, -0.4);

        // Use pre-allocated buffer (Interior Mutability)
        let mut draw_list_ref = self.draw_list.borrow_mut();
        draw_list_ref.clear();
        let draw_list = &mut *draw_list_ref;

        let sphere_radius_base = 8.5; // Overlap for pipe look

        for v in &self.voxels {
            let mut local_debris_alpha = 1.0;
            if v.is_debris {
                let fade_start = 4.0 + (v.noise_factor * 3.0);
                let fade_end = fade_start + 2.5;
                local_debris_alpha = 1.0 - smoothstep(fade_start, fade_end, physics_t);
                if local_debris_alpha <= 0.01 {
                    continue;
                }
            }

            let mut v_center = v.pos;
            v_center = v_center
                .rotate_x(global_rot.x)
                .rotate_y(global_rot.y)
                .rotate_z(global_rot.z);

            let z_depth = cam_dist - v_center.z;
            if z_depth < 0.1 {
                continue;
            }

            let scale = fov / z_depth;
            let screen_pos =
                Pos2::new(center.x + v_center.x * scale, center.y - v_center.y * scale);

            // Radius calculation
            let r = sphere_radius_base * v.scale * scale;

            // Color Logic
            let mut alpha_local = master_alpha;
            if v.is_debris {
                alpha_local *= local_debris_alpha;

                // PREMIUM: Diverse opacity based on distance/noise
                let base_opacity = 0.4 + (v.noise_factor * 0.6);
                alpha_local *= base_opacity;

                // PREMIUM: Add subtle cosmic twinkle/glimmer
                let twinkle =
                    (t * (3.0 + v.noise_factor * 2.0) + v.noise_factor * 50.0).sin() * 0.25 + 0.75;
                alpha_local *= twinkle;
            }

            let mut base_col = v.color;

            // DYNAMIC COLOR SWAP: Fix sphere colors when theme changes on splash
            if !v.is_debris && v.color != C_WHITE {
                if self.is_dark {
                    // Switch to Night Colors
                    if v.color == C_DAY_REP {
                        base_col = C_MAGENTA;
                    } else if v.color == C_DAY_SEC {
                        base_col = C_CYAN;
                    }
                } else {
                    // Switch to Day Colors
                    if v.color == C_MAGENTA {
                        base_col = C_DAY_REP;
                    } else if v.color == C_CYAN {
                        base_col = C_DAY_SEC;
                    }
                }
            }

            // Day mode debris fix
            if !self.is_dark && v.is_debris {
                base_col = C_CLOUD_WHITE;
            }

            if warp_prog > 0.0 {
                // Exact match of physics timing
                let start_threshold = v.noise_factor * 0.75;
                let move_duration = 0.25;
                let local_linear = ((warp_prog - start_threshold) / move_duration).clamp(0.0, 1.0);

                // Fade out halfway through its flight
                let fade = (local_linear * 1.5).clamp(0.0, 1.0);
                alpha_local *= 1.0 - fade;
            }

            let final_col = base_col.linear_multiply(alpha_local);

            draw_list.push((
                z_depth,
                screen_pos,
                r,
                final_col,
                v.color == C_WHITE || v.color == C_DAY_SEC,
                v.is_debris,
            ));
        }

        // Sort back-to-front (Z-Painter's Algorithm)
        draw_list.sort_by(|a, b| b.0.partial_cmp(&a.0).unwrap_or(Ordering::Equal));

        for (_, pos, r, col, is_white_voxel, is_debris) in draw_list.iter().copied() {
            // 1. Shadow/Base (The "Rim" on the shadow side)
            // Use the clipped cloud painter for debris in Day mode so they don't enter the sea
            let p = if !self.is_dark && is_debris {
                &cloud_painter
            } else {
                &painter
            };

            // 1. Shadow/Base (The "Rim" on the shadow side)
            if !(!self.is_dark && is_debris) {
                let shadow_col = if self.is_dark {
                    Color32::from_black_alpha(200).linear_multiply(col.a() as f32 / 255.0)
                } else {
                    // In Day mode, white voxels get a blueish/grey shadow to define shape
                    if is_white_voxel {
                        Color32::from_rgb(100, 120, 150).linear_multiply(col.a() as f32 / 255.0)
                    } else {
                        // Blue voxels get dark blue shadow
                        Color32::from_rgb(0, 40, 100).linear_multiply(col.a() as f32 / 255.0)
                    }
                };
                p.circle_filled(pos, r, shadow_col);

                // 2. Main Body (Shifted towards light to create crescent shadow)
                let body_offset = light_dir_2d * (r * 0.15);
                p.circle_filled(pos + body_offset, r * 0.85, col);

                // 3. Inner Gradient / Glow (Soft light in center)
                let glow_col = if is_white_voxel {
                    Color32::WHITE.linear_multiply(0.5)
                } else {
                    col.linear_multiply(0.5)
                };
                let gradient_offset = light_dir_2d * (r * 0.3);
                p.circle_filled(pos + gradient_offset, r * 0.5, glow_col);
            } else {
                // Day Mode Debris: Pure white soft-edged "puffs" (no shading, no border)
                p.circle_filled(pos, r, col);
            }

            // 4. Specular Highlight (Sharp Reflection) - ONLY FOR MAIN LOGO VOXELS
            if !is_debris {
                let highlight_pos = pos + (light_dir_2d * (r * 0.5));
                let highlight_alpha = if self.is_dark { 0.8 } else { 0.9 };
                let highlight_col = Color32::from_white_alpha((255.0 * highlight_alpha) as u8)
                    .linear_multiply(col.a() as f32 / 255.0);

                painter.circle_filled(highlight_pos, r * 0.25, highlight_col);
                painter.circle_filled(
                    highlight_pos,
                    r * 0.15,
                    Color32::WHITE.linear_multiply(col.a() as f32 / 255.0),
                ); // Hotspot
            }
        }

        // --- LAYER 6: UI TEXT ---
        if master_alpha > 0.1 && warp_prog < 0.1 {
            let ui_alpha = 1.0 - (warp_prog * 10.0).clamp(0.0, 1.0);

            // UI Colors based on theme
            let ui_text_col = if self.is_dark { C_WHITE } else { C_DAY_TEXT };
            let ui_color = ui_text_col.linear_multiply(master_alpha * ui_alpha);

            // Loading text color (Orange in Day)
            let loading_col = if self.is_dark {
                C_CYAN.linear_multiply(master_alpha * ui_alpha)
            } else {
                C_DAY_TEXT.linear_multiply(master_alpha * ui_alpha)
            };

            // Click Text Color (Cyan in Night, White in Day)
            let click_col = if self.is_dark {
                C_CYAN.linear_multiply(master_alpha * ui_alpha)
            } else {
                C_WHITE.linear_multiply(master_alpha * ui_alpha)
            };

            let magenta_color = if self.is_dark {
                C_MAGENTA.linear_multiply(master_alpha * ui_alpha)
            } else {
                C_DAY_REP.linear_multiply(master_alpha * ui_alpha)
            };

            let title_text = format!("SCREEN GOATED TOOLBOX {}", env!("CARGO_PKG_VERSION"));
            let title_font = FontId::proportional(30.0); // Increased size
            let title_pos = center + Vec2::new(0.0, 150.0);

            // Stylized Shadow Colors
            let shadow_col = if self.is_dark {
                C_MAGENTA.linear_multiply(master_alpha * ui_alpha) // Retro Pink Shadow
            } else {
                C_WHITE.linear_multiply(master_alpha * ui_alpha) // Crisp White Shadow
            };

            // Stylized Bold/Shadow: Draw distinct color offset
            painter.text(
                title_pos + Vec2::new(2.0, 2.0), // Increased offset for better visibility
                Align2::CENTER_TOP,
                &title_text,
                title_font.clone(),
                shadow_col,
            );
            painter.text(
                title_pos,
                Align2::CENTER_TOP,
                &title_text,
                title_font,
                ui_color,
            );
            painter.text(
                center + Vec2::new(0.0, 210.0),
                Align2::CENTER_TOP,
                &self.loading_text,
                FontId::monospace(12.0),
                loading_col,
            );

            let bar_rect =
                Rect::from_center_size(center + Vec2::new(0.0, 230.0), Vec2::new(200.0, 4.0));
            // Bar Background
            let bar_bg_col = if self.is_dark {
                Color32::from_white_alpha((30.0 * ui_alpha) as u8)
            } else {
                Color32::from_black_alpha((30.0 * ui_alpha) as u8)
            };
            painter.rect_filled(bar_rect, 2.0, bar_bg_col);
            let prog = (physics_t / (ANIMATION_DURATION - 0.5)).clamp(0.0, 1.0);
            let mut fill = bar_rect;
            fill.set_width(bar_rect.width() * prog);
            painter.rect_filled(fill, 2.0, magenta_color);

            if t > ANIMATION_DURATION - 0.5 {
                let pulse = (t * 5.0).sin().abs() * 0.7 + 0.3;
                painter.text(
                    center - Vec2::new(0.0, 220.0),
                    Align2::CENTER_TOP,
                    "Click anywhere to continue",
                    FontId::proportional(14.0),
                    click_col.linear_multiply(pulse),
                );
            }
        }

        theme_clicked
    }
}
</file>

<file path="src/overlay/auto_copy_badge.rs">
use crate::APP;
use std::cell::RefCell;
use std::collections::VecDeque;
use std::sync::atomic::{AtomicBool, AtomicIsize, Ordering};
use std::sync::{Mutex, Once};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::DwmExtendFrameIntoClientArea;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::Com::{CoInitialize, CoUninitialize};
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebView, WebViewBuilder};

static REGISTER_BADGE_CLASS: Once = Once::new();

// Thread-safe handle using atomic (like preset_wheel)
static BADGE_HWND: AtomicIsize = AtomicIsize::new(0);
static IS_WARMING_UP: AtomicBool = AtomicBool::new(false);
static IS_WARMED_UP: AtomicBool = AtomicBool::new(false);

// Messages
const WM_APP_PROCESS_QUEUE: u32 = WM_USER + 201;

/// Notification themes
#[derive(Clone, Copy, PartialEq, Eq, Debug)]
pub enum NotificationType {
    Success, // Green - auto copied
    Info,    // Yellow - loading/warming up
    Update,  // Blue - update available (longer duration)
    Error,   // Red - error (e.g., no writable area for auto-paste)
}

#[derive(Clone, Debug)]
pub struct PendingNotification {
    pub title: String,
    pub snippet: String,
    pub n_type: NotificationType,
}

lazy_static::lazy_static! {
    static ref PENDING_QUEUE: Mutex<VecDeque<PendingNotification>> = Mutex::new(VecDeque::new());
}

thread_local! {
    static BADGE_WEBVIEW: RefCell<Option<WebView>> = RefCell::new(None);
    static BADGE_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);
}

// Dimensions
const BADGE_WIDTH: i32 = 1200; // Super wide
const BADGE_HEIGHT: i32 = 400; // Taller for stacking

/// Wrapper for HWND to implement HasWindowHandle
struct HwndWrapper(HWND);
unsafe impl Send for HwndWrapper {}
unsafe impl Sync for HwndWrapper {}

impl raw_window_handle::HasWindowHandle for HwndWrapper {
    fn window_handle(
        &self,
    ) -> std::result::Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError>
    {
        let raw = raw_window_handle::Win32WindowHandle::new(
            std::num::NonZeroIsize::new(self.0 .0 as isize).expect("HWND cannot be null"),
        );
        let handle = raw_window_handle::RawWindowHandle::Win32(raw);
        unsafe { Ok(raw_window_handle::WindowHandle::borrow_raw(handle)) }
    }
}

fn enqueue_notification(title: String, snippet: String, n_type: NotificationType) {
    crate::log_info!("[Badge] Enqueuing: '{}' ({:?})", title, n_type);
    {
        let mut q = PENDING_QUEUE.lock().unwrap();
        q.push_back(PendingNotification {
            title,
            snippet,
            n_type,
        });
    }
    ensure_window_and_post(WM_APP_PROCESS_QUEUE);
}

pub fn show_auto_copy_badge_text(text: &str) {
    let app = APP.lock().unwrap();
    let ui_lang = app.config.ui_language.clone();
    let locale = crate::gui::locale::LocaleText::get(&ui_lang);
    let title = locale.auto_copied_badge.to_string();
    drop(app);

    let clean_text = text.replace('\n', " ").replace('\r', "");
    let snippet = format!("\"{}\"", clean_text);

    enqueue_notification(title, snippet, NotificationType::Success);
}

pub fn show_auto_copy_badge_image() {
    let app = APP.lock().unwrap();
    let ui_lang = app.config.ui_language.clone();
    let locale = crate::gui::locale::LocaleText::get(&ui_lang);
    let title = locale.auto_copied_badge.to_string();
    let snippet = locale.auto_copied_image_badge.to_string();
    drop(app);

    enqueue_notification(title, snippet, NotificationType::Success);
}

/// Show a loading/info notification with just a title (yellow theme)
pub fn show_notification(title: &str) {
    enqueue_notification(title.to_string(), String::new(), NotificationType::Info);
}

/// Show an update available notification (blue theme, longer duration)
pub fn show_update_notification(title: &str) {
    enqueue_notification(title.to_string(), String::new(), NotificationType::Update);
}

/// Show an error notification (red theme)
pub fn show_error_notification(title: &str) {
    enqueue_notification(title.to_string(), String::new(), NotificationType::Error);
}

/// Show a detailed notification with title and snippet (custom type)
pub fn show_detailed_notification(title: &str, snippet: &str, n_type: NotificationType) {
    enqueue_notification(title.to_string(), snippet.to_string(), n_type);
}

fn ensure_window_and_post(msg: u32) {
    // Check if already warmed up
    if !IS_WARMED_UP.load(Ordering::SeqCst) {
        // Trigger warmup if not started yet
        warmup();
        // We don't block anymore. The notification is in PENDING_QUEUE.
        // internal_create_window_loop will post WM_APP_PROCESS_QUEUE to itself once ready.
        return;
    }

    let hwnd_val = BADGE_HWND.load(Ordering::SeqCst);
    let hwnd = HWND(hwnd_val as *mut _);
    if hwnd_val != 0 && !hwnd.is_invalid() {
        unsafe {
            let res = PostMessageW(Some(hwnd), msg, WPARAM(0), LPARAM(0));
            println!("[Badge] PostMessage Result: {:?}", res);
        }
    } else {
        println!("[Badge] Invalid HWND: {:?}", hwnd);
    }
}

pub fn warmup() {
    // Prevent multiple warmup threads from spawning (like preset_wheel)
    if IS_WARMING_UP
        .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
        .is_err()
    {
        return;
    }
    std::thread::spawn(|| {
        internal_create_window_loop();
    });
}

fn get_badge_html() -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
    {font_css}
    :root {{
        /* Defaults just in case */
        --this-bg: #1A3D2A;
        --this-border: #4ADE80;
        --this-text-prio: #ffffff;
        --this-text-sec: rgba(255, 255, 255, 0.9);
        --this-accent: #4ADE80;
        --this-bloom: rgba(74, 222, 128, 0.6);
        --this-shadow: rgba(0, 0, 0, 0.5);
    }}
    
    * {{ margin: 0; padding: 0; box-sizing: border-box; }}
    
    body {{
        overflow: hidden;
        background: transparent;
        font-family: 'Google Sans Flex', 'Segoe UI', sans-serif;
        display: flex;
        flex-direction: column;
        justify-content: flex-end; /* Align bottom */
        align-items: center;
        height: 100vh;
        user-select: none;
        cursor: default;
        padding-bottom: 20px;
    }}
    
    #notifications {{
        display: flex;
        flex-direction: column;
        width: 100%;
        align-items: center;
        gap: 10px;
    }}

    .badge {{
        min-width: 180px;
        max-width: 90%;
        width: auto;
        
        background: var(--this-bg);
        border: 2.5px solid var(--this-border);
        border-radius: 12px;
        
        box-shadow: 0 0 12px var(--this-bloom), 
                    0 4px 15px var(--this-shadow);
                    
        backdrop-filter: blur(12px);
        -webkit-backdrop-filter: blur(12px);
        
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        
        padding: 4px 18px;
        position: relative;
        
        opacity: 0;
        transform: translateY(20px) scale(0.92);
        transition: all 0.4s cubic-bezier(0.2, 0.8, 0.2, 1);
    }}
    
    .badge.visible {{
        opacity: 1;
        transform: translateY(0) scale(1);
    }}
    
    .row {{
        display: flex;
        align-items: center;
        justify-content: center;
        width: 100%;
        line-height: normal;
        position: relative;
    }}
    
    .title-row {{ margin-bottom: 0px; }}
    
    .title {{
        font-size: 15px;
        font-weight: 700;
        color: var(--this-text-prio);
        display: flex;
        align-items: center;
        gap: 8px;
        letter-spacing: 1.2px; 
        text-transform: uppercase;
        font-variation-settings: 'wght' 700, 'wdth' 115, 'ROND' 100;
    }}
    
    .check {{
        color: var(--this-accent);
        font-weight: 800;
        font-size: 18px;
        display: flex;
        align-items: center;
        justify-content: center;
        animation: pop 0.4s cubic-bezier(0.175, 0.885, 0.32, 1.275) forwards;
        animation-delay: 0.1s;
        opacity: 0;
        transform: scale(0);
        filter: drop-shadow(0 0 5px var(--this-accent));
    }}
    
    @keyframes pop {{
        from {{ opacity: 0; transform: scale(0); }}
        to {{ opacity: 1; transform: scale(1); }}
    }}
    
    .snippet {{
        font-size: 13px;
        font-weight: 500;
        color: var(--this-text-sec);
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
        max-width: 100%;
        text-align: center;
        padding-top: 1px;
        font-family: 'Google Sans Flex', 'Segoe UI', sans-serif;
        font-variation-settings: 'wght' 500, 'wdth' 85, 'ROND' 50;
        letter-spacing: -0.3px;
    }}
    
    .snippet-container {{
        width: 100%;
        display: flex;
        justify-content: center;
        overflow: hidden;
    }}
</style>
</head>
<body>
    <div id="notifications"></div>
    <script>
        // JS Error Handler for Debugging
        window.onerror = function(msg, source, line, col, error) {{
            window.ipc.postMessage('error: ' + msg + ' @ ' + line);
        }};

        // Theme definitions (Copied from original)
        const themes = {{
            success: {{
                dark: {{
                    bg: 'rgba(10, 24, 18, 0.95)',
                    border: '#4ADE80',
                    textPrio: '#ffffff',
                    textSec: 'rgba(255, 255, 255, 0.9)',
                    accent: '#4ADE80',
                    bloom: 'rgba(74, 222, 128, 0.5)',
                    shadow: 'rgba(0, 0, 0, 0.6)'
                }},
                light: {{
                    bg: 'rgba(255, 255, 255, 0.95)',
                    border: '#16a34a',
                    textPrio: '#1a1a1a',
                    textSec: '#333333',
                    accent: '#16a34a',
                    bloom: 'rgba(22, 163, 74, 0.3)',
                    shadow: 'rgba(0, 0, 0, 0.2)'
                }},
                duration: 1000
            }},
            info: {{
                dark: {{
                    bg: 'rgba(30, 25, 10, 0.95)',
                    border: '#FACC15',
                    textPrio: '#ffffff',
                    textSec: 'rgba(255, 255, 255, 0.9)',
                    accent: '#FACC15',
                    bloom: 'rgba(250, 204, 21, 0.5)',
                    shadow: 'rgba(0, 0, 0, 0.6)'
                }},
                light: {{
                    bg: 'rgba(255, 251, 235, 0.95)',
                    border: '#CA8A04',
                    textPrio: '#1a1a1a',
                    textSec: '#333333',
                    accent: '#CA8A04',
                    bloom: 'rgba(202, 138, 4, 0.3)',
                    shadow: 'rgba(0, 0, 0, 0.2)'
                }},
                duration: 1500
            }},
            update: {{
                dark: {{
                    bg: 'rgba(10, 18, 30, 0.95)',
                    border: '#60A5FA',
                    textPrio: '#ffffff',
                    textSec: 'rgba(255, 255, 255, 0.9)',
                    accent: '#60A5FA',
                    bloom: 'rgba(96, 165, 250, 0.5)',
                    shadow: 'rgba(0, 0, 0, 0.6)'
                }},
                light: {{
                    bg: 'rgba(239, 246, 255, 0.95)',
                    border: '#2563EB',
                    textPrio: '#1a1a1a',
                    textSec: '#333333',
                    accent: '#2563EB',
                    bloom: 'rgba(37, 99, 235, 0.3)',
                    shadow: 'rgba(0, 0, 0, 0.2)'
                }},
                duration: 5000
            }},
            error: {{
                dark: {{
                    bg: 'rgba(30, 10, 10, 0.95)',
                    border: '#F87171',
                    textPrio: '#ffffff',
                    textSec: 'rgba(255, 255, 255, 0.9)',
                    accent: '#F87171',
                    bloom: 'rgba(248, 113, 113, 0.5)',
                    shadow: 'rgba(0, 0, 0, 0.6)'
                }},
                light: {{
                    bg: 'rgba(254, 242, 242, 0.95)',
                    border: '#DC2626',
                    textPrio: '#1a1a1a',
                    textSec: '#333333',
                    accent: '#DC2626',
                    bloom: 'rgba(220, 38, 38, 0.3)',
                    shadow: 'rgba(0, 0, 0, 0.2)'
                }},
                duration: 2500
            }}
        }};
        
        let isDarkMode = false;
        
        window.setTheme = (isDark) => {{
            isDarkMode = isDark;
        }};
        
        function getColors(type, isDark) {{
            const t = themes[type] || themes.success;
            return isDark ? t.dark : t.light;
        }}
        
        window.addNotification = (title, snippet, type) => {{
            const container = document.getElementById('notifications');
            const colors = getColors(type, isDarkMode);
            const duration = (themes[type] || themes.success).duration;
            
            const badge = document.createElement('div');
            badge.className = 'badge';
            
            // Set styles
            const s = badge.style;
            s.setProperty('--this-bg', colors.bg);
            s.setProperty('--this-border', colors.border);
            s.setProperty('--this-text-prio', colors.textPrio);
            s.setProperty('--this-text-sec', colors.textSec);
            s.setProperty('--this-accent', colors.accent);
            s.setProperty('--this-bloom', colors.bloom);
            s.setProperty('--this-shadow', colors.shadow);
            
            const hasSnippet = (snippet && snippet.length > 0);
            const checkDisplay = hasSnippet ? 'flex' : 'none';
            const snippetDisplay = hasSnippet ? 'flex' : 'none';
            
            badge.innerHTML = `
                <div class="row title-row">
                    <div class="title">
                        <span class="check" style="display: ${{checkDisplay}}">
                            <svg width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="4.5" stroke-linecap="round" stroke-linejoin="round">
                                <polyline points="20 6 9 17 4 12"></polyline>
                            </svg>
                        </span>
                        <span>${{title}}</span>
                    </div>
                </div>
                <div class="row snippet-container" style="display: ${{snippetDisplay}}">
                    <div class="snippet">${{snippet}}</div>
                </div>
            `;
            
            container.appendChild(badge);
            
            // Animate In
            // Double raf to ensure transition
            requestAnimationFrame(() => {{
                requestAnimationFrame(() => {{
                   badge.classList.add('visible'); 
                }});
            }});
            
            // Remove logic
            setTimeout(() => {{
                badge.classList.remove('visible');
                setTimeout(() => {{
                    if (badge.parentNode) badge.parentNode.removeChild(badge);
                    if (container.children.length === 0) {{
                        window.ipc.postMessage('finished');
                    }}
                }}, 400);
            }}, duration);
        }};
    </script>
</body>
</html>"#
    )
}

fn internal_create_window_loop() {
    unsafe {
        // Initialize COM for the thread (Critical for WebView2/Wry)
        let coinit = CoInitialize(None);
        crate::log_info!("[Badge] Internal Loop Start - CoInit: {:?}", coinit);

        let instance = GetModuleHandleW(None).unwrap_or_default();
        let class_name = w!("SGT_AutoCopyBadgeWebView");

        REGISTER_BADGE_CLASS.call_once(|| {
            let mut wc = WNDCLASSW::default();
            wc.lpfnWndProc = Some(badge_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap_or_default();
            wc.lpszClassName = class_name;
            wc.style = CS_HREDRAW | CS_VREDRAW;
            wc.hbrBackground = HBRUSH(std::ptr::null_mut());
            let _ = RegisterClassW(&wc);
        });
        crate::log_info!("[Badge] Class Registered");

        let hwnd = CreateWindowExW(
            WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED | WS_EX_TRANSPARENT | WS_EX_NOACTIVATE,
            class_name,
            w!("SGT AutoCopy Badge"),
            WS_POPUP,
            -4000,
            -4000,
            BADGE_WIDTH,
            BADGE_HEIGHT,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();
        crate::log_info!("[Badge] Window created with HWND: {:?}", hwnd);

        if hwnd.is_invalid() {
            crate::log_info!("[Badge] Window creation failed, HWND is invalid.");
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            BADGE_HWND.store(0, Ordering::SeqCst);
            let _ = CoUninitialize();
            return;
        }

        // Don't store HWND yet - wait until WebView is ready
        let margins = MARGINS {
            cxLeftWidth: -1,
            cxRightWidth: -1,
            cyTopHeight: -1,
            cyBottomHeight: -1,
        };
        let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

        let wrapper = HwndWrapper(hwnd);

        // Initialize shared WebContext if needed (uses same data dir as other modules)
        BADGE_WEB_CONTEXT.with(|ctx| {
            if ctx.borrow().is_none() {
                // Consolidate all minor overlays to 'common' to share one browser process and keep RAM at ~80MB
                let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
                *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
            }
        });
        crate::log_info!("[Badge] Starting WebView initialization...");

        // Stagger start to avoid global WebView2 init lock contention
        std::thread::sleep(std::time::Duration::from_millis(50));

        let webview = {
            // LOCK SCOPE: Only one WebView builds at a time to prevent "Not enough quota"
            let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
            crate::log_info!("[Badge] Acquired init lock. Building...");

            let build_res = BADGE_WEB_CONTEXT.with(|ctx| {
                let mut ctx_ref = ctx.borrow_mut();
                let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                    WebViewBuilder::new_with_web_context(web_ctx)
                } else {
                    WebViewBuilder::new()
                };

                let builder =
                    crate::overlay::html_components::font_manager::configure_webview(builder);

                // Store HTML in font server and get URL for same-origin font loading
                let badge_html = get_badge_html();
                let page_url = crate::overlay::html_components::font_manager::store_html_page(
                    badge_html.clone(),
                )
                .unwrap_or_else(|| format!("data:text/html,{}", urlencoding::encode(&badge_html)));

                builder
                    .with_transparent(true)
                    .with_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                            0, 0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            BADGE_WIDTH as u32,
                            BADGE_HEIGHT as u32,
                        )),
                    })
                    .with_url(&page_url)
                    .with_ipc_handler(move |msg: wry::http::Request<String>| {
                        let body = msg.body();
                        if body == "finished" {
                            let _ = ShowWindow(hwnd, SW_HIDE);
                        } else if body.starts_with("error:") {
                            crate::log_info!("[BadgeJS] {}", body);
                        }
                    })
                    .build(&wrapper)
            });

            crate::log_info!(
                "[Badge] Build phase finished. Releasing lock. Status: {}",
                if build_res.is_ok() { "OK" } else { "ERR" }
            );
            build_res
        };

        if let Ok(wv) = webview {
            crate::log_info!("[Badge] WebView initialization SUCCESSFUL");
            BADGE_WEBVIEW.with(|cell| {
                *cell.borrow_mut() = Some(wv);
            });

            // Now that WebView is ready, publicize the HWND and mark as ready
            BADGE_HWND.store(hwnd.0 as isize, Ordering::SeqCst);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            IS_WARMED_UP.store(true, Ordering::SeqCst);

            // Process any notifications that were enqueued during warmup
            let _ = PostMessageW(Some(hwnd), WM_APP_PROCESS_QUEUE, WPARAM(0), LPARAM(0));
        } else {
            // Initialization failed - cleanup and exit
            let _ = DestroyWindow(hwnd);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            BADGE_HWND.store(0, Ordering::SeqCst);
            let _ = CoUninitialize();
            return;
        }

        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
        }

        // Cleanup on exit - reset all state so warmup can be retriggered
        BADGE_WEBVIEW.with(|cell| {
            *cell.borrow_mut() = None;
        });
        BADGE_HWND.store(0, Ordering::SeqCst);
        IS_WARMING_UP.store(false, Ordering::SeqCst);
        IS_WARMED_UP.store(false, Ordering::SeqCst);
        let _ = CoUninitialize();
    }
}

unsafe extern "system" fn badge_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_PROCESS_QUEUE => {
            let app = APP.lock().unwrap();
            let is_dark = match app.config.theme_mode {
                crate::config::ThemeMode::Dark => true,
                crate::config::ThemeMode::Light => false,
                crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
            };
            drop(app);

            // Update badge position (if screen changed?)
            let screen_w = GetSystemMetrics(SM_CXSCREEN);
            let screen_h = GetSystemMetrics(SM_CYSCREEN);
            let x = (screen_w - BADGE_WIDTH) / 2;
            let y = screen_h - BADGE_HEIGHT - 100;

            let _ = SetWindowPos(
                hwnd,
                Some(HWND_TOPMOST),
                x,
                y,
                BADGE_WIDTH,
                BADGE_HEIGHT,
                SWP_NOACTIVATE | SWP_SHOWWINDOW,
            );

            // Fetch generic queue items
            let mut items = Vec::new();
            {
                let mut q = PENDING_QUEUE.lock().unwrap();
                while let Some(item) = q.pop_front() {
                    items.push(item);
                }
            }

            if !items.is_empty() {
                BADGE_WEBVIEW.with(|wv| {
                    if let Some(webview) = wv.borrow().as_ref() {
                        // Update Theme
                        let theme_script = format!("window.setTheme({});", is_dark);
                        let _ = webview.evaluate_script(&theme_script);

                        // Add Notifications logic
                        for item in items {
                            let type_str = match item.n_type {
                                NotificationType::Success => "success",
                                NotificationType::Info => "info",
                                NotificationType::Update => "update",
                                NotificationType::Error => "error",
                            };

                            let safe_title = item
                                .title
                                .replace('\\', "\\\\")
                                .replace('"', "\\\"")
                                .replace('\'', "\\'");

                            let safe_snippet = item
                                .snippet
                                .replace('\\', "\\\\")
                                .replace('"', "\\\"")
                                .replace('\'', "\\'")
                                .replace('\n', " ");

                            let script = format!(
                                "window.addNotification('{}', '{}', '{}');",
                                safe_title, safe_snippet, type_str
                            );
                            let _ = webview.evaluate_script(&script);
                        }
                    }
                });
            }

            LRESULT(0)
        }
        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }
        WM_ERASEBKGND => LRESULT(1),
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/selection.rs">
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::UI::Input::KeyboardAndMouse::{
    GetAsyncKeyState, ReleaseCapture, SetCapture, VK_ESCAPE,
};
use windows::Win32::UI::WindowsAndMessaging::*;

use super::process::start_processing_pipeline;
use crate::win_types::{SendHbitmap, SendHwnd};
use crate::{GdiCapture, APP};
use std::sync::atomic::{AtomicBool, Ordering};
use std::sync::Arc;

lazy_static::lazy_static! {
    static ref SELECTION_ABORT_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
}

// FFI types for Windows Magnification API (loaded dynamically from Magnification.dll)
type MagInitializeFn = unsafe extern "system" fn() -> BOOL;
type MagUninitializeFn = unsafe extern "system" fn() -> BOOL;
type MagSetFullscreenTransformFn = unsafe extern "system" fn(f32, i32, i32) -> BOOL;

static mut MAG_DLL: HMODULE = HMODULE(std::ptr::null_mut());
static mut MAG_INITIALIZE: Option<MagInitializeFn> = None;
static mut MAG_UNINITIALIZE: Option<MagUninitializeFn> = None;
static mut MAG_SET_FULLSCREEN_TRANSFORM: Option<MagSetFullscreenTransformFn> = None;

// --- CONFIGURATION ---
const FADE_TIMER_ID: usize = 2;
const TARGET_OPACITY: u8 = 120;
const FADE_STEP: u8 = 40;

// --- STATE ---
static mut START_POS: POINT = POINT { x: 0, y: 0 };
static mut CURR_POS: POINT = POINT { x: 0, y: 0 };
static mut IS_DRAGGING: bool = false;
static mut IS_FADING_OUT: bool = false;
static mut CURRENT_ALPHA: u8 = 0;
static SELECTION_OVERLAY_ACTIVE: AtomicBool = AtomicBool::new(false);
static mut SELECTION_OVERLAY_HWND: SendHwnd = SendHwnd(HWND(std::ptr::null_mut()));
static mut CURRENT_PRESET_IDX: usize = 0;
static mut SELECTION_HOOK: HHOOK = HHOOK(std::ptr::null_mut());

// CONTINUOUS MODE HOTKEY TRACKING
static mut TRIGGER_VK_CODE: u32 = 0;
static mut TRIGGER_MODIFIERS: u32 = 0;
static IS_HOTKEY_HELD: AtomicBool = AtomicBool::new(false);
static CONTINUOUS_ACTIVATED_THIS_SESSION: AtomicBool = AtomicBool::new(false);
static HOLD_DETECTED_THIS_SESSION: AtomicBool = AtomicBool::new(false);

// Cached back buffer to avoid per-frame allocations
// Use a 32-bit DIB section for per-pixel alpha support (opaque box on semi-transparent dim)
static mut CACHED_BITMAP: SendHbitmap = SendHbitmap(HBITMAP(std::ptr::null_mut()));
static mut CACHED_BITS: *mut u8 = std::ptr::null_mut();
static mut CACHED_W: i32 = 0;
static mut CACHED_H: i32 = 0;

// --- ZOOM/MAGNIFICATION STATE ---
const ZOOM_STEP: f32 = 0.25;
const MIN_ZOOM: f32 = 1.0;
const MAX_ZOOM: f32 = 4.0;
const ZOOM_TIMER_ID: usize = 3;
const CONTINUOUS_CHECK_TIMER_ID: usize = 4;

static mut ZOOM_LEVEL: f32 = 1.0; // Target Zoom
static mut ZOOM_CENTER_X: f32 = 0.0; // Target Center X
static mut ZOOM_CENTER_Y: f32 = 0.0; // Target Center Y

// --- SMOOTH ZOOM STATE ---
static mut RENDER_ZOOM: f32 = 1.0;
static mut RENDER_CENTER_X: f32 = 0.0;
static mut RENDER_CENTER_Y: f32 = 0.0;

// --- PANNING STATE ---
static mut IS_RIGHT_DRAGGING: bool = false;
static mut LAST_PAN_POS: POINT = POINT { x: 0, y: 0 }; // Last cursor pos for panning

// Alpha override when zoomed (0 = fully transparent dim)
static mut ZOOM_ALPHA_OVERRIDE: Option<u8> = None;
// Track if Windows Magnification API is initialized
static mut MAG_INITIALIZED: bool = false;

#[allow(static_mut_refs)]
unsafe fn load_magnification_api() -> bool {
    // Correctly access static mut using addr_of for Rust 2024 compliance
    let mag_dll = std::ptr::addr_of!(MAG_DLL).read();
    if !mag_dll.is_invalid() {
        return true; // Already loaded
    }

    let dll_name = w!("Magnification.dll");
    let dll = LoadLibraryW(dll_name);

    if let Ok(h) = dll {
        MAG_DLL = h;

        // Get function pointers
        if let Some(init) = GetProcAddress(h, s!("MagInitialize")) {
            MAG_INITIALIZE = Some(std::mem::transmute(init));
        }
        if let Some(uninit) = GetProcAddress(h, s!("MagUninitialize")) {
            MAG_UNINITIALIZE = Some(std::mem::transmute(uninit));
        }
        if let Some(transform) = GetProcAddress(h, s!("MagSetFullscreenTransform")) {
            MAG_SET_FULLSCREEN_TRANSFORM = Some(std::mem::transmute(transform));
        }

        let init_ptr = std::ptr::addr_of!(MAG_INITIALIZE).read();
        let trans_ptr = std::ptr::addr_of!(MAG_SET_FULLSCREEN_TRANSFORM).read();
        return init_ptr.is_some() && trans_ptr.is_some();
    }

    false
}

// Helper to extract bytes from the HBITMAP only for the selected area
unsafe fn extract_crop_from_hbitmap(
    capture: &GdiCapture,
    crop_rect: RECT,
) -> image::ImageBuffer<image::Rgba<u8>, Vec<u8>> {
    let hdc_screen = GetDC(None);
    let hdc_mem = CreateCompatibleDC(Some(hdc_screen));

    // Select the big screenshot into DC
    let old_obj = SelectObject(hdc_mem, capture.hbitmap.into());

    let w = (crop_rect.right - crop_rect.left).abs();
    let h = (crop_rect.bottom - crop_rect.top).abs();

    // Create a BMI for just the cropped area
    let mut bmi = BITMAPINFO {
        bmiHeader: BITMAPINFOHEADER {
            biSize: std::mem::size_of::<BITMAPINFOHEADER>() as u32,
            biWidth: w,
            biHeight: -h, // Top-down
            biPlanes: 1,
            biBitCount: 32,
            biCompression: BI_RGB.0 as u32,
            ..Default::default()
        },
        ..Default::default()
    };

    let mut buffer: Vec<u8> = vec![0; (w * h * 4) as usize];

    // Create small temp bitmap, blit crop to it, read bits
    let hdc_temp = CreateCompatibleDC(Some(hdc_screen));
    let hbm_temp = CreateCompatibleBitmap(hdc_screen, w, h);
    SelectObject(hdc_temp, hbm_temp.into());

    // Copy only the crop region from the huge screenshot
    // IMPORTANT: virtual screen coordinates calculation
    let v_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
    let v_y = GetSystemMetrics(SM_YVIRTUALSCREEN);

    // source x/y in the bitmap
    let src_x = crop_rect.left - v_x;
    let src_y = crop_rect.top - v_y;

    let _ = BitBlt(hdc_temp, 0, 0, w, h, Some(hdc_mem), src_x, src_y, SRCCOPY).ok();

    // Now read pixels from small bitmap
    GetDIBits(
        hdc_temp,
        hbm_temp,
        0,
        h as u32,
        Some(buffer.as_mut_ptr() as *mut _),
        &mut bmi,
        DIB_RGB_COLORS,
    );

    // BGR -> RGB correction
    for chunk in buffer.chunks_exact_mut(4) {
        chunk.swap(0, 2);
        chunk[3] = 255;
    }

    let _ = DeleteObject(hbm_temp.into());
    let _ = DeleteDC(hdc_temp);

    // Cleanup main DC
    SelectObject(hdc_mem, old_obj);
    let _ = DeleteDC(hdc_mem);
    ReleaseDC(None, hdc_screen);

    image::ImageBuffer::from_raw(w as u32, h as u32, buffer).unwrap()
}

pub fn is_selection_overlay_active() -> bool {
    SELECTION_OVERLAY_ACTIVE.load(Ordering::SeqCst)
}

#[allow(static_mut_refs)]
pub fn show_selection_overlay(preset_idx: usize) {
    unsafe {
        CURRENT_PRESET_IDX = preset_idx;
        SELECTION_OVERLAY_ACTIVE.store(true, Ordering::SeqCst);
        CURRENT_ALPHA = 0;
        IS_FADING_OUT = false;
        IS_DRAGGING = false;

        // Reset zoom state
        ZOOM_LEVEL = 1.0;
        ZOOM_CENTER_X = 0.0;
        ZOOM_CENTER_Y = 0.0;
        RENDER_ZOOM = 1.0;
        RENDER_CENTER_X = 0.0;
        RENDER_CENTER_Y = 0.0;
        IS_RIGHT_DRAGGING = false;
        ZOOM_ALPHA_OVERRIDE = None;

        // Only reset session flags if NOT already in continuous mode
        // (to prevent issues on hotkey repeats)
        if !super::continuous_mode::is_active() {
            HOLD_DETECTED_THIS_SESSION.store(false, Ordering::SeqCst);
            CONTINUOUS_ACTIVATED_THIS_SESSION.store(false, Ordering::SeqCst);
        }

        // Initialize Hotkey Tracking for Continuous Mode
        if let Some((mods, vk)) = super::continuous_mode::get_current_hotkey_info() {
            TRIGGER_MODIFIERS = mods;
            TRIGGER_VK_CODE = vk;

            // Only overwrite IS_HOTKEY_HELD if continuous mode is not already active
            if !super::continuous_mode::is_active() {
                let is_physically_held = (GetAsyncKeyState(vk as i32) as u16 & 0x8000) != 0;
                IS_HOTKEY_HELD.store(is_physically_held, Ordering::SeqCst);
            }
        } else {
            IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
            TRIGGER_MODIFIERS = 0;
            TRIGGER_VK_CODE = 0;
        }

        SELECTION_ABORT_SIGNAL.store(false, Ordering::SeqCst);
        let instance = GetModuleHandleW(None).unwrap();
        let class_name = w!("SnippingOverlay");

        let mut wc = WNDCLASSW::default();
        if !GetClassInfoW(Some(instance.into()), class_name, &mut wc).is_ok() {
            wc.lpfnWndProc = Some(selection_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_CROSS).unwrap();
            wc.lpszClassName = class_name;
            wc.hbrBackground = CreateSolidBrush(COLORREF(0x00000000));
            RegisterClassW(&wc);
        }

        let x = GetSystemMetrics(SM_XVIRTUALSCREEN);
        let y = GetSystemMetrics(SM_YVIRTUALSCREEN);
        let w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
        let h = GetSystemMetrics(SM_CYVIRTUALSCREEN);

        let hwnd = CreateWindowExW(
            WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
            class_name,
            w!("Snipping"),
            WS_POPUP,
            x,
            y,
            w,
            h,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        SELECTION_OVERLAY_HWND = SendHwnd(hwnd);

        // Install Hook
        let hook = SetWindowsHookExW(
            WH_KEYBOARD_LL,
            Some(selection_hook_proc),
            Some(GetModuleHandleW(None).unwrap().into()),
            0,
        );
        if let Ok(h) = hook {
            SELECTION_HOOK = h;
        }

        // CRITICAL: Re-check physical key state AFTER hook is installed.
        // This catches the race condition where user released key between
        // the initial GetAsyncKeyState check and hook installation.
        if TRIGGER_VK_CODE != 0 {
            let is_still_held = (GetAsyncKeyState(TRIGGER_VK_CODE as i32) as u16 & 0x8000) != 0;
            if !is_still_held {
                IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
            }
        }

        // Initial sync to set alpha 0
        sync_layered_window_contents(hwnd);
        let _ = ShowWindow(hwnd, SW_SHOWNOACTIVATE);

        let _ = SetTimer(Some(hwnd), FADE_TIMER_ID, 16, None);
        let _ = SetTimer(Some(hwnd), CONTINUOUS_CHECK_TIMER_ID, 50, None);

        let mut msg = MSG::default();
        loop {
            while PeekMessageW(&mut msg, None, 0, 0, PM_REMOVE).as_bool() {
                let _ = TranslateMessage(&msg);
                let _ = DispatchMessageW(&msg);
                if msg.message == WM_QUIT {
                    break;
                }
            }
            if msg.message == WM_QUIT {
                break;
            }

            if SELECTION_ABORT_SIGNAL.load(Ordering::SeqCst) {
                // Trigger graceful close (fade out)
                let _ = SendMessageW(hwnd, WM_CLOSE, Some(WPARAM(0)), Some(LPARAM(0)));
                SELECTION_ABORT_SIGNAL.store(false, Ordering::SeqCst);
            }

            let _ = WaitMessage();
        }

        // Uninstall Hook
        let hook = std::ptr::addr_of!(SELECTION_HOOK).read();
        if !hook.is_invalid() {
            let _ = UnhookWindowsHookEx(hook);
            SELECTION_HOOK = HHOOK(std::ptr::null_mut());
        }

        SELECTION_OVERLAY_ACTIVE.store(false, Ordering::SeqCst);
        SELECTION_OVERLAY_HWND = SendHwnd::default();
    }
}

unsafe extern "system" fn selection_hook_proc(
    code: i32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    if code == HC_ACTION as i32 {
        let kbd = &*(lparam.0 as *const KBDLLHOOKSTRUCT);
        if wparam.0 == WM_KEYDOWN as usize || wparam.0 == WM_SYSKEYDOWN as usize {
            if kbd.vkCode == VK_ESCAPE.0 as u32 {
                super::continuous_mode::deactivate();
                SELECTION_ABORT_SIGNAL.store(true, Ordering::SeqCst);
                let hwnd = std::ptr::addr_of!(SELECTION_OVERLAY_HWND).read().0;
                if !hwnd.is_invalid() {
                    // Wake the message loop
                    let _ = PostMessageW(Some(hwnd), WM_NULL, WPARAM(0), LPARAM(0));
                }
                return LRESULT(1);
            }
            if kbd.vkCode == TRIGGER_VK_CODE {
                if !IS_HOTKEY_HELD.load(Ordering::SeqCst) {
                    super::continuous_mode::deactivate();
                    SELECTION_ABORT_SIGNAL.store(true, Ordering::SeqCst);
                    let hwnd = std::ptr::addr_of!(SELECTION_OVERLAY_HWND).read().0;
                    if !hwnd.is_invalid() {
                        let _ = PostMessageW(Some(hwnd), WM_NULL, WPARAM(0), LPARAM(0));
                    }
                    return LRESULT(1);
                }
            }
        } else if wparam.0 == WM_KEYUP as usize || wparam.0 == WM_SYSKEYUP as usize {
            // Monitor Key Release for Continuous Mode
            if kbd.vkCode == TRIGGER_VK_CODE {
                IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
            }
        }
    }
    CallNextHookEx(None, code, wparam, lparam)
}

#[allow(static_mut_refs)]
unsafe extern "system" fn selection_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_LBUTTONDOWN => {
            if !IS_FADING_OUT {
                IS_DRAGGING = true;
                let _ = GetCursorPos(std::ptr::addr_of_mut!(START_POS));

                CURR_POS = START_POS;
                SetCapture(hwnd);
                sync_layered_window_contents(hwnd);
            }
            LRESULT(0)
        }
        WM_RBUTTONDOWN => {
            if !IS_FADING_OUT && ZOOM_LEVEL > 1.0 {
                IS_RIGHT_DRAGGING = true;
                let _ = GetCursorPos(std::ptr::addr_of_mut!(LAST_PAN_POS));
                SetCapture(hwnd);
                // Start timer ensuring smooth updates while dragging
                let _ = SetTimer(Some(hwnd), ZOOM_TIMER_ID, 16, None);
            }
            LRESULT(0)
        }
        WM_RBUTTONUP => {
            if IS_RIGHT_DRAGGING {
                IS_RIGHT_DRAGGING = false;
                let _ = ReleaseCapture();
            }
            LRESULT(0)
        }
        WM_NCHITTEST => LRESULT(HTCLIENT as _),
        WM_MOUSEMOVE => {
            if IS_DRAGGING {
                let _ = GetCursorPos(std::ptr::addr_of_mut!(CURR_POS));
                // Force immediate repaint for smoothness
                sync_layered_window_contents(hwnd);
            } else if IS_RIGHT_DRAGGING {
                let mut curr_pan = POINT::default();
                let _ = GetCursorPos(&mut curr_pan);

                let dx_screen = curr_pan.x - LAST_PAN_POS.x;
                let dy_screen = curr_pan.y - LAST_PAN_POS.y;
                LAST_PAN_POS = curr_pan;

                // Dragging right -> moves viewport left -> center x decreases
                // Scale by RENDER_ZOOM to map screen pixels to source pixels
                if RENDER_ZOOM > 0.1 {
                    // Boost sensitivity by 2.0x for faster traversal
                    let sensitivity = 2.0;
                    let dx_source = (dx_screen as f32 / RENDER_ZOOM) * sensitivity;
                    let dy_source = (dy_screen as f32 / RENDER_ZOOM) * sensitivity;

                    ZOOM_CENTER_X -= dx_source;
                    ZOOM_CENTER_Y -= dy_source;
                }
            }
            LRESULT(0)
        }
        WM_MOUSEWHEEL => {
            if !IS_FADING_OUT && !IS_DRAGGING {
                // Extract wheel delta from wparam high word (signed)
                let delta = ((wparam.0 >> 16) as i16) as i32;

                // Get cursor position for zoom center
                let mut cursor = POINT::default();
                let _ = GetCursorPos(&mut cursor);

                if delta > 0 {
                    // Scroll up = zoom in
                    ZOOM_LEVEL = (ZOOM_LEVEL + ZOOM_STEP).min(MAX_ZOOM);
                    // Update center to cursor on zoom in
                    ZOOM_CENTER_X = cursor.x as f32;
                    ZOOM_CENTER_Y = cursor.y as f32;
                } else if delta < 0 {
                    // Scroll down = zoom out
                    ZOOM_LEVEL = (ZOOM_LEVEL - ZOOM_STEP).max(MIN_ZOOM);
                    // On zoom out, we keep the current center to prevent jumping around
                    // unless we are reset to 1.0, then it matters less
                }

                // Initialize panning targets if this is the first move
                if RENDER_CENTER_X == 0.0 && RENDER_CENTER_Y == 0.0 {
                    RENDER_CENTER_X = ZOOM_CENTER_X;
                    RENDER_CENTER_Y = ZOOM_CENTER_Y;
                }

                // Initialize magnification API instantly if needed
                if !MAG_INITIALIZED && ZOOM_LEVEL > 1.0 {
                    if load_magnification_api() {
                        if let Some(init_fn) = MAG_INITIALIZE {
                            if init_fn().as_bool() {
                                MAG_INITIALIZED = true;
                            }
                        }
                    }
                }

                // Start animation timer
                let _ = SetTimer(Some(hwnd), ZOOM_TIMER_ID, 16, None);
            }
            LRESULT(0)
        }
        WM_LBUTTONUP => {
            if IS_DRAGGING {
                let mut pt = POINT::default();
                let _ = GetCursorPos(&mut pt);

                IS_DRAGGING = false;
                let _ = ReleaseCapture();

                let rect = RECT {
                    left: START_POS.x.min(CURR_POS.x),
                    top: START_POS.y.min(CURR_POS.y),
                    right: START_POS.x.max(CURR_POS.x),
                    bottom: START_POS.y.max(CURR_POS.y),
                };

                let width = (rect.right - rect.left).abs();
                let height = (rect.bottom - rect.top).abs();

                if width <= 10 && height <= 10 {
                    // COLOR PICKER: Clicking without dragging copies the pixel color
                    unsafe {
                        let mut pt = POINT::default();
                        let _ = GetCursorPos(&mut pt);

                        let hex_color = {
                            let guard = APP.lock().unwrap();
                            if let Some(capture) = &guard.screenshot_handle {
                                let hdc_screen = GetDC(None);
                                let hdc_mem = CreateCompatibleDC(Some(hdc_screen));
                                let old_bmp = SelectObject(hdc_mem, capture.hbitmap.into());

                                // Convert global screen cursor to bitmap-local coordinates
                                let sx = GetSystemMetrics(SM_XVIRTUALSCREEN);
                                let sy = GetSystemMetrics(SM_YVIRTUALSCREEN);
                                let local_x = pt.x - sx;
                                let local_y = pt.y - sy;

                                let color = GetPixel(hdc_mem, local_x, local_y);

                                SelectObject(hdc_mem, old_bmp);
                                let _ = DeleteDC(hdc_mem);
                                let _ = ReleaseDC(None, hdc_screen);

                                // COLORREF is 0x00BBGGRR
                                let r = (color.0 & 0x000000FF) as u8;
                                let g = ((color.0 & 0x0000FF00) >> 8) as u8;
                                let b = ((color.0 & 0x00FF0000) >> 16) as u8;

                                Some(format!("#{:02X}{:02X}{:02X}", r, g, b))
                            } else {
                                None
                            }
                        };

                        if let Some(hex) = hex_color {
                            super::utils::copy_to_clipboard(&hex, hwnd);
                            super::auto_copy_badge::show_auto_copy_badge_text(&hex);
                        }
                    }

                    // Force fade out session immediately after picking color
                    unsafe {
                        IS_FADING_OUT = true;
                        if MAG_INITIALIZED {
                            if let Some(transform_fn) = MAG_SET_FULLSCREEN_TRANSFORM {
                                let _ = transform_fn(1.0, 0, 0);
                            }
                        }
                    }
                    let _ = SetTimer(Some(hwnd), FADE_TIMER_ID, 16, None);
                    return LRESULT(0);
                }

                if width > 10 && height > 10 {
                    // Check if this is a MASTER preset
                    let is_master = {
                        let guard = APP.lock().unwrap();
                        guard
                            .config
                            .presets
                            .get(CURRENT_PRESET_IDX)
                            .map(|p| p.is_master)
                            .unwrap_or(false)
                    };

                    // For MASTER presets, show the preset wheel first
                    let final_preset_idx = if is_master {
                        // Get cursor position for wheel center
                        let mut cursor_pos = POINT::default();
                        let _ = GetCursorPos(&mut cursor_pos);

                        // Hide selection overlay temporarily while showing wheel
                        // Hide selection overlay temporarily while showing wheel
                        ZOOM_ALPHA_OVERRIDE = Some(60);
                        sync_layered_window_contents(hwnd);

                        // Show preset wheel - this blocks until user makes selection
                        let selected =
                            super::preset_wheel::show_preset_wheel("image", None, cursor_pos);

                        if let Some(idx) = selected {
                            Some(idx)
                        } else {
                            // User dismissed wheel - cancel operation
                            IS_FADING_OUT = true;
                            SetTimer(Some(hwnd), FADE_TIMER_ID, 16, None);
                            return LRESULT(0);
                        }
                    } else {
                        Some(CURRENT_PRESET_IDX)
                    };

                    if let Some(preset_idx) = final_preset_idx {
                        // 3. CHECK FOR CONTINUOUS MODE ACTIVATION (IMPROVED)
                        if !super::continuous_mode::is_active() {
                            // Instant activation if key is physically held during mouse-up
                            let is_held = {
                                if TRIGGER_VK_CODE != 0 {
                                    (unsafe { GetAsyncKeyState(TRIGGER_VK_CODE as i32) } as u16
                                        & 0x8000)
                                        != 0
                                } else {
                                    false
                                }
                            };

                            let held_detected = HOLD_DETECTED_THIS_SESSION.load(Ordering::SeqCst);

                            if (is_held || held_detected)
                                && !CONTINUOUS_ACTIVATED_THIS_SESSION.load(Ordering::SeqCst)
                            {
                                let mut hotkey_name = super::continuous_mode::get_hotkey_name();
                                if hotkey_name.is_empty() {
                                    hotkey_name = super::continuous_mode::get_latest_hotkey_name();
                                }
                                if hotkey_name.is_empty() {
                                    hotkey_name = "Hotkey".to_string();
                                }

                                let p_name = {
                                    if let Ok(app) = APP.lock() {
                                        app.config
                                            .presets
                                            .get(preset_idx)
                                            .map(|p| p.id.clone())
                                            .unwrap_or_default()
                                    } else {
                                        "Preset".to_string()
                                    }
                                };

                                super::continuous_mode::activate(preset_idx, hotkey_name.clone());
                                super::continuous_mode::show_activation_notification(
                                    &p_name,
                                    &hotkey_name,
                                );
                                CONTINUOUS_ACTIVATED_THIS_SESSION.store(true, Ordering::SeqCst);
                            }
                        }

                        // 1. EXTRACT CROP (New Logic)
                        let (cropped_img, config, preset) = {
                            let mut guard = APP.lock().unwrap();

                            // CRITICAL: Update active_preset_idx so auto_paste logic works!
                            guard.config.active_preset_idx = preset_idx;

                            // Access the handle
                            let capture = guard
                                .screenshot_handle
                                .as_ref()
                                .expect("Screenshot handle missing");
                            let config_clone = guard.config.clone();
                            let preset_clone = guard.config.presets[preset_idx].clone();

                            // Extract pixels NOW (The slow part happens here, AFTER user finishes drawing)
                            let img = extract_crop_from_hbitmap(capture, rect);

                            (img, config_clone, preset_clone)
                        };

                        // 2. TRIGGER PROCESSING
                        std::thread::spawn(move || {
                            // Pass the rect for result window positioning
                            start_processing_pipeline(cropped_img, rect, config, preset);
                        });

                        // 3. Continuous mode is handled by the loop in main.rs
                    }

                    // 3. SEAMLESS CONTINUOUS MODE OR FADE OUT
                    if super::continuous_mode::is_active() {
                        // --- STICKY SEAMLESS SUCCESSION ---
                        // Mode is active - we stay in the overlay even if the key is released.
                        // This allows drawing multiple boxes in succession.
                        // Dismissal is handled by ESC or Hotkey Tap.
                        START_POS = POINT::default();
                        CURR_POS = POINT::default();
                        ZOOM_ALPHA_OVERRIDE = None;
                        sync_layered_window_contents(hwnd);
                        return LRESULT(0);
                    }

                    // 3. START FADE OUT
                    IS_FADING_OUT = true;
                    // Reset magnification instantly
                    unsafe {
                        if MAG_INITIALIZED {
                            if let Some(transform_fn) = MAG_SET_FULLSCREEN_TRANSFORM {
                                let _ = transform_fn(1.0, 0, 0);
                            }
                        }
                    }
                    let _ = SetTimer(Some(hwnd), FADE_TIMER_ID, 16, None);

                    return LRESULT(0);
                } else {
                    let _ = SendMessageW(hwnd, WM_CLOSE, Some(WPARAM(0)), Some(LPARAM(0)));
                }
            }
            LRESULT(0)
        }
        WM_TIMER => {
            if wparam.0 == ZOOM_TIMER_ID {
                // Lerp factor - increased for responsiveness
                let t = 0.4;
                let mut changed = false;

                // 1. Interpolate Zoom
                let diff_zoom = ZOOM_LEVEL - RENDER_ZOOM;
                if diff_zoom.abs() > 0.001 {
                    RENDER_ZOOM += diff_zoom * t;
                    changed = true;
                } else {
                    RENDER_ZOOM = ZOOM_LEVEL;
                }

                // 2. Interpolate Center
                let target_cx = ZOOM_CENTER_X;
                let target_cy = ZOOM_CENTER_Y;

                let dx = target_cx - RENDER_CENTER_X;
                let dy = target_cy - RENDER_CENTER_Y;

                if dx.abs() > 0.1 || dy.abs() > 0.1 {
                    RENDER_CENTER_X += dx * t;
                    RENDER_CENTER_Y += dy * t;
                    changed = true;
                } else {
                    RENDER_CENTER_X = target_cx;
                    RENDER_CENTER_Y = target_cy;
                }

                // 3. Apply Transform if Changed or Dragging
                if changed || IS_RIGHT_DRAGGING {
                    if MAG_INITIALIZED {
                        if let Some(transform_fn) = MAG_SET_FULLSCREEN_TRANSFORM {
                            if RENDER_ZOOM > 1.01 {
                                let screen_w = GetSystemMetrics(SM_CXVIRTUALSCREEN);
                                let screen_h = GetSystemMetrics(SM_CYVIRTUALSCREEN);
                                let screen_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
                                let screen_y = GetSystemMetrics(SM_YVIRTUALSCREEN);

                                // View dimensions at current interpolated zoom
                                let view_w = screen_w as f32 / RENDER_ZOOM;
                                let view_h = screen_h as f32 / RENDER_ZOOM;

                                // Calculate top-left offset
                                let mut off_x = RENDER_CENTER_X - view_w / 2.0;
                                let mut off_y = RENDER_CENTER_Y - view_h / 2.0;

                                // Clamp
                                off_x = off_x
                                    .max(screen_x as f32)
                                    .min((screen_x + screen_w) as f32 - view_w);
                                off_y = off_y
                                    .max(screen_y as f32)
                                    .min((screen_y + screen_h) as f32 - view_h);

                                let _ = transform_fn(RENDER_ZOOM, off_x as i32, off_y as i32);
                            } else {
                                // Reset
                                let _ = transform_fn(1.0, 0, 0);
                            }
                        }
                    }
                    sync_layered_window_contents(hwnd);
                } else if !changed && !IS_RIGHT_DRAGGING {
                    // Stop timer if settled and not dragging
                    let _ = KillTimer(Some(hwnd), ZOOM_TIMER_ID);
                }
            } else if wparam.0 == CONTINUOUS_CHECK_TIMER_ID {
                // SYNC PHYSICAL KEY STATE
                if TRIGGER_VK_CODE != 0 {
                    let is_physically_down =
                        (unsafe { GetAsyncKeyState(TRIGGER_VK_CODE as i32) } as u16 & 0x8000) != 0;
                    if !is_physically_down && IS_HOTKEY_HELD.load(Ordering::SeqCst) {
                        IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
                    }
                }

                // Background Hold Detection - Check even if not dragging
                if !super::continuous_mode::is_active()
                    && !CONTINUOUS_ACTIVATED_THIS_SESSION.load(Ordering::SeqCst)
                {
                    let heartbeat = super::continuous_mode::was_triggered_recently(1500);
                    if heartbeat {
                        HOLD_DETECTED_THIS_SESSION.store(true, Ordering::SeqCst);

                        let is_master = {
                            if let Ok(app) = APP.lock() {
                                app.config
                                    .presets
                                    .get(CURRENT_PRESET_IDX)
                                    .map(|p| p.is_master)
                                    .unwrap_or(false)
                            } else {
                                false
                            }
                        };

                        if !is_master {
                            let mut hotkey_name = super::continuous_mode::get_hotkey_name();
                            if hotkey_name.is_empty() {
                                hotkey_name = super::continuous_mode::get_latest_hotkey_name();
                            }
                            if hotkey_name.is_empty() {
                                hotkey_name = "Hotkey".to_string();
                            }

                            let p_name = {
                                if let Ok(app) = APP.lock() {
                                    app.config
                                        .presets
                                        .get(CURRENT_PRESET_IDX)
                                        .map(|p| p.id.clone())
                                        .unwrap_or_default()
                                } else {
                                    "Preset".to_string()
                                }
                            };

                            super::continuous_mode::activate(
                                CURRENT_PRESET_IDX,
                                hotkey_name.clone(),
                            );
                            super::continuous_mode::show_activation_notification(
                                &p_name,
                                &hotkey_name,
                            );
                            CONTINUOUS_ACTIVATED_THIS_SESSION.store(true, Ordering::SeqCst);
                        }
                    }
                }
            } else if wparam.0 == FADE_TIMER_ID {
                let mut changed = false;
                if IS_FADING_OUT {
                    if CURRENT_ALPHA > FADE_STEP {
                        CURRENT_ALPHA -= FADE_STEP;
                        changed = true;
                    } else {
                        CURRENT_ALPHA = 0;
                        let _ = KillTimer(Some(hwnd), FADE_TIMER_ID);
                        let _ = DestroyWindow(hwnd);
                        PostQuitMessage(0);
                        return LRESULT(0);
                    }
                } else {
                    if CURRENT_ALPHA < TARGET_OPACITY {
                        CURRENT_ALPHA = (CURRENT_ALPHA as u16 + FADE_STEP as u16)
                            .min(TARGET_OPACITY as u16)
                            as u8;
                        changed = true;
                    } else {
                        let _ = KillTimer(Some(hwnd), FADE_TIMER_ID);
                    }
                }

                if changed {
                    sync_layered_window_contents(hwnd);
                }
            }
            LRESULT(0)
        }
        WM_PAINT => {
            let mut ps = PAINTSTRUCT::default();
            let _ = BeginPaint(hwnd, &mut ps);
            sync_layered_window_contents(hwnd);
            let _ = EndPaint(hwnd, &mut ps);
            LRESULT(0)
        }
        WM_ERASEBKGND => LRESULT(1), // Handle erasing to prevent flicker
        WM_CLOSE => {
            if !IS_FADING_OUT {
                IS_FADING_OUT = true;
                // Reset magnification instantly
                unsafe {
                    if MAG_INITIALIZED {
                        if let Some(transform_fn) = MAG_SET_FULLSCREEN_TRANSFORM {
                            let _ = transform_fn(1.0, 0, 0);
                        }
                    }
                }
                let _ = KillTimer(Some(hwnd), FADE_TIMER_ID);
                let _ = KillTimer(Some(hwnd), ZOOM_TIMER_ID);
                SetTimer(Some(hwnd), FADE_TIMER_ID, 16, None);
            }
            LRESULT(0)
        }
        WM_DESTROY => {
            // Reset magnification before closing
            unsafe {
                if MAG_INITIALIZED {
                    if let Some(transform_fn) = MAG_SET_FULLSCREEN_TRANSFORM {
                        let _ = transform_fn(1.0, 0, 0);
                    }
                    if let Some(uninit_fn) = MAG_UNINITIALIZE {
                        let _ = uninit_fn();
                    }
                    MAG_INITIALIZED = false;
                }
            }

            // Cleanup cached back buffer resources
            unsafe {
                if !std::ptr::addr_of!(CACHED_BITMAP).read().is_invalid() {
                    let _ = DeleteObject(CACHED_BITMAP.0.into());
                    CACHED_BITMAP = SendHbitmap::default();
                    CACHED_BITS = std::ptr::null_mut();
                }
                CACHED_W = 0;
                CACHED_H = 0;
            }
            DefWindowProcW(hwnd, msg, wparam, lparam)
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

/// New high-performance renderer using UpdateLayeredWindow
/// This allows us to have an OPAQUE white box even when the dim background is TRANSPARENT
#[allow(static_mut_refs)]
unsafe fn sync_layered_window_contents(hwnd: HWND) {
    let width = GetSystemMetrics(SM_CXVIRTUALSCREEN);
    let height = GetSystemMetrics(SM_CYVIRTUALSCREEN);

    if width <= 0 || height <= 0 {
        return;
    }

    // 1. Prepare/Cache 32-bit DIB Context
    if std::ptr::addr_of!(CACHED_BITMAP).read().is_invalid()
        || CACHED_W != width
        || CACHED_H != height
    {
        if !std::ptr::addr_of!(CACHED_BITMAP).read().is_invalid() {
            let _ = DeleteObject(CACHED_BITMAP.0.into());
            CACHED_BITS = std::ptr::null_mut();
        }

        let bmi = BITMAPINFO {
            bmiHeader: BITMAPINFOHEADER {
                biSize: std::mem::size_of::<BITMAPINFOHEADER>() as u32,
                biWidth: width,
                biHeight: -height, // Top-down
                biPlanes: 1,
                biBitCount: 32,
                biCompression: BI_RGB.0,
                ..Default::default()
            },
            ..Default::default()
        };

        let hdc_screen = GetDC(None);
        let mut bits: *mut std::ffi::c_void = std::ptr::null_mut();
        let hbm = CreateDIBSection(Some(hdc_screen), &bmi, DIB_RGB_COLORS, &mut bits, None, 0);
        ReleaseDC(None, hdc_screen);

        if let Ok(h) = hbm {
            CACHED_BITMAP = SendHbitmap(h);
            CACHED_BITS = bits as *mut u8;
            CACHED_W = width;
            CACHED_H = height;
        } else {
            return;
        }
    }

    // 2. Draw using GDI to the DIB
    let hdc_screen = GetDC(None);
    let mem_dc = CreateCompatibleDC(Some(hdc_screen));
    let old_bmp = SelectObject(mem_dc, CACHED_BITMAP.0.into());

    // OPTIMIZATION: Clear background directly via memory fill (much faster than GDI)
    let effective_alpha = if let Some(zoom_alpha) = ZOOM_ALPHA_OVERRIDE {
        zoom_alpha.min(CURRENT_ALPHA)
    } else {
        CURRENT_ALPHA
    };

    let total_pixels = (width * height) as usize;
    let pixels_u32 = std::slice::from_raw_parts_mut(CACHED_BITS as *mut u32, total_pixels);

    // Fill with pre-multiplied alpha black: (0, 0, 0, alpha)
    let bg_val = (effective_alpha as u32) << 24;
    pixels_u32.fill(bg_val);

    // Draw the selection rectangle
    if IS_DRAGGING {
        let rect_abs = RECT {
            left: START_POS.x.min(CURR_POS.x),
            top: START_POS.y.min(CURR_POS.y),
            right: START_POS.x.max(CURR_POS.x),
            bottom: START_POS.y.max(CURR_POS.y),
        };

        let screen_x = GetSystemMetrics(SM_XVIRTUALSCREEN);
        let screen_y = GetSystemMetrics(SM_YVIRTUALSCREEN);

        let r = RECT {
            left: rect_abs.left - screen_x,
            top: rect_abs.top - screen_y,
            right: rect_abs.right - screen_x,
            bottom: rect_abs.bottom - screen_y,
        };

        let w = (r.right - r.left).abs();
        let h = (r.bottom - r.top).abs();

        if w > 0 && h > 0 {
            // ANTI-ALIASED ROUNDED BOX (Custom pixel shader replaces aliased GDI RoundRect)
            let default_radius = 12.0f32;
            let border_width = 2.0f32;

            // Box coordinates (relative to virtual screen)
            let l_f = r.left as f32;
            let t_f = r.top as f32;
            let r_f = r.right as f32;
            let b_f = r.bottom as f32;

            let hw = (r_f - l_f) / 2.0;
            let hh = (b_f - t_f) / 2.0;
            let cx = l_f + hw;
            let cy = t_f + hh;

            // ADAPTIVE RADIUS: Scale down if box is smaller than radius
            let radius = default_radius.min(hw).min(hh);

            let bg_alpha_f = effective_alpha as f32 / 255.0;

            // 3. SECURING ALPHA: Only iterate over the bounding area of the selection
            // This is much faster than processing the whole screen on every move
            let b_left = (r.left - 10).max(0);
            let b_top = (r.top - 10).max(0);
            let b_right = (r.right + 10).min(width);
            let b_bottom = (r.bottom + 10).min(height);

            let rad_int = radius.ceil() as i32;
            let top_band_end = (r.top + rad_int).min(b_bottom);
            let bottom_band_start = (r.bottom - rad_int).max(top_band_end);

            for py_int in b_top..b_bottom {
                let row_base = (py_int * width) as usize;

                // --- FAST PATH: Middle Band (no corners, just straight vertical edges) ---
                if py_int >= top_band_end && py_int < bottom_band_start {
                    let lb = r.left as usize;
                    let rb = r.right as usize;
                    if row_base + lb < pixels_u32.len() {
                        // 1. Clear Hole (Transparent interior)
                        let start = (row_base + lb).min(pixels_u32.len());
                        let end = (row_base + rb).min(pixels_u32.len());
                        if start < end {
                            pixels_u32[start..end].fill(0x00000000);
                        }

                        // 2. Draw Left/Right Borders (2 pixels wide, opaque white)
                        for x in 0..2 {
                            if row_base + lb + x < pixels_u32.len() {
                                pixels_u32[row_base + lb + x] = 0xFFFFFFFF;
                            }
                            if row_base + rb - 1 - x < pixels_u32.len() {
                                pixels_u32[row_base + rb - 1 - x] = 0xFFFFFFFF;
                            }
                        }
                    }
                    continue;
                }

                // --- SLOW PATH: Top/Bottom Bands (SDF for corners) ---
                let py = py_int as f32 + 0.5; // pixel center
                for px_int in b_left..b_right {
                    let idx = row_base + px_int as usize;
                    if idx >= pixels_u32.len() {
                        continue;
                    }

                    let px = px_int as f32 + 0.5;

                    // Rounded Rect SDF (Signed Distance Field)
                    let dx = (px - cx).abs() - (hw - radius);
                    let dy = (py - cy).abs() - (hh - radius);

                    let dist = if dx > 0.0 && dy > 0.0 {
                        (dx * dx + dy * dy).sqrt() - radius
                    } else {
                        dx.max(dy) - radius
                    };

                    // Composition:
                    // alpha_outer: 1.0 inside boundary, 0.0 outside. Smooth transition at edge.
                    let alpha_outer = (0.5 - dist).clamp(0.0, 1.0);
                    // alpha_inner: 1.0 inside inner border, 0.0 outside.
                    let alpha_inner = (0.5 - (dist + border_width)).clamp(0.0, 1.0);

                    let border_alpha = alpha_outer - alpha_inner;

                    // Initial background alpha (dimming) reduces inside the hole
                    let final_bg_alpha = bg_alpha_f * (1.0 - alpha_outer);

                    // Final Color (Pre-multiplied alpha)
                    // Background is black (0,0,0), border is white (1,1,1)
                    let a = ((final_bg_alpha + border_alpha) * 255.0) as u32;
                    let c = (border_alpha * 255.0) as u32;

                    pixels_u32[idx] = (a << 24) | (c << 16) | (c << 8) | c;
                }
            }
        }
    }

    // 4. Update the Layered Window
    let blend = BLENDFUNCTION {
        BlendOp: AC_SRC_OVER as u8,
        BlendFlags: 0,
        SourceConstantAlpha: 255, // Use per-pixel alpha from the bitmap
        AlphaFormat: AC_SRC_ALPHA as u8,
    };

    let screen_pos = POINT {
        x: GetSystemMetrics(SM_XVIRTUALSCREEN),
        y: GetSystemMetrics(SM_YVIRTUALSCREEN),
    };
    let wnd_size = SIZE {
        cx: width,
        cy: height,
    };
    let src_pos = POINT { x: 0, y: 0 };

    let _ = UpdateLayeredWindow(
        hwnd,
        Some(hdc_screen),
        Some(&screen_pos),
        Some(&wnd_size),
        Some(mem_dc),
        Some(&src_pos),
        COLORREF(0),
        Some(&blend),
        ULW_ALPHA,
    );

    // Cleanup DC
    SelectObject(mem_dc, old_bmp);
    let _ = DeleteDC(mem_dc);
    ReleaseDC(None, hdc_screen);
}
</file>

<file path="screen-record/src/lib/videoRenderer.ts">
import { BackgroundConfig, MousePosition, VideoSegment, ZoomKeyframe, TextSegment } from '@/types/video';

export interface RenderContext {
  video: HTMLVideoElement;
  canvas: HTMLCanvasElement;
  tempCanvas: HTMLCanvasElement;
  segment: VideoSegment;
  backgroundConfig: BackgroundConfig;
  mousePositions: MousePosition[];
  currentTime: number;
}

export interface RenderOptions {
  exportMode?: boolean;
  highQuality?: boolean;
}

export class VideoRenderer {
  private animationFrame: number | null = null;
  private isDrawing: boolean = false;
  private lastDrawTime: number = 0;
  private latestElapsed: number = 0;
  private readonly FRAME_INTERVAL = 1000 / 120; // 120fps target
  private backgroundConfig: BackgroundConfig | null = null;
  private pointerImage: HTMLImageElement;
  private customBackgroundPattern: CanvasPattern | null = null;
  private lastCustomBackground: string | undefined = undefined;

  private readonly DEFAULT_STATE: ZoomKeyframe = {
    time: 0,
    duration: 0,
    zoomFactor: 1,
    positionX: 0.5,
    positionY: 0.5,
    easingType: 'linear' as const
  };

  private lastCalculatedState: ZoomKeyframe | null = null;
  public getLastCalculatedState() { return this.lastCalculatedState; }

  private smoothedPositions: MousePosition[] | null = null;
  private hasLoggedPositions = false;

  private isDraggingText = false;
  private draggedTextId: string | null = null;
  private dragOffset = { x: 0, y: 0 };

  // Smooth cursor animation state
  private currentSquishScale = 1.0;
  private lastHoldTime = -1;
  private readonly CLICK_FUSE_THRESHOLD = 0.15;
  private readonly SQUISH_SPEED = 0.015;
  private readonly RELEASE_SPEED = 0.01;

  constructor() {
    this.pointerImage = new Image();
    this.pointerImage.src = '/pointer.svg';
    this.pointerImage.onload = () => { };
  }

  private activeRenderContext: RenderContext | null = null;

  public updateRenderContext(context: RenderContext) {
    this.activeRenderContext = context;
  }

  public startAnimation(renderContext: RenderContext) {
    // console.log('[VideoRenderer] Starting animation');
    this.stopAnimation();
    this.lastDrawTime = 0;
    this.smoothedPositions = null;
    this.activeRenderContext = renderContext;

    const animate = () => {
      // Stop animation loop if video is paused or context missing
      if (!this.activeRenderContext || this.activeRenderContext.video.paused) {
        this.animationFrame = null;
        return;
      }

      const now = performance.now();
      const elapsed = now - this.lastDrawTime;

      if (this.lastDrawTime === 0 || elapsed >= this.FRAME_INTERVAL) {
        this.drawFrame(this.activeRenderContext)
          .catch((err: unknown) => console.error('[VideoRenderer] Draw error:', err));
      }

      this.animationFrame = requestAnimationFrame(animate);
    };

    this.animationFrame = requestAnimationFrame(animate);
  }

  public stopAnimation() {
    if (this.animationFrame !== null) {
      cancelAnimationFrame(this.animationFrame);
      this.animationFrame = null;
      this.lastDrawTime = 0;
      this.activeRenderContext = null;
      this.lastHoldTime = -1;
      this.currentSquishScale = 1.0;
    }
  }

  public drawFrame = async (
    context: RenderContext,
    options: RenderOptions = {}
  ): Promise<void> => {
    if (this.isDrawing) return;

    const { video, canvas, tempCanvas, segment, backgroundConfig, mousePositions } = context;
    if (!video || !canvas || !segment) return;

    // Safety check: video must have data
    if (video.readyState < 2) return;

    const isExportMode = options.exportMode || false;
    const quality = options.highQuality || isExportMode ? 'high' : 'medium';

    const ctx = canvas.getContext('2d', {
      alpha: false,
      willReadFrequently: false
    });
    if (!ctx) return;

    this.isDrawing = true;
    ctx.imageSmoothingQuality = quality as ImageSmoothingQuality;

    const now = performance.now();
    this.latestElapsed = this.lastDrawTime === 0 ? 1000 / 60 : now - this.lastDrawTime;
    this.lastDrawTime = now;

    // Get dimensions from video element
    const vidW = video.videoWidth;
    const vidH = video.videoHeight;

    // Basic safety check for 0-dimension videos
    if (!vidW || !vidH) {
      this.isDrawing = false;
      return;
    }

    const crop = segment.crop || { x: 0, y: 0, width: 1, height: 1 };
    const srcX = vidW * crop.x;
    const srcY = vidH * crop.y;
    const srcW = vidW * crop.width;
    const srcH = vidH * crop.height;

    const canvasW = Math.round(srcW);
    const canvasH = Math.round(srcH);

    // Resize canvas if needed
    if (canvas.width !== canvasW || canvas.height !== canvasH) {
      canvas.width = canvasW;
      canvas.height = canvasH;
      tempCanvas.width = canvasW;
      tempCanvas.height = canvasH;
    }

    if (!isExportMode) {
      canvas.style.aspectRatio = `${canvasW} / ${canvasH}`;
    }

    try {
      const legacyCrop = (backgroundConfig.cropBottom || 0) / 100;
      const scale = backgroundConfig.scale / 100;
      const scaledWidth = canvas.width * scale;
      const scaledHeight = (canvas.height * (1 - legacyCrop)) * scale;
      const x = (canvas.width - scaledWidth) / 2;
      const y = (canvas.height - scaledHeight) / 2;
      const zoomState = this.calculateCurrentZoomState(video.currentTime, segment, canvas.width, canvas.height);

      ctx.save();

      if (zoomState && zoomState.zoomFactor !== 1) {
        const zoomedWidth = canvas.width * zoomState.zoomFactor;
        const zoomedHeight = canvas.height * zoomState.zoomFactor;
        const zoomOffsetX = (canvas.width - zoomedWidth) * zoomState.positionX;
        const zoomOffsetY = (canvas.height - zoomedHeight) * zoomState.positionY;

        ctx.translate(zoomOffsetX, zoomOffsetY);
        ctx.scale(zoomState.zoomFactor, zoomState.zoomFactor);
      }

      // Draw Background
      ctx.fillStyle = this.getBackgroundStyle(
        ctx,
        backgroundConfig.backgroundType,
        backgroundConfig.customBackground
      );
      ctx.fillRect(0, 0, canvas.width, canvas.height);

      // Temp Canvas setup for Rounded Corners
      if (tempCanvas.width !== canvas.width || tempCanvas.height !== canvas.height) {
        tempCanvas.width = canvas.width;
        tempCanvas.height = canvas.height;
      }
      const tempCtx = tempCanvas.getContext('2d', { alpha: true, willReadFrequently: false });
      if (!tempCtx) return;

      tempCtx.clearRect(0, 0, canvas.width, canvas.height);
      tempCtx.save();
      tempCtx.imageSmoothingEnabled = true;
      tempCtx.imageSmoothingQuality = 'high';

      const radius = backgroundConfig.borderRadius;
      const offset = 0.5;

      // Draw Shadow
      if (backgroundConfig.shadow) {
        tempCtx.save();
        tempCtx.shadowColor = 'rgba(0, 0, 0, 0.5)';
        tempCtx.shadowBlur = backgroundConfig.shadow;
        tempCtx.shadowOffsetY = backgroundConfig.shadow * 0.5;

        // Path
        tempCtx.beginPath();
        tempCtx.moveTo(x + radius + offset, y + offset);
        tempCtx.lineTo(x + scaledWidth - radius - offset, y + offset);
        tempCtx.quadraticCurveTo(x + scaledWidth - offset, y + offset, x + scaledWidth - offset, y + radius + offset);
        tempCtx.lineTo(x + scaledWidth - offset, y + scaledHeight - radius - offset);
        tempCtx.quadraticCurveTo(x + scaledWidth - offset, y + scaledHeight - offset, x + scaledWidth - radius - offset, y + scaledHeight - offset);
        tempCtx.lineTo(x + radius + offset, y + scaledHeight - offset);
        tempCtx.quadraticCurveTo(x + offset, y + scaledHeight - offset, x + offset, y + scaledHeight - radius - offset);
        tempCtx.lineTo(x + offset, y + radius + offset);
        tempCtx.quadraticCurveTo(x + offset, y + offset, x + radius + offset, y + offset);
        tempCtx.closePath();

        tempCtx.fillStyle = '#fff';
        tempCtx.fill();
        tempCtx.restore();
      }

      // Draw Video
      tempCtx.beginPath();
      tempCtx.moveTo(x + radius + offset, y + offset);
      tempCtx.lineTo(x + scaledWidth - radius - offset, y + offset);
      tempCtx.quadraticCurveTo(x + scaledWidth - offset, y + offset, x + scaledWidth - offset, y + radius + offset);
      tempCtx.lineTo(x + scaledWidth - offset, y + scaledHeight - radius - offset);
      tempCtx.quadraticCurveTo(x + scaledWidth - offset, y + scaledHeight - offset, x + scaledWidth - radius - offset, y + scaledHeight - offset);
      tempCtx.lineTo(x + radius + offset, y + scaledHeight - offset);
      tempCtx.quadraticCurveTo(x + offset, y + scaledHeight - offset, x + offset, y + scaledHeight - radius - offset);
      tempCtx.lineTo(x + offset, y + radius + offset);
      tempCtx.quadraticCurveTo(x + offset, y + offset, x + radius + offset, y + offset);
      tempCtx.closePath();

      tempCtx.clip();

      // Ensure video is drawable
      try {
        tempCtx.drawImage(
          video,
          srcX, srcY, srcW, srcH * (1 - legacyCrop),
          x, y, scaledWidth, scaledHeight
        );
      } catch (e) {
        // Ignore drawImage errors (e.g. if video not fully loaded)
      }

      tempCtx.strokeStyle = 'rgba(0, 0, 0, 0.1)';
      tempCtx.lineWidth = 1;
      tempCtx.stroke();
      tempCtx.restore();

      ctx.drawImage(tempCanvas, 0, 0);

      // Cursor
      const interpolatedPosition = this.interpolateCursorPosition(
        video.currentTime,
        mousePositions
      );
      if (interpolatedPosition) {
        ctx.save();
        ctx.setTransform(1, 0, 0, 1, 0, 0);

        const mX = interpolatedPosition.x;
        const mY = interpolatedPosition.y;

        if (mX >= srcX && mX <= (srcX + srcW) && mY >= srcY && mY <= (srcY + srcH * (1 - legacyCrop))) {
          const relX = (mX - srcX) / srcW;
          const relY = (mY - srcY) / (srcH * (1 - legacyCrop));

          let cursorX = x + (relX * scaledWidth);
          let cursorY = y + (relY * scaledHeight);

          if (zoomState && zoomState.zoomFactor !== 1) {
            cursorX = cursorX * zoomState.zoomFactor + (canvas.width - canvas.width * zoomState.zoomFactor) * zoomState.positionX;
            cursorY = cursorY * zoomState.zoomFactor + (canvas.height - canvas.height * zoomState.zoomFactor) * zoomState.positionY;
          }

          const sizeRatio = Math.min(canvas.width / srcW, canvas.height / srcH);
          const cursorSizeScale = (backgroundConfig.cursorScale || 2) * sizeRatio * (zoomState?.zoomFactor || 1);

          const isActuallyClicked = interpolatedPosition.isClicked;
          const timeSinceLastHold = video.currentTime - this.lastHoldTime;
          const shouldBeSquished = isActuallyClicked || (this.lastHoldTime >= 0 && timeSinceLastHold < this.CLICK_FUSE_THRESHOLD && timeSinceLastHold > 0);

          if (isActuallyClicked) {
            this.lastHoldTime = video.currentTime;
          }

          const targetScale = shouldBeSquished ? 0.75 : 1.0;
          if (this.currentSquishScale > targetScale) {
            this.currentSquishScale = Math.max(targetScale, this.currentSquishScale - this.SQUISH_SPEED * (this.latestElapsed / (1000 / 120)));
          } else if (this.currentSquishScale < targetScale) {
            this.currentSquishScale = Math.min(targetScale, this.currentSquishScale + this.RELEASE_SPEED * (this.latestElapsed / (1000 / 120)));
          }

          this.drawMouseCursor(
            ctx,
            cursorX,
            cursorY,
            shouldBeSquished,
            cursorSizeScale,
            interpolatedPosition.cursor_type || 'default'
          );
        }
        ctx.restore();
      }

      this.backgroundConfig = context.backgroundConfig;

      if (segment.textSegments) {
        for (const textSegment of segment.textSegments) {
          if (video.currentTime >= textSegment.startTime && video.currentTime <= textSegment.endTime) {
            this.drawTextOverlay(ctx, textSegment, canvas.width, canvas.height);
          }
        }
      }

    } finally {
      this.isDrawing = false;
      ctx.restore();
    }
  };

  private getBackgroundStyle(
    ctx: CanvasRenderingContext2D,
    type: BackgroundConfig['backgroundType'],
    customBackground?: string
  ): string | CanvasGradient | CanvasPattern {
    switch (type) {
      case 'gradient1': {
        const gradient = ctx.createLinearGradient(0, 0, ctx.canvas.width, 0);
        gradient.addColorStop(0, '#2563eb');
        gradient.addColorStop(1, '#7c3aed');
        return gradient;
      }
      case 'gradient2': {
        const gradient = ctx.createLinearGradient(0, 0, ctx.canvas.width, 0);
        gradient.addColorStop(0, '#fb7185');
        gradient.addColorStop(1, '#fdba74');
        return gradient;
      }
      case 'gradient3': {
        const gradient = ctx.createLinearGradient(0, 0, ctx.canvas.width, 0);
        gradient.addColorStop(0, '#10b981');
        gradient.addColorStop(1, '#2dd4bf');
        return gradient;
      }
      case 'custom': {
        if (customBackground) {
          if (this.lastCustomBackground !== customBackground || !this.customBackgroundPattern) {
            const img = new Image();
            img.src = customBackground;

            if (img.complete) {
              const tempCanvas = document.createElement('canvas');
              const tempCtx = tempCanvas.getContext('2d');

              if (tempCtx) {
                const targetWidth = Math.min(1920, window.innerWidth);
                const scale = targetWidth / img.width;
                const targetHeight = img.height * scale;

                tempCanvas.width = targetWidth;
                tempCanvas.height = targetHeight;
                tempCtx.imageSmoothingEnabled = true;
                tempCtx.imageSmoothingQuality = 'high';
                tempCtx.drawImage(img, 0, 0, targetWidth, targetHeight);
                this.customBackgroundPattern = ctx.createPattern(tempCanvas, 'repeat');
                this.lastCustomBackground = customBackground;
                tempCanvas.remove();
              }
            }
          }

          if (this.customBackgroundPattern) {
            this.customBackgroundPattern.setTransform(new DOMMatrix());
            const scale = Math.max(
              ctx.canvas.width / window.innerWidth,
              ctx.canvas.height / window.innerHeight
            ) * 1.1;
            const matrix = new DOMMatrix().scale(scale);
            this.customBackgroundPattern.setTransform(matrix);
            return this.customBackgroundPattern;
          }
        }
        return '#000000';
      }
      case 'solid': {
        const gradient = ctx.createLinearGradient(0, 0, 0, ctx.canvas.height);
        gradient.addColorStop(0, '#0a0a0a');
        gradient.addColorStop(0.5, '#000000');
        gradient.addColorStop(1, '#0a0a0a');

        const centerX = ctx.canvas.width / 2;
        const centerY = ctx.canvas.height / 2;
        const radialGradient = ctx.createRadialGradient(
          centerX, centerY, 0,
          centerX, centerY, ctx.canvas.width * 0.8
        );
        radialGradient.addColorStop(0, 'rgba(30, 30, 30, 0.15)');
        radialGradient.addColorStop(1, 'rgba(0, 0, 0, 0)');

        ctx.fillStyle = gradient;
        ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);
        ctx.fillStyle = radialGradient;
        ctx.fillRect(0, 0, ctx.canvas.width, ctx.canvas.height);

        return 'rgba(0,0,0,0)';
      }
      default:
        return '#000000';
    }
  }

  private calculateCurrentZoomState(
    currentTime: number,
    segment: VideoSegment,
    viewW: number,
    viewH: number
  ): ZoomKeyframe {
    const state = this.calculateCurrentZoomStateInternal(currentTime, segment, viewW, viewH);
    this.lastCalculatedState = state;
    return state;
  }

  private calculateCurrentZoomStateInternal(
    currentTime: number,
    segment: VideoSegment,
    viewW: number,
    viewH: number
  ): ZoomKeyframe {
    if (segment.smoothMotionPath && segment.smoothMotionPath.length > 0) {
      const path = segment.smoothMotionPath;
      const idx = path.findIndex((p: any) => p.time >= currentTime);
      let cam = { x: viewW / 2, y: viewH / 2, zoom: 1.0 };

      if (idx === -1) {
        const last = path[path.length - 1];
        cam = { x: last.x, y: last.y, zoom: last.zoom };
      } else if (idx === 0) {
        const first = path[0];
        cam = { x: first.x, y: first.y, zoom: first.zoom };
      } else {
        const p1 = path[idx - 1];
        const p2 = path[idx];
        const t = (currentTime - p1.time) / (p2.time - p1.time);
        cam = {
          x: p1.x + (p2.x - p1.x) * t,
          y: p1.y + (p2.y - p1.y) * t,
          zoom: p1.zoom + (p2.zoom - p1.zoom) * t
        };
      }

      if (segment.zoomInfluencePoints && segment.zoomInfluencePoints.length > 0) {
        const points = segment.zoomInfluencePoints;
        let influence = 1.0;
        const iIdx = points.findIndex((p: { time: number }) => p.time >= currentTime);

        if (iIdx === -1) {
          influence = points[points.length - 1].value;
        } else if (iIdx === 0) {
          influence = points[0].value;
        } else {
          const ip1 = points[iIdx - 1];
          const ip2 = points[iIdx];
          const it = (currentTime - ip1.time) / (ip2.time - ip1.time);
          const cosT = (1 - Math.cos(it * Math.PI)) / 2;
          influence = ip1.value * (1 - cosT) + ip2.value * cosT;
        }

        cam.zoom = 1.0 + (cam.zoom - 1.0) * influence;
        cam.x = (viewW / 2) + (cam.x - (viewW / 2)) * influence;
        cam.y = (viewH / 2) + (cam.y - (viewH / 2)) * influence;
      }

      let resultState: ZoomKeyframe = {
        time: currentTime,
        duration: 0,
        zoomFactor: cam.zoom,
        positionX: cam.x / viewW,
        positionY: cam.y / viewH,
        easingType: 'linear'
      };

      if (segment.zoomKeyframes && segment.zoomKeyframes.length > 0) {
        const WINDOW = 1.5;
        const nearby = segment.zoomKeyframes
          .map((kf: ZoomKeyframe) => ({ kf, dist: Math.abs(kf.time - currentTime) }))
          .filter((item: { kf: ZoomKeyframe; dist: number }) => item.dist < WINDOW)
          .sort((a: { dist: number }, b: { dist: number }) => a.dist - b.dist)[0];

        if (nearby) {
          const ratio = nearby.dist / WINDOW;
          const weight = (1 + Math.cos(ratio * Math.PI)) / 2;
          resultState.zoomFactor = resultState.zoomFactor * (1 - weight) + nearby.kf.zoomFactor * weight;
          resultState.positionX = resultState.positionX * (1 - weight) + nearby.kf.positionX * weight;
          resultState.positionY = resultState.positionY * (1 - weight) + nearby.kf.positionY * weight;
        }
      }

      return resultState;
    }

    const sortedKeyframes = [...segment.zoomKeyframes].sort((a: ZoomKeyframe, b: ZoomKeyframe) => a.time - b.time);
    if (sortedKeyframes.length === 0) return this.DEFAULT_STATE;

    const nextKeyframe = sortedKeyframes.find(k => k.time > currentTime);
    const prevKeyframe = [...sortedKeyframes].reverse().find(k => k.time <= currentTime);
    const TRANSITION_DURATION = 1.0;

    if (prevKeyframe && nextKeyframe && (nextKeyframe.time - prevKeyframe.time) <= TRANSITION_DURATION) {
      const progress = (currentTime - prevKeyframe.time) / (nextKeyframe.time - prevKeyframe.time);
      const easedProgress = this.easeOutCubic(Math.min(1, Math.max(0, progress)));
      return {
        time: currentTime,
        duration: nextKeyframe.time - prevKeyframe.time,
        zoomFactor: prevKeyframe.zoomFactor + (nextKeyframe.zoomFactor - prevKeyframe.zoomFactor) * easedProgress,
        positionX: prevKeyframe.positionX + (nextKeyframe.positionX - prevKeyframe.positionX) * easedProgress,
        positionY: prevKeyframe.positionY + (nextKeyframe.positionY - prevKeyframe.positionY) * easedProgress,
        easingType: 'easeOut' as const
      };
    }

    if (nextKeyframe) {
      const timeToNext = nextKeyframe.time - currentTime;
      if (timeToNext <= TRANSITION_DURATION) {
        const progress = (TRANSITION_DURATION - timeToNext) / TRANSITION_DURATION;
        const easedProgress = this.easeOutCubic(Math.min(1, Math.max(0, progress)));
        const startState = prevKeyframe || this.DEFAULT_STATE;
        return {
          time: currentTime,
          duration: TRANSITION_DURATION,
          zoomFactor: startState.zoomFactor + (nextKeyframe.zoomFactor - startState.zoomFactor) * easedProgress,
          positionX: startState.positionX + (nextKeyframe.positionX - startState.positionX) * easedProgress,
          positionY: startState.positionY + (nextKeyframe.positionY - startState.positionY) * easedProgress,
          easingType: 'easeOut' as const
        };
      }
    }

    if (prevKeyframe) return prevKeyframe;
    return this.DEFAULT_STATE;
  }

  private easeOutCubic(x: number): number {
    return 1 - Math.pow(1 - x, 3);
  }

  private catmullRomInterpolate(p0: number, p1: number, p2: number, p3: number, t: number): number {
    const t2 = t * t;
    const t3 = t2 * t;
    return 0.5 * (
      (2 * p1) +
      (-p0 + p2) * t +
      (2 * p0 - 5 * p1 + 4 * p2 - p3) * t2 +
      (-p0 + 3 * p1 - 3 * p2 + p3) * t3
    );
  }

  private smoothMousePositions(positions: MousePosition[], targetFps: number = 120): MousePosition[] {
    if (positions.length < 4) return positions;
    const smoothed: MousePosition[] = [];

    for (let i = 0; i < positions.length - 3; i++) {
      const p0 = positions[i];
      const p1 = positions[i + 1];
      const p2 = positions[i + 2];
      const p3 = positions[i + 3];

      const segmentDuration = p2.timestamp - p1.timestamp;
      const numFrames = Math.ceil(segmentDuration * targetFps);

      for (let frame = 0; frame < numFrames; frame++) {
        const t = frame / numFrames;
        const timestamp = p1.timestamp + (segmentDuration * t);
        const x = this.catmullRomInterpolate(p0.x, p1.x, p2.x, p3.x, t);
        const y = this.catmullRomInterpolate(p0.y, p1.y, p2.y, p3.y, t);
        const isClicked = Boolean(p1.isClicked || p2.isClicked);
        const cursor_type = t < 0.5 ? p1.cursor_type : p2.cursor_type;
        smoothed.push({ x, y, timestamp, isClicked, cursor_type });
      }
    }

    const windowSize = ((this.backgroundConfig?.cursorSmoothness || 5) * 2) + 1;
    const passes = Math.ceil(windowSize / 2);
    let currentSmoothed = smoothed;

    for (let pass = 0; pass < passes; pass++) {
      const passSmoothed: MousePosition[] = [];
      for (let i = 0; i < currentSmoothed.length; i++) {
        let sumX = 0;
        let sumY = 0;
        let totalWeight = 0;
        const cursor_type = currentSmoothed[i].cursor_type;

        for (let j = Math.max(0, i - windowSize); j <= Math.min(currentSmoothed.length - 1, i + windowSize); j++) {
          const distance = Math.abs(i - j);
          const weight = Math.exp(-distance * (0.5 / windowSize));
          sumX += currentSmoothed[j].x * weight;
          sumY += currentSmoothed[j].y * weight;
          totalWeight += weight;
        }

        passSmoothed.push({
          x: sumX / totalWeight,
          y: sumY / totalWeight,
          timestamp: currentSmoothed[i].timestamp,
          isClicked: currentSmoothed[i].isClicked,
          cursor_type
        });
      }
      currentSmoothed = passSmoothed;
    }

    const threshold = 0.5 / (windowSize / 2);
    let lastSignificantPos = currentSmoothed[0];
    const finalSmoothed = [lastSignificantPos];

    for (let i = 1; i < currentSmoothed.length; i++) {
      const current = currentSmoothed[i];
      const distance = Math.sqrt(
        Math.pow(current.x - lastSignificantPos.x, 2) +
        Math.pow(current.y - lastSignificantPos.y, 2)
      );

      if (distance > threshold || current.isClicked !== lastSignificantPos.isClicked) {
        finalSmoothed.push(current);
        lastSignificantPos = current;
      } else {
        finalSmoothed.push({
          ...lastSignificantPos,
          timestamp: current.timestamp
        });
      }
    }

    return finalSmoothed;
  }

  private interpolateCursorPosition(
    currentTime: number,
    mousePositions: MousePosition[],
  ): { x: number; y: number; isClicked: boolean; cursor_type: string } | null {
    if (mousePositions.length === 0) return null;

    if (!this.hasLoggedPositions) {
      this.hasLoggedPositions = true;
    }

    if (!this.smoothedPositions || this.smoothedPositions.length === 0) {
      this.smoothedPositions = this.smoothMousePositions(mousePositions);
    }

    const positions = this.smoothedPositions;
    const exactMatch = positions.find((pos: MousePosition) => Math.abs(pos.timestamp - currentTime) < 0.001);
    if (exactMatch) {
      return {
        x: exactMatch.x,
        y: exactMatch.y,
        isClicked: Boolean(exactMatch.isClicked),
        cursor_type: exactMatch.cursor_type || 'default'
      };
    }

    const nextIndex = positions.findIndex((pos: MousePosition) => pos.timestamp > currentTime);
    if (nextIndex === -1) {
      const last = positions[positions.length - 1];
      return {
        x: last.x,
        y: last.y,
        isClicked: Boolean(last.isClicked),
        cursor_type: last.cursor_type || 'default'
      };
    }

    if (nextIndex === 0) {
      const first = positions[0];
      return {
        x: first.x,
        y: first.y,
        isClicked: Boolean(first.isClicked),
        cursor_type: first.cursor_type || 'default'
      };
    }

    const prev = positions[nextIndex - 1];
    const next = positions[nextIndex];
    const t = (currentTime - prev.timestamp) / (next.timestamp - prev.timestamp);

    return {
      x: prev.x + (next.x - prev.x) * t,
      y: prev.y + (next.y - prev.y) * t,
      isClicked: Boolean(prev.isClicked || next.isClicked),
      cursor_type: next.cursor_type || 'default'
    };
  }

  private drawMouseCursor(
    ctx: CanvasRenderingContext2D,
    x: number,
    y: number,
    isClicked: boolean,
    scale: number = 2,
    cursorType: string = 'default'
  ) {
    ctx.save();
    this.drawCursorShape(ctx, x, y, isClicked, scale, cursorType);
    ctx.restore();
  }

  private drawCursorShape(
    ctx: CanvasRenderingContext2D,
    x: number,
    y: number,
    _isClicked: boolean,
    scale: number = 2,
    cursorType: string
  ) {
    const lowerType = cursorType.toLowerCase();
    ctx.save();
    ctx.translate(x, y);
    ctx.scale(scale, scale);
    ctx.scale(this.currentSquishScale, this.currentSquishScale);

    switch (lowerType) {
      case 'text': {
        ctx.translate(-6, -8);
        const ibeam = new Path2D(`
          M 2 0 L 10 0 L 10 2 L 7 2 L 7 14 L 10 14 L 10 16 L 2 16 L 2 14 L 5 14 L 5 2 L 2 2 Z
        `);
        ctx.strokeStyle = 'white';
        ctx.lineWidth = 1.5;
        ctx.stroke(ibeam);
        ctx.fillStyle = 'black';
        ctx.fill(ibeam);
        break;
      }

      case 'pointer': {
        let imgWidth = 24, imgHeight = 24;
        if (this.pointerImage.complete && this.pointerImage.naturalWidth > 0) {
          imgWidth = this.pointerImage.naturalWidth;
          imgHeight = this.pointerImage.naturalHeight;
        }
        const offsetX = 8;
        const offsetY = 16;
        ctx.translate(-imgWidth / 2 + offsetX, -imgHeight / 2 + offsetY);
        ctx.drawImage(this.pointerImage, 0, 0, imgWidth, imgHeight);
        break;
      }

      default: {
        ctx.translate(-8, -5);
        const mainArrow = new Path2D('M 8.2 4.9 L 19.8 16.5 L 13 16.5 L 12.6 16.6 L 8.2 20.9 Z');
        const clickIndicator = new Path2D('M 17.3 21.6 L 13.7 23.1 L 9 12 L 12.7 10.5 Z');
        ctx.strokeStyle = 'white';
        ctx.lineWidth = 1.5;
        ctx.stroke(mainArrow);
        ctx.stroke(clickIndicator);
        ctx.fillStyle = 'black';
        ctx.fill(mainArrow);
        ctx.fill(clickIndicator);
        break;
      }
    }
    ctx.restore();
  }

  private drawTextOverlay(
    ctx: CanvasRenderingContext2D,
    textSegment: TextSegment,
    width: number,
    height: number
  ) {
    ctx.save();
    ctx.font = `${textSegment.style.fontSize}px sans-serif`;
    ctx.fillStyle = textSegment.style.color;
    ctx.textAlign = 'center';

    const x = (textSegment.style.x / 100) * width;
    const y = (textSegment.style.y / 100) * height;

    const metrics = ctx.measureText(textSegment.text);
    const textHeight = textSegment.style.fontSize;
    const hitArea = {
      x: x - metrics.width / 2 - 10,
      y: y - textHeight - 10,
      width: metrics.width + 20,
      height: textHeight + 20
    };

    if (this.draggedTextId === textSegment.id) {
      ctx.fillStyle = 'rgba(0, 121, 211, 0.1)';
      ctx.fillRect(hitArea.x, hitArea.y, hitArea.width, hitArea.height);
    }

    ctx.shadowColor = 'rgba(0,0,0,0.7)';
    ctx.shadowBlur = 6;
    ctx.shadowOffsetX = 2;
    ctx.shadowOffsetY = 2;
    ctx.fillStyle = textSegment.style.color;
    ctx.fillText(textSegment.text, x, y);

    ctx.restore();
    return hitArea;
  }

  public handleMouseDown(e: MouseEvent, segment: VideoSegment, canvas: HTMLCanvasElement) {
    const rect = canvas.getBoundingClientRect();
    const x = (e.clientX - rect.left) * (canvas.width / rect.width);
    const y = (e.clientY - rect.top) * (canvas.height / rect.height);

    for (const text of segment.textSegments) {
      const ctx = canvas.getContext('2d');
      if (!ctx) return;
      const hitArea = this.drawTextOverlay(ctx, text, canvas.width, canvas.height);
      if (x >= hitArea.x && x <= hitArea.x + hitArea.width &&
        y >= hitArea.y && y <= hitArea.y + hitArea.height) {
        this.isDraggingText = true;
        this.draggedTextId = text.id;
        this.dragOffset.x = x - (text.style.x / 100 * canvas.width);
        this.dragOffset.y = y - (text.style.y / 100 * canvas.height);
        canvas.style.cursor = 'move';
        break;
      }
    }
  }

  public handleMouseMove(
    e: MouseEvent,
    _segment: VideoSegment,
    canvas: HTMLCanvasElement,
    onTextMove: (id: string, x: number, y: number) => void
  ) {
    if (!this.isDraggingText || !this.draggedTextId) return;

    const rect = canvas.getBoundingClientRect();
    const x = (e.clientX - rect.left) * (canvas.width / rect.width);
    const y = (e.clientY - rect.top) * (canvas.height / rect.height);

    const newX = Math.max(0, Math.min(100, ((x - this.dragOffset.x) / canvas.width) * 100));
    const newY = Math.max(0, Math.min(100, ((y - this.dragOffset.y) / canvas.height) * 100));

    onTextMove(this.draggedTextId, newX, newY);
  }

  public handleMouseUp(canvas: HTMLCanvasElement) {
    this.isDraggingText = false;
    this.draggedTextId = null;
    canvas.style.cursor = 'default';
  }
}

export const videoRenderer = new VideoRenderer();
</file>

<file path="src/overlay/favorite_bubble/panel.rs">
use super::html::{escape_js, generate_panel_css, generate_panel_html, get_favorite_presets_html};
use super::render::update_bubble_visual;
use super::state::*;
use super::utils::HwndWrapper;
use crate::APP;
use std::sync::atomic::Ordering;
use windows::core::w;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmExtendFrameIntoClientArea, DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE,
};
use windows::Win32::Graphics::Gdi::HBRUSH;
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::HiDpi::GetDpiForWindow;
use windows::Win32::UI::WindowsAndMessaging::{
    CreateWindowExW, DefWindowProcW, DestroyWindow, FindWindowW, GetClientRect,
    GetForegroundWindow, GetSystemMetrics, GetWindowRect, LoadCursorW, PostMessageW,
    RegisterClassW, SendMessageW, SetForegroundWindow, SetWindowPos, ShowWindow, HTCAPTION,
    IDC_ARROW, SM_CXSCREEN, SWP_NOACTIVATE, SWP_NOCOPYBITS, SWP_NOSIZE, SWP_NOZORDER, SW_HIDE,
    SW_SHOWNOACTIVATE, WM_ACTIVATE, WM_APP, WM_CLOSE, WM_HOTKEY, WM_KILLFOCUS, WM_NCCALCSIZE,
    WM_NCLBUTTONDOWN, WNDCLASSW, WS_EX_LAYERED, WS_EX_NOACTIVATE, WS_EX_TOOLWINDOW, WS_EX_TOPMOST,
    WS_POPUP, WS_VISIBLE,
};
use wry::{Rect, WebContext, WebViewBuilder};

// For focus restoration
use windows::Win32::UI::Input::KeyboardAndMouse::SetFocus;

const WM_REFRESH_PANEL: u32 = WM_APP + 42;
pub const WM_FORCE_SHOW_PANEL: u32 = WM_APP + 43;

pub fn show_panel(bubble_hwnd: HWND) {
    if IS_EXPANDED.load(Ordering::SeqCst) {
        return;
    }

    // CRITICAL: Save the current foreground window BEFORE showing the panel.
    // The WebView will steal focus when clicked, but we need to restore focus
    // to the original window for text-select presets to work (they send Ctrl+C).
    unsafe {
        let fg = GetForegroundWindow();
        if !fg.is_invalid() {
            LAST_FOREGROUND_HWND.store(fg.0 as isize, Ordering::SeqCst);
        }
    }

    // Ensure window AND webview exist (webview creation is deferred to here to avoid focus steal)
    let just_created = ensure_panel_created(bubble_hwnd, true);

    let panel_val = PANEL_HWND.load(Ordering::SeqCst);
    if panel_val == 0 {
        return;
    }

    unsafe {
        let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);

        // CRITICAL: Set state to true BEFORE refreshing or showing,
        // so that any incoming 'close_now' IPC messages (from a previous close)
        // will see that we are now EXPANDED and ignore the hide command.
        IS_EXPANDED.store(true, Ordering::SeqCst);

        if just_created {
            // If just created, it might take a moment for WebView2 to be ready for scripts.
            // We show it immediately, but trigger a refresh after a small delay to ensure content & animations.
            let _ = ShowWindow(panel_hwnd, SW_SHOWNOACTIVATE);

            std::thread::spawn(move || {
                std::thread::sleep(std::time::Duration::from_millis(600));
                let panel_val = PANEL_HWND.load(Ordering::SeqCst);
                if panel_val != 0 {
                    let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);
                    let _ = PostMessageW(Some(panel_hwnd), WM_REFRESH_PANEL, WPARAM(0), LPARAM(0));
                }
            });
        } else if let Ok(app) = APP.lock() {
            let is_dark = match app.config.theme_mode {
                crate::config::ThemeMode::Dark => true,
                crate::config::ThemeMode::Light => false,
                crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
            };

            refresh_panel_layout_and_content(
                bubble_hwnd,
                panel_hwnd,
                &app.config.presets,
                &app.config.ui_language,
                is_dark,
            );
        }

        update_bubble_visual(bubble_hwnd);
    }
}

pub fn update_favorites_panel() {
    // Send a message to the Bubble Window (dedicated thread) to handle the update.
    // This prevents creating a duplicate/desync'd WebView on the main thread.
    let bubble_val = BUBBLE_HWND.load(Ordering::SeqCst);
    if bubble_val != 0 {
        let bubble_hwnd = HWND(bubble_val as *mut std::ffi::c_void);
        unsafe {
            let _ = PostMessageW(Some(bubble_hwnd), WM_FORCE_SHOW_PANEL, WPARAM(0), LPARAM(0));
        }
    }
}

/// Ensure the panel window exists.
/// If `with_webview` is true, also create the WebView2 (deferred to avoid focus stealing during warmup).
pub fn ensure_panel_created(bubble_hwnd: HWND, with_webview: bool) -> bool {
    let mut created = false;
    let panel_exists = PANEL_HWND.load(Ordering::SeqCst) != 0;

    if !panel_exists {
        create_panel_window_internal(bubble_hwnd);
    }

    // Create WebView2 only when requested AND it doesn't exist yet
    if with_webview {
        let has_webview = PANEL_WEBVIEW.with(|wv| wv.borrow().is_some());
        if !has_webview {
            let panel_val = PANEL_HWND.load(Ordering::SeqCst);
            if panel_val != 0 {
                let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);
                create_panel_webview(panel_hwnd);
                created = true;
            }
        }
    }
    created
}

// Triggers the animation-based close
pub fn close_panel() {
    // Set expanded to false immediately to allow re-opening
    if !IS_EXPANDED.swap(false, Ordering::SeqCst) {
        return;
    }

    let webview_exists = PANEL_WEBVIEW.with(|wv| {
        if let Some(webview) = wv.borrow().as_ref() {
            let _ = webview.evaluate_script("if(window.closePanel) window.closePanel();");
            true
        } else {
            false
        }
    });

    if !webview_exists {
        close_panel_internal();
    }
}

// Actually hides the window
fn close_panel_internal() {
    // CRITICAL: If IS_EXPANDED was set to true (e.g. by a quick click to re-open),
    // do NOT hide the window.
    if IS_EXPANDED.load(Ordering::SeqCst) {
        return;
    }

    let panel_val = PANEL_HWND.load(Ordering::SeqCst);
    if panel_val != 0 {
        unsafe {
            let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);
            let _ = ShowWindow(panel_hwnd, SW_HIDE);
        }
    }

    // Update bubble visual
    let bubble_val = BUBBLE_HWND.load(Ordering::SeqCst);
    if bubble_val != 0 {
        let bubble_hwnd = HWND(bubble_val as *mut std::ffi::c_void);
        update_bubble_visual(bubble_hwnd);
    }

    // Save position
    save_bubble_position();
}

// Actually destroys the panel (cleanup)
pub fn destroy_panel() {
    let panel_val = PANEL_HWND.swap(0, Ordering::SeqCst);
    if panel_val != 0 {
        PANEL_WEBVIEW.with(|wv| {
            *wv.borrow_mut() = None;
        });

        unsafe {
            let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);
            let _ = DestroyWindow(panel_hwnd);
        }
    }
}

pub fn move_panel_to_bubble(bubble_x: i32, bubble_y: i32) {
    let panel_val = PANEL_HWND.load(Ordering::SeqCst);
    if panel_val == 0 {
        return;
    }

    unsafe {
        let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);
        let mut panel_rect = RECT::default();
        let _ = GetWindowRect(panel_hwnd, &mut panel_rect);
        let panel_w = panel_rect.right - panel_rect.left;
        let panel_h = panel_rect.bottom - panel_rect.top;

        let screen_w = GetSystemMetrics(SM_CXSCREEN);
        let bubble_size = BUBBLE_SIZE.load(Ordering::SeqCst);
        let (panel_x, panel_y) = if bubble_x > screen_w / 2 {
            (
                bubble_x - panel_w - 8,
                bubble_y - panel_h / 2 + bubble_size / 2,
            )
        } else {
            (
                bubble_x + bubble_size + 8,
                bubble_y - panel_h / 2 + bubble_size / 2,
            )
        };

        let _ = SetWindowPos(
            panel_hwnd,
            None,
            panel_x,
            panel_y.max(10),
            0,
            0,
            SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
        );
    }
}

fn create_panel_window_internal(_bubble_hwnd: HWND) {
    unsafe {
        let instance = GetModuleHandleW(None).unwrap_or_default();
        let class_name = w!("SGTFavoritePanel");

        REGISTER_PANEL_CLASS.call_once(|| {
            let wc = WNDCLASSW {
                lpfnWndProc: Some(panel_wnd_proc),
                hInstance: instance.into(),
                lpszClassName: class_name,
                hCursor: LoadCursorW(None, IDC_ARROW).unwrap_or_default(),
                hbrBackground: HBRUSH(std::ptr::null_mut()),
                ..Default::default()
            };
            RegisterClassW(&wc);
        });

        let panel_hwnd = CreateWindowExW(
            WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
            class_name,
            w!("FavPanel"),
            WS_POPUP | WS_VISIBLE,
            -4000,
            -4000,
            2000, // Dummy width (Large to avoid multi-column hit-test clipping)
            2000, // Dummy height (Large to avoid hit-test clipping)
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        if !panel_hwnd.is_invalid() {
            PANEL_HWND.store(panel_hwnd.0 as isize, Ordering::SeqCst);

            // Windows 11 Rounded Corners - Disable native rounding
            let corner_pref = 1u32; // DWMWCP_DONOTROUND
            let _ = DwmSetWindowAttribute(
                panel_hwnd,
                DWMWA_WINDOW_CORNER_PREFERENCE,
                std::ptr::addr_of!(corner_pref) as *const _,
                std::mem::size_of_val(&corner_pref) as u32,
            );

            // Extend frame for transparency
            let margins = MARGINS {
                cxLeftWidth: -1,
                cxRightWidth: -1,
                cyTopHeight: -1,
                cyBottomHeight: -1,
            };
            let _ = DwmExtendFrameIntoClientArea(panel_hwnd, &margins);

            // NOTE: WebView2 creation is deferred to show_panel()
        }
    }
}

unsafe fn refresh_panel_layout_and_content(
    bubble_hwnd: HWND,
    panel_hwnd: HWND,
    presets: &[crate::config::Preset],
    lang: &str,
    is_dark: bool,
) {
    let mut bubble_rect = RECT::default();
    let _ = GetWindowRect(bubble_hwnd, &mut bubble_rect);

    let height_per_item = 48;

    let favs: Vec<_> = presets
        .iter()
        .filter(|p| p.is_favorite && !p.is_upcoming)
        .collect();

    let fav_count = favs.len();
    let num_cols = if fav_count > 15 {
        (fav_count + 14) / 15
    } else {
        1
    };

    let items_per_col = if fav_count > 0 {
        (fav_count + num_cols - 1) / num_cols
    } else {
        0
    };

    // Buffer for padding (no bounce overshoot with smooth easing)
    let buffer_x = 40;
    let buffer_y = 60;

    let panel_width = if fav_count == 0 {
        (PANEL_WIDTH as i32 * 2).max(320)
    } else {
        (PANEL_WIDTH as usize * num_cols) as i32 + buffer_x
    };

    // Height for the keep-open toggle row
    let keep_open_row_height = 40;

    let panel_height = if fav_count == 0 {
        80 + buffer_y + keep_open_row_height
    } else {
        (items_per_col as i32 * height_per_item) + 24 + buffer_y + keep_open_row_height + 100
        // Extra buffer
    };
    let panel_height = panel_height.max(50);

    // Get DPI scale
    let dpi = unsafe { GetDpiForWindow(panel_hwnd) };
    let scale = if dpi == 0 { 1.0 } else { dpi as f32 / 96.0 };

    let panel_width_physical = (panel_width as f32 * scale).ceil() as i32;
    let panel_height_physical = (panel_height as f32 * scale).ceil() as i32;

    let screen_w = GetSystemMetrics(SM_CXSCREEN);
    let bubble_size = BUBBLE_SIZE.load(Ordering::SeqCst);

    let (panel_x, panel_y, side) = if bubble_rect.left > screen_w / 2 {
        (
            bubble_rect.left - panel_width_physical - 4, // Closer to bubble
            bubble_rect.top - panel_height_physical / 2 + bubble_size / 2,
            "right",
        )
    } else {
        (
            bubble_rect.right + 4,
            bubble_rect.top - panel_height_physical / 2 + bubble_size / 2,
            "left",
        )
    };

    // Use the actual clamped panel_y for positioning
    let actual_panel_y = panel_y.max(10);

    let _ = SetWindowPos(
        panel_hwnd,
        None,
        panel_x,
        actual_panel_y,
        panel_width_physical,
        panel_height_physical,
        SWP_NOZORDER | SWP_NOACTIVATE | SWP_NOCOPYBITS,
    );

    // Explicitly show the window to ensure it's visible after a SW_HIDE
    let _ = ShowWindow(panel_hwnd, SW_SHOWNOACTIVATE);

    PANEL_WEBVIEW.with(|wv| {
        if let Some(webview) = wv.borrow().as_ref() {
            let _ = webview.set_bounds(Rect {
                position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                    panel_width_physical as u32,
                    panel_height_physical as u32,
                )),
            });
        }
    });

    // Check if theme changed and inject new CSS if needed
    let last_dark = LAST_THEME_IS_DARK.load(Ordering::SeqCst);
    if last_dark != is_dark {
        let new_css = generate_panel_css(is_dark);
        let escaped_css = escape_js(&new_css); // Reuse escape_js which escapes quotes and newlines
                                               // We need to be careful with escape_js for CSS.
                                               // Simple escape_js replaces " with \" and \n with \\n.
                                               // For inline script, we need to make sure we don't break the string.
        PANEL_WEBVIEW.with(|wv| {
            if let Some(webview) = wv.borrow().as_ref() {
                let script = format!(
                    "document.querySelector('style').innerHTML = \"{}\";",
                    escaped_css
                );
                let _ = webview.evaluate_script(&script);
            }
        });
        LAST_THEME_IS_DARK.store(is_dark, Ordering::SeqCst);
    }

    let favorites_html = get_favorite_presets_html(presets, lang, is_dark);
    update_panel_content(&favorites_html, num_cols);

    // Pass side and bubble center relative to panel to JS
    // Use actual_panel_y (clamped) to match the real window position
    let bx = if side == "left" {
        -(bubble_size / 2) - 4
    } else {
        (panel_width_physical / scale as i32) + (bubble_size / 2) + 4
    };
    let by = (bubble_rect.top + bubble_size / 2) - actual_panel_y;

    PANEL_WEBVIEW.with(|wv| {
        if let Some(webview) = wv.borrow().as_ref() {
            let script = format!(
                "if(window.setSide) window.setSide('{}'); if(window.animateIn) window.animateIn({}, {});",
                side, bx, by
            );
            let _ = webview.evaluate_script(&script);
        }
    });
}

fn create_panel_webview(panel_hwnd: HWND) {
    crate::log_info!("[BubblePanel] Creating WebView for HWND: {:?}", panel_hwnd);
    let mut rect = RECT::default();
    unsafe {
        let _ = GetClientRect(panel_hwnd, &mut rect);
    }

    let html = if let Ok(app) = APP.lock() {
        let is_dark = match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        };
        // Update static state to match initial generation
        LAST_THEME_IS_DARK.store(is_dark, Ordering::SeqCst);
        generate_panel_html(
            &app.config.presets,
            &app.config.ui_language,
            is_dark,
            app.config.favorites_keep_open,
        )
    } else {
        String::new()
    };

    let wrapper = HwndWrapper(panel_hwnd);

    PANEL_WEB_CONTEXT.with(|ctx| {
        if ctx.borrow().is_none() {
            let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
            *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
        }
    });

    let result = {
        // LOCK SCOPE: Serialized build to prevent resource contention
        let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
        crate::log_info!(
            "[BubblePanel] Acquired init lock. Building for HWND: {:?}...",
            panel_hwnd
        );

        let build_res = PANEL_WEB_CONTEXT.with(|ctx| {
            let mut ctx_ref = ctx.borrow_mut();
            let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                WebViewBuilder::new_with_web_context(web_ctx)
            } else {
                WebViewBuilder::new()
            };
            let builder = crate::overlay::html_components::font_manager::configure_webview(builder);

            // Store HTML in font server and get URL for same-origin font loading
            let page_url =
                crate::overlay::html_components::font_manager::store_html_page(html.clone())
                    .unwrap_or_else(|| format!("data:text/html,{}", urlencoding::encode(&html)));

            builder
                .with_bounds(Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                        (rect.right - rect.left) as u32,
                        (rect.bottom - rect.top) as u32,
                    )),
                })
                .with_url(&page_url)
                .with_transparent(true)
                .with_ipc_handler(move |msg: wry::http::Request<String>| {
                    let body = msg.body();

                    if body == "drag" {
                        unsafe {
                            use windows::Win32::UI::Input::KeyboardAndMouse::ReleaseCapture;
                            let _ = ReleaseCapture();
                            SendMessageW(
                                panel_hwnd,
                                WM_NCLBUTTONDOWN,
                                Some(WPARAM(HTCAPTION as usize)),
                                Some(LPARAM(0)),
                            );
                        }
                    } else if body == "close" {
                        close_panel();
                    } else if body == "close_now" {
                        close_panel_internal();
                    } else if body.starts_with("trigger:") {
                        if let Ok(idx) = body[8..].parse::<usize>() {
                            // trigger() in JS starts the close animation and will send close_now when done.
                            // We must set IS_EXPANDED to false so close_panel_internal (called by close_now)
                            // actually hides the window. We DON'T call close_panel_internal here to allow animation.
                            IS_EXPANDED.store(false, Ordering::SeqCst);
                            trigger_preset(idx);
                        }
                    } else if body.starts_with("trigger_only:") {
                        // Keep Open mode: trigger preset without closing panel
                        if let Ok(idx) = body[13..].parse::<usize>() {
                            trigger_preset(idx);
                        }
                    } else if body.starts_with("trigger_continuous:") {
                        if let Ok(idx) = body[19..].parse::<usize>() {
                            IS_EXPANDED.store(false, Ordering::SeqCst);
                            activate_continuous_from_panel(idx);
                            trigger_preset(idx);
                        }
                    } else if body.starts_with("trigger_continuous_only:") {
                        if let Ok(idx) = body[24..].parse::<usize>() {
                            activate_continuous_from_panel(idx);
                            trigger_preset(idx);
                        }
                    } else if body.starts_with("set_keep_open:") {
                        if let Ok(val) = body[14..].parse::<u32>() {
                            if let Ok(mut app) = APP.lock() {
                                app.config.favorites_keep_open = val == 1;
                                crate::config::save_config(&app.config);
                            }
                        }
                    } else if body.starts_with("resize:") {
                        if let Ok(h) = body[7..].parse::<i32>() {
                            resize_panel_height(h);
                        }
                    } else if body == "increase_size" {
                        if let Ok(mut app) = APP.lock() {
                            let new_size = (app.config.favorite_bubble_size + 8).min(80);
                            app.config.favorite_bubble_size = new_size;
                            crate::config::save_config(&app.config);
                            BUBBLE_SIZE.store(new_size as i32, Ordering::SeqCst);
                        }
                        update_favorites_panel();
                    } else if body == "decrease_size" {
                        if let Ok(mut app) = APP.lock() {
                            let new_size =
                                (app.config.favorite_bubble_size.saturating_sub(8)).max(24);
                            app.config.favorite_bubble_size = new_size;
                            crate::config::save_config(&app.config);
                            BUBBLE_SIZE.store(new_size as i32, Ordering::SeqCst);
                        }
                        update_favorites_panel();
                    }
                })
                .with_background_color((0, 0, 0, 0))
                .build(&wrapper)
        });
        crate::log_info!(
            "[BubblePanel] Build finished. Status: {}",
            if build_res.is_ok() { "OK" } else { "ERR" }
        );
        build_res
    };

    if let Ok(webview) = result {
        crate::log_info!("[BubblePanel] WebView success for HWND: {:?}", panel_hwnd);
        PANEL_WEBVIEW.with(|wv| {
            *wv.borrow_mut() = Some(webview);
        });
    } else if let Err(e) = result {
        crate::log_info!(
            "[BubblePanel] WebView FAILED for HWND: {:?}, Error: {:?}",
            panel_hwnd,
            e
        );
    }
}

unsafe extern "system" fn panel_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_CLOSE => {
            close_panel();
            LRESULT(0)
        }
        WM_KILLFOCUS => LRESULT(0),
        WM_ACTIVATE => {
            if wparam.0 == 0 {
                // Window deactivated logic (optional)
            }
            LRESULT(0)
        }
        WM_REFRESH_PANEL => {
            let bubble_hwnd = HWND(BUBBLE_HWND.load(Ordering::SeqCst) as *mut std::ffi::c_void);

            if let Ok(app) = APP.lock() {
                let is_dark = match app.config.theme_mode {
                    crate::config::ThemeMode::Dark => true,
                    crate::config::ThemeMode::Light => false,
                    crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
                };

                // Set expanded to true so it moves with bubble
                IS_EXPANDED.store(true, Ordering::SeqCst);

                refresh_panel_layout_and_content(
                    bubble_hwnd,
                    hwnd,
                    &app.config.presets,
                    &app.config.ui_language,
                    is_dark,
                );
            }
            // Lock released here

            // Correctly call update_bubble_visual outside the lock
            // (update_bubble_visual internally calls is_dark_mode() which locks APP)
            update_bubble_visual(bubble_hwnd);

            LRESULT(0)
        }
        WM_NCCALCSIZE => {
            if wparam.0 != 0 {
                LRESULT(0)
            } else {
                DefWindowProcW(hwnd, msg, wparam, lparam)
            }
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

fn trigger_preset(preset_idx: usize) {
    unsafe {
        // CRITICAL: Restore focus to the original foreground window before triggering.
        // This ensures that text-select presets can send Ctrl+C to the correct window
        // (the one that had text selected before the user clicked on the bubble panel).
        let saved_fg = LAST_FOREGROUND_HWND.load(Ordering::SeqCst);
        if saved_fg != 0 {
            let fg_hwnd = HWND(saved_fg as *mut std::ffi::c_void);
            if !fg_hwnd.is_invalid() {
                // SetForegroundWindow may not always work due to Windows focus stealing prevention,
                // but SetFocus on a window that's already visible should work.
                // We use a combination approach for best results.
                let _ = SetForegroundWindow(fg_hwnd);
                let _ = SetFocus(Some(fg_hwnd));
                // Small delay to allow focus to settle before triggering the preset
                std::thread::sleep(std::time::Duration::from_millis(30));
            }
        }

        let class = w!("HotkeyListenerClass");
        let title = w!("Listener");
        let hwnd = FindWindowW(class, title).unwrap_or_default();

        if !hwnd.is_invalid() {
            let hotkey_id = (preset_idx as i32 * 1000) + 1;
            let _ = PostMessageW(Some(hwnd), WM_HOTKEY, WPARAM(hotkey_id as usize), LPARAM(0));
        }
    }
}

fn activate_continuous_from_panel(preset_idx: usize) {
    let (p_type, p_id) = {
        if let Ok(app) = APP.lock() {
            if let Some(p) = app.config.presets.get(preset_idx) {
                (p.preset_type.clone(), p.id.clone())
            } else {
                return;
            }
        } else {
            return;
        }
    };

    if crate::overlay::continuous_mode::supports_continuous_mode(&p_type) {
        // Find first hotkey name for the instruction message
        let hotkey_name = "ESC".to_string();

        crate::overlay::continuous_mode::set_pending_start(preset_idx, hotkey_name.clone());
        crate::overlay::continuous_mode::show_activation_notification(&p_id, &hotkey_name);
    }
}

pub fn save_bubble_position() {
    let bubble_val = BUBBLE_HWND.load(Ordering::SeqCst);
    if bubble_val == 0 {
        return;
    }

    unsafe {
        let bubble_hwnd = HWND(bubble_val as *mut std::ffi::c_void);
        let mut rect = RECT::default();
        let _ = GetWindowRect(bubble_hwnd, &mut rect);

        if let Ok(mut app) = APP.lock() {
            app.config.favorite_bubble_position = Some((rect.left, rect.top));
            crate::config::save_config(&app.config);
        }
    }
}

fn resize_panel_height(content_height: i32) {
    let panel_val = PANEL_HWND.load(Ordering::SeqCst);
    if panel_val == 0 {
        return;
    }

    // Add a small buffer to ensure no scrollbars appear

    unsafe {
        let panel_hwnd = HWND(panel_val as *mut std::ffi::c_void);

        // Get DPI to scale the CSS pixels (content_height) to Physical pixels
        let dpi = GetDpiForWindow(panel_hwnd);
        let scale = if dpi == 0 { 1.0 } else { dpi as f32 / 96.0 };

        // Add +100px buffer to ensure window is definitely taller than content
        // This solves the 'click-through' issue at the bottom if DPI scaling is slightly off
        let new_height_pixels = (content_height as f32 * scale).ceil() as i32 + 100;

        let mut panel_rect = RECT::default();
        let _ = GetWindowRect(panel_hwnd, &mut panel_rect);
        let current_width = panel_rect.right - panel_rect.left;
        let current_height = panel_rect.bottom - panel_rect.top;

        // Only resize if significantly different to avoid jitter loops
        if (current_height - new_height_pixels).abs() < 4 {
            return;
        }

        let bubble_val = BUBBLE_HWND.load(Ordering::SeqCst);
        let bubble_hwnd = if bubble_val != 0 {
            HWND(bubble_val as *mut std::ffi::c_void)
        } else {
            return;
        };

        let mut bubble_rect = RECT::default();
        let _ = GetWindowRect(bubble_hwnd, &mut bubble_rect);

        // Recalculate Y position to keep centered on bubble
        let screen_w = GetSystemMetrics(SM_CXSCREEN);
        let bubble_size = BUBBLE_SIZE.load(Ordering::SeqCst);
        let (_panel_x, panel_y) = if bubble_rect.left > screen_w / 2 {
            (
                bubble_rect.left - current_width - 4,
                bubble_rect.top - new_height_pixels / 2 + bubble_size / 2,
            )
        } else {
            (
                bubble_rect.right + 4,
                bubble_rect.top - new_height_pixels / 2 + bubble_size / 2,
            )
        };

        // Clamp Y
        let actual_panel_y = panel_y.max(10);

        let _ = SetWindowPos(
            panel_hwnd,
            None,
            panel_rect.left, // Keep X
            actual_panel_y,
            current_width,
            new_height_pixels,
            SWP_NOZORDER | SWP_NOACTIVATE | SWP_NOCOPYBITS,
        );

        // Update WebView bounds
        PANEL_WEBVIEW.with(|wv| {
            if let Some(webview) = wv.borrow().as_ref() {
                let _ = webview.set_bounds(Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                        current_width as u32,
                        new_height_pixels as u32,
                    )),
                });
            }
        });
    }
}

fn update_panel_content(html: &str, cols: usize) {
    PANEL_WEBVIEW.with(|wv| {
        if let Some(webview) = wv.borrow().as_ref() {
            let escaped = escape_js(html);
            let script = format!(
                "document.querySelector('.list').style.columnCount = '{}'; document.querySelector('.list').innerHTML = \"{}\"; if(window.fitText) window.fitText();",
                cols, escaped
            );
            let _ = webview.evaluate_script(&script);
        }
    });
}
</file>

<file path="src/overlay/text_input.rs">
use crate::gui::locale::LocaleText;
use raw_window_handle::{
    HandleError, HasWindowHandle, RawWindowHandle, Win32WindowHandle, WindowHandle,
};
use std::cell::RefCell;
use std::num::NonZeroIsize;
use std::sync::{Mutex, Once};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmExtendFrameIntoClientArea, DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE,
};
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::Com::{CoInitialize, CoUninitialize};
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::HiDpi::GetDpiForSystem;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebViewBuilder};

use std::sync::atomic::{AtomicBool, AtomicIsize, Ordering};

static REGISTER_INPUT_CLASS: Once = Once::new();
static INPUT_HWND: AtomicIsize = AtomicIsize::new(0);
static IS_WARMING_UP: AtomicBool = AtomicBool::new(false);
static IS_WARMED_UP: AtomicBool = AtomicBool::new(false);
static IS_SHOWING: AtomicBool = AtomicBool::new(false);

// COL_DARK_BG removed

// Global storage for submitted text (from webview IPC)
lazy_static::lazy_static! {
    static ref SUBMITTED_TEXT: Mutex<Option<String>> = Mutex::new(None);
    static ref SHOULD_CLOSE: Mutex<bool> = Mutex::new(false);
    static ref SHOULD_CLEAR_ONLY: Mutex<bool> = Mutex::new(false);

    // Config Storage (Thread-safe for persistent window)
    static ref CFG_TITLE: Mutex<String> = Mutex::new(String::new());
    static ref CFG_LANG: Mutex<String> = Mutex::new(String::new());
    static ref CFG_CANCEL: Mutex<String> = Mutex::new(String::new());
    static ref CFG_CALLBACK: Mutex<Option<Box<dyn Fn(String, HWND) + Send>>> = Mutex::new(None);
    static ref CFG_CONTINUOUS: Mutex<bool> = Mutex::new(false);

    // Cross-thread text injection (for auto-paste from transcription)
    static ref PENDING_TEXT: Mutex<Option<String>> = Mutex::new(None);
}

const WM_APP_SHOW: u32 = WM_USER + 99;
const WM_APP_SET_TEXT: u32 = WM_USER + 100; // New: trigger text injection from other threads
const WM_APP_HIDE: u32 = WM_USER + 101; // New: trigger fade out sequence

// Thread-local storage for WebView (not Send)
thread_local! {
    static TEXT_INPUT_WEBVIEW: RefCell<Option<wry::WebView>> = RefCell::new(None);
    // Shared WebContext for this thread using common data directory
    static TEXT_INPUT_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);
}

/// Wrapper for HWND to implement HasWindowHandle
struct HwndWrapper(HWND);

impl HasWindowHandle for HwndWrapper {
    fn window_handle(&self) -> std::result::Result<WindowHandle<'_>, HandleError> {
        let hwnd = self.0 .0 as isize;
        if let Some(non_zero) = NonZeroIsize::new(hwnd) {
            let mut handle = Win32WindowHandle::new(non_zero);
            handle.hinstance = None;
            let raw = RawWindowHandle::Win32(handle);
            Ok(unsafe { WindowHandle::borrow_raw(raw) })
        } else {
            Err(HandleError::Unavailable)
        }
    }
}

/// CSS for the modern text input editor
fn get_editor_css(is_dark: bool) -> String {
    let vars = if is_dark {
        r#"
        :root {
            /* Premium Dark Mode (Google UI Inspired) */
            --bg-color: rgba(32, 33, 36, 0.8);
            --text-color: #e8eaed;
            --header-text: #9aa0a6;
            --footer-text: #9aa0a6;
            --placeholder-color: #9aa0a6;
            --scrollbar-thumb: #5f6368;
            --scrollbar-thumb-hover: #80868b;
            --btn-bg: #3c4043; /* Elevated surface */
            --btn-border: rgba(255, 255, 255, 0.1);
            --mic-fill: #8ab4f8; 
            --mic-border: transparent;
            --mic-hover-bg: rgba(138, 180, 248, 0.12);
            --send-fill: #8ab4f8;
            --send-border: transparent;
            --send-hover-bg: rgba(138, 180, 248, 0.12);
            --hint-color: #9aa0a6;
            --close-hover-bg: rgba(232, 234, 237, 0.08);
            --container-border: 1px solid #3c4043;
            --container-shadow: 0 0px 16px rgba(0,0,0,0.25);
            --input-bg: #303134; /* Base surface */
            --input-border: 1px solid transparent;
            --wave-color: #8ab4f8; 
        }
        "#
    } else {
        r#"
        :root {
            /* Premium Light Mode (Google UI Inspired) */
            --bg-color: rgba(255, 255, 255, 0.75);
            --text-color: #202124;
            --header-text: #5f6368;
            --footer-text: #5f6368;
            --wave-color: #1a73e8;
            --placeholder-color: #5f6368;
            --scrollbar-thumb: #dadce0;
            --scrollbar-thumb-hover: #bdc1c6;
            --btn-bg: #ffffff; /* Elevated action button */
            --btn-border: #dadce0;
            --mic-fill: #1a73e8;
            --mic-border: transparent;
            --mic-hover-bg: rgba(26, 115, 232, 0.06);
            --send-fill: #1a73e8;
            --send-border: transparent;
            --send-hover-bg: rgba(26, 115, 232, 0.06);
            --hint-color: #5f6368;
            --close-hover-bg: rgba(32, 33, 36, 0.04);
            --container-border: 1px solid #dadce0;
            --container-shadow: 0 0px 16px rgba(0,0,0,0.25);
            --input-bg: #f1f3f4; /* Base surface */
            --input-border: 1px solid transparent;
        }
        "#
    };

    format!(
        r#"
    {vars}

    html, body {{
        width: 100%;
        height: 100%;
        overflow: hidden;
        background: transparent;
        padding: 10px; /* Reduced to fit calc(100% - 20px) better */
        font-family: 'Google Sans Flex', sans-serif;
        font-variation-settings: 'ROND' 100;
    }}
    
    * {{ 
        box-sizing: border-box; 
        margin: 0; 
        padding: 0; 
        user-select: none; 
        font-variation-settings: 'ROND' 100; 
    }}
    
    *::-webkit-scrollbar {{
        width: 10px;
        height: 10px;
        background: transparent;
    }}
    *::-webkit-scrollbar-thumb {{
        background: var(--scrollbar-thumb);
        border-radius: 5px;
        border: 2px solid transparent;
        background-clip: content-box;
    }}
    *::-webkit-scrollbar-thumb:hover {{
        background: var(--scrollbar-thumb-hover);
        border: 2px solid transparent;
        background-clip: content-box;
    }}
    
    .editor-container {{
        width: calc(100% - 20px);
        height: calc(100% - 20px);
        margin: 10px;
        display: flex;
        flex-direction: column;
        overflow: hidden;
        background: var(--bg-color);
        position: relative;
        border-radius: 20px;
        border: var(--container-border);
        box-shadow: var(--container-shadow);
        
        /* Initial State for Animation */
        opacity: 0;
        transform: scale(0.95);
        transition: background 0.2s, border-color 0.2s;
    }}

    .editor-container.entering {{
        animation: inputFadeIn 0.2s cubic-bezier(0.2, 0, 0, 1) forwards;
    }}

    .editor-container.exiting {{
        animation: inputFadeOut 0.15s cubic-bezier(0.2, 0, 0, 1) forwards;
    }}

    @keyframes inputFadeIn {{
        to {{ opacity: 1; transform: scale(1); }}
    }}

    @keyframes inputFadeOut {{
        from {{ opacity: 1; transform: scale(1); }}
        to {{ opacity: 0; transform: scale(0.95); }}
    }}
    
    /* Header (Draggable) */
    .header {{
        height: 32px;
        background: transparent;
        display: flex;
        align-items: center;
        padding: 0 10px;
        cursor: default;
        /* No border for header to seamless blend */
    }}
    
    .header-title {{
        flex: 1;
        font-size: 14px;
        font-weight: 600;
        text-transform: uppercase;
        font-stretch: 151%;
        letter-spacing: 0.15em;
        line-height: 24px;
        padding-top: 4px; /* Visual centering */
        color: var(--header-text);
        padding-left: 14px;
        white-space: nowrap;
        overflow: hidden;
        text-overflow: ellipsis;
        font-family: 'Google Sans Flex', sans-serif;
    }}
    
    .header-title span {{
        display: inline-block;
        transition: color 0.2s;
    }}

    @keyframes waveColor {{
        0%, 100% {{
            color: var(--header-text);
            font-variation-settings: 'GRAD' 0, 'wght' 600, 'ROND' 100;
        }}
        50% {{
            color: var(--wave-color);
            font-variation-settings: 'GRAD' 200, 'wght' 1000, 'ROND' 100;
        }}
    }}
    
    .close-btn {{
        width: 32px;
        height: 32px;
        display: flex;
        align-items: center;
        justify-content: center;
        border-radius: 50%;
        cursor: pointer;
        color: var(--header-text);
        transition: background 0.1s;
        margin-right: 6px;
    }}

    .close-btn svg {{
        width: 20px;
        height: 20px;
        fill: currentColor;
    }}
    
    .mic-btn svg, .send-btn svg {{
        width: 22px;
        height: 22px;
    }}
    
    .mic-btn svg {{ fill: var(--mic-fill); }}
    .send-btn svg {{ fill: var(--send-fill); }}
    
    .close-btn:hover {{
        background: var(--close-hover-bg);
    }}

    #editor {{
        flex: 1;
        width: 100%;
        margin: 0px 8px;
        background: var(--input-bg);
        border-radius: 22px; /* Ultra rounded pill look */
        padding: 12px 14px;
        padding-right: 68px; /* Space for mic + send buttons to prevent overlap */
        border: var(--input-border);
        outline: none;
        resize: none;
        font-family: 'Google Sans Flex', sans-serif;
        font-size: 15px;
        line-height: 1.55;
        color: var(--text-color);
        overflow-y: auto;
        user-select: text;
        width: calc(100% - 16px);
    }}
    
    #editor::placeholder {{
        color: var(--placeholder-color);
        opacity: 1;
    }}
    
    /* Footer */
    .footer {{
        height: 28px;
        background: transparent;
        /* No border for seamless blend */
        display: flex;
        align-items: center;
        justify-content: center;
        font-size: 11px;
        color: var(--footer-text);
        font-variation-settings: 'ROND' 100, 'slnt' -10;
        cursor: default;
    }}

    /* Floating Buttons */
    /* Floating Buttons - Vertical Stack */
    .btn-container {{
        position: absolute;
        bottom: 40px; /* Above footer */
        right: 20px;
        display: flex;
        flex-direction: column;
        gap: 12px;
        z-index: 100;
    }}

    .mic-btn, .send-btn {{
        width: 48px;
        height: 48px; /* Big buttons */
        border-radius: 50%;
        display: flex;
        align-items: center;
        justify-content: center;
        cursor: pointer;
        background: var(--btn-bg);
        border: 1px solid var(--btn-border);
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        transition: all 0.2s cubic-bezier(0.2, 0.0, 0.2, 1);
        backdrop-filter: blur(8px);
        -webkit-backdrop-filter: blur(8px);
    }}
    
    .mic-btn svg, .send-btn svg {{
        width: 28px; /* Bigger icons */
        height: 28px;
        transition: transform 0.2s, fill 0.2s;
    }}
    
    .mic-btn:active, .send-btn:active {{
        transform: scale(0.95);
    }}
    


    .mic-btn svg {{ fill: var(--mic-fill); }}
    .send-btn svg {{ fill: var(--send-fill); }}

    .mic-btn:hover {{
        background: var(--mic-hover-bg);
        border-color: var(--mic-fill);
    }}
    
    .send-btn:hover {{
        background: var(--send-hover-bg);
        border-color: var(--send-fill);
    }}
"#,
        vars = vars
    )
}

/// Generate HTML for the text input webview
fn get_editor_html(placeholder: &str, is_dark: bool) -> String {
    let css = get_editor_css(is_dark);
    let theme_attr = if is_dark {
        "data-theme=\"dark\""
    } else {
        "data-theme=\"light\""
    };
    let font_css = crate::overlay::html_components::font_manager::get_font_css();
    let escaped_placeholder = placeholder
        .replace('\\', "\\\\")
        .replace('"', "\\\"")
        .replace('\n', "\\n");

    // Locale text
    let (submit_txt, newline_txt, cancel_txt) = {
        let lang = crate::overlay::text_input::CFG_LANG.lock().unwrap().clone();
        let locale = crate::gui::locale::LocaleText::get(&lang);
        (
            locale.text_input_footer_submit.to_string(),
            locale.text_input_footer_newline.to_string(),
            locale.text_input_footer_cancel.to_string(),
        )
    };
    let cancel_hint = {
        let sub = crate::overlay::text_input::CFG_CANCEL.lock().unwrap();
        if sub.is_empty() {
            "Esc".to_string()
        } else {
            format!("Esc / {}", sub)
        }
    };
    let title_text = {
        let t = crate::overlay::text_input::CFG_TITLE.lock().unwrap();
        if t.is_empty() {
            let lang = crate::overlay::text_input::CFG_LANG.lock().unwrap().clone();
            let locale = crate::gui::locale::LocaleText::get(&lang);
            locale.text_input_placeholder.to_string()
        } else {
            t.clone()
        }
    };

    format!(
        r#"<!DOCTYPE html>
<html {theme_attr}>
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <style>{font_css}</style>
    <style id="theme-style">{css}</style>
</head>
<body>
    <div class="editor-container">
        <div class="header" id="headerRegion">
            <span class="header-title" id="headerTitle">{title_text}</span>
            <div class="close-btn" id="closeBtn" title="Close">
                {close_svg}
            </div>
        </div>
        
        <textarea id="editor" placeholder="{placeholder}" autofocus></textarea>
        
        <div class="btn-container">
            <button class="mic-btn" id="micBtn" title="Speech to text">
                {mic_svg}
            </button>
            <button class="send-btn" id="sendBtn" title="Send">
                {send_svg}
            </button>
        </div>
        
        <div class="footer" id="footerRegion">
            {submit_txt}  |  {newline_txt}  |  {cancel_hint} {cancel_txt}
        </div>
    </div>
    <script>
        const container = document.querySelector('.editor-container');
        const editor = document.getElementById('editor');
        const closeBtn = document.getElementById('closeBtn');
        const micBtn = document.getElementById('micBtn');
        const sendBtn = document.getElementById('sendBtn');
        
        // Drag window logic - Entire container except interactive elements
        container.addEventListener('mousedown', (e) => {{
            const isInteractive = e.target.closest('#editor') || 
                                e.target.closest('.close-btn') || 
                                e.target.closest('.mic-btn') || 
                                e.target.closest('.send-btn');
            if (isInteractive) return;
            
            // Only left click
            if (e.button === 0) {{
                window.ipc.postMessage('drag_window');
            }}
        }});
        
        // Close button
        closeBtn.addEventListener('click', (e) => {{
            window.ipc.postMessage('close_window');
        }});
        
        window.onload = () => {{
            setTimeout(() => editor.focus(), 50);
        }};
        
        // ... keydown handles ...
        editor.addEventListener('keydown', (e) => {{
            if (e.key === 'Enter' && !e.shiftKey) {{
                e.preventDefault();
                const text = editor.value.trim();
                if (text) {{
                    window.ipc.postMessage('submit:' + text);
                }}
            }}
            
            if (e.key === 'Escape') {{
                e.preventDefault();
                window.ipc.postMessage('cancel');
            }}
            
            if (e.key === 'ArrowUp') {{
                const isSingleLine = !editor.value.includes('\n');
                if ((isSingleLine || editor.selectionStart === 0) && !e.shiftKey) {{
                    e.preventDefault();
                    window.ipc.postMessage('history_up:' + editor.value);
                }}
            }}

            if (e.key === 'ArrowDown') {{
                const isSingleLine = !editor.value.includes('\n');
                if ((isSingleLine || editor.selectionStart === editor.value.length) && !e.shiftKey) {{
                    e.preventDefault();
                    window.ipc.postMessage('history_down:' + editor.value);
                }}
            }}
        }});
        
        micBtn.addEventListener('click', (e) => {{
            e.preventDefault();
            window.ipc.postMessage('mic');
        }});
        
        sendBtn.addEventListener('click', (e) => {{
            e.preventDefault();
            const text = editor.value.trim();
            if (text) {{
                window.ipc.postMessage('submit:' + text);
            }}
        }});
        
        document.addEventListener('contextmenu', e => e.preventDefault());
        
        window.setEditorText = (text) => {{
            editor.value = text;
            editor.selectionStart = editor.selectionEnd = text.length;
            editor.focus();
        }};

        window.updateTheme = (isDark) => {{
            document.documentElement.setAttribute('data-theme', isDark ? 'dark' : 'light');
        }};

        window.playEntry = () => {{
            const el = document.querySelector('.editor-container');
            if(el) {{
                el.classList.remove('exiting');
                el.classList.add('entering');
                
                // Trigger wave animation on title characters
                const title = document.getElementById('headerTitle');
                if (title && !title.hasAttribute('data-wrapped')) {{
                    const text = title.innerText;
                    title.innerHTML = text.split('').map((char, i) => 
                        `<span style="animation: waveColor 0.6s ease forwards ${{0.2 + i * 0.05}}s">${{char === ' ' ? '&nbsp;' : char}}</span>`
                    ).join('');
                    title.setAttribute('data-wrapped', 'true');
                }} else if (title) {{
                    // Re-trigger animation by removing/adding spans or class
                     const text = title.innerText; // Get raw text back from spans
                     title.innerHTML = text.split('').map((char, i) => 
                        `<span style="animation: waveColor 0.6s ease forwards ${{0.2 + i * 0.05}}s">${{char === ' ' ? '&nbsp;' : char}}</span>`
                    ).join('');
                }}
            }}
        }};

        window.playExit = () => {{
            const el = document.querySelector('.editor-container');
            if(el) {{
                el.classList.remove('entering');
                el.classList.add('exiting');
            }}
        }};

    </script>
</body>
</html>"#,
        theme_attr = theme_attr,
        font_css = font_css,
        css = css,
        title_text = title_text,
        placeholder = escaped_placeholder,
        submit_txt = submit_txt,
        newline_txt = newline_txt,
        cancel_hint = cancel_hint,
        cancel_txt = cancel_txt,
        close_svg = crate::overlay::html_components::icons::get_icon_svg("close"),
        mic_svg = crate::overlay::html_components::icons::get_icon_svg("mic"),
        send_svg = crate::overlay::html_components::icons::get_icon_svg("send")
    )
}

pub fn is_active() -> bool {
    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val == 0 {
        return false;
    }
    unsafe {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        if !IsWindowVisible(hwnd).as_bool() {
            return false;
        }
        // Since we use offscreen WS_VISIBLE, we must check coordinates
        let mut rect = RECT::default();
        if GetWindowRect(hwnd, &mut rect).is_ok() {
            return rect.left > -3000;
        }
        false
    }
}

pub fn cancel_input() {
    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        unsafe {
            let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
            let _ = PostMessageW(Some(hwnd), WM_APP_HIDE, WPARAM(0), LPARAM(0));
        }
    }
}

/// Set text content in the webview editor (for paste operations)
/// This is thread-safe and can be called from any thread
pub fn set_editor_text(text: &str) {
    // Store the text in the mutex
    *PENDING_TEXT.lock().unwrap() = Some(text.to_string());

    // Post message to the text input window to trigger the injection
    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        unsafe {
            let _ = PostMessageW(
                Some(HWND(hwnd_val as *mut std::ffi::c_void)),
                WM_APP_SET_TEXT,
                WPARAM(0),
                LPARAM(0),
            );
        }
    }
}

/// Internal function to apply pending text (called on the window's thread)
/// Inserts text at the current cursor position instead of replacing all content
fn apply_pending_text() {
    let text = PENDING_TEXT.lock().unwrap().take();
    if let Some(text) = text {
        // Check if this is a history replacement (replace all) or insertion
        let (is_replace_all, actual_text) =
            if let Some(stripped) = text.strip_prefix("__REPLACE_ALL__") {
                (true, stripped.to_string())
            } else {
                (false, text)
            };

        let escaped = actual_text
            .replace('\\', "\\\\")
            .replace('`', "\\`")
            .replace("${", "\\${")
            .replace('\n', "\\n")
            .replace('\r', "");

        TEXT_INPUT_WEBVIEW.with(|webview| {
            if let Some(wv) = webview.borrow().as_ref() {
                let script = if is_replace_all {
                    // Replace all text (for history navigation)
                    format!(
                        r#"(function() {{
                            const editor = document.getElementById('editor');
                            const text = `{}`;
                            editor.value = text;
                            editor.selectionStart = editor.selectionEnd = text.length;
                            editor.focus();
                        }})();"#,
                        escaped
                    )
                } else {
                    // Insert at cursor position (for paste/transcription)
                    format!(
                        r#"(function() {{
                            const editor = document.getElementById('editor');
                            const start = editor.selectionStart;
                            const end = editor.selectionEnd;
                            const text = `{}`;
                            editor.value = editor.value.substring(0, start) + text + editor.value.substring(end);
                            editor.selectionStart = editor.selectionEnd = start + text.length;
                            editor.focus();
                        }})();"#,
                        escaped
                    )
                };
                let _ = wv.evaluate_script(&script);
            }
        });
        println!("[Badge] Starting WebView initialization...");
    }
}

/// Clear the webview editor content and refocus (for continuous input mode)
pub fn clear_editor_text() {
    TEXT_INPUT_WEBVIEW.with(|webview| {
        if let Some(wv) = webview.borrow().as_ref() {
            let script = r#"document.getElementById('editor').value = ''; document.getElementById('editor').focus();"#;
            let _ = wv.evaluate_script(script);
        }
    });
}

/// Update the UI text (header) and trigger a repaint
pub fn update_ui_text(header_text: String) {
    *CFG_TITLE.lock().unwrap() = header_text.clone();
    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe {
            let _ = SetWindowTextW(hwnd, &HSTRING::from(header_text));
            let _ = PostMessageW(Some(hwnd), WM_APP_SHOW, WPARAM(1), LPARAM(0));
        }
    }
}

/// Bring the text input window to foreground and focus the editor
/// Call this after closing modal windows like the preset wheel
pub fn refocus_editor() {
    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe {
            use windows::Win32::UI::Input::KeyboardAndMouse::SetFocus;
            use windows::Win32::UI::WindowsAndMessaging::{
                BringWindowToTop, SetForegroundWindow, SetTimer,
            };

            // Aggressive focus: try multiple methods
            let _ = BringWindowToTop(hwnd);
            let _ = SetForegroundWindow(hwnd);
            let _ = SetFocus(Some(hwnd));

            // Focus the webview editor immediately
            TEXT_INPUT_WEBVIEW.with(|webview| {
                if let Some(wv) = webview.borrow().as_ref() {
                    // First focus the WebView itself (native focus)
                    let _ = wv.focus();
                    // Then focus the textarea inside via JavaScript
                    let _ = wv.evaluate_script("document.getElementById('editor').focus();");
                }
            });

            // Schedule another focus attempt after 200ms via timer ID 3
            // This will be handled in WM_TIMER in the same thread
            let _ = SetTimer(Some(hwnd), 3, 200, None);
        }
    }
}

/// Get the current window rect of the text input window (if active)
pub fn get_window_rect() -> Option<RECT> {
    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        let mut rect = RECT::default();
        unsafe {
            if GetWindowRect(HWND(hwnd_val as *mut std::ffi::c_void), &mut rect).is_ok() {
                return Some(rect);
            }
        }
    }
    None
}

/// Start the persistent hidden window (called from main)
pub fn warmup() {
    // Thread-safe atomic check-and-set to prevent multiple warmup threads
    if IS_WARMED_UP.load(Ordering::SeqCst) {
        return;
    }
    if IS_WARMING_UP
        .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
        .is_err()
    {
        return;
    }
    std::thread::spawn(|| {
        internal_create_window_loop();
    });
}

pub fn show(
    prompt_guide: String,
    ui_language: String,
    cancel_hotkey_name: String,
    continuous_mode: bool,
    on_submit: impl Fn(String, HWND) + Send + 'static,
) {
    // Re-entrancy guard: if we are already in the process of showing/waiting, ignore subsequent calls
    // This prevents key-mashing from spawning multiple wait loops or confused states
    if IS_SHOWING
        .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
        .is_err()
    {
        return;
    }

    // Ensure we clear the flag when we return
    struct Guard;
    impl Drop for Guard {
        fn drop(&mut self) {
            IS_SHOWING.store(false, Ordering::SeqCst);
        }
    }
    let _guard = Guard;

    // Clone lang for locale notification before moving/consuming it
    let lang_for_locale = ui_language.clone();

    // Update shared state FIRST so it's ready when window shows up
    *CFG_TITLE.lock().unwrap() = prompt_guide;
    *CFG_LANG.lock().unwrap() = ui_language;
    *CFG_CANCEL.lock().unwrap() = cancel_hotkey_name;
    *CFG_CONTINUOUS.lock().unwrap() = continuous_mode;
    *CFG_CALLBACK.lock().unwrap() = Some(Box::new(on_submit));

    *SUBMITTED_TEXT.lock().unwrap() = None;
    *SHOULD_CLOSE.lock().unwrap() = false;
    *SHOULD_CLEAR_ONLY.lock().unwrap() = false;

    // Check if warmed up
    if !IS_WARMED_UP.load(Ordering::SeqCst) {
        // Trigger warmup for recovery
        warmup();

        // Show localized message that feature is not ready yet
        let locale = LocaleText::get(&lang_for_locale);
        crate::overlay::auto_copy_badge::show_notification(locale.text_input_loading);

        // Blocking wait with message pump
        // We wait up to 20 seconds. If it fails, we simply return (preventing premature broken window)
        for _ in 0..2000 {
            unsafe {
                let mut msg = MSG::default();
                while PeekMessageW(&mut msg, None, 0, 0, PM_REMOVE).as_bool() {
                    let _ = TranslateMessage(&msg);
                    DispatchMessageW(&msg);
                }
            }

            std::thread::sleep(std::time::Duration::from_millis(10));

            if IS_WARMED_UP.load(Ordering::SeqCst) {
                break;
            }
        }

        // If still not warmed up after wait, give up
        if !IS_WARMED_UP.load(Ordering::SeqCst) {
            return;
        }
    }

    let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
        unsafe {
            // ALWAYS show logic (Toggle logic handled by caller if needed)
            // Fixes issue where dynamic prompt mode fails to appear if window state is desync
            let _ = PostMessageW(Some(hwnd), WM_APP_SHOW, WPARAM(0), LPARAM(0));
        }
    }
}

fn internal_create_window_loop() {
    unsafe {
        let coinit = CoInitialize(None); // Required for WebView
        crate::log_info!("[TextInput] Loop Start - CoInit: {:?}", coinit);
        let instance = GetModuleHandleW(None).unwrap();
        let class_name = w!("SGT_TextInputWry");

        REGISTER_INPUT_CLASS.call_once(|| {
            let mut wc = WNDCLASSW::default();
            wc.lpfnWndProc = Some(input_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
            wc.lpszClassName = class_name;
            wc.style = CS_HREDRAW | CS_VREDRAW;
            // Use NULL brush to prevent white flashes/stripes on resize
            wc.hbrBackground = HBRUSH(GetStockObject(NULL_BRUSH).0);
            let _ = RegisterClassW(&wc);
        });
        crate::log_info!("[TextInput] Class Registered");

        crate::log_info!("[TextInput] Calculating scale...");
        let screen_w = GetSystemMetrics(SM_CXSCREEN);
        let scale = {
            let dpi = GetDpiForSystem();
            crate::log_info!("[TextInput] System DPI: {}", dpi);
            dpi as f64 / 96.0
        };
        // Width scaling: matches 800px physical at 1.25 scale (Laptop preferred),
        // but creates ~580px physical at 1.0 scale (PC preferred, narrower than 640).
        let mut win_w = ((880.0 * scale) - 300.0).round() as i32;

        // User requested smaller width for 1920x1080 laptops (usually scale > 1.0)
        // Current formula gives 800px at 1.25 scale, which is too wide.
        // We reduce it by 15% to ~680px for this specific case.
        if screen_w == 1920 && scale > 1.1 {
            win_w = (win_w as f64 * 0.85).round() as i32;
        }
        let win_h = (253.0 * scale).round() as i32;

        crate::log_info!(
            "[TextInput] Creating window: scale={:.2}, width={}, height={}",
            scale,
            win_w,
            win_h
        );

        // Start HIDDEN logic (Offscreen but VISIBLE for Webview init)
        let hwnd = CreateWindowExW(
            WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_LAYERED,
            class_name,
            w!("Text Input"),
            WS_POPUP | WS_VISIBLE,
            -4000,
            -4000,
            win_w,
            win_h,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();
        crate::log_info!("[TextInput] CreateWindowExW returned HWND: {:?}", hwnd);

        if hwnd.is_invalid() {
            crate::log_info!("[TextInput] Critical Error: Failed to create window.");
            IS_WARMED_UP.store(false, Ordering::SeqCst);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            let _ = CoUninitialize();
            return;
        }

        INPUT_HWND.store(hwnd.0 as isize, Ordering::SeqCst);

        // Windows 11 Rounded Corners - Disable native rounding
        let corner_pref = 1u32; // DWMWCP_DONOTROUND
        let _ = DwmSetWindowAttribute(
            hwnd,
            DWMWA_WINDOW_CORNER_PREFERENCE,
            std::ptr::addr_of!(corner_pref) as *const _,
            std::mem::size_of_val(&corner_pref) as u32,
        );
        crate::log_info!("[TextInput] HWND stored, starting WebView initialization...");

        // WebView Initialization
        // Initialize use simple DwmExtendFrameIntoClientArea for full transparency
        // NO SetLayeredWindowAttributes(hwnd, COLORREF(0), 0, LWA_COLORKEY) as it conflicts with Dwm
        // Use margins -1 to extend glass effect to entire window (fully transparent client area)
        let margins = MARGINS {
            cxLeftWidth: -1,
            cxRightWidth: -1,
            cyTopHeight: -1,
            cyBottomHeight: -1,
        };
        let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

        // REMOVED GDI REGION CLIPPING
        // We now rely on HTML/CSS border-radius and transparent background

        // Create webview with retry logic
        let mut attempts = 0;
        let max_attempts = 3;
        let mut webview_success = false;

        while attempts < max_attempts {
            if init_webview(hwnd, win_w, win_h).is_ok() {
                webview_success = true;
                break;
            }
            crate::log_info!(
                "[TextInput] WebView init attempt {} failed, retrying...",
                attempts + 1
            );
            attempts += 1;
            crate::log_info!(
                "[TextInput] WebView init failed, retrying ({}/{})",
                attempts,
                max_attempts
            );
            std::thread::sleep(std::time::Duration::from_millis(500));
        }

        if !webview_success {
            crate::log_info!(
                "[TextInput] Critical Error: Failed to initialize WebView after {} attempts.",
                max_attempts
            );
            // Don't mark as warmed up, let it fail so show() can re-trigger warmup if needed
            IS_WARMED_UP.store(false, Ordering::SeqCst);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            let _ = DestroyWindow(hwnd);
            let _ = CoUninitialize();
            return;
        }

        // Mark as warmed up and ready
        IS_WARMED_UP.store(true, Ordering::SeqCst);
        IS_WARMING_UP.store(false, Ordering::SeqCst); // Done warming up

        // Message Loop
        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).as_bool() {
            let _ = TranslateMessage(&msg);
            let _ = DispatchMessageW(&msg);
        }

        // Cleanup on exit
        TEXT_INPUT_WEBVIEW.with(|wv| {
            *wv.borrow_mut() = None;
        });
        INPUT_HWND.store(0, Ordering::SeqCst);
        IS_WARMED_UP.store(false, Ordering::SeqCst);
        IS_WARMING_UP.store(false, Ordering::SeqCst);
        let _ = CoUninitialize();
    }
}

unsafe fn init_webview(hwnd: HWND, w: i32, h: i32) -> std::result::Result<(), ()> {
    // Use exact window dimensions for the webview, no insets.
    // The CSS .editor-container handles the padding/border-radius/shadow.
    let webview_x = 0;
    let webview_y = 0;
    let webview_w = w;
    let webview_h = h;

    let is_dark = if let Ok(app) = crate::APP.lock() {
        match app.config.theme_mode {
            crate::config::ThemeMode::Dark => true,
            crate::config::ThemeMode::Light => false,
            crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
        }
    } else {
        true
    };

    let placeholder = "Ready...";
    let html = get_editor_html(placeholder, is_dark);
    let wrapper = HwndWrapper(hwnd);

    // Initialize shared WebContext if needed
    TEXT_INPUT_WEB_CONTEXT.with(|ctx| {
        if ctx.borrow().is_none() {
            // Consolidate all minor overlays to 'common' to share one browser process and keep RAM at ~80MB
            let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
            *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
        }
    });

    crate::log_info!("[TextInput] Starting WebView build phase...");

    let result = {
        // LOCK SCOPE: Only one WebView builds at a time to prevent "Not enough quota"
        let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
        crate::log_info!("[TextInput] Acquired init lock. Building...");

        let build_res = TEXT_INPUT_WEB_CONTEXT.with(|ctx| {
            let mut ctx_ref = ctx.borrow_mut();
            let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                WebViewBuilder::new_with_web_context(web_ctx)
            } else {
                WebViewBuilder::new()
            };
            let builder = builder.with_transparent(true);
            let builder = crate::overlay::html_components::font_manager::configure_webview(builder);
            crate::log_info!("[TextInput] Builder configured. Preparing build...");

            let page_url =
                crate::overlay::html_components::font_manager::store_html_page(html.clone())
                    .unwrap_or_else(|| format!("data:text/html,{}", urlencoding::encode(&html)));

            crate::log_info!("[TextInput] URL prepared. Invoking build...");

            builder
                // Store HTML in font server and get URL for same-origin font loading
                .with_background_color((0, 0, 0, 0))
                .with_bounds(Rect {
                    position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(
                        webview_x, webview_y,
                    )),
                    size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                        webview_w as u32,
                        webview_h as u32,
                    )),
                })
                .with_url(&page_url)
                .with_transparent(true)
                .with_ipc_handler(move |msg: wry::http::Request<String>| {
                    let body = msg.body();
                    if body.starts_with("submit:") {
                        let text = body.strip_prefix("submit:").unwrap_or("").to_string();
                        if !text.trim().is_empty() {
                            // Save to history before submitting
                            crate::overlay::input_history::add_to_history(&text);
                            *SUBMITTED_TEXT.lock().unwrap() = Some(text);
                            *SHOULD_CLOSE.lock().unwrap() = true;
                        }
                    } else if body == "cancel" {
                        crate::overlay::input_history::reset_history_navigation();
                        *SHOULD_CLOSE.lock().unwrap() = true;
                    } else if body.starts_with("history_up:") {
                        let current = body.strip_prefix("history_up:").unwrap_or("");
                        if let Some(text) =
                            crate::overlay::input_history::navigate_history_up(current)
                        {
                            *PENDING_TEXT.lock().unwrap() =
                                Some(format!("__REPLACE_ALL__{}", text));
                            let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
                            if hwnd_val != 0 {
                                unsafe {
                                    let _ = PostMessageW(
                                        Some(HWND(hwnd_val as *mut std::ffi::c_void)),
                                        WM_APP_SET_TEXT,
                                        WPARAM(0),
                                        LPARAM(0),
                                    );
                                }
                            }
                        }
                    } else if body.starts_with("history_down:") {
                        let current = body.strip_prefix("history_down:").unwrap_or("");
                        if let Some(text) =
                            crate::overlay::input_history::navigate_history_down(current)
                        {
                            *PENDING_TEXT.lock().unwrap() =
                                Some(format!("__REPLACE_ALL__{}", text));
                            let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
                            if hwnd_val != 0 {
                                unsafe {
                                    let _ = PostMessageW(
                                        Some(HWND(hwnd_val as *mut std::ffi::c_void)),
                                        WM_APP_SET_TEXT,
                                        WPARAM(0),
                                        LPARAM(0),
                                    );
                                }
                            }
                        }
                    } else if body == "mic" {
                        // Trigger transcription preset
                        let transcribe_idx = {
                            let app = crate::APP.lock().unwrap();
                            app.config
                                .presets
                                .iter()
                                .position(|p| p.id == "preset_transcribe")
                        };

                        if let Some(preset_idx) = transcribe_idx {
                            std::thread::spawn(move || {
                                crate::overlay::recording::show_recording_overlay(preset_idx);
                            });
                        }
                    } else if body == "drag_window" {
                        let hwnd_val = INPUT_HWND.load(Ordering::SeqCst);
                        if hwnd_val != 0 {
                            unsafe {
                                let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);
                                let _ = ReleaseCapture();
                                let _ = SendMessageW(
                                    hwnd,
                                    WM_NCLBUTTONDOWN,
                                    Some(WPARAM(HTCAPTION as usize)),
                                    Some(LPARAM(0)),
                                );
                            }
                        }
                    } else if body == "close_window" {
                        cancel_input();
                    }
                })
                .build_as_child(&wrapper)
        });
        crate::log_info!(
            "[TextInput] Build phase finished. Releasing lock. Status: {}",
            if build_res.is_ok() { "OK" } else { "ERR" }
        );
        build_res
    };

    if let Ok(webview) = result {
        println!("[TextInput] WebView initialization SUCCESSFUL");
        TEXT_INPUT_WEBVIEW.with(|wv| {
            *wv.borrow_mut() = Some(webview);
        });
        Ok(())
    } else {
        Err(())
    }
}

unsafe extern "system" fn input_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    // State variables for this window instance
    static mut FADE_ALPHA: i32 = 0;
    // IS_DRAGGING is no longer needed with native drag

    match msg {
        WM_APP_SHOW => {
            // Restore History Navigation State
            crate::overlay::input_history::reset_history_navigation();

            // Moved playEntry to end of block to run AFTER text updates

            // 1. Position Logic - Center on the monitor where the cursor is
            if wparam.0 != 1 {
                let mut cursor = POINT::default();
                unsafe {
                    let _ = GetCursorPos(&mut cursor);
                    let hmonitor = MonitorFromPoint(cursor, MONITOR_DEFAULTTONEAREST);
                    let mut mi = MONITORINFO {
                        cbSize: std::mem::size_of::<MONITORINFO>() as u32,
                        ..Default::default()
                    };
                    let _ = GetMonitorInfoW(hmonitor, &mut mi);

                    let mut rect = RECT::default();
                    let _ = GetWindowRect(hwnd, &mut rect);
                    let w = rect.right - rect.left;
                    let h = rect.bottom - rect.top;

                    let monitor_w = mi.rcWork.right - mi.rcWork.left;
                    let monitor_h = mi.rcWork.bottom - mi.rcWork.top;

                    let x = mi.rcWork.left + (monitor_w - w) / 2;
                    let y = mi.rcWork.top + (monitor_h - h) / 2;

                    let _ = SetWindowPos(
                        hwnd,
                        Some(HWND_TOP),
                        x,
                        y,
                        0,
                        0,
                        SWP_NOSIZE | SWP_SHOWWINDOW,
                    );
                }
            }

            // 2. Focus - Force window to foreground
            let _ = SetForegroundWindow(hwnd);
            let _ = SetFocus(Some(hwnd));
            // Force Webview focus immediately
            TEXT_INPUT_WEBVIEW.with(|webview| {
                if let Some(wv) = webview.borrow().as_ref() {
                    let _ = wv.focus();
                }
            });

            // 3. Dynamic Update (Theme + Locales)
            let is_dark = if let Ok(app) = crate::APP.lock() {
                match app.config.theme_mode {
                    crate::config::ThemeMode::Dark => true,
                    crate::config::ThemeMode::Light => false,
                    crate::config::ThemeMode::System => crate::gui::utils::is_system_in_dark_mode(),
                }
            } else {
                true
            };

            // Re-fetch locales to ensure they are current
            let (title, submit, newline, cancel, cancel_hint, placeholder) = {
                let lang = crate::overlay::text_input::CFG_LANG.lock().unwrap().clone();
                let locale = crate::gui::locale::LocaleText::get(&lang);
                let t = crate::overlay::text_input::CFG_TITLE
                    .lock()
                    .unwrap()
                    .clone();
                let title = if t.is_empty() {
                    let lang = crate::overlay::text_input::CFG_LANG.lock().unwrap().clone();
                    let locale = crate::gui::locale::LocaleText::get(&lang);
                    locale.text_input_placeholder.to_string()
                } else {
                    t
                };
                let hotkey = crate::overlay::text_input::CFG_CANCEL.lock().unwrap();
                let ch = if hotkey.is_empty() {
                    "Esc".to_string()
                } else {
                    format!("Esc / {}", hotkey)
                };
                (
                    title,
                    locale.text_input_footer_submit.to_string(),
                    locale.text_input_footer_newline.to_string(),
                    locale.text_input_footer_cancel.to_string(),
                    ch,
                    locale.text_input_placeholder.to_string(),
                )
            };

            // Update window title
            let _ = SetWindowTextW(hwnd, &HSTRING::from(&title));

            let css = get_editor_css(is_dark);
            let css_escaped = css.replace("`", "\\`");

            // Construct footer HTML
            let footer_html = format!("{}  |  {}  |  {} {}", submit, newline, cancel_hint, cancel);
            let placeholder_escaped = placeholder.replace("'", "\\'"); // rudimentary escape

            let script = format!(
                r#"
                if (document.getElementById('theme-style')) {{
                   document.getElementById('theme-style').innerHTML = `{}`;
                }}
                if (document.getElementById('headerTitle')) {{
                   document.getElementById('headerTitle').innerText = `{}`;
                }}
                if (document.getElementById('footerRegion')) {{
                   document.getElementById('footerRegion').innerHTML = `{}`;
                }}
                if (document.getElementById('editor')) {{
                   document.getElementById('editor').placeholder = '{}';
                }}
                document.documentElement.setAttribute('data-theme', '{}');
                // Force focus on editor 
                setTimeout(() => {{
                    const el = document.getElementById('editor');
                    if (el) {{
                        el.focus();     
                        el.select(); 
                        el.selectionStart = el.selectionEnd = el.value.length; 
                    }}
                }}, 10);
                "#,
                css_escaped,
                title,
                footer_html,
                placeholder_escaped,
                if is_dark { "dark" } else { "light" }
            );

            TEXT_INPUT_WEBVIEW.with(|webview| {
                if let Some(wv) = webview.borrow().as_ref() {
                    let _ = wv.evaluate_script(&script);
                    // NOW trigger animation, after text has been updated
                    let _ = wv.evaluate_script("playEntry();");
                }
            });

            // Reset state
            FADE_ALPHA = 0;

            // IPC check timer
            SetTimer(Some(hwnd), 2, 50, None);

            LRESULT(0)
        }

        WM_APP_SET_TEXT => {
            // Apply pending text from cross-thread call
            apply_pending_text();
            LRESULT(0)
        }

        WM_APP_HIDE => {
            // Trigger Fade Out Script & Delay Hide
            TEXT_INPUT_WEBVIEW.with(|webview| {
                if let Some(wv) = webview.borrow().as_ref() {
                    let _ = wv.evaluate_script("playExit();");
                }
            });
            // 150ms delay for animation (Timer ID 4)
            SetTimer(Some(hwnd), 4, 150, None);
            LRESULT(0)
        }

        WM_CLOSE => {
            let _ = ShowWindow(hwnd, SW_HIDE);
            let _ = KillTimer(Some(hwnd), 1);
            let _ = KillTimer(Some(hwnd), 2);
            let _ = KillTimer(Some(hwnd), 3);
            LRESULT(0)
        }

        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }

        WM_ERASEBKGND => LRESULT(1),

        WM_SETFOCUS => {
            TEXT_INPUT_WEBVIEW.with(|webview| {
                if let Some(wv) = webview.borrow().as_ref() {
                    let _ = wv.focus();
                }
            });
            LRESULT(0)
        }

        WM_TIMER => {
            if wparam.0 == 1 {
                // Fade Timer Logic removed
                let _ = KillTimer(Some(hwnd), 1);
            }

            if wparam.0 == 2 {
                // IPC messages
                let should_close = *SHOULD_CLOSE.lock().unwrap();
                if should_close {
                    *SHOULD_CLOSE.lock().unwrap() = false;
                    let submitted = SUBMITTED_TEXT.lock().unwrap().take();
                    if let Some(text) = submitted {
                        let continuous = *CFG_CONTINUOUS.lock().unwrap();
                        if continuous {
                            let cb_lock = CFG_CALLBACK.lock().unwrap();
                            if let Some(cb) = cb_lock.as_ref() {
                                cb(text, hwnd);
                            }
                            clear_editor_text();
                            refocus_editor();
                        } else {
                            let _ = ShowWindow(hwnd, SW_HIDE);
                            let cb_lock = CFG_CALLBACK.lock().unwrap();
                            if let Some(cb) = cb_lock.as_ref() {
                                cb(text, hwnd);
                            }
                        }
                    } else {
                        let _ = ShowWindow(hwnd, SW_HIDE);
                    }
                }
            }
            // Timer 3: focus logic (used by refocus_editor after preset wheel)
            if wparam.0 == 3 {
                let _ = KillTimer(Some(hwnd), 3);
                TEXT_INPUT_WEBVIEW.with(|webview| {
                    if let Some(wv) = webview.borrow().as_ref() {
                        let _ = wv.focus();
                        let _ = wv.evaluate_script("document.getElementById('editor').focus();");
                    }
                });
            }
            // Timer 4: Hide window after fade-out
            if wparam.0 == 4 {
                let _ = KillTimer(Some(hwnd), 4);
                let _ = ShowWindow(hwnd, SW_HIDE);

                // Signal closure if needed
                let mut should_close = SHOULD_CLOSE.lock().unwrap();
                if *should_close {
                    *should_close = false;
                    let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
            }
            LRESULT(0)
        }

        WM_LBUTTONDOWN => {
            let x = (lparam.0 & 0xFFFF) as i16 as i32;
            let y = ((lparam.0 >> 16) & 0xFFFF) as i16 as i32;

            let mut rect = RECT::default();
            let _ = GetClientRect(hwnd, &mut rect);
            let w = rect.right;

            // Close Button
            let close_x = w - 30;
            let close_y = 20;
            if (x - close_x).abs() < 15 && (y - close_y).abs() < 15 {
                let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                return LRESULT(0);
            }

            // Title Bar Drag - Use Native Drag (Fix drifting issues)
            if y < 50 {
                let _ = ReleaseCapture();
                SendMessageW(hwnd, WM_SYSCOMMAND, Some(WPARAM(0xF012)), Some(LPARAM(0)));
                return LRESULT(0);
            }
            LRESULT(0)
        }

        WM_MOUSEMOVE => {
            // WM_MOUSEMOVE drag logic removed in favor of native drag
            LRESULT(0)
        }

        WM_LBUTTONUP => {
            // No capture cleanup needed for native drag
            LRESULT(0)
        }

        WM_SIZE => {
            // Resize WebView to match the new client area
            let mut rect = RECT::default();
            let _ = GetClientRect(hwnd, &mut rect);
            let width = rect.right - rect.left;
            let height = rect.bottom - rect.top;

            if width > 0 && height > 0 {
                TEXT_INPUT_WEBVIEW.with(|wv| {
                    if let Some(webview) = wv.borrow().as_ref() {
                        let _ = webview.set_bounds(Rect {
                            position: wry::dpi::Position::Physical(
                                wry::dpi::PhysicalPosition::new(0, 0),
                            ),
                            size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                                width as u32,
                                height as u32,
                            )),
                        });
                    }
                });
            }
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/screen_record/mod.rs">
use raw_window_handle::{
    HandleError, HasWindowHandle, RawWindowHandle, Win32WindowHandle, WindowHandle,
};
use std::borrow::Cow;
use std::num::NonZeroIsize;
use std::sync::{Arc, Once};
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::{
    DwmSetWindowAttribute, DWMWA_WINDOW_CORNER_PREFERENCE, DWMWCP_ROUND,
};
use windows::Win32::Graphics::Gdi::HBRUSH;
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::Input::KeyboardAndMouse::{ReleaseCapture, SetFocus};
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebViewBuilder};
use serde::Deserialize;
use crate::APP;
use crate::config::Hotkey;
use std::process::Child;
use std::sync::Mutex;
use std::path::PathBuf;

const WM_RELOAD_HOTKEYS: u32 = WM_USER + 101;
const MOD_ALT: u32 = 0x0001;
const MOD_CONTROL: u32 = 0x0002;
const MOD_SHIFT: u32 = 0x0004;
const MOD_WIN: u32 = 0x0008;

pub mod engine;
pub mod audio_engine;
pub mod keyviz;
// New module
pub mod native_export;

use engine::{
    get_monitors, CaptureHandler, AUDIO_ENCODING_FINISHED, ENCODING_FINISHED, MOUSE_POSITIONS,
    SHOULD_STOP, VIDEO_PATH, AUDIO_PATH
};
use windows_capture::capture::GraphicsCaptureApiHandler;
use windows_capture::settings::{
    ColorFormat, CursorCaptureSettings, DrawBorderSettings, Settings,
    SecondaryWindowSettings, MinimumUpdateIntervalSettings, DirtyRegionSettings
};
use windows_capture::monitor::Monitor;
use tiny_http::{Server, Response, StatusCode};
use std::fs::File;
use std::io::{Read, Seek};
use std::thread;

use crate::win_types::SendHwnd;

static REGISTER_SR_CLASS: Once = Once::new();
static mut SR_HWND: SendHwnd = SendHwnd(HWND(std::ptr::null_mut()));
static mut IS_WARMED_UP: bool = false;
static mut IS_INITIALIZING: bool = false;
const WM_APP_SHOW: u32 = WM_USER + 110;
const WM_APP_TOGGLE: u32 = WM_USER + 111;
const WM_APP_RUN_SCRIPT: u32 = WM_USER + 112;
const WM_UNREGISTER_HOTKEYS: u32 = WM_USER + 103;
const WM_REGISTER_HOTKEYS: u32 = WM_USER + 104;

thread_local! {
    static SR_WEBVIEW: std::cell::RefCell<Option<std::sync::Arc<wry::WebView>>> = std::cell::RefCell::new(None);
    static SR_WEB_CONTEXT: std::cell::RefCell<Option<WebContext>> = std::cell::RefCell::new(None);
}

lazy_static::lazy_static! {
    static ref SERVER_PORT: std::sync::atomic::AtomicU16 = std::sync::atomic::AtomicU16::new(0);
    static ref FFMPEG_PROCESS: Mutex<Option<Child>> = Mutex::new(None);
}

#[derive(Deserialize)]
struct IpcRequest {
    id: String,
    cmd: String,
    args: serde_json::Value,
}

// Assets
const INDEX_HTML: &[u8] = include_bytes!("dist/index.html");
const ASSET_INDEX_JS: &[u8] = include_bytes!("dist/assets/index.js");
const ASSET_INDEX_CSS: &[u8] = include_bytes!("dist/assets/index.css");
const ASSET_VITE_SVG: &[u8] = include_bytes!("dist/vite.svg");
const ASSET_TAURI_SVG: &[u8] = include_bytes!("dist/tauri.svg");
const ASSET_POINTER_SVG: &[u8] = include_bytes!("dist/pointer.svg");
const ASSET_SCREENSHOT_PNG: &[u8] = include_bytes!("dist/screenshot.png");

unsafe extern "system" fn sr_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_SHOW => {
            let _ = ShowWindow(hwnd, SW_SHOW);
            let _ = SetForegroundWindow(hwnd);
            let _ = SetFocus(Some(hwnd));
            LRESULT(0)
        }
        WM_CLOSE => {
            let _ = ShowWindow(hwnd, SW_HIDE);
            LRESULT(0)
        }
        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }
        WM_ERASEBKGND => LRESULT(1),
        WM_NCCALCSIZE => LRESULT(0),
        WM_NCHITTEST => {
            let mut rect = RECT::default();
            let _ = GetWindowRect(hwnd, &mut rect);
            let x = (lparam.0 & 0xFFFF) as i32;
            let y = ((lparam.0 >> 16) & 0xFFFF) as i32;
            
            let border = 8;
            let title_height = 44; 

            if y < rect.top + border {
                if x < rect.left + border { return LRESULT(HTTOPLEFT as isize); }
                if x > rect.right - border { return LRESULT(HTTOPRIGHT as isize); }
                return LRESULT(HTTOP as isize);
            }
            if y > rect.bottom - border {
                if x < rect.left + border { return LRESULT(HTBOTTOMLEFT as isize); }
                if x > rect.right - border { return LRESULT(HTBOTTOMRIGHT as isize); }
                return LRESULT(HTBOTTOM as isize);
            }
            if x < rect.left + border { return LRESULT(HTLEFT as isize); }
            if x > rect.right - border { return LRESULT(HTRIGHT as isize); }

            if y < rect.top + title_height {
                return LRESULT(HTCLIENT as isize);
            }

            LRESULT(HTCLIENT as isize)
        }
        WM_SIZE => {
            SR_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let mut r = RECT::default();
                    let _ = GetClientRect(hwnd, &mut r);
                    let width = r.right - r.left;
                    let height = r.bottom - r.top;
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(width as u32, height as u32)),
                    });
                }
            });
            LRESULT(0)
        }
        WM_APP_TOGGLE => {
            SR_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let _ = webview.evaluate_script("window.dispatchEvent(new CustomEvent('toggle-recording'));");
                }
            });
            LRESULT(0)
        }
        WM_SETFOCUS => {
            SR_WEBVIEW.with(|wv| {
                if let Some(webview) = wv.borrow().as_ref() {
                    let _ = webview.focus();
                }
            });
            LRESULT(0)
        }
        WM_APP_RUN_SCRIPT => {
            let script_ptr = lparam.0 as *mut String;
            if !script_ptr.is_null() {
                let script = unsafe { Box::from_raw(script_ptr) };
                SR_WEBVIEW.with(|wv| {
                    if let Some(webview) = wv.borrow().as_ref() {
                        let _ = webview.evaluate_script(&script);
                    }
                });
            }
            LRESULT(0)
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

struct HwndWrapper(HWND);

impl HasWindowHandle for HwndWrapper {
    fn window_handle(&self) -> std::result::Result<WindowHandle<'_>, HandleError> {
        let hwnd = self.0 .0 as isize;
        if hwnd == 0 {
            return Err(HandleError::Unavailable);
        }
        if let Some(non_zero) = NonZeroIsize::new(hwnd) {
            let mut handle = Win32WindowHandle::new(non_zero);
            handle.hinstance = None;
            let raw = RawWindowHandle::Win32(handle);
            Ok(unsafe { WindowHandle::borrow_raw(raw) })
        } else {
            Err(HandleError::Unavailable)
        }
    }
}

fn wnd_http_response(
    status: u16,
    content_type: &str,
    body: Cow<'static, [u8]>,
) -> wry::http::Response<Cow<'static, [u8]>> {
    wry::http::Response::builder()
        .status(status)
        .header("Content-Type", content_type)
        .header("Access-Control-Allow-Origin", "*")
        .body(body)
        .unwrap_or_else(|_| {
            wry::http::Response::builder()
                .status(500)
                .body(Cow::Borrowed(b"Internal Error".as_slice()))
                .unwrap()
        })
}

pub fn show_screen_record() {
    unsafe {
        if !IS_WARMED_UP {
            if !IS_INITIALIZING {
                IS_INITIALIZING = true;
                std::thread::spawn(|| {
                    internal_create_sr_loop();
                });
            }

            std::thread::spawn(|| {
                for _ in 0..100 {
                    std::thread::sleep(std::time::Duration::from_millis(100));
                    let hwnd_wrapper = std::ptr::addr_of!(SR_HWND).read();
                    if IS_WARMED_UP && !hwnd_wrapper.is_invalid() {
                        let _ =
                            PostMessageW(Some(hwnd_wrapper.0), WM_APP_SHOW, WPARAM(0), LPARAM(0));
                        return;
                    }
                }
            });
            return;
        }

        let hwnd_wrapper = std::ptr::addr_of!(SR_HWND).read();
        if !hwnd_wrapper.is_invalid() {
            let _ = PostMessageW(Some(hwnd_wrapper.0), WM_APP_SHOW, WPARAM(0), LPARAM(0));
        }
    }
}

pub fn toggle_recording() {
    unsafe {
        let hwnd_wrapper = std::ptr::addr_of!(SR_HWND).read();
        
        if hwnd_wrapper.is_invalid() {
            show_screen_record();
        } else {
            if IsWindowVisible(hwnd_wrapper.0).as_bool() {
                let _ = PostMessageW(Some(hwnd_wrapper.0), WM_APP_TOGGLE, WPARAM(0), LPARAM(0));
            } else {
                show_screen_record();
            }
        }
    }
}

unsafe fn internal_create_sr_loop() {
    let instance = GetModuleHandleW(None).unwrap();
    let class_name = windows::core::w!("ScreenRecord_Class");

    REGISTER_SR_CLASS.call_once(|| {
        let mut wc = WNDCLASSW::default();
        wc.lpfnWndProc = Some(sr_wnd_proc);
        wc.hInstance = instance.into();
        wc.lpszClassName = class_name;
        wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
        wc.hbrBackground = HBRUSH(std::ptr::null_mut());
        let _ = RegisterClassW(&wc);
    });

    let screen_w = GetSystemMetrics(SM_CXSCREEN);
    let screen_h = GetSystemMetrics(SM_CYSCREEN);

    let width = 1300;
    let height = 850;
    let x = (screen_w - width) / 2;
    let y = (screen_h - height) / 2;

    let hwnd = CreateWindowExW(
        WS_EX_APPWINDOW,
        class_name,
        windows::core::w!("Screen Record"),
        WS_POPUP | WS_THICKFRAME | WS_CAPTION | WS_SYSMENU | WS_MINIMIZEBOX | WS_MAXIMIZEBOX,
        x,
        y,
        width,
        height,
        None,
        None,
        Some(instance.into()),
        None,
    )
    .unwrap();

    SR_HWND = SendHwnd(hwnd);

    let corner_pref = DWMWCP_ROUND;
    let _ = DwmSetWindowAttribute(
        hwnd,
        DWMWA_WINDOW_CORNER_PREFERENCE,
        &corner_pref as *const _ as *const std::ffi::c_void,
        std::mem::size_of_val(&corner_pref) as u32,
    );

    let wrapper = HwndWrapper(hwnd);

    SR_WEB_CONTEXT.with(|ctx| {
        if ctx.borrow().is_none() {
            let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
            *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
        }
    });

    std::thread::sleep(std::time::Duration::from_millis(100));

    let webview_result = {
        let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();

        SR_WEB_CONTEXT.with(|ctx| {
            let mut ctx_ref = ctx.borrow_mut();
            let mut builder = WebViewBuilder::new_with_web_context(ctx_ref.as_mut().unwrap())
                .with_custom_protocol("screenrecord".to_string(), move |_id, request| {
                    let path = request.uri().path();
                    let (content, mime) = if path == "/" || path == "/index.html" {
                        (Cow::Borrowed(INDEX_HTML), "text/html")
                    } else if path.ends_with("index.js") {
                        (Cow::Borrowed(ASSET_INDEX_JS), "application/javascript")
                    } else if path.ends_with("index.css") {
                        (Cow::Borrowed(ASSET_INDEX_CSS), "text/css")
                    } else if path.ends_with("vite.svg") {
                        (Cow::Borrowed(ASSET_VITE_SVG), "image/svg+xml")
                    } else if path.ends_with("tauri.svg") {
                        (Cow::Borrowed(ASSET_TAURI_SVG), "image/svg+xml")
                    } else if path.ends_with("pointer.svg") {
                        (Cow::Borrowed(ASSET_POINTER_SVG), "image/svg+xml")
                    } else if path.ends_with("screenshot.png") {
                        (Cow::Borrowed(ASSET_SCREENSHOT_PNG), "image/png")
                    } else {
                        return wnd_http_response(
                            404,
                            "text/plain",
                            Cow::Borrowed(b"Not Found".as_slice()),
                        );
                    };
                    wnd_http_response(200, mime, content)
                })
                .with_initialization_script(r#"
                    (function() {
                        const originalPostMessage = window.ipc.postMessage;
                        window.__TAURI_INTERNALS__ = {
                            invoke: async (cmd, args) => {
                                return new Promise((resolve, reject) => {
                                    const id = Math.random().toString(36).substring(7);
                                    const handler = (e) => {
                                        if (e.detail && e.detail.id === id) {
                                            window.removeEventListener('ipc-reply', handler);
                                            if (e.detail.error) reject(e.detail.error);
                                            else resolve(e.detail.result);
                                        }
                                    };
                                    window.addEventListener('ipc-reply', handler);
                                    originalPostMessage(JSON.stringify({ id, cmd, args }));
                                });
                            }
                        };
                        window.__TAURI__ = {
                            core: {
                                invoke: window.__TAURI_INTERNALS__.invoke
                            }
                        };
                    })();
                "#)
                .with_ipc_handler({
                    let send_hwnd = SendHwnd(hwnd);
                    move |msg: wry::http::Request<String>| {
                        let body = msg.body().as_str();
                        let hwnd = send_hwnd.0;
                        if body == "drag_window" {
                            let _ = ReleaseCapture();
                            let _ = SendMessageW(
                                hwnd,
                                WM_NCLBUTTONDOWN,
                                Some(WPARAM(HTCAPTION as usize)),
                                Some(LPARAM(0)),
                            );
                        } else if body == "minimize_window" {
                            let _ = ShowWindow(hwnd, SW_MINIMIZE);
                        } else if body == "toggle_maximize" {
                            if unsafe { IsZoomed(hwnd).as_bool() } {
                                let _ = ShowWindow(hwnd, SW_RESTORE);
                            } else {
                                let _ = ShowWindow(hwnd, SW_MAXIMIZE);
                            }
                        } else if body == "close_window" {
                            let _ = ShowWindow(hwnd, SW_HIDE);
                        } else if let Ok(req) = serde_json::from_str::<IpcRequest>(body) {
                            let id = req.id;
                            let cmd = req.cmd;
                            let args = req.args;
                            let target_hwnd_val = send_hwnd.as_isize();
                            
                            thread::spawn(move || {
                                let result = handle_ipc_command(cmd, args);
                                let json_res = match result {
                                    Ok(res) => serde_json::json!({ "id": id, "result": res }),
                                    Err(err) => serde_json::json!({ "id": id, "error": err }),
                                };
                                let script = format!(
                                    "window.dispatchEvent(new CustomEvent('ipc-reply', {{ detail: {} }}))",
                                    json_res.to_string()
                                );
                                
                                let script_ptr = Box::into_raw(Box::new(script));
                                unsafe {
                                    let _ = PostMessageW(
                                        Some(HWND(target_hwnd_val as *mut std::ffi::c_void)), 
                                        WM_APP_RUN_SCRIPT, 
                                        WPARAM(0), 
                                        LPARAM(script_ptr as isize)
                                    );
                                }
                            });
                        }
                    }
                })
                .with_url("screenrecord://localhost/index.html");

            builder = crate::overlay::html_components::font_manager::configure_webview(builder);
            builder.build_as_child(&wrapper)
        })
    };

    let webview = match webview_result {
        Ok(wv) => wv,
        Err(e) => {
            eprintln!("Failed to create ScreenRecord WebView: {:?}", e);
            let _ = DestroyWindow(hwnd);
            SR_HWND = SendHwnd::default();
            return;
        }
    };
    let webview_arc = Arc::new(webview);

    let mut r = RECT::default();
    let _ = GetClientRect(hwnd, &mut r);
    let _ = webview_arc.set_bounds(Rect {
        position: wry::dpi::Position::Physical(wry::dpi::PhysicalPosition::new(0, 0)),
        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
            (r.right - r.left) as u32,
            (r.bottom - r.top) as u32,
        )),
    });

    SR_WEBVIEW.with(|wv| {
        *wv.borrow_mut() = Some(webview_arc);
    });

    unsafe {
        IS_WARMED_UP = true;
    }

    let mut msg = MSG::default();
    unsafe {
        while GetMessageW(&mut msg, None, 0, 0).as_bool() {
            let _ = TranslateMessage(&msg);
            let _ = DispatchMessageW(&msg);
        }
    }

    SR_WEBVIEW.with(|wv| {
        *wv.borrow_mut() = None;
    });
    unsafe {
        SR_HWND = SendHwnd::default();
        IS_WARMED_UP = false;
        IS_INITIALIZING = false;
    }
}

fn get_ffmpeg_path() -> PathBuf {
    dirs::data_local_dir()
        .unwrap_or_else(|| PathBuf::from("."))
        .join("screen-goated-toolbox")
        .join("bin")
        .join("ffmpeg.exe")
}

fn handle_ipc_command(cmd: String, args: serde_json::Value) -> Result<serde_json::Value, String> {
    match cmd.as_str() {
        "start_export_server" => {
            native_export::start_native_export(args)
        }
        "get_monitors" => {
            let monitors = get_monitors();
            Ok(serde_json::to_value(monitors).unwrap())
        }
        "install_keyviz" => {
            std::thread::spawn(|| {
                if let Err(e) = keyviz::install_keyviz() {
                    crate::log_info!("Keyviz install failed: {}", e);
                }
            });
            Ok(serde_json::Value::Null)
        }
        "set_keyviz_enabled" => {
            let enabled = args["enabled"].as_bool().unwrap_or(false);
            keyviz::set_enabled(enabled);
            Ok(serde_json::Value::Null)
        }
        "get_keyviz_status" => {
            Ok(serde_json::json!({
                "installed": keyviz::is_installed(),
                "enabled": keyviz::is_enabled()
            }))
        }
        "start_recording" => {
            let monitor_id = args["monitorId"].as_str().unwrap_or("0");
            let monitor_index = monitor_id.parse::<usize>().unwrap_or(0);
            
            SHOULD_STOP.store(false, std::sync::atomic::Ordering::SeqCst);
            crate::overlay::screen_record::engine::IS_MOUSE_CLICKED.store(false, std::sync::atomic::Ordering::SeqCst);
            crate::overlay::screen_record::engine::CLICK_CAPTURED.store(false, std::sync::atomic::Ordering::SeqCst);
            crate::overlay::screen_record::engine::MOUSE_POSITIONS.lock().clear();
            
            let monitor = Monitor::from_index(monitor_index + 1).map_err(|e| e.to_string())?;

            unsafe {
                let mut monitors: Vec<windows::Win32::Graphics::Gdi::HMONITOR> = Vec::new();
                let _ = windows::Win32::Graphics::Gdi::EnumDisplayMonitors(
                    None,
                    None,
                    Some(crate::overlay::screen_record::engine::monitor_enum_proc),
                    windows::Win32::Foundation::LPARAM(&mut monitors as *mut _ as isize),
                );
                if let Some(&hmonitor) = monitors.get(monitor_index) {
                    let mut info: windows::Win32::Graphics::Gdi::MONITORINFOEXW = std::mem::zeroed();
                    info.monitorInfo.cbSize = std::mem::size_of::<windows::Win32::Graphics::Gdi::MONITORINFOEXW>() as u32;
                    if windows::Win32::Graphics::Gdi::GetMonitorInfoW(hmonitor, &mut info.monitorInfo as *mut _).as_bool() {
                        crate::overlay::screen_record::engine::MONITOR_X = info.monitorInfo.rcMonitor.left;
                        crate::overlay::screen_record::engine::MONITOR_Y = info.monitorInfo.rcMonitor.top;
                    }
                }
            }

            let settings = Settings::new(
                monitor,
                CursorCaptureSettings::WithoutCursor,
                DrawBorderSettings::Default,
                SecondaryWindowSettings::Include,
                MinimumUpdateIntervalSettings::Default,
                DirtyRegionSettings::Default,
                ColorFormat::Bgra8,
                monitor_id.to_string(),
            );

            let _ = keyviz::start();

            std::thread::spawn(move || {
                let _ = CaptureHandler::start_free_threaded(settings);
            });

            Ok(serde_json::Value::Null)
        }
        "stop_recording" => {
            SHOULD_STOP.store(true, std::sync::atomic::Ordering::SeqCst);
            let _ = keyviz::stop();
            
            let start = std::time::Instant::now();
            while (!ENCODING_FINISHED.load(std::sync::atomic::Ordering::SeqCst) || 
                   !AUDIO_ENCODING_FINISHED.load(std::sync::atomic::Ordering::SeqCst)) && 
                  start.elapsed().as_secs() < 10 {
                std::thread::sleep(std::time::Duration::from_millis(100));
            }

            let video_path = unsafe { VIDEO_PATH.clone() }.ok_or("No video path")?;
            let audio_path = unsafe { AUDIO_PATH.clone() }.ok_or("No audio path")?;
            
            let port = start_media_server(video_path, audio_path.clone())?;
            
            let mouse_positions = MOUSE_POSITIONS.lock().drain(..).collect::<Vec<_>>();
            
            let video_url = format!("http://localhost:{}/video", port);
            let audio_url = format!("http://localhost:{}/audio", port);
            
            let audio_file_path = audio_path; 

            Ok(serde_json::json!([video_url, audio_url, mouse_positions, audio_file_path]))
        }
        "get_hotkeys" => {
            let app = APP.lock().unwrap();
            Ok(serde_json::to_value(&app.config.screen_record_hotkeys).unwrap())
        }
        "remove_hotkey" => {
            let index = args["index"].as_u64().ok_or("Missing index")? as usize;
            {
                let mut app = APP.lock().unwrap();
                if index < app.config.screen_record_hotkeys.len() {
                    app.config.screen_record_hotkeys.remove(index);
                    crate::config::save_config(&app.config);
                }
            }
            trigger_hotkey_reload();
            Ok(serde_json::Value::Null)
        }
        "set_hotkey" => {
            let code_str = args["code"].as_str().ok_or("Missing code")?;
            let mods_arr = args["modifiers"].as_array().ok_or("Missing modifiers")?;
            let key_name = args["key"].as_str().unwrap_or("Unknown");

            let vk_code = js_code_to_vk(code_str).ok_or(format!("Unsupported key code: {}", code_str))?;
            
            let mut modifiers = 0;
            for m in mods_arr {
                match m.as_str() {
                    Some("Control") => modifiers |= MOD_CONTROL,
                    Some("Alt") => modifiers |= MOD_ALT,
                    Some("Shift") => modifiers |= MOD_SHIFT,
                    Some("Meta") => modifiers |= MOD_WIN,
                    _ => {}
                }
            }

            {
                let app = APP.lock().unwrap();
                if let Some(msg) = app.config.check_hotkey_conflict(vk_code, modifiers, None) {
                    return Err(msg);
                }
            }

            let mut name_parts = Vec::new();
            if (modifiers & MOD_CONTROL) != 0 { name_parts.push("Ctrl"); }
            if (modifiers & MOD_ALT) != 0 { name_parts.push("Alt"); }
            if (modifiers & MOD_SHIFT) != 0 { name_parts.push("Shift"); }
            if (modifiers & MOD_WIN) != 0 { name_parts.push("Win"); }
            
            let formatted_key = if key_name.len() == 1 {
                key_name.to_uppercase()
            } else {
                match key_name {
                    " " => "Space".to_string(),
                    _ => key_name.to_string(),
                }
            };
            name_parts.push(&formatted_key);
            
            let hotkey = Hotkey {
                code: vk_code,
                modifiers,
                name: name_parts.join(" + "),
            };

            {
                let mut app = APP.lock().unwrap();
                app.config.screen_record_hotkeys.push(hotkey.clone());
                crate::config::save_config(&app.config);
            }

            trigger_hotkey_reload();

            Ok(serde_json::to_value(&hotkey).unwrap())
        }
        "unregister_hotkeys" => {
            unsafe {
                if let Ok(hwnd) = FindWindowW(windows::core::w!("HotkeyListenerClass"), windows::core::w!("Listener")) {
                    if !hwnd.is_invalid() {
                        let _ = PostMessageW(Some(hwnd), WM_UNREGISTER_HOTKEYS, WPARAM(0), LPARAM(0));
                    }
                }
            }
            Ok(serde_json::Value::Null)
        }
        "register_hotkeys" => {
            unsafe {
                if let Ok(hwnd) = FindWindowW(windows::core::w!("HotkeyListenerClass"), windows::core::w!("Listener")) {
                    if !hwnd.is_invalid() {
                        let _ = PostMessageW(Some(hwnd), WM_REGISTER_HOTKEYS, WPARAM(0), LPARAM(0));
                    }
                }
            }
            Ok(serde_json::Value::Null)
        }
        "minimize_window" => {
            unsafe {
                let hwnd = std::ptr::addr_of!(SR_HWND).read();
                if !hwnd.is_invalid() {
                    let _ = ShowWindow(hwnd.0, SW_MINIMIZE);
                }
            }
            Ok(serde_json::Value::Null)
        }
        "toggle_maximize" => {
            unsafe {
                let hwnd = std::ptr::addr_of!(SR_HWND).read();
                if !hwnd.is_invalid() {
                    if IsZoomed(hwnd.0).as_bool() {
                        let _ = ShowWindow(hwnd.0, SW_RESTORE);
                    } else {
                        let _ = ShowWindow(hwnd.0, SW_MAXIMIZE);
                    }
                }
            }
            Ok(serde_json::Value::Null)
        }
        "close_window" => {
            unsafe {
                let hwnd = std::ptr::addr_of!(SR_HWND).read();
                if !hwnd.is_invalid() {
                    let _ = ShowWindow(hwnd.0, SW_HIDE);
                }
            }
            Ok(serde_json::Value::Null)
        }
        "is_maximized" => {
            unsafe {
                let hwnd = std::ptr::addr_of!(SR_HWND).read();
                let maximized = if !hwnd.is_invalid() {
                    IsZoomed(hwnd.0).as_bool()
                } else {
                    false
                };
                Ok(serde_json::json!(maximized))
            }
        }
        _ => Err(format!("Unknown command: {}", cmd)),
    }
}

fn trigger_hotkey_reload() {
    unsafe {
        if let Ok(hwnd) = FindWindowW(windows::core::w!("HotkeyListenerClass"), windows::core::w!("Listener")) {
            if !hwnd.is_invalid() {
                let _ = PostMessageW(Some(hwnd), WM_RELOAD_HOTKEYS, WPARAM(0), LPARAM(0));
            }
        }
    }
}

fn js_code_to_vk(code: &str) -> Option<u32> {
    match code {
        c if c.starts_with("Key") => {
            let chars: Vec<char> = c.chars().collect();
            if chars.len() == 4 {
                Some(chars[3] as u32) 
            } else { None }
        },
        c if c.starts_with("Digit") => {
            let chars: Vec<char> = c.chars().collect();
            if chars.len() == 6 {
                Some(chars[5] as u32) 
            } else { None }
        },
        c if c.starts_with("F") && c.len() <= 3 => {
             c[1..].parse::<u32>().ok().map(|n| 0x70 + n - 1)
        },
        "Space" => Some(0x20),
        "Enter" => Some(0x0D),
        "Escape" => Some(0x1B),
        "Backspace" => Some(0x08),
        "Tab" => Some(0x09),
        "Delete" => Some(0x2E),
        "Insert" => Some(0x2D),
        "Home" => Some(0x24),
        "End" => Some(0x23),
        "PageUp" => Some(0x21),
        "PageDown" => Some(0x22),
        "ArrowUp" => Some(0x26),
        "ArrowDown" => Some(0x28),
        "ArrowLeft" => Some(0x25),
        "ArrowRight" => Some(0x27),
        "Backquote" => Some(0xC0),
        "Minus" => Some(0xBD),
        "Equal" => Some(0xBB),
        "BracketLeft" => Some(0xDB),
        "BracketRight" => Some(0xDD),
        "Backslash" => Some(0xDC),
        "Semicolon" => Some(0xBA),
        "Quote" => Some(0xDE),
        "Comma" => Some(0xBC),
        "Period" => Some(0xBE),
        "Slash" => Some(0xBF),
        c if c.starts_with("Numpad") => {
            let chars: Vec<char> = c.chars().collect();
            if chars.len() == 7 {
                Some(chars[6] as u32 + 0x30) 
            } else { None }
        },
        _ => None,
    }
}

fn start_media_server(video_path: String, audio_path: String) -> Result<u16, String> {
    let mut port = 8000;
    let server = loop {
        match Server::http(format!("127.0.0.1:{}", port)) {
            Ok(s) => break s,
            Err(_) => {
                port += 1;
                if port > 9000 { return Err("No port available".to_string()); }
            }
        }
    };

    let actual_port = port;
    SERVER_PORT.store(actual_port, std::sync::atomic::Ordering::SeqCst);

    std::thread::spawn(move || {
        for request in server.incoming_requests() {
            if request.method() == &tiny_http::Method::Options {
                let mut res = Response::empty(204);
                res.add_header(tiny_http::Header::from_bytes(&b"Access-Control-Allow-Origin"[..], &b"*"[..]).unwrap());
                res.add_header(tiny_http::Header::from_bytes(&b"Access-Control-Allow-Methods"[..], &b"GET, OPTIONS"[..]).unwrap());
                res.add_header(tiny_http::Header::from_bytes(&b"Access-Control-Allow-Headers"[..], &b"Range"[..]).unwrap());
                let _ = request.respond(res);
                continue;
            }

            let url = request.url();
            let is_audio = url.contains("audio");
            let media_path = if is_audio { &audio_path } else { &video_path };
            let content_type = if is_audio { "audio/wav" } else { "video/mp4" };

            if let Ok(file) = File::open(media_path) {
                let file_size = file.metadata().map(|m| m.len()).unwrap_or(0);
                let mut start = 0;
                let mut end = file_size.saturating_sub(1);

                if let Some(range) = request.headers().iter().find(|h| h.field.as_str() == "Range") {
                    if let Some(r) = range.value.as_str().strip_prefix("bytes=") {
                        let parts: Vec<&str> = r.split('-').collect();
                        if parts.len() == 2 {
                            if let Ok(s) = parts[0].parse::<u64>() { start = s; }
                            if let Ok(e) = parts[1].parse::<u64>() {
                                if !parts[1].is_empty() { end = e; }
                            }
                        }
                    }
                }

                if let Ok(mut f) = File::open(media_path) {
                    let _ = f.seek(std::io::SeekFrom::Start(start));
                    let mut res = Response::new(
                        if start == 0 && end == file_size.saturating_sub(1) { StatusCode(200) } else { StatusCode(206) },
                        vec![
                            tiny_http::Header::from_bytes(&b"Content-Type"[..], content_type.as_bytes()).unwrap(),
                            tiny_http::Header::from_bytes(&b"Access-Control-Allow-Origin"[..], &b"*"[..]).unwrap(),
                        ],
                        Box::new(f.take(end - start + 1)) as Box<dyn Read + Send>,
                        Some((end - start + 1) as usize),
                        None,
                    );
                    if start != 0 || end != file_size.saturating_sub(1) {
                        res.add_header(tiny_http::Header::from_bytes(&b"Content-Range"[..], format!("bytes {}-{}/{}", start, end, file_size).as_bytes()).unwrap());
                    }
                    let _ = request.respond(res);
                }
            } else {
                let _ = request.respond(Response::from_string("File not found").with_status_code(404));
            }
        }
    });

    Ok(actual_port)
}
</file>

<file path="Cargo.toml">
[package]
name = "screen-goated-toolbox"
version = "4.5.1"
edition = "2021"

[build-dependencies]
winres = "0.1"
image = { version = "0.25", default-features = false, features = ["png", "bmp"] }

[dependencies]
# Network & Serialization
ureq = { version = "3.1", features = ["json"] }
tungstenite = { version = "0.28", features = ["native-tls"] }
native-tls = "0.2"
url = "2.5"
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
anyhow = "1.0"
base64 = "0.22"
self_update = { version = "0.42", features = ["archive-zip", "compression-zip-deflate"] }
zip = "7.0"
byteorder = "1.5"
rayon = "1.8"

# Image Processing
image = { version = "0.25", default-features = false, features = ["png", "bmp", "jpeg", "gif", "webp", "tiff"] }

# Time
chrono = { version = "0.4", features = ["serde"] }

# System
dirs = "6.0"
lazy_static = "1.5"
textwrap = "0.16"
open = "5.3"
sys-locale = "0.3"
winreg = "0.55"
auto-launch = "0.5"
urlencoding = "2.1"

# Language Data
isolang = { version = "2.4", features = ["serde", "english_names"] }
whatlang = "0.18"

# GUI & Media
eframe = { version = "0.33", default-features = false, features = ["glow"] }
egui-snarl = { path = "libs/egui-snarl", features = ["serde"] }
tray-icon = "0.21.3"
cpal = "0.17"
hound = "3.5"
wasapi = "0.22"
minimp3 = "0.6"
egui_extras = { version = "0.33", features = ["all_loaders"] }
symphonia = { version = "0.5", features = ["mp3", "flac", "ogg", "wav", "aac", "alac", "pcm"] }

# Markdown Rendering
pulldown-cmark = "0.13"
wry = "0.53.5"
raw-window-handle = "0.6"
windows-core = "0.62"
parakeet-rs = { version = "0.2.7", features = ["directml"] }
ort = { version = "2.0.0-rc.10", features = ["directml", "load-dynamic"] }
ringbuf = "0.4.8"
dark-light = "2.0.0"
windows-capture = "1.5.0"
rdev = "0.5.3"
tiny_http = "0.12"
memmap2 = "0.5.10"
parking_lot = "0.12"

# Vector Graphics Rendering
resvg = "0.45"
tiny-skia = "0.11"

[dependencies.windows]
version = "0.62"
features = [
    "Win32_Foundation",
    "Win32_UI_WindowsAndMessaging",
    "Win32_UI_Controls",
    "Win32_Graphics_Gdi",
    "Win32_UI_Input_KeyboardAndMouse",
    "Win32_System_LibraryLoader",
    "Win32_Graphics_Dwm",
    "Win32_UI_HiDpi",
    "Win32_System_Threading",
    "Win32_Security",
    "Win32_System_Com",
    "Win32_System_DataExchange",
    "Win32_System_Memory",
    "Win32_Media_Audio",
    "Win32_System_SystemInformation",
    "Win32_UI_Shell",
    "Win32_UI_Shell_Common",
    "Win32_UI_Accessibility",
    "Win32_Graphics_Direct3D11",
    "Win32_Graphics_Dxgi",
]

[profile.release]
opt-level = "z"
lto = true
codegen-units = 1
strip = "symbols"
debug = 1
panic = "unwind"
</file>

<file path="screen-record/src/App.tsx">
import { useState, useRef, useEffect, useCallback } from "react";
import { invoke } from "@tauri-apps/api/core";
import { Play, Pause, Video, Trash2, Search, Download, Loader2, FolderOpen, Upload, Wand2, Type, Keyboard, X, Minus, Square, Copy } from "lucide-react";
import "./App.css";
import { Button } from "@/components/ui/button";
import { videoRenderer } from '@/lib/videoRenderer';
import { BackgroundConfig, VideoSegment, ZoomKeyframe, MousePosition, ExportOptions, Project, TextSegment } from '@/types/video';
import { videoExporter, EXPORT_PRESETS, DIMENSION_PRESETS } from '@/lib/videoExporter';
import { createVideoController } from '@/lib/videoController';

import { projectManager } from '@/lib/projectManager';
import { autoZoomGenerator } from '@/lib/autoZoom';
import { Timeline } from '@/components/Timeline';
import { thumbnailGenerator } from '@/lib/thumbnailGenerator';
import { useUndoRedo } from '@/hooks/useUndoRedo';
import { Crop } from "lucide-react";

// Replace the debounce utility with throttle
const useThrottle = (callback: Function, limit: number) => {
  const lastRunRef = useRef<number>(0);

  return useCallback((...args: any[]) => {
    const now = Date.now();
    if (now - lastRunRef.current >= limit) {
      callback(...args);
      lastRunRef.current = now;
    }
  }, [callback, limit]);
};

// Add these interfaces near the top of the file
interface MonitorInfo {
  id: string;
  name: string;
  width: number;
  height: number;
  x: number;
  y: number;
  is_primary: boolean;
}

interface Hotkey {
  code: number;
  name: string;
  modifiers: number;
}

// Add this helper function near the top of the file
const sortMonitorsByPosition = (monitors: MonitorInfo[]) => {
  return [...monitors]
    .sort((a, b) => a.x - b.x)
    .map((monitor, index) => ({
      ...monitor,
      name: `Display ${index + 1}${monitor.is_primary ? ' (Primary)' : ''}`
    }));
};

// Added helper function to calculate the range for a zoom keyframe.
// It returns an object containing the range start and end for the given keyframe.
const getKeyframeRange = (
  keyframes: ZoomKeyframe[],
  index: number
): { rangeStart: number; rangeEnd: number } => {
  const keyframe = keyframes[index];
  const prevKeyframe = index > 0 ? keyframes[index - 1] : null;
  const rangeStart =
    prevKeyframe && keyframe.time - prevKeyframe.time <= 1.0
      ? prevKeyframe.time
      : Math.max(0, keyframe.time - 1.0);
  return { rangeStart, rangeEnd: keyframe.time };
};

function App() {
  const [isRecording, setIsRecording] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [currentTime, setCurrentTime] = useState(0);
  const [duration, setDuration] = useState(0);
  const [isPlaying, setIsPlaying] = useState(false);
  const { state: segment, setState: setSegment, undo, redo, canUndo, canRedo } = useUndoRedo<VideoSegment | null>(null);
  const [editingKeyframeId, setEditingKeyframeId] = useState<number | null>(null);
  const [zoomFactor, setZoomFactor] = useState(1.5);
  const [isProcessing, setIsProcessing] = useState(false);
  const [currentVideo, setCurrentVideo] = useState<string | null>(null);
  const [exportProgress, setExportProgress] = useState(0);
  const [isLoadingVideo, setIsLoadingVideo] = useState(false);
  const [loadingProgress, setLoadingProgress] = useState(0);
  const [currentAudio, setCurrentAudio] = useState<string | null>(null);
  const [isCropping, setIsCropping] = useState(false);
  const [audioFilePath, setAudioFilePath] = useState<string>("");

  const videoRef = useRef<HTMLVideoElement | null>(null);
  const audioRef = useRef<HTMLAudioElement | null>(null);
  const canvasRef = useRef<HTMLCanvasElement | null>(null);
  const timelineRef = useRef<HTMLDivElement>(null);
  const previewContainerRef = useRef<HTMLDivElement>(null);

  // Add this to your App component state
  const [backgroundConfig, setBackgroundConfig] = useState<BackgroundConfig>({
    scale: 90,
    borderRadius: 48,
    backgroundType: 'gradient2',
    shadow: 100,
    volume: 1,
    cursorScale: 5
  });

  // Add this state to toggle between panels
  const [activePanel, setActivePanel] = useState<'zoom' | 'background' | 'cursor' | 'text'>('zoom');

  // Add these gradient constants
  const GRADIENT_PRESETS = {
    solid: 'bg-black',
    gradient1: 'bg-gradient-to-r from-blue-600 to-violet-600',
    gradient2: 'bg-gradient-to-r from-rose-400 to-orange-300',
    gradient3: 'bg-gradient-to-r from-emerald-500 to-teal-400'
  };

  // Add at the top of your component
  const tempCanvasRef = useRef<HTMLCanvasElement>(document.createElement('canvas'));

  // Add to your App component state
  const [mousePositions, setMousePositions] = useState<MousePosition[]>([]);

  // Add new state at the top of App component
  const [isVideoReady, setIsVideoReady] = useState(false);

  // Create video controller ref
  const videoControllerRef = useRef<ReturnType<typeof createVideoController>>();

  // Initialize controller
  useEffect(() => {
    if (!videoRef.current || !canvasRef.current) return;

    videoControllerRef.current = createVideoController({
      videoRef: videoRef.current,
      audioRef: audioRef.current || undefined,
      canvasRef: canvasRef.current,
      tempCanvasRef: tempCanvasRef.current,
      onTimeUpdate: (time) => setCurrentTime(time),
      onPlayingChange: (playing) => setIsPlaying(playing),
      onVideoReady: (ready) => setIsVideoReady(ready),
      onDurationChange: (duration) => setDuration(duration),
      onError: (error) => setError(error),
      onMetadataLoaded: (metadata) => {
        // When metadata loads, if we have a segment with invalid trimEnd (0 or > duration),
        // we must update it to match the actual duration.
        // This fixes the "Reached trim end" bug on project load.
        setSegment(prevSegment => {
          if (!prevSegment) return null;

          if (prevSegment.trimEnd === 0 || prevSegment.trimEnd > metadata.duration) {
            console.log('[App] Fixing invalid trimEnd on metadata load:', metadata.duration);
            return {
              ...prevSegment,
              trimEnd: metadata.duration
            };
          }
          return prevSegment;
        });
      }
    });

    return () => {
      videoControllerRef.current?.destroy();
    };
  }, []);

  // Sync volume with controller
  useEffect(() => {
    if (videoControllerRef.current && backgroundConfig.volume !== undefined) {
      videoControllerRef.current.setVolume(backgroundConfig.volume);
    }
  }, [backgroundConfig.volume]);

  // Sync renderOptions with controller when segment/config changes
  useEffect(() => {
    if (!segment || !videoControllerRef.current) return;
    videoControllerRef.current.updateRenderOptions({
      segment,
      backgroundConfig,
      mousePositions
    });
  }, [segment, backgroundConfig, mousePositions]);

  // Helper function to render a frame
  const renderFrame = useCallback(() => {
    if (!segment || !videoRef.current || !canvasRef.current) return;

    // Explicitly draw frame if paused to reflect changes immediately
    if (videoRef.current.paused) {
      // If cropping, force a 1.0 zoom render AND full source (no crop) so we see the full context
      const renderSegment = isCropping ? {
        ...segment,
        crop: undefined, // Show full video
        zoomKeyframes: segment.zoomKeyframes.map(k => ({
          ...k,
          zoomFactor: 1.0,
          positionX: 0.5,
          positionY: 0.5
        }))
      } : segment;

      // Ensure we Strip all background config (Scale 100%, No padding, No shadow)
      const renderBackground = isCropping ? {
        ...backgroundConfig,
        scale: 100,
        borderRadius: 0,
        shadow: 0,
        backgroundType: 'solid' as const,
        customBackground: undefined,
        cropBottom: 0
      } : backgroundConfig;

      videoRenderer.drawFrame({
        video: videoRef.current,
        canvas: canvasRef.current,
        tempCanvas: tempCanvasRef.current,
        segment: renderSegment,
        backgroundConfig: renderBackground,
        mousePositions,
        currentTime: videoRef.current.currentTime
      });
    }
  }, [segment, backgroundConfig, mousePositions, isCropping]);

  // Remove frameCallback and simplify the animation effect
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    // Start animation when playing, render single frame when paused
    if (video.paused) {
      renderFrame();
    } else {
      // Logic for playing state: Also override if cropping
      const loopSegment = (isCropping && segment) ? {
        ...segment,
        crop: undefined,
        zoomKeyframes: segment.zoomKeyframes.map(k => ({ ...k, zoomFactor: 1.0, positionX: 0.5, positionY: 0.5 }))
      } : segment;

      const loopBackground = isCropping ? {
        ...backgroundConfig,
        scale: 100,
        borderRadius: 0,
        shadow: 0,
        backgroundType: 'solid' as const,
        customBackground: undefined,
        cropBottom: 0
      } : backgroundConfig;

      const renderContext = {
        video,
        canvas: canvasRef.current!,
        tempCanvas: tempCanvasRef.current,
        segment: loopSegment!,
        backgroundConfig: loopBackground,
        mousePositions,
        currentTime: video.currentTime
      };
      videoRenderer.startAnimation(renderContext);
    }

    return () => {
      videoRenderer.stopAnimation();
    };
  }, [segment, backgroundConfig, mousePositions, isCropping]);

  const [isWindowMaximized, setIsWindowMaximized] = useState(false);

  useEffect(() => {
    invoke<boolean>('is_maximized').then(setIsWindowMaximized).catch(() => { });
  }, []);

  // Update other places where drawFrame was used to use renderFrame instead
  useEffect(() => {
    if (videoRef.current && !videoRef.current.paused) return;
    renderFrame();
  }, [backgroundConfig, renderFrame]);

  // Add these state variables inside App component
  const [monitors, setMonitors] = useState<MonitorInfo[]>([]);
  const [showMonitorSelect, setShowMonitorSelect] = useState(false);


  // Add this function to fetch monitors
  const getMonitors = async () => {
    try {
      const monitors = await invoke<MonitorInfo[]>("get_monitors");
      // Sort monitors before setting state
      const sortedMonitors = sortMonitorsByPosition(monitors);
      setMonitors(sortedMonitors);
      return sortedMonitors;
    } catch (err) {
      console.error("Failed to get monitors:", err);
      setError(err as string);
      return [];
    }
  };

  const [hotkeys, setHotkeys] = useState<Hotkey[]>([]);
  const [showHotkeyDialog, setShowHotkeyDialog] = useState(false);
  const [listeningForKey, setListeningForKey] = useState(false);

  useEffect(() => {
    invoke<Hotkey[]>('get_hotkeys').then(setHotkeys).catch(() => { });
  }, []);

  const handleRemoveHotkey = async (index: number) => {
    try {
      await invoke('remove_hotkey', { index });
      setHotkeys(prev => prev.filter((_, i) => i !== index));
    } catch (err) {
      console.error("Failed to remove hotkey:", err);
    }
  };

  const [keyvizStatus, setKeyvizStatus] = useState({ installed: false, enabled: false });

  useEffect(() => {
    invoke<{ installed: boolean; enabled: boolean }>('get_keyviz_status')
      .then(setKeyvizStatus)
      .catch(console.error);
  }, []);

  const toggleKeyviz = async () => {
    try {
      if (!keyvizStatus.installed && !keyvizStatus.enabled) {
        await invoke('install_keyviz');
        await invoke('set_keyviz_enabled', { enabled: true });
        setKeyvizStatus({ installed: true, enabled: true });
      } else {
        const newEnabled = !keyvizStatus.enabled;
        await invoke('set_keyviz_enabled', { enabled: newEnabled });
        setKeyvizStatus(prev => ({ ...prev, enabled: newEnabled }));
      }
    } catch (err) {
      console.error("Failed to toggle keyviz:", err);
    }
  };

  useEffect(() => {
    if (showHotkeyDialog && listeningForKey) {
      invoke('unregister_hotkeys').catch(() => { });
      window.focus();
    } else {
      invoke('register_hotkeys').catch(() => { });
    }
    return () => {
      invoke('register_hotkeys').catch(() => { });
    };
  }, [showHotkeyDialog, listeningForKey]);

  useEffect(() => {
    if (showHotkeyDialog && listeningForKey) {
      const handleKeyDown = async (e: KeyboardEvent) => {
        e.preventDefault();

        // Ignore modifier-only presses
        if (['Control', 'Alt', 'Shift', 'Meta'].includes(e.key)) return;

        const modifiers = [];
        if (e.ctrlKey) modifiers.push('Control');
        if (e.altKey) modifiers.push('Alt');
        if (e.shiftKey) modifiers.push('Shift');
        if (e.metaKey) modifiers.push('Meta');

        try {
          const newHotkey = await invoke<Hotkey>('set_hotkey', {
            code: e.code,
            modifiers,
            key: e.key
          });
          setHotkeys(prev => [...prev, newHotkey]);
          setListeningForKey(false);
          setShowHotkeyDialog(false);
        } catch (err) {
          console.error("Failed to set hotkey:", err);
          setError(err as string || "Failed to set hotkey");
          setListeningForKey(false);
        }
      };

      window.addEventListener('keydown', handleKeyDown);
      return () => window.removeEventListener('keydown', handleKeyDown);
    }
  }, [showHotkeyDialog, listeningForKey]);

  useEffect(() => {
    const handleToggle = () => {
      if (showHotkeyDialog) {
        console.log("Toggle recording ignored: Hotkey dialog is open");
        return;
      }
      console.log("Toggle recording requested via hotkey/IPC");
      if (isRecording) {
        handleStopRecording();
      } else {
        handleStartRecording();
      }
    };
    window.addEventListener('toggle-recording', handleToggle);
    return () => window.removeEventListener('toggle-recording', handleToggle);
  }, [isRecording, currentVideo, showHotkeyDialog]);

  // Update handleStartRecording
  async function handleStartRecording() {
    if (isRecording) return;

    try {
      const monitors = await getMonitors();

      if (monitors.length > 1) {
        setShowMonitorSelect(true);
        return;
      }

      // If only one monitor, use it directly
      await startNewRecording('0');
    } catch (err) {
      console.error("Failed to handle start recording:", err);
      setError(err as string);
    }
  }

  // Update startNewRecording to handle string IDs
  async function startNewRecording(monitorId: string) {
    try {
      // Clear all states first
      setMousePositions([]);
      setIsVideoReady(false);
      setCurrentTime(0);
      setDuration(0);
      setIsPlaying(false);
      setSegment(null);
      setZoomFactor(1.5);
      setEditingKeyframeId(null);
      setThumbnails([]);

      // Clear previous video
      if (currentVideo) {
        URL.revokeObjectURL(currentVideo);
        setCurrentVideo(null);
      }
      if (currentAudio) {
        URL.revokeObjectURL(currentAudio);
        setCurrentAudio(null);
      }

      // Reset video element
      if (videoRef.current) {
        videoRef.current.pause();
        videoRef.current.src = "";
        videoRef.current.load();
        videoRef.current.removeAttribute('src');
        videoRef.current.currentTime = 0;
      }

      // Clear canvas
      const canvas = canvasRef.current;
      if (canvas) {
        const ctx = canvas.getContext('2d');
        if (ctx) {
          ctx.clearRect(0, 0, canvas.width, canvas.height);
        }
      }

      // Reset audio element
      if (audioRef.current) {
        audioRef.current.pause();
        audioRef.current.src = "";
        audioRef.current.load();
        audioRef.current.removeAttribute('src');
      }

      // Now start the new recording
      await invoke("start_recording", { monitorId });
      setIsRecording(true);
      setError(null);
    } catch (err) {
      console.error("Failed to start recording:", err);
      setError(err as string);
    }
  }

  // Update handleStopRecording
  async function handleStopRecording() {
    if (!isRecording) return;

    try {
      setIsRecording(false);
      setIsLoadingVideo(true);
      setIsVideoReady(false);
      setLoadingProgress(0);
      setThumbnails([]);

      // Capture audioPath from Rust
      const [videoUrl, audioUrl, rawMouseData, audioPath] = await invoke<[string, string, any[], string]>("stop_recording");

      setAudioFilePath(audioPath);

      // Explicitly map fields to handle potential camelCase vs snake_case mismatches
      const mouseData: MousePosition[] = rawMouseData.map(p => ({
        x: p.x,
        y: p.y,
        timestamp: p.timestamp,
        isClicked: p.isClicked !== undefined ? p.isClicked : p.is_clicked, // Handle both casing
        cursor_type: p.cursor_type || 'default'
      }));

      setMousePositions(mouseData);

      // Use the new centralized video loading
      const objectUrl = await videoControllerRef.current?.loadVideo({
        videoUrl,
        onLoadingProgress: (progress) => setLoadingProgress(progress)
      });

      if (objectUrl) {
        setCurrentVideo(objectUrl);

        // Load audio if available
        if (audioUrl) {
          const audioObjectUrl = await videoControllerRef.current?.loadAudio({
            audioUrl,
            onLoadingProgress: (p) => console.log('Audio Progress:', p)
          });
          if (audioObjectUrl) {
            setCurrentAudio(audioObjectUrl);
          }
        }

        setIsVideoReady(true);
        generateThumbnails();

        console.log(`[App] Received recording data. Video URL: ${videoUrl}, Audio URL: ${audioUrl}, Mouse Points: ${mouseData.length}, Clicks: ${mouseData.filter(p => p.isClicked).length}`);

        // Get actual video duration for the segment
        const videoDuration = videoRef.current?.duration || 0;
        const initialSegment: VideoSegment = {
          trimStart: 0,
          trimEnd: videoDuration,
          zoomKeyframes: [],
          textSegments: []
        };

        // Set segment immediately so first frame can render
        setSegment(initialSegment);

        // Render first frame immediately
        if (videoRef.current && canvasRef.current && videoRef.current.readyState >= 2) {
          videoRenderer.drawFrame({
            video: videoRef.current,
            canvas: canvasRef.current,
            tempCanvas: tempCanvasRef.current,
            segment: initialSegment,
            backgroundConfig,
            mousePositions: mouseData,
            currentTime: 0
          });
        }

        // Auto-save the initial project
        const response = await fetch(objectUrl);
        const videoBlob = await response.blob();
        const timestamp = new Date().toLocaleString();

        // Fetch audio blob if available
        let audioBlob: Blob | undefined;
        if (audioUrl) {
          const audioResponse = await fetch(audioUrl);
          audioBlob = await audioResponse.blob();
        }

        // Final frame render to ensure we have a thumbnail
        renderFrame();
        const thumbnail = generateThumbnail();

        const project = await projectManager.saveProject({
          name: `Recording ${timestamp}`,
          videoBlob,
          audioBlob,
          segment: initialSegment,
          backgroundConfig,
          mousePositions: mouseData,
          thumbnail
        });
        setCurrentProjectId(project.id);
        await loadProjects();
      }

    } catch (err) {
      setError(err as string);
    } finally {
      setIsLoadingVideo(false);
      setLoadingProgress(0);
    }
  }

  // Add cleanup for video object URL
  useEffect(() => {
    return () => {
      if (currentVideo && currentVideo.startsWith('blob:')) {
        URL.revokeObjectURL(currentVideo);
      }
    };
  }, [currentVideo]);

  // Add cleanup for audio object URL
  useEffect(() => {
    return () => {
      if (currentAudio && currentAudio.startsWith('blob:')) {
        URL.revokeObjectURL(currentAudio);
      }
    };
  }, [currentAudio]);

  // Toggle play/pause
  const togglePlayPause = () => {
    videoControllerRef.current?.togglePlayPause();
  };

  useEffect(() => {
    const handleKeyDown = (e: KeyboardEvent) => {
      const target = e.target as HTMLElement;
      const isInput = ['INPUT', 'TEXTAREA'].includes(target.tagName);

      if (e.code === 'Space' && !isInput) {
        e.preventDefault();
        togglePlayPause();
      }

      // Delete Keyframe
      if ((e.code === 'Delete' || e.code === 'Backspace') && editingKeyframeId !== null && !isInput) {
        if (segment && segment.zoomKeyframes[editingKeyframeId]) {
          const newKeyframes = [...segment.zoomKeyframes];
          newKeyframes.splice(editingKeyframeId, 1);
          setSegment({ ...segment, zoomKeyframes: newKeyframes });
          setEditingKeyframeId(null);
        }
      }

      // Undo/Redo
      if (e.ctrlKey || e.metaKey) {
        if (e.code === 'KeyZ') {
          if (e.shiftKey) {
            e.preventDefault();
            if (canRedo) redo();
          } else {
            e.preventDefault();
            if (canUndo) undo();
          }
        } else if (e.code === 'KeyY') {
          e.preventDefault();
          if (canRedo) redo();
        }
      }
    };

    window.addEventListener('keydown', handleKeyDown);
    return () => window.removeEventListener('keydown', handleKeyDown);
  }, [togglePlayPause, editingKeyframeId, segment, canUndo, canRedo, undo, redo]);

  // Add this effect to handle metadata loading
  useEffect(() => {
    const video = videoRef.current;
    if (!video) return;

    const handleLoadedMetadata = () => {
      debugLog('Video loaded metadata', {
        duration: video.duration,
        width: video.videoWidth,
        height: video.videoHeight
      });

      if (video.duration !== Infinity) {
        setDuration(video.duration);
      }
    };

    const handleDurationChange = () => {
      debugLog('Duration changed:', video.duration);
      if (video.duration !== Infinity) {
        setDuration(video.duration);
      }
    };

    video.addEventListener('loadedmetadata', handleLoadedMetadata);
    video.addEventListener('durationchange', handleDurationChange);

    return () => {
      video.removeEventListener('loadedmetadata', handleLoadedMetadata);
      video.removeEventListener('durationchange', handleDurationChange);
    };
  }, []);

  // Replace the debugLog function
  const debugLog = (_message: string, _data?: any) => {
    // Disabled
  };

  // Add new export function to replace video-exporter.ts
  const handleExport = async () => {
    setShowExportDialog(true);
  };

  // Add new method to handle actual export
  const startExport = async () => {
    if (!currentVideo || !segment || !videoRef.current || !canvasRef.current) return;

    try {
      setShowExportDialog(false);
      setIsProcessing(true);

      // Create a complete export options object
      const exportConfig: ExportOptions & { audioFilePath: string } = {
        quality: exportOptions.quality,
        dimensions: exportOptions.dimensions,
        speed: exportOptions.speed,
        video: videoRef.current, // Passed as source reference only
        canvas: canvasRef.current,
        tempCanvas: tempCanvasRef.current,
        segment,
        backgroundConfig,
        mousePositions,
        audio: audioRef.current || undefined,
        audioFilePath: audioFilePath, // Pass the path here
        onProgress: (progress: number) => {
          setExportProgress(progress);
        }
      };

      await videoExporter.exportAndDownload(exportConfig);

    } catch (error) {
      console.error('[App] Export error:', error);
    } finally {
      setIsProcessing(false);
      setExportProgress(0);
    }
  };

  // Update handleAddKeyframe to include duration
  const handleAddKeyframe = (override?: Partial<ZoomKeyframe>) => {
    if (!segment || !videoRef.current) return;

    const currentTime = videoRef.current.currentTime;

    // Check for nearby keyframe to update (debounce/merge)
    const nearbyIndex = segment.zoomKeyframes.findIndex(k => Math.abs(k.time - currentTime) < 0.2);

    let updatedKeyframes: ZoomKeyframe[];

    if (nearbyIndex !== -1) {
      // Update existing keyframe
      const existing = segment.zoomKeyframes[nearbyIndex];
      updatedKeyframes = [...segment.zoomKeyframes];
      updatedKeyframes[nearbyIndex] = {
        ...existing,
        zoomFactor: override?.zoomFactor ?? existing.zoomFactor,
        positionX: override?.positionX ?? existing.positionX,
        positionY: override?.positionY ?? existing.positionY,
      };
      setEditingKeyframeId(nearbyIndex);
    } else {
      // Create new keyframe
      // Find previous keyframe for defaults
      const previousKeyframe = [...segment.zoomKeyframes]
        .sort((a, b) => b.time - a.time)
        .find(k => k.time < currentTime);

      const newKeyframe: ZoomKeyframe = {
        time: currentTime,
        duration: 1.0,
        zoomFactor: override?.zoomFactor ?? previousKeyframe?.zoomFactor ?? 1.5,
        positionX: override?.positionX ?? previousKeyframe?.positionX ?? 0.5,
        positionY: override?.positionY ?? previousKeyframe?.positionY ?? 0.5,
        easingType: 'easeInOut'
      };

      updatedKeyframes = [...segment.zoomKeyframes, newKeyframe]
        .sort((a, b) => a.time - b.time);

      setEditingKeyframeId(updatedKeyframes.indexOf(newKeyframe));
    }

    setSegment({
      ...segment,
      zoomKeyframes: updatedKeyframes
    });

    // Update zoomFactor state so the slider stays in sync during wheel/panning
    const finalFactor = override?.zoomFactor ?? updatedKeyframes[editingKeyframeId !== null ? nearbyIndex !== -1 ? nearbyIndex : updatedKeyframes.length - 1 : updatedKeyframes.length - 1]?.zoomFactor;
    if (finalFactor !== undefined) {
      setZoomFactor(finalFactor);
    }

    // Trigger AutoZoom update if smooth path is active
    if (segment.smoothMotionPath && segment.smoothMotionPath.length > 0) {
      // We need to re-run auto zoom generation with the new keyframes!
      // But we need the mouse data... which is in `mousePositions` state.
      // We need to access `mousePositions`.
      // BUT, generating path takes time.
      // We can trigger it in a useEffect or directly here if we have data.
    }
  };

  // Sync zoomFactor state with editing keyframe
  useEffect(() => {
    if (segment && editingKeyframeId !== null) {
      const kf = segment.zoomKeyframes[editingKeyframeId];
      if (kf) {
        setZoomFactor(kf.zoomFactor);
      }
    }
  }, [editingKeyframeId]);



  // Update the throttled update function for zoom configuration
  const throttledUpdateZoom = useThrottle((updates: Partial<ZoomKeyframe>) => {
    if (!segment || editingKeyframeId === null) return;

    const updatedKeyframes = segment.zoomKeyframes.map((keyframe, index) =>
      index === editingKeyframeId
        ? { ...keyframe, ...updates }
        : keyframe
    );

    setSegment({
      ...segment,
      zoomKeyframes: updatedKeyframes
    }, false);

    // Seek if needed (optional, usually dragging slider expects update)
    if (videoRef.current) {
      const kf = updatedKeyframes[editingKeyframeId];
      if (Math.abs(videoRef.current.currentTime - kf.time) > 0.1) {
        videoRef.current.currentTime = kf.time;
        setCurrentTime(kf.time);
      }
    }

    // Force a redraw to show the changes
    requestAnimationFrame(() => {
      renderFrame();
    });
  }, 32); // 32ms throttle

  // Non-passive wheel listener to fix scrolling issue
  useEffect(() => {
    const container = previewContainerRef.current;
    if (!container) return;

    const handleWheel = (e: WheelEvent) => {
      if (!currentVideo || isCropping) return;
      e.preventDefault();
      e.stopPropagation();

      const lastState = videoRenderer.getLastCalculatedState();
      if (!lastState) return;

      // Sensitivity
      const zoomDelta = -e.deltaY * 0.002 * lastState.zoomFactor;
      const newZoom = Math.max(1.0, Math.min(12.0, lastState.zoomFactor + zoomDelta));

      handleAddKeyframe({
        zoomFactor: newZoom,
        positionX: lastState.positionX,
        positionY: lastState.positionY
      });
      setActivePanel('zoom');
    };

    container.addEventListener('wheel', handleWheel, { passive: false });
    return () => container.removeEventListener('wheel', handleWheel);
  }, [currentVideo, segment]); // Re-bind if segment changes? No, handleAddKeyframe uses ref state mostly but logic is closed over? 
  // handleAddKeyframe in App depends on 'segment'.
  // If 'segment' changes, handleAddKeyframe is stale?
  // Yes, functions in App are re-created.
  // We need to fetch fresh state or use ref for handlers.
  // Actually, 'handleAddKeyframe' is stable dependency? No it changes on render.
  // So we must include it in dep array or `handleWheel` calls old closure.
  // Added [handleAddKeyframe] to dependencies.

  // Add this effect to redraw when background config changes
  useEffect(() => {
    if (videoRef.current && !videoRef.current.paused) return; // Don't interrupt if playing

    // Create a proper FrameRequestCallback
    const frameCallback: FrameRequestCallback = (_time: number) => {
      renderFrame();
    };

    requestAnimationFrame(frameCallback);
  }, [backgroundConfig, renderFrame]);

  // Add this state near the top of the App component
  const [recordingDuration, setRecordingDuration] = useState(0);

  // Add this effect to track recording duration
  useEffect(() => {
    let interval: number;

    if (isRecording) {
      const startTime = Date.now();
      interval = window.setInterval(() => {
        setRecordingDuration(Math.floor((Date.now() - startTime) / 1000));
      }, 1000);
    } else {
      setRecordingDuration(0);
    }

    return () => {
      if (interval) {
        clearInterval(interval);
      }
    };
  }, [isRecording]);

  // Add this effect after the other useEffect hooks
  useEffect(() => {
    if (!segment || !isVideoReady) return;

    // Find the active keyframe based on current time
    const findActiveKeyframe = () => {
      const sortedKeyframes = [...segment.zoomKeyframes].sort((a, b) => a.time - b.time);

      for (let i = 0; i < sortedKeyframes.length; i++) {
        // Use the helper to compute rangeStart and rangeEnd
        const { rangeStart, rangeEnd } = getKeyframeRange(sortedKeyframes, i);

        // Check if current time is within this keyframe's range
        if (currentTime >= rangeStart && currentTime <= rangeEnd) {
          if (editingKeyframeId !== i) {
            setEditingKeyframeId(i);
            setZoomFactor(sortedKeyframes[i].zoomFactor);
            if (activePanel !== "zoom") {
              setActivePanel("zoom");
            }
          }
          return;
        }
      }

      // If we're not in any keyframe's range, deselect
      if (editingKeyframeId !== null) {
        setEditingKeyframeId(null);
      }
    };

    findActiveKeyframe();
  }, [currentTime, segment, isVideoReady]);

  // Update the loading placeholder to show progress
  const renderPlaceholder = () => {
    return (
      <div className="absolute inset-0 bg-[#1a1a1b] flex flex-col items-center justify-center">
        {/* Grid pattern background */}
        <div className="absolute inset-0 opacity-5">
          <div className="w-full h-full" style={{
            backgroundImage: `
              linear-gradient(to right, #fff 1px, transparent 1px),
              linear-gradient(to bottom, #fff 1px, transparent 1px)
            `,
            backgroundSize: '20px 20px'
          }} />
        </div>

        {isLoadingVideo ? (
          // Loading state after recording
          <div className="flex flex-col items-center">
            <Loader2 className="w-12 h-12 text-[#0079d3] animate-spin mb-4" />
            <p className="text-[#d7dadc] font-medium">Processing Video</p>
            <p className="text-[#818384] text-sm mt-1">This may take a few moments...</p>
          </div>
        ) : isRecording ? (
          // Recording state (only show if no video is loaded)
          <div className="flex flex-col items-center">
            <div className="w-4 h-4 rounded-full bg-red-500 animate-pulse mb-4" />
            <p className="text-[#d7dadc] font-medium">Recording in progress...</p>
            <p className="text-[#818384] text-sm mt-1">Screen is being captured</p>
            <span className="text-[#d7dadc] text-xl font-mono mt-4">{formatTime(recordingDuration)}</span>
          </div>
        ) : (
          // No video state
          <div className="flex flex-col items-center">
            <Video className="w-12 h-12 text-[#343536] mb-4" />
            <p className="text-[#d7dadc] font-medium">No Video Selected</p>
            <p className="text-[#818384] text-sm mt-1">Click 'Start Recording' to begin</p>
          </div>
        )}
        {isLoadingVideo && loadingProgress > 0 && (
          <div className="mt-2">
            <p className="text-[#818384] text-sm">
              Loading video: {Math.min(Math.round(loadingProgress), 100)}%
            </p>
          </div>
        )}
      </div>
    );
  };

  // Add new state for export options
  const [showExportDialog, setShowExportDialog] = useState(false);
  const [exportOptions, setExportOptions] = useState<ExportOptions>({
    quality: 'balanced',
    dimensions: '1080p',
    speed: 1 // Default to 100% speed
  });

  // Add these state variables in the App component
  const [projects, setProjects] = useState<Omit<Project, 'videoBlob'>[]>([]);
  const [showProjectsDialog, setShowProjectsDialog] = useState(false);

  // Add this effect to load projects on mount
  useEffect(() => {
    loadProjects();
  }, []);

  // Add these functions to the App component
  const loadProjects = async () => {
    const projects = await projectManager.getProjects();
    setProjects(projects);
  };

  // States removed: showSaveDialog, projectNameInput
  const [currentProjectId, setCurrentProjectId] = useState<string | null>(null);
  const [editingProjectNameId, setEditingProjectNameId] = useState<string | null>(null);
  const [projectRenameValue, setProjectRenameValue] = useState("");

  const generateThumbnail = useCallback((): string | undefined => {
    if (!canvasRef.current) return undefined;
    try {
      return canvasRef.current.toDataURL('image/jpeg', 0.5);
    } catch (e) {
      return undefined;
    }
  }, []);

  // Update handleSaveProject to show different options when editing existing project
  // Auto-save effect
  useEffect(() => {
    if (!currentProjectId || !currentVideo || !segment) return;

    const performAutoSave = async () => {
      try {
        const response = await fetch(currentVideo);
        const videoBlob = await response.blob();
        const thumbnail = generateThumbnail();
        await projectManager.updateProject(currentProjectId, {
          name: projects.find(p => p.id === currentProjectId)?.name || "Auto Saved Project",
          videoBlob,
          segment,
          backgroundConfig,
          mousePositions,
          thumbnail
        });
        await loadProjects();
      } catch (err) {
        // Silent fail on auto-save
      }
    };

    const timer = setTimeout(performAutoSave, 2000);
    return () => clearTimeout(timer);
  }, [segment, backgroundConfig, mousePositions, currentProjectId]);

  const handleRenameProject = async (id: string) => {
    if (!projectRenameValue.trim()) return;
    const project = projects.find(p => p.id === id);
    if (!project) return;

    // Load full project to update name
    const fullProject = await projectManager.loadProject(id);
    if (fullProject) {
      await projectManager.updateProject(id, {
        ...fullProject,
        name: projectRenameValue.trim()
      });
      await loadProjects();
    }
    setEditingProjectNameId(null);
  };

  // Update handleLoadProject to use loadVideo instead of handleVideoSourceChange
  const handleLoadProject = async (projectId: string) => {
    const project = await projectManager.loadProject(projectId);
    if (!project) return;

    // Clear previous video and audio URLs
    if (currentVideo) URL.revokeObjectURL(currentVideo);
    if (currentAudio) URL.revokeObjectURL(currentAudio);

    setThumbnails([]);
    setCurrentAudio(null);

    // Load Video
    console.log('[App] Loading project video blob:', project.videoBlob.size);
    const videoObjectUrl = await videoControllerRef.current?.loadVideo({ videoBlob: project.videoBlob });
    if (videoObjectUrl) setCurrentVideo(videoObjectUrl);

    // Load Audio
    if (project.audioBlob) {
      console.log('[App] Loading project audio blob:', project.audioBlob.size);
      const audioObjectUrl = await videoControllerRef.current?.loadAudio({ audioBlob: project.audioBlob });
      if (audioObjectUrl) setCurrentAudio(audioObjectUrl);
    } else {
      console.log('[App] Project has no audio blob');
      setCurrentAudio(null);
    }

    // Fix trimEnd: 0 from saved projects - use actual video duration
    const videoDuration = videoControllerRef.current?.duration || 0;
    const correctedSegment = { ...project.segment };
    if (correctedSegment.trimEnd === 0 || correctedSegment.trimEnd > videoDuration) {
      correctedSegment.trimEnd = videoDuration;
    }


    setSegment(correctedSegment);
    setBackgroundConfig(project.backgroundConfig);
    setMousePositions(project.mousePositions);

    // Sync volume immediately
    if (videoControllerRef.current && project.backgroundConfig.volume !== undefined) {
      videoControllerRef.current.setVolume(project.backgroundConfig.volume);
    }

    setShowProjectsDialog(false);
    setCurrentProjectId(projectId);
  };

  // Add these states in App component
  const [thumbnails, setThumbnails] = useState<string[]>([]);

  // Replace the existing generateThumbnails function
  const generateThumbnails = useCallback(async () => {
    if (!currentVideo || !segment) return;

    const thumbnails = await thumbnailGenerator.generateThumbnails(currentVideo, 20, {
      trimStart: segment.trimStart,
      trimEnd: segment.trimEnd
    });

    setThumbnails(thumbnails);
  }, [currentVideo, segment]);

  // Add this effect
  useEffect(() => {
    if (isVideoReady && duration > 0 && thumbnails.length === 0) {
      generateThumbnails();
    }
  }, [isVideoReady, duration, generateThumbnails]);

  // Add this state near the top of App component
  const [recentUploads, setRecentUploads] = useState<string[]>([]);

  // Update handleBackgroundUpload function
  const handleBackgroundUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file) {
      const reader = new FileReader();
      reader.onload = (event) => {
        const imageUrl = event.target?.result as string;
        // Update background config
        setBackgroundConfig(prev => ({
          ...prev,
          backgroundType: 'custom',
          customBackground: imageUrl
        }));

        // Update recent uploads (keep last 3)
        setRecentUploads(prev => {
          const newUploads = [imageUrl, ...prev].slice(0, 3);
          return newUploads;
        });
      };
      reader.readAsDataURL(file);
    }
  };

  // Initialize segment when video loads
  useEffect(() => {
    if (duration > 0 && !segment) {
      const initialSegment: VideoSegment = {
        trimStart: 0,
        trimEnd: duration,
        zoomKeyframes: [],
        textSegments: []
      };
      setSegment(initialSegment);

      // Render first frame after segment is set (next tick to ensure state is updated)
      setTimeout(() => {
        if (videoRef.current && canvasRef.current && videoRef.current.readyState >= 2) {
          videoRenderer.drawFrame({
            video: videoRef.current,
            canvas: canvasRef.current,
            tempCanvas: tempCanvasRef.current,
            segment: initialSegment,
            backgroundConfig,
            mousePositions,
            currentTime: 0
          });
        }
      }, 0);
    }
  }, [duration, segment, backgroundConfig, mousePositions]);

  // Add this state for text segments
  const [editingTextId, setEditingTextId] = useState<string | null>(null);

  // Add this function to handle adding new text segments
  const handleAddText = () => {
    if (!segment) return;

    const newText: TextSegment = {
      id: crypto.randomUUID(),
      startTime: currentTime,
      endTime: Math.min(currentTime + 3, duration),
      text: 'New Text',
      style: {
        fontSize: 24,
        color: '#ffffff',
        x: 50,  // Center by default
        y: 50   // Center by default
      }
    };

    setSegment({
      ...segment,
      textSegments: [...(segment.textSegments || []), newText]
    });
    setEditingTextId(newText.id);
    setActivePanel('text');
  };

  // Add these handlers in the App component
  const handleTextDragMove = (id: string, x: number, y: number) => {
    if (!segment) return;
    setSegment({
      ...segment,
      textSegments: segment.textSegments.map(t =>
        t.id === id ? { ...t, style: { ...t.style, x, y } } : t
      )
    });
  };

  // Add event listeners to the canvas
  useEffect(() => {
    const canvas = canvasRef.current;
    if (!canvas || !segment) return;

    const handleMouseDown = (e: MouseEvent) => {
      videoRenderer.handleMouseDown(e, segment, canvas);
    };

    const handleMouseMove = (e: MouseEvent) => {
      videoRenderer.handleMouseMove(e, segment, canvas, handleTextDragMove);
    };

    const handleMouseUp = () => {
      videoRenderer.handleMouseUp(canvas);
    };

    canvas.addEventListener('mousedown', handleMouseDown);
    canvas.addEventListener('mousemove', handleMouseMove);
    canvas.addEventListener('mouseup', handleMouseUp);
    canvas.addEventListener('mouseleave', handleMouseUp);

    return () => {
      canvas.removeEventListener('mousedown', handleMouseDown);
      canvas.removeEventListener('mousemove', handleMouseMove);
      canvas.removeEventListener('mouseup', handleMouseUp);
      canvas.removeEventListener('mouseleave', handleMouseUp);
    };
  }, [segment]);

  return (
    <div className="min-h-screen bg-[#1a1a1b]">
      <header
        className="bg-[#1a1a1b] border-b border-[#343536] select-none h-11 flex items-center justify-between cursor-default"
        onMouseDown={() => {
          (window as any).ipc.postMessage('drag_window');
        }}
      >
        <div className="flex items-center gap-4 px-4 h-full">
          <div className="flex items-center gap-3">
            <Video className="w-5 h-5 text-[#0079d3]" />
            <span className="text-[#d7dadc] text-sm font-medium">Screen Record</span>
          </div>

          <div className="h-full flex items-center">
            {isRecording && currentVideo && (
              <div className="flex items-center gap-3 bg-red-500/10 border border-red-500/30 px-3 py-1 rounded-full animate-in fade-in slide-in-from-left-2 duration-300">
                <div className="w-2 h-2 rounded-full bg-red-500 animate-pulse" />
                <div className="flex flex-col">
                  <span className="text-red-500 text-[10px] font-bold leading-none uppercase tracking-wider">Recording</span>
                  <span className="text-[#818384] text-[9px] leading-tight">Screen is being captured</span>
                </div>
                <span className="text-[#d7dadc] text-xs font-mono ml-1">{formatTime(recordingDuration)}</span>
              </div>
            )}
          </div>
        </div>

        <div className="flex items-center gap-3 h-full px-2">
          <div className="flex items-center gap-2 flex-wrap max-w-[400px] justify-end">
            {hotkeys.map((h, i) => (
              <Button
                key={i}
                onMouseDown={(e) => e.stopPropagation()}
                onClick={() => handleRemoveHotkey(i)}
                className="bg-[#272729] hover:bg-red-500/20 text-[#d7dadc] hover:text-red-400 px-2 h-7 text-xs border border-transparent hover:border-red-500/30 flex-shrink-0"
                title="Click to remove"
              >
                <span className="truncate max-w-[80px]">{h.name}</span>
                <X className="w-3 h-3 ml-1 flex-shrink-0" />
              </Button>
            ))}
            <Button
              onMouseDown={(e) => e.stopPropagation()}
              onClick={() => { setShowHotkeyDialog(true); setListeningForKey(true); }}
              className="bg-[#0079d3] hover:bg-[#0079d3]/90 text-white px-2 h-7 text-xs flex-shrink-0"
              title="Add Global Hotkey"
            >
              <Keyboard className="w-3 h-3 mr-1" />
              Add Hotkey
            </Button>
            <Button
              onMouseDown={(e) => e.stopPropagation()}
              onClick={toggleKeyviz}
              className={`px-2 h-7 text-xs flex-shrink-0 transition-colors ${keyvizStatus.enabled
                ? 'bg-green-600 hover:bg-green-700 text-white'
                : 'bg-[#272729] hover:bg-[#343536] text-[#d7dadc]'
                }`}
              title={keyvizStatus.installed ? "Toggle Keyviz" : "Install & Enable Keyviz"}
            >
              <Keyboard className="w-3 h-3 mr-1" />
              {keyvizStatus.enabled ? "Keystrokes: ON" : "Show Keystrokes"}
            </Button>
          </div>

          <div className="flex items-center gap-2">
            {currentVideo && (
              <Button
                onMouseDown={(e) => e.stopPropagation()}
                onClick={handleExport}
                disabled={isProcessing}
                className={`flex items-center px-4 py-2 h-8 text-xs font-medium ${isProcessing
                  ? 'bg-gray-600 text-gray-400 cursor-not-allowed'
                  : 'bg-[#9C17FF] hover:bg-[#9C17FF]/90 text-white'
                  }`}
              >
                <Download className="w-4 h-4 mr-2" />Export
              </Button>
            )}
            <Button
              variant="ghost"
              size="sm"
              onMouseDown={(e) => e.stopPropagation()}
              onClick={() => setShowProjectsDialog(true)}
              className="h-8 text-xs text-[#d7dadc] hover:bg-[#272729]"
            >
              <FolderOpen className="w-4 h-4 mr-2" />Projects
            </Button>
          </div>

          <div className="flex items-center h-full ml-4">
            <button
              onMouseDown={(e) => e.stopPropagation()}
              onClick={(e) => {
                e.stopPropagation();
                (window as any).ipc.postMessage('minimize_window');
              }}
              className="px-3 h-full text-[#d7dadc] hover:bg-[#272729] transition-colors flex items-center"
              title="Minimize"
            >
              <Minus className="w-4 h-4" />
            </button>
            <button
              onMouseDown={(e) => e.stopPropagation()}
              onClick={async (e) => {
                e.stopPropagation();
                (window as any).ipc.postMessage('toggle_maximize');
                // Small delay to let the state settle before checking
                setTimeout(async () => {
                  const maximized = await invoke<boolean>('is_maximized');
                  setIsWindowMaximized(maximized);
                }, 50);
              }}
              className="px-3 h-full text-[#d7dadc] hover:bg-[#272729] transition-colors flex items-center"
              title={isWindowMaximized ? "Restore" : "Maximize"}
            >
              {isWindowMaximized ? <Copy className="w-3.5 h-3.5" /> : <Square className="w-3.5 h-3.5" />}
            </button>
            <button
              onMouseDown={(e) => e.stopPropagation()}
              onClick={(e) => {
                e.stopPropagation();
                (window as any).ipc.postMessage('close_window');
              }}
              className="px-3 h-full text-[#d7dadc] hover:bg-[#e81123] hover:text-white transition-colors flex items-center"
              title="Close"
            >
              <X className="w-4 h-4" />
            </button>
          </div>
        </div>
      </header>

      <main className="max-w-6xl mx-auto px-4 py-6">
        {error && <p className="text-red-500 mb-4">{error}</p>}

        <div className="space-y-6">
          <div className="grid grid-cols-4 gap-6 items-start">
            <div className="col-span-3 rounded-lg overflow-hidden bg-black/20 flex items-center justify-center">
              <div className="relative w-full flex justify-center max-h-[70vh]">
                <div
                  ref={previewContainerRef}
                  className={`relative flex items-center justify-center cursor-crosshair group ${!currentVideo ? 'w-full aspect-video' : ''}`}
                  onMouseDown={(e) => {
                    if (!currentVideo) return;
                    if (isCropping) return; // Disable pan/zoom when cropping
                    if (activePanel === 'text') return; // Disable panning when in text mode (allow text drag)
                    e.preventDefault();
                    e.stopPropagation(); // Prevent drag of window if any

                    if (isPlaying) togglePlayPause();

                    const startX = e.clientX;
                    const startY = e.clientY;
                    const lastState = videoRenderer.getLastCalculatedState();
                    if (!lastState) return;

                    const startPosX = lastState.positionX;
                    const startPosY = lastState.positionY;
                    const z = lastState.zoomFactor;
                    const rect = e.currentTarget.getBoundingClientRect();

                    const handleMouseMove = (me: MouseEvent) => {
                      const dx = me.clientX - startX;
                      const dy = me.clientY - startY;

                      // Drag World: Dragging Right (dx > 0) moves camera Left (pos decreases)
                      const ndx = -(dx / rect.width) / z;
                      const ndy = -(dy / rect.height) / z;

                      handleAddKeyframe({
                        zoomFactor: z,
                        positionX: Math.max(0, Math.min(1, startPosX + ndx)),
                        positionY: Math.max(0, Math.min(1, startPosY + ndy))
                      });
                      setActivePanel('zoom');
                    };

                    const handleMouseUp = () => {
                      window.removeEventListener('mousemove', handleMouseMove);
                      window.removeEventListener('mouseup', handleMouseUp);
                    };

                    window.addEventListener('mousemove', handleMouseMove);
                    window.addEventListener('mouseup', handleMouseUp);
                  }}
                >
                  <canvas
                    ref={canvasRef}
                    className="max-w-full max-h-[70vh] object-contain"
                  />
                  <canvas ref={tempCanvasRef} className="hidden" />
                  <video ref={videoRef} className="hidden" playsInline preload="auto" />
                  <audio ref={audioRef} className="hidden" />
                  {(!currentVideo || isLoadingVideo) && renderPlaceholder()}

                  {/* Crop Overlay */}
                  {isCropping && currentVideo && segment && (
                    <div
                      className="absolute inset-0 z-20 pointer-events-none"
                    >
                      {(() => {
                        // 1. Calculate the actual video rectangle within the container
                        const container = previewContainerRef.current;
                        const video = videoRef.current;
                        // We need to ensure we can read dimensions. If video isn't ready, we can't show crop box correctly aligned.
                        if (!container || !video) return null;

                        const containerRect = container.getBoundingClientRect();
                        const vidW = video.videoWidth;
                        const vidH = video.videoHeight;

                        if (!vidW || !vidH) return null;

                        const containerRatio = containerRect.width / containerRect.height;
                        const videoRatio = vidW / vidH;

                        let renderW, renderH, renderTop, renderLeft;

                        if (containerRatio > videoRatio) {
                          // Container is wider -> Video fits height
                          renderH = containerRect.height;
                          renderW = renderH * videoRatio;
                          renderTop = 0;
                          renderLeft = (containerRect.width - renderW) / 2;
                        } else {
                          // Container is taller -> Video fits width
                          renderW = containerRect.width;
                          renderH = renderW / videoRatio;
                          renderLeft = 0;
                          renderTop = (containerRect.height - renderH) / 2;
                        }

                        // 2. Wrap the crop logic in a div positioned exactly over the video content
                        return (
                          <div
                            style={{
                              position: 'absolute',
                              left: renderLeft,
                              top: renderTop,
                              width: renderW,
                              height: renderH,
                            }}
                          >
                            {(() => {
                              // Current Crop State
                              // Default to full video if undefined
                              const crop = segment.crop || { x: 0, y: 0, width: 1, height: 1 };

                              // Visual properties (in %)
                              const leftPct = crop.x;
                              const topPct = crop.y;
                              const widthPct = crop.width;
                              const heightPct = crop.height;

                              // Helper for resize handlers
                              const handleResizeStart = (e: React.MouseEvent, type: string) => {
                                e.preventDefault();
                                e.stopPropagation();
                                const startX = e.clientX;
                                const startY = e.clientY;
                                const startCrop = { ...crop };

                                const rectW = renderW;
                                const rectH = renderH;

                                const handleMove = (me: MouseEvent) => {
                                  const dx = (me.clientX - startX);
                                  const dy = (me.clientY - startY);

                                  // Convert to percentage change
                                  const dXPct = dx / rectW;
                                  const dYPct = dy / rectH;

                                  let newX = startCrop.x;
                                  let newY = startCrop.y;
                                  let newW = startCrop.width;
                                  let newH = startCrop.height;

                                  // Adjust based on handle type
                                  // N/S affect Y and Height
                                  if (type.includes('n')) {
                                    // If dragging North: New Top = Old Top + Delta
                                    // New Height = Old Height - Delta
                                    // Constraint: New Top >= 0, New Height >= Min
                                    let desiredY = startCrop.y + dYPct;
                                    // Clamp Y between 0 and (Bottom - MinHeight)
                                    const maxY = startCrop.y + startCrop.height - 0.05;
                                    desiredY = Math.max(0, Math.min(maxY, desiredY));

                                    const deltaY = desiredY - startCrop.y;
                                    newY = desiredY;
                                    newH = startCrop.height - deltaY;
                                  } else if (type.includes('s')) {
                                    // Dragging South: Top fixed, Height changes
                                    // New Height = Old Height + Delta
                                    let desiredH = startCrop.height + dYPct;
                                    // Clamp H: Min <= H <= (1 - Top)
                                    newH = Math.max(0.05, Math.min(1 - startCrop.y, desiredH));
                                  }

                                  // E/W affect X and Width
                                  if (type.includes('w')) {
                                    // Dragging West: New Left = Old Left + Delta
                                    // New Width = Old Width - Delta
                                    let desiredX = startCrop.x + dXPct;
                                    const maxX = startCrop.x + startCrop.width - 0.05;
                                    desiredX = Math.max(0, Math.min(maxX, desiredX));

                                    const deltaX = desiredX - startCrop.x;
                                    newX = desiredX;
                                    newW = startCrop.width - deltaX;
                                  } else if (type.includes('e')) {
                                    // Dragging East
                                    let desiredW = startCrop.width + dXPct;
                                    newW = Math.max(0.05, Math.min(1 - startCrop.x, desiredW));
                                  }

                                  // Update Segment State
                                  setSegment(prev => prev ? ({
                                    ...prev,
                                    crop: { x: newX, y: newY, width: newW, height: newH }
                                  }) : null);
                                };

                                const handleUp = () => {
                                  window.removeEventListener('mousemove', handleMove);
                                  window.removeEventListener('mouseup', handleUp);
                                };
                                window.addEventListener('mousemove', handleMove);
                                window.addEventListener('mouseup', handleUp);
                              };

                              return (
                                <div
                                  className="absolute border-2 border-[#0079d3] bg-[#0079d3]/10 pointer-events-auto"
                                  style={{
                                    left: `${leftPct * 100}%`,
                                    top: `${topPct * 100}%`,
                                    width: `${widthPct * 100}%`,
                                    height: `${heightPct * 100}%`,
                                    boxShadow: '0 0 0 9999px rgba(0, 0, 0, 0.7)'
                                  }}
                                  onMouseDown={(e) => {
                                    e.preventDefault();
                                    e.stopPropagation();
                                    const startX = e.clientX;
                                    const startY = e.clientY;
                                    const startCrop = { ...crop };
                                    const rectW = renderW;
                                    const rectH = renderH;

                                    const handleBoxMove = (me: MouseEvent) => {
                                      const dx = (me.clientX - startX) / rectW;
                                      const dy = (me.clientY - startY) / rectH;

                                      // Move crop rect, clamping to bounds
                                      let newX = startCrop.x + dx;
                                      let newY = startCrop.y + dy;

                                      // Clamp
                                      newX = Math.max(0, Math.min(1 - startCrop.width, newX));
                                      newY = Math.max(0, Math.min(1 - startCrop.height, newY));

                                      setSegment(prev => prev ? ({
                                        ...prev,
                                        crop: { x: newX, y: newY, width: startCrop.width, height: startCrop.height }
                                      }) : null);
                                    };
                                    const handleUp = () => {
                                      window.removeEventListener('mousemove', handleBoxMove);
                                      window.removeEventListener('mouseup', handleUp);
                                    };
                                    window.addEventListener('mousemove', handleBoxMove);
                                    window.addEventListener('mouseup', handleUp);
                                  }}
                                >
                                  {/* Grid Lines (Rule of Thirds) */}
                                  <div className="absolute inset-0 flex flex-col pointer-events-none opacity-30">
                                    <div className="flex-1 border-b border-white/50" />
                                    <div className="flex-1 border-b border-white/50" />
                                    <div className="flex-1" />
                                  </div>
                                  <div className="absolute inset-0 flex pointer-events-none opacity-30">
                                    <div className="flex-1 border-r border-white/50" />
                                    <div className="flex-1 border-r border-white/50" />
                                    <div className="flex-1" />
                                  </div>

                                  {/* 8 Handles */}
                                  {[
                                    { t: 'nw', c: 'cursor-nw-resize', s: '-top-1.5 -left-1.5' },
                                    { t: 'n', c: 'cursor-n-resize', s: '-top-1.5 left-1/2 -translate-x-1/2' },
                                    { t: 'ne', c: 'cursor-ne-resize', s: '-top-1.5 -right-1.5' },
                                    { t: 'w', c: 'cursor-w-resize', s: 'top-1/2 -translate-y-1/2 -left-1.5' },
                                    { t: 'e', c: 'cursor-e-resize', s: 'top-1/2 -translate-y-1/2 -right-1.5' },
                                    { t: 'sw', c: 'cursor-sw-resize', s: '-bottom-1.5 -left-1.5' },
                                    { t: 's', c: 'cursor-s-resize', s: '-bottom-1.5 left-1/2 -translate-x-1/2' },
                                    { t: 'se', c: 'cursor-se-resize', s: '-bottom-1.5 -right-1.5' },
                                  ].map(handle => (
                                    <div
                                      key={handle.t}
                                      className={`absolute w-3 h-3 bg-white border border-[#0079d3] rounded-full z-30 hover:scale-125 transition-transform ${handle.c} ${handle.s}`}
                                      onMouseDown={(e) => handleResizeStart(e, handle.t)}
                                    />
                                  ))}

                                  {/* Central Crosshair */}
                                  <div className="absolute top-1/2 left-1/2 -translate-x-1/2 -translate-y-1/2 w-4 h-4 opacity-50 pointer-events-none">
                                    <div className="absolute w-full h-[1px] bg-white top-1/2 -translate-y-1/2 shadow-sm" />
                                    <div className="absolute h-full w-[1px] bg-white left-1/2 -translate-x-1/2 shadow-sm" />
                                  </div>
                                </div>
                              );
                            })()}
                          </div>
                        );
                      })()}
                    </div>
                  )}

                </div>
                {currentVideo && !isLoadingVideo && (
                  <div className="absolute bottom-4 left-1/2 transform -translate-x-1/2 flex items-center gap-3 bg-black/80 rounded-full px-4 py-2 backdrop-blur-sm z-50">
                    <Button
                      onClick={() => {
                        if (isCropping) {
                          // Confirm/Apply Crop
                          setIsCropping(false);
                          setActivePanel('zoom');
                          // Reset Zoom to 1.0 to view the new crop clearly without inherited zoom
                          setZoomFactor(1.0);
                          // Also reset any focused keyframe to avoid confusion
                          setEditingKeyframeId(null);
                        } else {
                          // Enter Crop Mode
                          setIsCropping(true);
                          if (isPlaying) togglePlayPause();
                        }
                      }}
                      variant="ghost"
                      size="icon"
                      className={`w-8 h-8 rounded-full transition-colors ${isCropping ? 'bg-green-500/80 text-white hover:bg-green-600' : 'text-white/80 hover:text-white hover:bg-white/10'}`}
                      title={isCropping ? "Apply Crop" : "Crop Video"}
                    >
                      {isCropping ? (
                        <svg width="16" height="16" viewBox="0 0 24 24" fill="none" stroke="currentColor" strokeWidth="2" strokeLinecap="round" strokeLinejoin="round"><polyline points="20 6 9 17 4 12" /></svg>
                      ) : (
                        <Crop className="w-4 h-4" />
                      )}
                    </Button>
                    <div className="w-px h-4 bg-white/20 mx-1" />
                    <Button
                      onClick={togglePlayPause}
                      disabled={isProcessing || !isVideoReady}
                      variant="ghost"
                      size="icon"
                      className={`w-8 h-8 rounded-full transition-colors text-white bg-transparent hover:text-white hover:bg-transparent ${isProcessing || !isVideoReady
                        ? 'opacity-50 cursor-not-allowed'
                        : ''
                        }`}
                    >
                      {isPlaying ? (
                        <Pause className="w-4 h-4" />
                      ) : (
                        <Play className="w-4 h-4 ml-0.5" />
                      )}
                    </Button>
                    <div className="text-white/90 text-sm font-medium">
                      {formatTime(currentTime)} / {formatTime(duration)}
                    </div>
                  </div>
                )}
              </div>
            </div>

            <div className="col-span-1 space-y-3">
              <div className="flex bg-[#272729] p-0.5 rounded-md">
                <Button
                  onClick={() => setActivePanel('zoom')}
                  variant={activePanel === 'zoom' ? 'default' : 'outline'}
                  size="sm"
                  className={`flex-1 ${activePanel === 'zoom'
                    ? 'bg-[#1a1a1b] text-[#d7dadc] border-0'
                    : 'bg-transparent text-[#818384] border-0 hover:bg-[#1a1a1b]/10 hover:text-[#d7dadc]'
                    }`}
                >
                  Zoom
                </Button>
                <Button
                  onClick={() => setActivePanel('background')}
                  variant={activePanel === 'background' ? 'default' : 'outline'}
                  size="sm"
                  className={`flex-1 ${activePanel === 'background'
                    ? 'bg-[#1a1a1b] text-[#d7dadc] border-0'
                    : 'bg-transparent text-[#818384] border-0 hover:bg-[#1a1a1b]/10 hover:text-[#d7dadc]'
                    }`}
                >
                  Background
                </Button>
                <Button
                  onClick={() => setActivePanel('cursor')}
                  variant={activePanel === 'cursor' ? 'default' : 'outline'}
                  size="sm"
                  className={`flex-1 ${activePanel === 'cursor'
                    ? 'bg-[#1a1a1b] text-[#d7dadc] border-0'
                    : 'bg-transparent text-[#818384] border-0 hover:bg-[#1a1a1b]/10 hover:text-[#d7dadc]'
                    }`}
                >
                  Cursor
                </Button>
                <Button
                  onClick={() => setActivePanel('text')}
                  variant={activePanel === 'text' ? 'default' : 'outline'}
                  size="sm"
                  className={`flex-1 ${activePanel === 'text'
                    ? 'bg-[#1a1a1b] text-[#d7dadc] border-0'
                    : 'bg-transparent text-[#818384] border-0 hover:bg-[#1a1a1b]/10 hover:text-[#d7dadc]'
                    }`}
                >
                  Text
                </Button>
              </div>

              {activePanel === 'zoom' ? (
                <>
                  {(editingKeyframeId !== null) ? (
                    <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-4">
                      <div className="flex justify-between items-center mb-4">
                        <h2 className="text-base font-semibold text-[#d7dadc]">Zoom Configuration</h2>
                        {editingKeyframeId !== null && <Button onClick={() => { if (segment && editingKeyframeId !== null) { setSegment({ ...segment, zoomKeyframes: segment.zoomKeyframes.filter((_, i) => i !== editingKeyframeId) }); setEditingKeyframeId(null); } }} variant="ghost" size="icon" className="text-[#d7dadc] hover:text-red-400 hover:bg-red-400/10 transition-colors"><Trash2 className="w-5 h-5" /></Button>}
                      </div>
                      <div className="space-y-4">
                        <div>
                          <label className="text-sm font-medium text-[#d7dadc] mb-2">Zoom Factor</label>
                          <div className="space-y-2">
                            <input type="range" min="1" max="3" step="0.1" value={zoomFactor} onChange={(e) => { const newValue = Number(e.target.value); setZoomFactor(newValue); throttledUpdateZoom({ zoomFactor: newValue }); }} className="w-full accent-[#0079d3]" />
                            <div className="flex justify-between text-xs text-[#818384] font-medium">
                              <span>1x</span>
                              <span>{zoomFactor.toFixed(1)}x</span>
                              <span>3x</span>
                            </div>
                          </div>
                        </div>
                        <div className="space-y-4">
                          <div>
                            <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between"><span>Horizontal Position</span><span className="text-[#818384]">{Math.round((segment?.zoomKeyframes[editingKeyframeId!]?.positionX ?? 0.5) * 100)}%</span></label>
                            <input type="range" min="0" max="1" step="0.01" value={segment?.zoomKeyframes[editingKeyframeId!]?.positionX ?? 0.5} onChange={(e) => { throttledUpdateZoom({ positionX: Number(e.target.value) }); }} className="w-full accent-[#0079d3]" />
                          </div>
                          <div>
                            <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between"><span>Vertical Position</span><span className="text-[#818384]">{Math.round((segment?.zoomKeyframes[editingKeyframeId!]?.positionY ?? 0.5) * 100)}%</span></label>
                            <input type="range" min="0" max="1" step="0.01" value={segment?.zoomKeyframes[editingKeyframeId!]?.positionY ?? 0.5} onChange={(e) => { throttledUpdateZoom({ positionY: Number(e.target.value) }); }} className="w-full accent-[#0079d3]" />
                          </div>
                        </div>
                      </div>
                    </div>
                  ) : (
                    <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-6 flex flex-col items-center justify-center text-center">
                      <div className="bg-[#272729] rounded-full p-3 mb-3"><Search className="w-6 h-6 text-[#818384]" /></div>
                      <p className="text-[#d7dadc] font-medium">This Area Doesn't Have Manual Zoom</p>
                      <p className="text-[#818384] text-sm mt-1 max-w-[200px]">Use your scroll wheel or drag inside the video player to add one</p>
                    </div>
                  )}
                </>
              ) : activePanel === 'background' ? (
                <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-4">
                  <h2 className="text-base font-semibold text-[#d7dadc] mb-4">Background & Layout</h2>
                  <div className="space-y-4">
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between">
                        <span>Video Size</span>
                        <span className="text-[#818384]">{backgroundConfig.scale}%</span>
                      </label>
                      <input type="range" min="50" max="100" value={backgroundConfig.scale}
                        onChange={(e) => setBackgroundConfig(prev => ({ ...prev, scale: Number(e.target.value) }))}
                        className="w-full accent-[#0079d3]"
                      />
                    </div>
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between">
                        <span>Roundness</span>
                        <span className="text-[#818384]">{backgroundConfig.borderRadius}px</span>
                      </label>
                      <input type="range" min="0" max="64" value={backgroundConfig.borderRadius}
                        onChange={(e) => setBackgroundConfig(prev => ({ ...prev, borderRadius: Number(e.target.value) }))}
                        className="w-full accent-[#0079d3]"
                      />
                    </div>
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between">
                        <span>Shadow</span>
                        <span className="text-[#818384]">{backgroundConfig.shadow || 0}px</span>
                      </label>
                      <input type="range" min="0" max="100" value={backgroundConfig.shadow || 0}
                        onChange={(e) => setBackgroundConfig(prev => ({ ...prev, shadow: Number(e.target.value) }))}
                        className="w-full accent-[#0079d3]"
                      />
                    </div>
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between">
                        <span>Volume</span>
                        <span className="text-[#818384]">{Math.round((backgroundConfig.volume ?? 1) * 100)}%</span>
                      </label>
                      <input type="range" min="0" max="1" step="0.01" value={backgroundConfig.volume ?? 1}
                        onChange={(e) => setBackgroundConfig(prev => ({ ...prev, volume: Number(e.target.value) }))}
                        className="w-full accent-[#0079d3]"
                      />
                    </div>
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-3 block">Background Style</label>
                      <div className="grid grid-cols-4 gap-4">
                        {Object.entries(GRADIENT_PRESETS).map(([key, gradient]) => (
                          <button
                            key={key}
                            onClick={() => setBackgroundConfig(prev => ({ ...prev, backgroundType: key as BackgroundConfig['backgroundType'] }))}
                            className={`aspect-square  h-10 rounded-lg transition-all ${gradient} ${backgroundConfig.backgroundType === key
                              ? 'ring-2 ring-[#0079d3] ring-offset-2 ring-offset-[#1a1a1b] scale-105'
                              : 'ring-1 ring-[#343536] hover:ring-[#0079d3]/50'
                              }`}
                          />
                        ))}

                        {/* Upload button - always first */}
                        <label
                          className={`aspect-square h-10 rounded-lg transition-all cursor-pointer
                            ring-1 ring-[#343536] hover:ring-[#0079d3]/50
                            relative overflow-hidden group bg-[#272729]
                          `}
                        >
                          <input
                            type="file"
                            accept="image/*"
                            onChange={handleBackgroundUpload}
                            className="hidden"
                          />
                          <div className="absolute inset-0 flex items-center justify-center">
                            <Upload className="w-5 h-5 text-[#818384] group-hover:text-[#0079d3] transition-colors" />
                          </div>
                        </label>

                        {/* Recent uploads */}
                        {recentUploads.map((imageUrl, index) => (
                          <button
                            key={index}
                            onClick={() => setBackgroundConfig(prev => ({
                              ...prev,
                              backgroundType: 'custom',
                              customBackground: imageUrl
                            }))}
                            className={`aspect-square h-10 rounded-lg transition-all relative overflow-hidden
                              ${backgroundConfig.backgroundType === 'custom' && backgroundConfig.customBackground === imageUrl
                                ? 'ring-2 ring-[#0079d3] ring-offset-2 ring-offset-[#1a1a1b] scale-105'
                                : 'ring-1 ring-[#343536] hover:ring-[#0079d3]/50'
                              }
                            `}
                          >
                            <img
                              src={imageUrl}
                              alt={`Upload ${index + 1}`}
                              className="absolute inset-0 w-full h-full object-cover"
                            />
                          </button>
                        ))}
                      </div>
                    </div>
                  </div>
                </div>
              ) : activePanel === 'cursor' ? (
                <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-4">
                  <h2 className="text-base font-semibold text-[#d7dadc] mb-4">Cursor Settings</h2>
                  <div className="space-y-4">
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between">
                        <span>Cursor Size</span>
                        <span className="text-[#818384]">{backgroundConfig.cursorScale ?? 2}x</span>
                      </label>
                      <input
                        type="range"
                        min="1"
                        max="8"
                        step="0.1"
                        value={backgroundConfig.cursorScale ?? 2}
                        onChange={(e) => setBackgroundConfig(prev => ({ ...prev, cursorScale: Number(e.target.value) }))}
                        className="w-full accent-[#0079d3]"
                      />
                    </div>
                    <div>
                      <label className="text-sm font-medium text-[#d7dadc] mb-2 flex justify-between">
                        <span>Movement Smoothing</span>
                        <span className="text-[#818384]">{backgroundConfig.cursorSmoothness ?? 5}</span>
                      </label>
                      <input
                        type="range"
                        min="0"
                        max="10"
                        step="1"
                        value={backgroundConfig.cursorSmoothness ?? 5}
                        onChange={(e) => setBackgroundConfig(prev => ({ ...prev, cursorSmoothness: Number(e.target.value) }))}
                        className="w-full accent-[#0079d3]"
                      />
                    </div>
                  </div>
                </div>
              ) : activePanel === 'text' && (
                <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-4">
                  <div className="flex justify-between items-center mb-4">
                    <h2 className="text-base font-semibold text-[#d7dadc]">Text Overlay</h2>
                    <Button
                      onClick={handleAddText}
                      className="bg-[#0079d3] hover:bg-[#0079d3]/90 text-white"
                    >
                      <Type className="w-4 h-4 mr-2" />Add Text
                    </Button>
                  </div>

                  {editingTextId && segment?.textSegments?.find(t => t.id === editingTextId) ? (
                    <div className="space-y-4">
                      <div>
                        <label className="text-sm font-medium text-[#d7dadc] mb-2 block">Text Content</label>
                        <textarea
                          value={segment.textSegments.find(t => t.id === editingTextId)?.text}
                          onChange={(e) => {
                            if (!segment) return;
                            setSegment({
                              ...segment,
                              textSegments: segment.textSegments.map(t =>
                                t.id === editingTextId ? { ...t, text: e.target.value } : t
                              )
                            });
                          }}
                          className="w-full bg-[#272729] border border-[#343536] rounded-md px-3 py-2 text-[#d7dadc]"
                          rows={3}
                        />
                      </div>

                      {/* Shorter helper text */}
                      <div className="bg-[#272729] rounded-lg p-3 text-sm text-[#818384]">
                        <p className="flex items-center gap-2">
                          <span className="bg-[#343536] rounded-full p-1">
                            <Type className="w-4 h-4" />
                          </span>
                          Drag text to reposition
                        </p>
                      </div>

                      <div className="grid grid-cols-2 gap-4">
                        <div>
                          <label className="text-sm font-medium text-[#d7dadc] mb-2 block">Font Size</label>
                          <select
                            value={segment.textSegments.find(t => t.id === editingTextId)?.style.fontSize}
                            onChange={(e) => {
                              if (!segment) return;
                              setSegment({
                                ...segment,
                                textSegments: segment.textSegments.map(t =>
                                  t.id === editingTextId ? { ...t, style: { ...t.style, fontSize: Number(e.target.value) } } : t
                                )
                              });
                            }}
                            className="w-full bg-[#272729] border border-[#343536] rounded-md px-3 py-2 text-[#d7dadc]"
                          >
                            <option value="16">16</option>
                            <option value="24">24</option>
                            <option value="32">32</option>
                            <option value="48">48</option>
                            <option value="64">64</option>
                            <option value="80">80</option>
                            <option value="96">96</option>
                            <option value="128">128</option>
                            <option value="160">160</option>
                            <option value="200">200</option>
                          </select>
                        </div>

                        <div>
                          <label className="text-sm font-medium text-[#d7dadc] mb-2 block">Color</label>
                          <input
                            type="color"
                            value={segment.textSegments.find(t => t.id === editingTextId)?.style.color}
                            onChange={(e) => {
                              if (!segment) return;
                              setSegment({
                                ...segment,
                                textSegments: segment.textSegments.map(t =>
                                  t.id === editingTextId ? { ...t, style: { ...t.style, color: e.target.value } } : t
                                )
                              });
                            }}
                            className="w-12 h-10 bg-[#272729] border border-[#343536] rounded-md p-1"
                          />
                        </div>
                      </div>
                    </div>
                  ) : (
                    <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-6 flex flex-col items-center justify-center text-center">
                      <div className="bg-[#272729] rounded-full p-3 mb-3">
                        <Type className="w-6 h-6 text-[#818384]" />
                      </div>
                      <p className="text-[#d7dadc] font-medium">No Text Selected</p>
                      <p className="text-[#818384] text-sm mt-1 max-w-[200px]">
                        Add a new text overlay or select an existing one from the timeline
                      </p>
                    </div>
                  )}
                </div>
              )}
            </div>
          </div>

          <div className="bg-[#1a1a1b] rounded-lg border border-[#343536] p-6">
            <div className="space-y-2 mb-8">
              <div className="flex justify-between items-center">
                <h2 className="text-lg font-semibold text-[#d7dadc]">Timeline</h2>
                <div className="flex gap-2">
                  <Button
                    onClick={() => {
                      if (!segment || !mousePositions.length) return;

                      // Generate auto zoom motion path
                      const motionPath = autoZoomGenerator.generateMotionPath(segment, mousePositions);

                      const newSegment: VideoSegment = {
                        ...segment,
                        zoomKeyframes: segment.zoomKeyframes,
                        smoothMotionPath: motionPath,
                        zoomInfluencePoints: [
                          { time: 0, value: 1.0 },
                          { time: duration, value: 1.0 }
                        ]
                      };

                      setSegment(newSegment);
                      if (currentProjectId) {
                        projectManager.updateProject(currentProjectId, {
                          segment: newSegment,
                          backgroundConfig: backgroundConfig,
                          mousePositions: mousePositions
                        }).then(() => loadProjects());
                      }

                      // Switch to zoom panel
                      setActivePanel('zoom');
                    }}
                    disabled={isProcessing || !currentVideo || !mousePositions.length}
                    className={`flex items-center px-4 py-2 h-9 text-sm font-medium transition-colors ${!currentVideo || isProcessing || !mousePositions.length
                      ? 'bg-gray-600/50 text-gray-400 cursor-not-allowed'
                      : 'bg-green-600 hover:bg-green-700 text-white shadow-sm'
                      }`}
                  >
                    <Wand2 className="w-4 h-4 mr-2" />Auto-Smart Zoom
                  </Button>



                </div>
              </div>
            </div>

            <Timeline
              duration={duration}
              currentTime={currentTime}
              segment={segment}
              thumbnails={thumbnails}
              timelineRef={timelineRef}
              videoRef={videoRef}
              editingKeyframeId={editingKeyframeId}
              editingTextId={editingTextId}
              setCurrentTime={setCurrentTime}
              setEditingKeyframeId={setEditingKeyframeId}
              setEditingTextId={setEditingTextId}
              setActivePanel={setActivePanel}
              setSegment={setSegment}
              onSeek={(time) => videoControllerRef.current?.seek(time)}
            />
          </div>
        </div>
      </main >

      {isProcessing && (
        <div className="fixed inset-0 bg-black/80 flex items-center justify-center z-50">
          <div className="bg-[#1a1a1b] p-6 rounded-lg border border-[#343536]">
            <p className="text-lg text-[#d7dadc]">{exportProgress > 0 ? `Exporting video... ${Math.round(exportProgress)}%` : 'Processing video...'}</p>
          </div>
        </div>
      )
      }

      {/* showConfirmNewRecording removed */}

      {
        showMonitorSelect && (
          <div className="fixed inset-0 bg-black/80 flex items-center justify-center z-50">
            <div className="bg-[#1a1a1b] p-6 rounded-lg border border-[#343536] max-w-md w-full mx-4">
              <h3 className="text-lg font-semibold text-[#d7dadc] mb-4">Select Monitor</h3>
              <div className="space-y-3 mb-6">
                {monitors.map((monitor) => (
                  <button
                    key={monitor.id}
                    onClick={() => {
                      setShowMonitorSelect(false);
                      startNewRecording(monitor.id);
                    }}
                    className="w-full p-4 rounded-lg border border-[#343536] hover:bg-[#272729] transition-colors text-left"
                  >
                    <div className="font-medium text-[#d7dadc]">
                      {monitor.name}
                    </div>
                    <div className="text-sm text-[#818384] mt-1">
                      {monitor.width}x{monitor.height} at ({monitor.x}, {monitor.y})
                    </div>
                  </button>
                ))}
              </div>
              <div className="flex justify-end">
                <Button
                  onClick={() => setShowMonitorSelect(false)}
                  variant="outline"
                  className="bg-transparent border-[#343536] text-[#d7dadc] hover:bg-[#272729] hover:text-[#d7dadc]"
                >
                  Cancel
                </Button>
              </div>
            </div>
          </div>
        )
      }

      {
        currentVideo && !isVideoReady && (
          <div className="absolute inset-0 flex items-center justify-center bg-black/50">
            <div className="text-white">Preparing video...</div>
          </div>
        )
      }

      {
        showExportDialog && (
          <div className="fixed inset-0 bg-black/80 flex items-center justify-center z-50">
            <div className="bg-[#1a1a1b] p-6 rounded-lg border border-[#343536] max-w-md w-full mx-4">
              <h3 className="text-lg font-semibold text-[#d7dadc] mb-4">Export Options</h3>

              <div className="space-y-4 mb-6">
                <div>
                  <label className="text-sm font-medium text-[#d7dadc] mb-2 block">Quality</label>
                  <select
                    value={exportOptions.quality}
                    onChange={(e) => setExportOptions(prev => ({ ...prev, quality: e.target.value as ExportOptions['quality'] }))}
                    className="w-full bg-[#272729] border border-[#343536] rounded-md px-3 py-2 text-[#d7dadc]"
                  >
                    {Object.entries(EXPORT_PRESETS).map(([key, preset]) => (
                      <option key={key} value={key}>{preset.label}</option>
                    ))}
                  </select>
                </div>

                <div>
                  <label className="text-sm font-medium text-[#d7dadc] mb-2 block">Dimensions</label>
                  <select
                    value={exportOptions.dimensions}
                    onChange={(e) => setExportOptions(prev => ({ ...prev, dimensions: e.target.value as ExportOptions['dimensions'] }))}
                    className="w-full bg-[#272729] border border-[#343536] rounded-md px-3 py-2 text-[#d7dadc]"
                  >
                    {Object.entries(DIMENSION_PRESETS).map(([key, preset]) => (
                      <option key={key} value={key}>{preset.label}</option>
                    ))}
                  </select>
                </div>

                <div>
                  <label className="text-sm font-medium text-[#d7dadc] mb-2 block">Speed</label>
                  <div className="bg-[#272729] rounded-md p-3">
                    <div className="flex items-center justify-between mb-3">
                      <div className="flex items-center gap-1.5">
                        <span className="text-sm text-[#d7dadc] tabular-nums">
                          {formatTime(segment ? (segment.trimEnd - segment.trimStart) / exportOptions.speed : 0)}
                        </span>
                        {segment && exportOptions.speed !== 1 && (
                          <span className={`text-xs ${exportOptions.speed > 1 ? 'text-red-400/90' : 'text-green-400/90'}`}>
                            {exportOptions.speed > 1 ? '↓' : '↑'}
                            {formatTime(Math.abs(
                              (segment.trimEnd - segment.trimStart) -
                              ((segment.trimEnd - segment.trimStart) / exportOptions.speed)
                            ))}
                          </span>
                        )}
                      </div>
                      <span className="text-sm font-medium text-[#d7dadc] tabular-nums">
                        {Math.round(exportOptions.speed * 100)}%
                      </span>
                    </div>

                    <div className="flex items-center gap-3">
                      <span className="text-xs text-[#818384] min-w-[36px]">Slower</span>
                      <div className="flex-1">
                        <input
                          type="range"
                          min="50"
                          max="200"
                          step="10"
                          value={exportOptions.speed * 100}
                          onChange={(e) => setExportOptions(prev => ({
                            ...prev,
                            speed: Number(e.target.value) / 100
                          }))}
                          className="w-full h-1 accent-[#0079d3] rounded-full"
                          style={{
                            background: `linear-gradient(to right, 
                            #818384 0%, 
                            #0079d3 ${((exportOptions.speed * 100 - 50) / 150) * 100}%`
                          }}
                        />
                      </div>
                      <span className="text-xs text-[#818384] min-w-[36px]">Faster</span>
                    </div>
                  </div>
                </div>
              </div>

              <div className="flex justify-end gap-3">
                <Button
                  variant="outline"
                  onClick={() => setShowExportDialog(false)}
                  className="bg-transparent border-[#343536] text-[#d7dadc] hover:bg-[#272729] hover:text-[#d7dadc]"
                >
                  Cancel
                </Button>
                <Button
                  onClick={startExport}
                  className="bg-[#0079d3] hover:bg-[#0079d3]/90 text-white"
                >
                  Export Video
                </Button>
              </div>
            </div>
          </div>
        )
      }

      {
        showProjectsDialog && (
          <div className="fixed inset-0 bg-black/80 flex items-center justify-center z-50">
            <div className="bg-[#1a1a1b] p-6 rounded-lg border border-[#343536] max-w-2xl w-full mx-4">
              <div className="flex justify-between items-center mb-6">
                <div className="flex items-center gap-4">
                  <h3 className="text-lg font-semibold text-[#d7dadc]">Recent Projects</h3>
                  <div className="flex items-center gap-2 ml-4">
                    <span className="text-xs text-[#818384]">Limit:</span>
                    <input
                      type="range"
                      min="10"
                      max="100"
                      value={projectManager.getLimit()}
                      onChange={(e) => {
                        projectManager.setLimit(parseInt(e.target.value));
                        loadProjects();
                      }}
                      className="w-24 h-1 bg-[#272729] rounded-lg appearance-none cursor-pointer accent-[#0079d3]"
                    />
                    <span className="text-xs text-[#d7dadc]">{projectManager.getLimit()}</span>
                  </div>
                </div>
                <Button
                  variant="ghost"
                  onClick={() => setShowProjectsDialog(false)}
                  className="text-[#818384] hover:text-[#d7dadc]"
                >
                  ✕
                </Button>
              </div>

              {projects.length === 0 ? (
                <div className="text-center py-8 text-[#818384]">
                  No saved projects yet
                </div>
              ) : (
                <div className="space-y-2 max-h-[60vh] overflow-y-auto">
                  {projects.map((project) => (
                    <div
                      key={project.id}
                      className="flex items-center justify-between p-3 rounded-lg border border-[#343536] hover:bg-[#272729] transition-colors gap-4"
                    >
                      <div className="w-24 h-14 bg-black rounded overflow-hidden flex-shrink-0 border border-[#343536]">
                        {project.thumbnail ? (
                          <img src={project.thumbnail} className="w-full h-full object-cover" alt="Preview" />
                        ) : (
                          <div className="w-full h-full flex items-center justify-center text-[#343536]">
                            <Video className="w-6 h-6" />
                          </div>
                        )}
                      </div>
                      <div className="flex-1 min-w-0">
                        {editingProjectNameId === project.id ? (
                          <input
                            autoFocus
                            className="bg-[#1a1a1b] border border-[#0079d3] rounded px-2 py-1 text-[#d7dadc] w-full"
                            value={projectRenameValue}
                            onChange={(e) => setProjectRenameValue(e.target.value)}
                            onBlur={() => handleRenameProject(project.id)}
                            onKeyDown={(e) => e.key === 'Enter' && handleRenameProject(project.id)}
                            onMouseDown={(e) => e.stopPropagation()}
                          />
                        ) : (
                          <h4
                            className="text-[#d7dadc] font-medium truncate cursor-primary hover:text-[#0079d3] cursor-pointer"
                            title="Click to rename"
                            onClick={() => {
                              setEditingProjectNameId(project.id);
                              setProjectRenameValue(project.name);
                            }}
                          >
                            {project.name}
                          </h4>
                        )}
                        <p className="text-sm text-[#818384]">
                          Last modified: {new Date(project.lastModified).toLocaleDateString()}
                        </p>
                      </div>
                      <div className="flex gap-2">
                        <Button
                          onClick={() => handleLoadProject(project.id)}
                          className="bg-[#0079d3] hover:bg-[#0079d3]/90 text-white"
                        >
                          Load Project
                        </Button>
                        <Button
                          variant="ghost"
                          onClick={async () => {
                            await projectManager.deleteProject(project.id);
                            await loadProjects();
                          }}
                          className="text-red-400 hover:text-red-300 hover:bg-red-900/20"
                        >
                          <Trash2 className="w-4 h-4" />
                        </Button>
                      </div>
                    </div>
                  ))}
                </div>
              )}
            </div>
          </div>
        )
      }

      {
        showHotkeyDialog && (
          <div className="fixed inset-0 bg-black/80 flex items-center justify-center z-50">
            <div className="bg-[#1a1a1b] p-6 rounded-lg border border-[#343536] max-w-sm w-full mx-4 text-center">
              <Keyboard className="w-12 h-12 text-[#0079d3] mx-auto mb-4" />
              <h3 className="text-lg font-semibold text-[#d7dadc] mb-2">
                Press Keys...
              </h3>
              <p className="text-[#818384] mb-6">
                Press the combination of keys you want to use.
              </p>

              <div className="flex justify-center gap-3">
                <Button
                  variant="ghost"
                  onClick={() => { setListeningForKey(false); setShowHotkeyDialog(false); }}
                  className="text-[#d7dadc] hover:bg-[#272729]"
                >
                  Cancel
                </Button>
              </div>
            </div>
          </div>
        )
      }
    </div >
  );
}

// Helper function to format time
function formatTime(seconds: number): string {
  const minutes = Math.floor(seconds / 60);
  const remainingSeconds = Math.floor(seconds % 60);
  return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
}

export default App;
</file>

<file path="src/overlay/result/button_canvas.rs">
// Button Canvas - Floating transparent WebView overlay for markdown result buttons
// Single fullscreen canvas that serves buttons for ALL markdown result windows
// Click-through background with radius-based opacity buttons

use std::cell::RefCell;
use std::collections::HashMap;
use std::sync::{
    atomic::{AtomicBool, AtomicIsize, Ordering},
    Mutex,
};
use windows::core::w;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Dwm::DwmExtendFrameIntoClientArea;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::Com::*;
use windows::Win32::System::LibraryLoader::GetModuleHandleW;
use windows::Win32::UI::Controls::MARGINS;
use windows::Win32::UI::HiDpi::GetDpiForSystem;
use windows::Win32::UI::WindowsAndMessaging::*;
use wry::{Rect, WebContext, WebView, WebViewBuilder};

use super::state::WINDOW_STATES;

/// Get DPI scale factor (1.0 = 100%, 1.5 = 150%, 2.0 = 200%, etc.)
fn get_dpi_scale() -> f64 {
    let dpi = unsafe { GetDpiForSystem() };
    dpi as f64 / 96.0
}

// Singleton canvas state
static CANVAS_HWND: AtomicIsize = AtomicIsize::new(0);
static IS_WARMED_UP: AtomicBool = AtomicBool::new(false);
static IS_DRAGGING_EXTERNAL: AtomicBool = AtomicBool::new(false); // New flag
static REGISTER_CANVAS_CLASS: std::sync::Once = std::sync::Once::new();

// Custom messages
const WM_APP_UPDATE_WINDOWS: u32 = WM_APP + 50;
const WM_APP_SHOW_CANVAS: u32 = WM_APP + 51;
const WM_APP_HIDE_CANVAS: u32 = WM_APP + 52;
const WM_APP_SEND_REFINE_TEXT: u32 = WM_APP + 53;

// Timer for cursor position polling (since WS_EX_TRANSPARENT prevents mouse events)
const CURSOR_POLL_TIMER_ID: usize = 1;

thread_local! {
    static CANVAS_WEBVIEW: RefCell<Option<WebView>> = RefCell::new(None);
    static CANVAS_WEB_CONTEXT: RefCell<Option<WebContext>> = RefCell::new(None);
}

lazy_static::lazy_static! {


    // Tracks which result windows are in markdown mode and their positions
    // Key: hwnd as isize, Value: (x, y, w, h)
    static ref MARKDOWN_WINDOWS: Mutex<HashMap<isize, (i32, i32, i32, i32)>> = Mutex::new(HashMap::new());
}

// HWND wrapper for wry
struct HwndWrapper(HWND);
unsafe impl Send for HwndWrapper {}
unsafe impl Sync for HwndWrapper {}
impl raw_window_handle::HasWindowHandle for HwndWrapper {
    fn window_handle(
        &self,
    ) -> Result<raw_window_handle::WindowHandle<'_>, raw_window_handle::HandleError> {
        let raw = raw_window_handle::Win32WindowHandle::new(
            std::num::NonZeroIsize::new(self.0 .0 as isize).expect("HWND cannot be null"),
        );
        let handle = raw_window_handle::RawWindowHandle::Win32(raw);
        unsafe { Ok(raw_window_handle::WindowHandle::borrow_raw(handle)) }
    }
}

static IS_INITIALIZING: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);

/// Register a markdown window for button overlay
pub fn register_markdown_window(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    // Initialize on-demand if not warmed up
    if !IS_WARMED_UP.load(Ordering::SeqCst) && CANVAS_HWND.load(Ordering::SeqCst) == 0 {
        if !IS_INITIALIZING.swap(true, Ordering::SeqCst) {
            std::thread::spawn(|| {
                create_canvas_window();
            });
        }

        // Polling thread to auto-show once ready
        std::thread::spawn(move || {
            for _ in 0..50 {
                std::thread::sleep(std::time::Duration::from_millis(100));
                if IS_WARMED_UP.load(Ordering::SeqCst) && CANVAS_HWND.load(Ordering::SeqCst) != 0 {
                    update_canvas();
                    show_canvas();
                    return;
                }
            }
        });
    }

    // Get window rect
    let rect = unsafe {
        let mut r = RECT::default();
        let _ = GetWindowRect(hwnd, &mut r);
        r
    };

    {
        let mut windows = MARKDOWN_WINDOWS.lock().unwrap();
        windows.insert(
            hwnd_key,
            (
                rect.left,
                rect.top,
                rect.right - rect.left,
                rect.bottom - rect.top,
            ),
        );
    }

    // Trigger canvas update
    update_canvas();
    show_canvas();
}

/// Unregister a markdown window
pub fn unregister_markdown_window(hwnd: HWND) {
    let hwnd_key = hwnd.0 as isize;

    {
        let mut windows = MARKDOWN_WINDOWS.lock().unwrap();
        windows.remove(&hwnd_key);

        // If no more markdown windows, hide canvas
        if windows.is_empty() {
            hide_canvas();
        }
    }

    update_canvas();
}

lazy_static::lazy_static! {
    static ref PENDING_REFINE_UPDATES: Mutex<HashMap<isize, String>> = Mutex::new(HashMap::new());
}

/// Update window position (call when window moves/resizes)
pub fn update_window_position(hwnd: HWND) {
    update_window_position_internal(hwnd, true);
}

fn update_window_position_internal(hwnd: HWND, notify: bool) {
    let hwnd_key = hwnd.0 as isize;

    let rect = unsafe {
        let mut r = RECT::default();
        let _ = GetWindowRect(hwnd, &mut r);
        r
    };

    {
        let mut windows = MARKDOWN_WINDOWS.lock().unwrap();
        if windows.contains_key(&hwnd_key) {
            windows.insert(
                hwnd_key,
                (
                    rect.left,
                    rect.top,
                    rect.right - rect.left,
                    rect.bottom - rect.top,
                ),
            );
        }
    }

    if notify {
        update_canvas();
        update_canvas();
    }
}

/// Update window position directly in the register (skips GetWindowRect, faster for bulk)
pub fn update_window_position_direct(hwnd: HWND, x: i32, y: i32, w: i32, h: i32) {
    let hwnd_key = hwnd.0 as isize;
    let mut windows = MARKDOWN_WINDOWS.lock().unwrap();
    if windows.contains_key(&hwnd_key) {
        windows.insert(hwnd_key, (x, y, w, h));
    }
}

/// Send update to set the text in the refine input bar
pub fn send_refine_text_update(hwnd: HWND, text: &str, is_insert: bool) {
    let hwnd_key = hwnd.0 as isize;

    // Store in pending updates
    {
        let mut updates = PENDING_REFINE_UPDATES.lock().unwrap();
        updates.insert(hwnd_key, text.to_string());
    }

    // Notify canvas thread
    let canvas_hwnd = CANVAS_HWND.load(Ordering::SeqCst);
    if canvas_hwnd != 0 {
        unsafe {
            let _ = PostMessageW(
                Some(HWND(canvas_hwnd as *mut _)),
                WM_APP_SEND_REFINE_TEXT,
                WPARAM(hwnd_key as usize),
                LPARAM(if is_insert { 1 } else { 0 }),
            );
        }
    }
}

/// Set drag mode (temporarily disable region clipping to prevent UI cutoff)
pub fn set_drag_mode(active: bool) {
    let canvas_hwnd = CANVAS_HWND.load(Ordering::SeqCst);
    if canvas_hwnd == 0 {
        return;
    }
    let hwnd = HWND(canvas_hwnd as *mut std::ffi::c_void);

    if active {
        // ENTER DRAG MODE: Remove region (full window visible/interactive)
        IS_DRAGGING_EXTERNAL.store(true, Ordering::SeqCst);
        unsafe {
            let _ = SetWindowRgn(hwnd, None, true);
        }
    } else {
        // EXIT DRAG MODE: Restore regions
        IS_DRAGGING_EXTERNAL.store(false, Ordering::SeqCst);

        // IMMEDIATE FIX: Reset region to empty (passthrough) so the underlying window
        // receives mouse events immediately. The correct button regions will be
        // restored asynchronously via update_canvas -> IPC -> SetWindowRgn.
        unsafe {
            let empty = CreateRectRgn(0, 0, 0, 0);
            let _ = SetWindowRgn(hwnd, Some(empty), true);
        }

        update_canvas(); // Trigger recalculation of regions
    }
}

/// Update canvas with current window positions
pub fn update_canvas() {
    let canvas_hwnd = CANVAS_HWND.load(Ordering::SeqCst);
    if canvas_hwnd != 0 {
        let hwnd = HWND(canvas_hwnd as *mut std::ffi::c_void);
        unsafe {
            let _ = PostMessageW(Some(hwnd), WM_APP_UPDATE_WINDOWS, WPARAM(0), LPARAM(0));
        }
    }
}

/// Show the canvas
fn show_canvas() {
    let canvas_hwnd = CANVAS_HWND.load(Ordering::SeqCst);
    if canvas_hwnd != 0 {
        let hwnd = HWND(canvas_hwnd as *mut std::ffi::c_void);
        unsafe {
            let _ = PostMessageW(Some(hwnd), WM_APP_SHOW_CANVAS, WPARAM(0), LPARAM(0));
        }
    }
}

/// Hide the canvas
fn hide_canvas() {
    let canvas_hwnd = CANVAS_HWND.load(Ordering::SeqCst);
    if canvas_hwnd != 0 {
        let hwnd = HWND(canvas_hwnd as *mut std::ffi::c_void);
        unsafe {
            let _ = PostMessageW(Some(hwnd), WM_APP_HIDE_CANVAS, WPARAM(0), LPARAM(0));
        }
    }
}

// Track last applied theme to avoid redundant injections
static LAST_THEME_IS_DARK: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(true);

fn get_canvas_theme_css(is_dark: bool) -> &'static str {
    if is_dark {
        r#"
        :root {
            --btn-bg: rgba(30, 30, 30, 0.85);
            --btn-border: rgba(255, 255, 255, 0.1);
            --btn-color: rgba(255, 255, 255, 0.8);
            --btn-hover-bg: rgba(60, 60, 60, 0.95);
            --btn-hover-color: #4fc3f7;
            --btn-active-bg: rgba(30, 30, 30, 0.95);
            --btn-active-color: #4fc3f7;
            --btn-success-color: #81c784;
            --shadow-color: rgba(79, 195, 247, 0.35);
            
            /* Refine Input Variables (Dark) */
            --refine-bg: #1e1e1e;
            --refine-border: #444;
            --refine-input-bg: #2d2d2d;
            --refine-text: #fff;
            --refine-placeholder: #888;
            --mic-bg: rgba(60, 60, 60, 0.5);
            --mic-fill: #00c8ff;
        }
        "#
    } else {
        r#"
        :root {
            --btn-bg: rgba(255, 255, 255, 0.92);
            --btn-border: rgba(0, 0, 0, 0.08);
            --btn-color: rgba(0, 0, 0, 0.7);
            --btn-hover-bg: #ffffff;
            --btn-hover-color: #0277bd;
            --btn-active-bg: #ffffff;
            --btn-active-color: #0277bd;
            --btn-success-color: #43a047;
            --shadow-color: rgba(2, 119, 189, 0.25);
            
            /* Refine Input Variables (Light) */
            --refine-bg: #ffffff;
            --refine-border: #ddd;
            --refine-input-bg: #f5f5f5;
            --refine-text: #333;
            --refine-placeholder: #999;
            --mic-bg: rgba(0, 0, 0, 0.05);
            --mic-fill: #0288d1;
        }
        "#
    }
}

fn generate_canvas_html() -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    // Get localization
    let lang = crate::APP.lock().unwrap().config.ui_language.clone();
    let locale = crate::gui::locale::LocaleText::get(&lang);
    let l10n_json = serde_json::json!({
        "copy": locale.overlay_copy_tooltip,
        "undo": locale.overlay_undo_tooltip,
        "redo": locale.overlay_redo_tooltip,
        "edit": locale.overlay_edit_tooltip,
        "markdown": locale.overlay_markdown_tooltip,
        "download": locale.overlay_download_tooltip,
        "speaker": locale.overlay_speaker_tooltip,
        "broom": locale.overlay_broom_tooltip,
        "back": locale.overlay_back_tooltip,
        "forward": locale.overlay_forward_tooltip,
        "opacity": locale.overlay_opacity_tooltip,
        "overlay_refine_placeholder": locale.overlay_refine_placeholder,
    })
    .to_string();

    let is_dark = crate::overlay::is_dark_mode();

    // Icon color based on theme - REMOVED to allow CSS currentColor to work
    // let icon_color = if is_dark {
    //     "rgba(255, 255, 255, 0.8)"
    // } else {
    //     "rgba(0, 0, 0, 0.7)"
    // };

    // Initialize state
    LAST_THEME_IS_DARK.store(is_dark, Ordering::SeqCst);
    let theme_css = get_canvas_theme_css(is_dark);

    // Get icon SVGs with theme-appropriate colors
    // CHANGED: Do NOT replace currentColor. This allows CSS to control icon color (hover, active, etc.)
    let get_colored_svg = |name: &str| -> String {
        crate::overlay::html_components::icons::get_icon_svg(name).to_string()
    };

    let icon_svgs_json = serde_json::json!({
        "arrow_back": get_colored_svg("arrow_back"),
        "arrow_forward": get_colored_svg("arrow_forward"),
        "undo": get_colored_svg("undo"),
        "redo": get_colored_svg("redo"),
        "newsmode": get_colored_svg("newsmode"),
        "notes": get_colored_svg("notes"),
        "hourglass_empty": get_colored_svg("hourglass_empty"),
        "stop": get_colored_svg("stop"),
        "cleaning_services": get_colored_svg("cleaning_services"),
        "content_copy": get_colored_svg("content_copy"),
        "check": get_colored_svg("check"),
        "download": get_colored_svg("download"),
        "volume_up": get_colored_svg("volume_up"),
        "mic": get_colored_svg("mic"),
        "send": get_colored_svg("send"),
        "opacity": get_colored_svg("opacity"),
    })
    .to_string();

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
<meta charset="UTF-8">
<style>
{font_css}
</style>
<style id="theme-css">
{theme_css}
</style>
<style>

.icons {{
    font-family: 'Material Symbols Rounded';
    font-variation-settings: 'FILL' 0, 'wght' 400, 'GRAD' 0, 'opsz' 20;
    font-size: 16px;
    line-height: 1;
}}

* {{ margin: 0; padding: 0; box-sizing: border-box; }}
html, body {{
    width: 100vw;
    height: 100vh;
    overflow: hidden;
    background: transparent;
    pointer-events: none; /* Click-through by default */
    font-family: 'Google Sans Flex', 'Segoe UI', sans-serif;
    user-select: none;
}}

.button-group {{
    position: absolute;
    display: flex;
    gap: 4px;
    padding: 2px;
    pointer-events: auto; /* Buttons accept clicks */
    transition: opacity 0.15s ease-out;
}}

.btn {{
    width: 24px;
    height: 24px;
    border-radius: 6px;
    background: var(--btn-bg);
    backdrop-filter: blur(12px);
    -webkit-backdrop-filter: blur(12px);
    border: 1px solid var(--btn-border);
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: pointer;
    transition: opacity 0.15s ease-out, background-color 0.15s ease-out, color 0.15s ease-out;
    color: var(--btn-color);
}}

.button-group.vertical {{
    flex-direction: column;
    padding: 6px 3px;
    height: auto;
    width: 32px;
}}
.button-group.vertical .btn {{
    margin: 3px 0;
}}

.btn:hover {{
    background: var(--btn-hover-bg);
    color: var(--btn-hover-color);
    transform: scale(1.05);
    /* Directional glow: left, right, bottom only (no top to avoid resize area) */
    box-shadow: 
        -5px 0 6px -3px var(--shadow-color),  /* left */
        5px 0 6px -3px var(--shadow-color),   /* right */
        0 5px 6px -3px var(--shadow-color);    /* bottom */
}}

.btn:active {{
    transform: scale(0.95);
}}

.btn.disabled {{
    opacity: 0.3;
    pointer-events: none;
}}

.btn.active {{
    background: var(--btn-active-bg);
    border-color: var(--btn-active-color);
    color: var(--btn-active-color);
}}

.btn.success {{
    background: var(--btn-active-bg);
    border-color: var(--btn-success-color);
    color: var(--btn-success-color);
}}

.btn.loading {{
    animation: pulse 1s infinite;
}}

@keyframes pulse {{
    0%, 100% {{ opacity: 1; }}
    50% {{ opacity: 0.5; }}
}}

/* Broom button special styling */
.btn.broom {{
    cursor: grab;
}}
.btn.broom:active {{
    cursor: grabbing;
}}

/* Hidden button - invisible but preserves space */
.btn.hidden {{
    visibility: hidden;
    pointer-events: none;
}}

/* Refine Input Bar */
.refine-bar {{
    display: flex;
    align-items: center;
    background: var(--refine-bg);
    border: 1px solid var(--refine-border);
    border-radius: 8px; /* Slightly tighter radius */
    padding: 2px 4px; /* More compact padding */
    box-shadow: 0 4px 12px rgba(0,0,0,0.15);
    pointer-events: auto;
    min-width: 250px; /* More compact */
    gap: 4px;
    animation: fadeIn 0.15s ease-out; /* Changed to simple fade */
}}

@keyframes fadeIn {{
    from {{ opacity: 0; transform: scale(0.98); }} /* Subtle scale instead of fly up */
    to {{ opacity: 1; transform: scale(1); }}
}}

.refine-input {{
    flex: 1;
    background: var(--refine-input-bg);
    border: 1px solid transparent;
    border-radius: 8px;
    padding: 6px 10px;
    color: var(--refine-text);
    font-family: 'Google Sans Flex', sans-serif;
    font-size: 13px;
    outline: none;
    transition: border-color 0.15s;
    min-width: 0;
}}

.refine-input:focus {{
    border-color: var(--btn-active-color);
}}

.refine-input::placeholder {{
    color: var(--refine-placeholder);
}}

.refine-action-btn {{
    width: 32px;
    height: 32px;
    border-radius: 50%;
    display: flex;
    align-items: center;
    justify-content: center;
    cursor: pointer;
    transition: all 0.15s;
    background: transparent;
    border: none;
    color: var(--mic-fill);
}}

.refine-action-btn:hover {{
    background: var(--mic-bg);
    transform: scale(1.05);
}}

.refine-action-btn.send {{
    color: var(--btn-active-color);
}}

/* Opacity Expanding Button - Expands Leftwards */
.opacity-btn-expandable {{
    width: 24px;
    height: 24px;
    transition: width 0.3s cubic-bezier(0.4, 0, 0.2, 1), height 0.3s cubic-bezier(0.4, 0, 0.2, 1), background-color 0.15s, color 0.15s !important;
    overflow: hidden;
    padding: 0 4px !important;
    display: flex !important;
    align-items: center;
    justify-content: flex-end !important; /* Anchor icon on the right */
    white-space: nowrap;
    border-radius: 6px;
}}

.opacity-btn-expandable:not(.vertical-slider):hover {{
    width: 110px !important; /* Reduced from 125px */
    background: var(--btn-hover-bg) !important;
    transform: none !important;
}}

/* Vertical slider specific styles */
.opacity-btn-expandable.vertical-slider {{
    flex-direction: column !important;
    justify-content: flex-end !important;
    padding: 4px 0 !important;
}}

.opacity-btn-expandable.vertical-slider:hover {{
    height: 110px !important; /* Exactly match horizontal expanded width */
    background: var(--btn-hover-bg) !important;
    transform: none !important;
}}

.opacity-icon-wrapper {{
    width: 16px;
    min-width: 16px;
    height: 24px;
    display: flex;
    align-items: center;
    justify-content: center;
    order: 2;
    flex-shrink: 0;
}}

.opacity-btn-expandable.vertical-slider .opacity-icon-wrapper {{
    height: 16px;
    width: 24px;
}}

.opacity-slider-wrapper {{
    flex: 1;
    display: flex;
    align-items: center;
    gap: 4px;
    opacity: 0;
    transition: opacity 0.2s ease;
    pointer-events: none;
    order: 1;
    padding-right: 4px;
    min-width: 0;
}}

.opacity-btn-expandable.vertical-slider .opacity-slider-wrapper {{
    flex-direction: column;
    padding-right: 0;
    padding-bottom: 2px;
    gap: 2px;
    justify-content: center;
}}

.opacity-btn-expandable:hover .opacity-slider-wrapper {{
    opacity: 1;
    pointer-events: auto;
    transition: opacity 0.3s ease 0.1s;
}}

.opacity-slider-inline {{
    -webkit-appearance: none;
    appearance: none;
    flex: 1;
    min-width: 0;
    height: 3px;
    background: var(--btn-border);
    border-radius: 2px;
    cursor: pointer;
    outline: none;
}}

/* Shared Thumb Style */
.opacity-slider-inline::-webkit-slider-thumb {{
    -webkit-appearance: none;
    appearance: none;
    width: 12px;
    height: 12px;
    background: var(--btn-active-color);
    border-radius: 50%;
    cursor: pointer;
    border: none;
}}

.opacity-btn-expandable.vertical-slider .opacity-slider-inline {{
    -webkit-appearance: none;
    appearance: none;
    width: 3px !important;
    min-width: 3px !important;
    height: 55px !important; /* Match horizontal flexed track length */
    flex: none;
    margin: 5px auto;
    writing-mode: vertical-lr;
    direction: rtl;
}}

.opacity-value-inline {{
    font-size: 9px;
    color: var(--btn-color);
    min-width: 25px;
    text-align: center;
}}
</style>
</head>
<body>
<div id="button-container"></div>
<script>
// Track registered windows: {{ hwnd: {{ x, y, w, h }} }}
window.registeredWindows = {{}};
window.L10N = #L10N_JSON#;
window.iconSvgs = #ICON_SVGS_JSON#;

// Track visibility state to minimize IPC calls
// Key: hwnd string, Value: boolean (isVisible)
let lastVisibleState = new Map();
// Key: hwnd string, Value: string (json of x,y,w,h)
let lastSentRegions = new Map();


// Track cursor position for radius-based opacity
// Note: Position is updated from Rust via updateCursorPosition() since WS_EX_TRANSPARENT
// prevents this window from receiving mouse events directly
let cursorX = 0, cursorY = 0;
// Track drag state globally so opacity updates can sync regions during drag
let broomDragData = null;

// Opacity slider state
window.opacityValues = {{}}; // hwnd -> current opacity value (10-100)

// Update opacity and send to Rust
window.updateOpacity = function(hwnd, value) {{
    value = parseInt(value);
    window.opacityValues[hwnd] = value;
    window.ipc.postMessage(JSON.stringify({{
        action: "set_opacity",
        hwnd: hwnd,
        value: value
    }}));
    
    // Update the local value display
    const group = document.querySelector('.button-group[data-hwnd="' + hwnd + '"]');
    if (group) {{
        const span = group.querySelector('.opacity-value-inline');
        if (span) span.textContent = value + '%';
    }}
}};

// Called from Rust every 50ms with current cursor position
window.updateCursorPosition = (x, y) => {{
    cursorX = x;
    cursorY = y;
    updateButtonOpacity();
}};

// Update button opacity based on distance from cursor to nearest edge of button group
function updateButtonOpacity() {{
    const groups = document.querySelectorAll('.button-group');
    // Force update during drag to ensure clipping region follows the buttons
    let needsUpdate = (broomDragData && broomDragData.moved) || false;
    
    groups.forEach(group => {{
        const rect = group.getBoundingClientRect();
        
        // Calculate distance to nearest edge of the rectangle (not center)
        let dx = 0, dy = 0;
        if (cursorX < rect.left) dx = rect.left - cursorX;
        else if (cursorX > rect.right) dx = cursorX - rect.right;
        
        if (cursorY < rect.top) dy = rect.top - cursorY;
        else if (cursorY > rect.bottom) dy = cursorY - rect.bottom;
        
        // If cursor is inside the rect, distance is 0
        const dist = Math.sqrt(dx * dx + dy * dy);
        
        // Radius-based opacity: full at 0, fade to 0 at 150px from edge
        const maxRadius = 150;
        let opacity = Math.max(0, Math.min(1, 1 - (dist / maxRadius)));
        
        // Force full opacity if dragging this specific window
        if (broomDragData && broomDragData.moved && broomDragData.hwnd === group.dataset.hwnd) {{
            opacity = 1.0;
        }}

        group.style.opacity = opacity;
        
        const isVisible = opacity > 0.1;
        group.style.pointerEvents = isVisible ? 'auto' : 'none';
        
        const hwnd = group.dataset.hwnd;
        if (lastVisibleState.get(hwnd) !== isVisible) {{
            lastVisibleState.set(hwnd, isVisible);
            needsUpdate = true;
        }}

        // Check if region dimensions changed (even if visibility didn't)
        if (isVisible) {{
            const currentRegion = {{
                x: Math.round(rect.left),
                y: Math.round(rect.top),
                w: Math.round(rect.width),
                h: Math.round(rect.height)
            }};
            const regionStr = JSON.stringify(currentRegion);
            if (lastSentRegions.get(hwnd) !== regionStr) {{
                // DON'T update map here, wait until we actually confirm sending
                needsUpdate = true;
            }}
        }}
    }});
    
    if (needsUpdate) {{
        // Send updated clickable regions to Rust
        // Only include regions that are currently visible
        const regions = [];
        const padding = 5; // Reduced 20 -> 5 to prevent resize handle overlap
        
        groups.forEach(group => {{
            if (lastVisibleState.get(group.dataset.hwnd)) {{
                const rect = group.getBoundingClientRect();
                const isVertical = group.classList.contains('vertical');
                let region;
                
                if (isVertical) {{
                    region = {{
                        // Add top buffer for vertical expanding slider
                        x: rect.left + 1,
                        y: rect.top - 200, 
                        w: rect.width + padding,
                        h: rect.height + 200 + padding
                    }};
                }} else {{
                    region = {{
                        // Add large left buffer (200px) to account for expanding UI
                        x: rect.left - 200,
                        // Start exactly at top edge or slightly below to avoid window border
                        // Vertical bar doesn't have the "bottom-right corner" issue as it's on the side
                        y: rect.top + 1, 
                        w: rect.width + 200 + padding,
                        h: rect.height + padding
                    }};
                }}
                regions.push(region);
                
                // Track what we sent (using the RAW rect, not the padded one, for change detection stability)
                const rawRegion = {{
                    x: Math.round(rect.left),
                    y: Math.round(rect.top),
                    w: Math.round(rect.width),
                    h: Math.round(rect.height)
                }};
                lastSentRegions.set(group.dataset.hwnd, JSON.stringify(rawRegion));
            }}
        }});
        
        window.ipc.postMessage(JSON.stringify({{
            action: "update_clickable_regions",
            regions: regions
        }}));
    }}
}}

// Calculate best position for button group based on window position and screen bounds
// Calculate best position for button group based on window position and screen bounds
// Calculate best position for button group based on window position and screen bounds
function calculateButtonPosition(winRect) {{
    const screenW = window.innerWidth;
    const screenH = window.innerHeight;
    const longDim = 300; // Length of the button group (reduced for compact UI)
    const shortDim = 32;  // Thickness of the button group (24px btn + padding)
    const margin = 4; // Gap of 4px to match button spacing
    
    // Check available space on each side (thickness-wise)
    const spaceBottom = screenH - (winRect.y + winRect.h);
    const spaceTop = winRect.y;
    const spaceRight = screenW - (winRect.x + winRect.w);
    const spaceLeft = winRect.x;
    
    // Helper to clamp position to keep bar on screen
    const clamp = (val, max) => Math.max(0, Math.min(val, max));

    // 1. Bottom Horizontal (Preferred) - Check if we have vertical space below
    if (spaceBottom >= shortDim + margin) {{
        // Right align relative to window (flush right), clamp to screen width
        let x = winRect.x + winRect.w - longDim;
        x = clamp(x, screenW - longDim);
        return {{
            x: x,
            y: winRect.y + winRect.h + margin,
            direction: 'bottom'
        }};
    }}
    // 2. Right Vertical - Check if we have horizontal space to the right
    else if (spaceRight >= shortDim + margin) {{
        // Center vertically relative to window, clamp to screen height
        let y = winRect.y + (winRect.h - longDim) / 2;
        y = clamp(y, screenH - longDim);
        return {{
            x: winRect.x + winRect.w + margin,
            y: y,
            direction: 'right'
        }};
    }}
    // 3. Left Vertical
    else if (spaceLeft >= shortDim + margin) {{
        let y = winRect.y + (winRect.h - longDim) / 2;
        y = clamp(y, screenH - longDim);
        return {{
            x: winRect.x - shortDim - margin,
            y: y,
            direction: 'left'
        }};
    }}
    // 4. Top Horizontal
    else if (spaceTop >= shortDim + margin) {{
        let x = winRect.x + (winRect.w - longDim) / 2;
        x = clamp(x, screenW - longDim);
        return {{
            x: x,
            y: winRect.y - shortDim - margin,
            direction: 'top'
        }};
    }}
    // Fallback: overlay inside window at bottom (clamped)
    else {{
        let x = winRect.x + (winRect.w - longDim) / 2;
        x = clamp(x, screenW - longDim);
        
        let y = winRect.y + winRect.h - shortDim - margin;
        // Ensure it doesn't go off top if window is tiny
        y = Math.max(winRect.y, y); 
        
        return {{
            x: x,
            y: y,
            direction: 'inside'
        }};
    }}
}}

// Generate buttons HTML for a window
// All buttons are always rendered but hidden when not applicable to preserve consistent layout
function generateButtonsHTML(hwnd, state, isVertical) {{
    const canGoBack = state.navDepth > 0;
    const canGoForward = state.navDepth < state.maxNavDepth;
    const isBrowsing = state.isBrowsing || false;
    const hideClass = isBrowsing ? 'hidden' : '';
    
    // IF EDITING: Show Refine Input Bar
    if (state.isEditing) {{
        return generateRefineInputHTML(hwnd, state);
    }}
    
    let buttons = '';
    
    
    // Back button - always rendered, hidden when not available
    const backHideClass = canGoBack ? '' : 'hidden';
    buttons += `<div class="btn ${{backHideClass}}" onclick="action('${{hwnd}}', 'back')" title="${{window.L10N.back}}">
        ${{window.iconSvgs.arrow_back}}
    </div>`;

    // Forward button - always rendered, hidden when not available
    const forwardHideClass = canGoForward ? '' : 'hidden';
    buttons += `<div class="btn ${{forwardHideClass}}" onclick="action('${{hwnd}}', 'forward')" title="${{window.L10N.forward}}">
        ${{window.iconSvgs.arrow_forward}}
    </div>`;
    
    // Opacity button - Expanding on hover
    const opacityValue = state.opacityPercent || 100;
    const verticalClass = isVertical ? 'vertical-slider' : '';
    buttons += `<div class="btn opacity-btn-expandable ${{verticalClass}} ${{hideClass}}" title="${{window.L10N.opacity}}">
        <div class="opacity-slider-wrapper">
            <input type="range" class="opacity-slider-inline" min="10" max="100" value="${{opacityValue}}" 
                oninput="updateOpacity('${{hwnd}}', this.value)" />
            <span class="opacity-value-inline">${{opacityValue}}%</span>
        </div>
        <div class="opacity-icon-wrapper">
            ${{window.iconSvgs.opacity}}
        </div>
    </div>`;

    // Copy - hidden when browsing but preserves space
    buttons += `<div class="btn ${{state.copySuccess ? 'success' : ''}} ${{hideClass}}" onclick="action('${{hwnd}}', 'copy')" title="${{window.L10N.copy}}">
        ${{window.iconSvgs[state.copySuccess ? 'check' : 'content_copy']}}
    </div>`;
    
    // Undo - only shown if there's history (hidden when browsing)
    if (state.hasUndo) {{
        buttons += `<div class="btn ${{hideClass}}" onclick="action('${{hwnd}}', 'undo')" title="${{window.L10N.undo}}">
            ${{window.iconSvgs.undo}}
        </div>`;
    }}

    // Redo - only shown if there's redo history (hidden when browsing)
    if (state.hasRedo) {{
        buttons += `<div class="btn ${{hideClass}}" onclick="action('${{hwnd}}', 'redo')" title="${{window.L10N.redo}}">
            ${{window.iconSvgs.redo}}
        </div>`;
    }}
    
    // Edit/Refine - hidden when browsing but preserves space
    buttons += `<div class="btn ${{hideClass}}" onclick="action('${{hwnd}}', 'edit')" title="${{window.L10N.edit}}">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 256 258" width="14" height="14" style="fill: currentColor; stroke: currentColor; stroke-width: 20; stroke-linejoin: round; opacity: 0.9;">
            <path d="m122.062 172.77l-10.27 23.52c-3.947 9.042-16.459 9.042-20.406 0l-10.27-23.52c-9.14-20.933-25.59-37.595-46.108-46.703L6.74 113.52c-8.987-3.99-8.987-17.064 0-21.053l27.385-12.156C55.172 70.97 71.917 53.69 80.9 32.043L91.303 6.977c3.86-9.303 16.712-9.303 20.573 0l10.403 25.066c8.983 21.646 25.728 38.926 46.775 48.268l27.384 12.156c8.987 3.99 8.987 17.063 0 21.053l-28.267 12.547c-20.52 9.108-36.97 25.77-46.109 46.703"/>
            <path d="m217.5 246.937l-2.888 6.62c-2.114 4.845-8.824 4.845-10.937 0l-2.889-6.62c-5.148-11.803-14.42-21.2-25.992-26.34l-8.898-3.954c-4.811-2.137-4.811-9.131 0-11.269l8.4-3.733c11.87-5.273 21.308-15.017 26.368-27.22l2.966-7.154c2.067-4.985 8.96-4.985 11.027 0l2.966 7.153c5.06 12.204 14.499 21.948 26.368 27.221l8.4 3.733c4.812 2.138 4.812 9.132 0 11.27l-8.898 3.953c-11.571 5.14-20.844 14.537-25.992 26.34"/>
        </svg>
    </div>`;
    
    // Markdown toggle - hidden when browsing but preserves space
    const mdClass = state.isMarkdown ? 'active' : '';
    const mdIcon = state.isMarkdown ? 'newsmode' : 'notes';
    buttons += `<div class="btn ${{mdClass}} ${{hideClass}}" onclick="action('${{hwnd}}', 'markdown')" title="${{window.L10N.markdown}}">
        ${{window.iconSvgs[mdIcon]}}
    </div>`;
    
    // Download - hidden when browsing but preserves space
    buttons += `<div class="btn ${{hideClass}}" onclick="action('${{hwnd}}', 'download')" title="${{window.L10N.download}}">
        ${{window.iconSvgs.download}}
    </div>`;
    
    // Speaker/TTS - hidden when browsing but preserves space
    const speakerIcon = state.ttsLoading ? 'hourglass_empty' : (state.ttsSpeaking ? 'stop' : 'volume_up');
    const speakerClass = state.ttsLoading ? 'loading' : (state.ttsSpeaking ? 'active' : '');
    buttons += `<div class="btn ${{speakerClass}} ${{hideClass}}" onclick="action('${{hwnd}}', 'speaker')" title="${{window.L10N.speaker}}">
        ${{window.iconSvgs[speakerIcon]}}
    </div>`;
    
    // Broom (close/drag) - always visible
    buttons += `<div class="btn broom"
        onmousedown="handleBroomDrag(event, '${{hwnd}}')"
        oncontextmenu="return false;"
        title="${{window.L10N.broom}}">
        ${{window.iconSvgs.cleaning_services}}
    </div>`;
    
    return buttons;
}}

// Handle broom drag
// Handle broom drag - NATIVE IMPLEMENTATION
function handleBroomDrag(e, hwnd) {{
    if (e.button !== 0 && e.button !== 1 && e.button !== 2) return; // Left, Middle, Right
    
    // 1. Hide the button group immediately (it will reappear after drag via updateWindows)
    const group = document.querySelector('.button-group[data-hwnd="' + hwnd + '"]');
    if (group) {{
        group.style.opacity = '0';
        group.style.pointerEvents = 'none';
        
        // Also update local state so it doesn't flicker back on if a cursor poll happens
        lastVisibleState.set(hwnd, false);
    }}

    // 2. Trigger native drag immediately
    let action = 'broom_drag_start';
    if (e.button === 1) action = 'broom_all_drag_start';
    else if (e.button === 2) action = 'broom_group_drag_start';

    window.ipc.postMessage(JSON.stringify({{
        action: action,
        hwnd: hwnd
    }}));
    
    // No need for mousemove logic/throttling anymore - the OS handles it!
}}

// Send action to Rust
function action(hwnd, cmd) {{
    // If it's a broom click and we just dragged, ignore it
    if (cmd === 'broom_click' && window.ignoreNextBroomClick) return;
    window.ipc.postMessage(JSON.stringify({{ action: cmd, hwnd: hwnd }}));
}}

// Update all button groups
function updateWindows(windowsData) {{
    window.registeredWindows = windowsData;
    
    const container = document.getElementById('button-container');
    const screenW = window.innerWidth;
    const screenH = window.innerHeight;
    
    // Diffing logic
    const existingGroups = new Map();
    container.querySelectorAll('.button-group').forEach(el => {{
        existingGroups.set(el.dataset.hwnd, el);
    }});
    
    for (const [hwnd, data] of Object.entries(windowsData)) {{
        // Pass 1: Estimate position
        let pos = calculateButtonPosition(data.rect);
        let group = existingGroups.get(hwnd);
        
        if (!group) {{
            group = document.createElement('div');
            group.className = 'button-group';
            group.style.opacity = '0'; // Start hidden
            group.dataset.hwnd = hwnd;
            container.appendChild(group);
        }} else {{
            existingGroups.delete(hwnd); // Mark as kept
        }}
        
        // Update content first to ensure correct dimensions for Pass 2
        const isVertical = pos.direction === 'left' || pos.direction === 'right';
        const newStateStr = JSON.stringify(data.state || {{}}) + isVertical;
        if (group.dataset.lastState !== newStateStr) {{
            group.innerHTML = generateButtonsHTML(hwnd, data.state || {{}}, isVertical);
            group.dataset.lastState = newStateStr;
        }}

        // Apply estimated class to get approximate dimensions
        if (isVertical) {{
            group.classList.add('vertical');
        }} else {{
            group.classList.remove('vertical');
        }}

        // Pass 2: Measure and Correct
        // Now that content and class are set, read actual dimensions
        const actualW = group.offsetWidth || (isVertical ? 50 : 400);
        const actualH = group.offsetHeight || (isVertical ? 400 : 50);

        // Re-clamp position based on actual dimensions
        let finalX = pos.x;
        let finalY = pos.y;

        if (pos.direction === 'bottom') {{
            // Right align relative to window
            finalX = data.rect.x + data.rect.w - actualW;
            finalY = data.rect.y + data.rect.h + 4; // margin 4
        }} else if (pos.direction === 'top') {{
            finalX = data.rect.x + (data.rect.w - actualW) / 2;
            finalY = data.rect.y - actualH - 4; // margin 4 (gap)
        }} else if (pos.direction === 'right') {{
            finalX = data.rect.x + data.rect.w + 4; // margin 4
            finalY = data.rect.y + (data.rect.h - actualH) / 2;
        }} else if (pos.direction === 'left') {{
            finalX = data.rect.x - actualW - 4; // margin 4
            finalY = data.rect.y + (data.rect.h - actualH) / 2;
        }} else {{ // inside
            finalX = data.rect.x + 8;
            finalY = data.rect.y + data.rect.h - actualH - 8;
             // Ensure it doesn't go off top if window is tiny
            finalY = Math.max(data.rect.y, finalY);
        }}

        // Helper to clamp
        const clamp = (val, size, max) => Math.max(0, Math.min(val, max - size));

        // Final screen clamping
        finalX = clamp(finalX, actualW, screenW);
        finalY = clamp(finalY, actualH, screenH);
        
        // CRITICAL: Do NOT update position if we are currently dragging this window!
        if (!broomDragData || broomDragData.hwnd !== hwnd) {{
            // Anchor to right if it's right-aligned to window
            if (pos.direction === 'bottom' || pos.direction === 'right') {{
                group.style.left = 'auto';
                group.style.right = (screenW - (finalX + actualW)) + 'px';
            }} else {{
                group.style.left = finalX + 'px';
                group.style.right = 'auto';
            }}

            // Anchor to bottom for vertical groups so expansion happens upwards
            if (isVertical) {{
                group.style.top = 'auto';
                group.style.bottom = (screenH - (finalY + actualH)) + 'px';
            }} else {{
                group.style.top = finalY + 'px';
                group.style.bottom = 'auto';
            }}
        }}
    }}
    
    // Remove stale
    existingGroups.forEach((el, key) => {{
        el.remove();
        lastVisibleState.delete(key);
    }});

    // CRITICAL: Update regions immediately so clicks work at new position
    updateButtonOpacity();
}}

// Expose to Rust
window.updateWindows = updateWindows;

function generateRefineInputHTML(hwnd, state) {{
    const micSvg = window.iconSvgs.mic;
    const sendSvg = window.iconSvgs.send;
    // We store the input value in a data attribute on the container if it exists, to preserve it on redraw
    // BUT since we redraw the whole HTML, we need a way to preserve text? 
    // Actually, updateWindows diffs and doesn't redraw if content same.
    // However, if we type, we don't trigger updateWindows.
    // Use an input ID unique to the hwnd
    
    // We need to ensure we don't blow away the input value when we re-render?
    // updateWindows checks: if (group.dataset.lastState !== newStateStr)
    // If state changes (e.g. typing doesn't change state), we don't redraw.
    // If external state changes (e.g. text update), we might redraw.
    // Currently, we don't send typing back to Rust until Submit.
    
    // Initial value? 
    // state.inputText is what we want to edit.
    // We should bind it.
    
    return `<div class="refine-bar">
        <input type="text" 
               id="input-${{hwnd}}" 
               class="refine-input" 
               placeholder="${{window.L10N.overlay_refine_placeholder || 'Refine...'}}" 
               value="${{state.inputText || ''}}"
               onkeydown="handleRefineKey(event, '${{hwnd}}')"
               oninput="handleInput(event, '${{hwnd}}')"
               onfocus="ensureNativeFocus('${{hwnd}}');"
               onclick="ensureNativeFocus('${{hwnd}}');"
               autofocus
               autocomplete="off">
        <div class="refine-action-btn" 
             onmousedown="event.preventDefault();"
             onclick="action('${{hwnd}}', 'mic')">
            ${{micSvg}}
        </div>
        <div class="refine-action-btn send" onclick="submitRefine('${{hwnd}}')">
            ${{sendSvg}}
        </div>
        <div class="btn" style="width:24px;height:24px;border:none;background:transparent;box-shadow:none;cursor:pointer;display:flex;align-items:center;justify-content:center;"
            onclick="action('${{hwnd}}', 'cancel_refine')"
            title="Cancel">
            <span style="font-size:14px;color:var(--refine-placeholder);pointer-events:none;">✕</span>
        </div>
    </div>`;
}}

// Preserve input focus and cursor position across updates
let focusedInput = null;
let selectionStart = 0;
let selectionEnd = 0;
let inputValues = new Map(); // hwnd -> current text

function ensureNativeFocus(hwnd) {{
    window.focus();
    window.ipc.postMessage(JSON.stringify({{ action: "request_focus", hwnd: hwnd }}));
}}

function handleInput(e, hwnd) {{
    ensureNativeFocus(hwnd);
    inputValues.set(hwnd, e.target.value);
}}

function handleRefineKey(e, hwnd) {{
    // Only request focus on keydown if not already focused? 
    // Actually safe to re-request to ensure we keep focus
    ensureNativeFocus(hwnd);
    if (e.key === 'Enter') {{
        e.preventDefault();
        submitRefine(hwnd);
    }} else if (e.key === 'Escape') {{
        e.preventDefault();
        action(hwnd, 'cancel_refine');
    }} else if (e.key === 'ArrowUp') {{
        e.preventDefault();
        const val = inputValues.get(hwnd) || '';
        window.ipc.postMessage(JSON.stringify({{ 
            action: 'history_up_refine', 
            hwnd: hwnd, 
            text: val 
        }}));
    }} else if (e.key === 'ArrowDown') {{
        e.preventDefault();
        const val = inputValues.get(hwnd) || '';
        window.ipc.postMessage(JSON.stringify({{ 
            action: 'history_down_refine', 
            hwnd: hwnd, 
            text: val 
        }}));
    }}
    
    // Track cursor
    focusedInput = e.target.id;
    selectionStart = e.target.selectionStart;
    selectionEnd = e.target.selectionEnd;
}}

function submitRefine(hwnd) {{
    const inputId = 'input-' + hwnd;
    const el = document.getElementById(inputId);
    const text = el ? el.value : (inputValues.get(hwnd) || '');
    if (text && text.trim().length > 0) {{
        window.ipc.postMessage(JSON.stringify({{
            action: 'submit_refine',
            hwnd: hwnd,
            text: text
        }}));
        // Clear value after submit
        inputValues.delete(hwnd);
    }}
}}

// Called from Rust to update refine text (e.g. history navigation)
// isInsert: 1 for insert at cursor, 0 for overwrite
window.setRefineText = (hwnd, text, isInsert) => {{
    const inputId = 'input-' + hwnd;
    const el = document.getElementById(inputId);
    if (el) {{
        if (isInsert) {{
            const start = el.selectionStart;
            const end = el.selectionEnd;
            const val = el.value;
            el.value = val.substring(0, start) + text + val.substring(end);
            el.selectionStart = el.selectionEnd = start + text.length;
        }} else {{
            el.value = text;
        }}
        inputValues.set(hwnd, el.value);
        el.focus();
    }}
}};

// Hook into updateWindows to restore focus
const originalUpdateWindows = window.updateWindows;
window.updateWindows = function(data) {{
    // Save focus state before update
    const activeEl = document.activeElement;
    if (activeEl && activeEl.tagName === 'INPUT') {{
        focusedInput = activeEl.id;
        selectionStart = activeEl.selectionStart;
        selectionEnd = activeEl.selectionEnd;
    }}
    
    originalUpdateWindows(data);
    
    // Restore focus OR focus newly opened edit bars
    let focusedFound = false;
    if (focusedInput) {{
        const el = document.getElementById(focusedInput);
        if (el) {{
            el.focus();
            focusedFound = true;
            // Restore text if we have it locally tracked (to prevent overwrite by stale state)
            const trackingHwnd = focusedInput.replace('input-', '');
            if (inputValues.has(trackingHwnd)) {{
                el.value = inputValues.get(trackingHwnd);
            }}
            
            try {{
                el.setSelectionRange(selectionStart, selectionEnd);
            }} catch(e) {{}}
        }}
    }}
    
    if (!focusedFound) {{
        // Find any visible edit bar and focus it
        const editBars = document.querySelectorAll('.refine-input');
        if (editBars.length > 0) {{
            editBars[0].focus();
        }}
    }}
}};
</script>
</body>
</html>"#,
        font_css = font_css
    )
    .replace("#L10N_JSON#", &l10n_json)
    .replace("#ICON_SVGS_JSON#", &icon_svgs_json)
}

/// Create the fullscreen transparent canvas window
fn create_canvas_window() {
    unsafe {
        // Initialize COM for WebView on this thread
        let _ = CoInitialize(None);

        let instance = GetModuleHandleW(None).unwrap_or_default();
        let class_name = w!("SGTButtonCanvas");

        REGISTER_CANVAS_CLASS.call_once(|| {
            let wc = WNDCLASSW {
                lpfnWndProc: Some(canvas_wnd_proc),
                hInstance: instance.into(),
                lpszClassName: class_name,
                hCursor: LoadCursorW(None, IDC_ARROW).unwrap_or_default(),
                hbrBackground: HBRUSH(std::ptr::null_mut()),
                ..Default::default()
            };
            RegisterClassW(&wc);
        });

        // Get screen dimensions
        let screen_w = GetSystemMetrics(SM_CXSCREEN);
        let screen_h = GetSystemMetrics(SM_CYSCREEN);

        // Create fullscreen transparent window
        // WS_EX_TOPMOST keeps it above result windows
        // WS_EX_TOOLWINDOW hides from taskbar
        // WS_EX_NOACTIVATE prevents focus stealing
        // WS_EX_TRANSPARENT removed to allow hit-testing (we handle passthrough via WM_NCHITTEST)
        // WS_EX_LAYERED removed - interfering with WebView2 creation when WS_EX_TRANSPARENT is missing?
        let hwnd = CreateWindowExW(
            WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_NOACTIVATE,
            class_name,
            w!("ButtonCanvas"),
            WS_POPUP | WS_CLIPCHILDREN,
            0,
            0,
            screen_w,
            screen_h - 1,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        if hwnd.is_invalid() {
            return;
        }

        CANVAS_HWND.store(hwnd.0 as isize, Ordering::SeqCst);

        // CRITICAL: DwmExtendFrameIntoClientArea with -1 margins enables
        // transparent background while keeping WebView content visible
        let margins = MARGINS {
            cxLeftWidth: -1,
            cxRightWidth: -1,
            cyTopHeight: -1,
            cyBottomHeight: -1,
        };
        let _ = DwmExtendFrameIntoClientArea(hwnd, &margins);

        // Initialize window region to empty (fully click-through)
        let empty_rgn = CreateRectRgn(0, 0, 0, 0);
        let _ = SetWindowRgn(hwnd, Some(empty_rgn), true);

        // Initialize WebContext
        CANVAS_WEB_CONTEXT.with(|ctx| {
            if ctx.borrow().is_none() {
                // Consolidate all minor overlays to 'common' to share one browser process and keep RAM at ~80MB
                let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));
                *ctx.borrow_mut() = Some(WebContext::new(Some(shared_data_dir)));
            }
        });

        let html = generate_canvas_html();
        let wrapper = HwndWrapper(hwnd);

        let webview = {
            // LOCK SCOPE: Only one WebView builds at a time to prevent "Not enough quota"
            let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();
            crate::log_info!("[ButtonCanvas] Acquired init lock. Building...");

            let build_res = CANVAS_WEB_CONTEXT.with(|ctx| {
                let mut ctx_ref = ctx.borrow_mut();
                let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                    WebViewBuilder::new_with_web_context(web_ctx)
                } else {
                    WebViewBuilder::new()
                };

                let builder =
                    crate::overlay::html_components::font_manager::configure_webview(builder);

                // Store HTML in font server
                let page_url =
                    crate::overlay::html_components::font_manager::store_html_page(html.clone())
                        .unwrap_or_else(|| {
                            format!("data:text/html,{}", urlencoding::encode(&html))
                        });

                builder
                    .with_bounds(Rect {
                        position: wry::dpi::Position::Logical(wry::dpi::LogicalPosition::new(
                            0.0, 0.0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            screen_w as u32,
                            (screen_h - 1) as u32,
                        )),
                    })
                    .with_transparent(true)
                    .with_visible(false)
                    .with_focused(false)
                    .with_url(&page_url)
                    .with_ipc_handler(move |msg: wry::http::Request<String>| {
                        handle_ipc_message(msg.body());
                    })
                    .build_as_child(&wrapper)
            });
            crate::log_info!(
                "[ButtonCanvas] Build finished. Releasing lock. Status: {}",
                if build_res.is_ok() { "OK" } else { "ERR" }
            );
            build_res
        };

        match webview {
            Ok(wv) => {
                crate::log_info!("[ButtonCanvas] WebView created successfully!");
                CANVAS_WEBVIEW.with(|cell| {
                    *cell.borrow_mut() = Some(wv);
                });
                IS_WARMED_UP.store(true, Ordering::SeqCst);
                crate::log_info!("[ButtonCanvas] Canvas is now warmed up and ready");
            }
            Err(e) => {
                crate::log_info!("[ButtonCanvas] Failed to create WebView: {:?}", e);
                // CRITICAL: Destroy the window so it doesn't block the screen invisibly
                crate::log_info!("[ButtonCanvas] Destroying canvas window due to WebView failure");
                let _ = DestroyWindow(hwnd);
                CANVAS_HWND.store(0, Ordering::SeqCst);
                CoUninitialize();
                return;
            }
        }

        // Message loop
        let mut msg = MSG::default();
        while GetMessageW(&mut msg, None, 0, 0).into() {
            let _ = TranslateMessage(&msg);
            DispatchMessageW(&msg);
        }

        // Cleanup
        IS_WARMED_UP.store(false, Ordering::SeqCst);
        IS_INITIALIZING.store(false, Ordering::SeqCst);
        CANVAS_HWND.store(0, Ordering::SeqCst);
        CANVAS_WEBVIEW.with(|cell| {
            *cell.borrow_mut() = None;
        });

        CoUninitialize();
    }
}

/// Handle IPC messages from the canvas WebView
fn handle_ipc_message(body: &str) {
    if let Ok(json) = serde_json::from_str::<serde_json::Value>(body) {
        let action = json.get("action").and_then(|v| v.as_str()).unwrap_or("");

        // Handle clickable regions update (global, not per-window)
        // Handle clickable regions update (global, not per-window)
        if action == "update_clickable_regions" {
            if let Some(regions) = json.get("regions").and_then(|v| v.as_array()) {
                let canvas_hwnd = HWND(CANVAS_HWND.load(Ordering::SeqCst) as *mut std::ffi::c_void);
                if canvas_hwnd.0.is_null() {
                    return;
                }

                // If currently dragging external window, IGNORE region updates
                // We want the window to remain unclipped (full screen) during drag for smoothness
                if IS_DRAGGING_EXTERNAL.load(Ordering::SeqCst) {
                    return;
                }

                unsafe {
                    let combined_rgn = CreateRectRgn(0, 0, 0, 0);

                    // JavaScript sends logical (CSS) coordinates, but SetWindowRgn expects physical
                    let scale = get_dpi_scale();

                    for r in regions {
                        // Parse logical coordinates from JavaScript
                        let logical_x = r.get("x").and_then(|v| v.as_f64()).unwrap_or(0.0);
                        let logical_y = r.get("y").and_then(|v| v.as_f64()).unwrap_or(0.0);
                        let logical_w = r.get("w").and_then(|v| v.as_f64()).unwrap_or(0.0);
                        let logical_h = r.get("h").and_then(|v| v.as_f64()).unwrap_or(0.0);

                        // Scale to physical coordinates
                        let x = (logical_x * scale) as i32;
                        let y = (logical_y * scale) as i32;
                        let w = (logical_w * scale) as i32;
                        let h = (logical_h * scale) as i32;

                        let rgn = CreateRectRgn(x, y, x + w, y + h);
                        let _ =
                            CombineRgn(Some(combined_rgn), Some(combined_rgn), Some(rgn), RGN_OR);
                        let _ = DeleteObject(rgn.into()); // Delete localized region after combining
                    }

                    // Apply the region to the window
                    // System owns combined_rgn after this call
                    let _ = SetWindowRgn(canvas_hwnd, Some(combined_rgn), true);
                }
            }
            return;
        }

        let hwnd_str = json.get("hwnd").and_then(|v| v.as_str()).unwrap_or("0");
        let hwnd_val: isize = hwnd_str.parse().unwrap_or(0);

        if hwnd_val == 0 {
            return;
        }

        let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);

        // Ensure canvas window is foreground for keyboard focus (Ctrl+A etc) - REMOVED to prevent focus stealing from games
        // Only specific actions like 'edit' might need focus, handled locally in their logic if needed.

        match action {
            "copy" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_COPY_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "undo" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_UNDO_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "redo" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_REDO_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "edit" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_EDIT_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "markdown" => {
                crate::overlay::result::trigger_markdown_toggle(hwnd);
            }
            "download" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_DOWNLOAD_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "back" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_BACK_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "forward" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_FORWARD_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "speaker" => unsafe {
                let _ = PostMessageW(
                    Some(hwnd),
                    super::event_handler::misc::WM_SPEAKER_CLICK,
                    WPARAM(0),
                    LPARAM(0),
                );
            },
            "broom_click" => {
                // Close window
                unsafe {
                    let _ = PostMessageW(Some(hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                }
            }
            "broom_right" => {
                // Right-click: close linked windows (via group)
                let group = crate::overlay::result::state::get_window_group(hwnd);
                for (h, _) in group {
                    unsafe {
                        let _ = PostMessageW(Some(h), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                }
            }
            "broom_middle" => {
                // Middle-click = close all
                crate::overlay::result::trigger_close_all();
            }
            "broom_drag_start" => {
                // Initiate manual Rust-side drag (more robust than system drag)
                unsafe {
                    use windows::Win32::UI::Input::KeyboardAndMouse::SetCapture;
                    use windows::Win32::UI::WindowsAndMessaging::GetCursorPos;

                    let mut pt = windows::Win32::Foundation::POINT::default();
                    if GetCursorPos(&mut pt).is_ok() {
                        use std::sync::atomic::Ordering;
                        ACTIVE_DRAG_TARGET.store(hwnd.0 as isize, Ordering::SeqCst);
                        DRAG_IS_GROUP.store(false, Ordering::SeqCst);

                        let mut last = LAST_DRAG_POS.lock().unwrap();
                        last.x = pt.x;
                        last.y = pt.y;

                        let mut start = START_DRAG_POS.lock().unwrap();
                        start.x = pt.x;
                        start.y = pt.y;

                        let canvas_val = CANVAS_HWND.load(Ordering::SeqCst);
                        if canvas_val != 0 {
                            let canvas_hwnd = HWND(canvas_val as *mut std::ffi::c_void);
                            let _ = SetCapture(canvas_hwnd);
                            // Hide all buttons immediately
                            update_canvas();
                        }
                    }
                }
            }
            "broom_group_drag_start" => {
                // Initiate mass drag for linked windows (Right-click drag)
                unsafe {
                    use windows::Win32::UI::Input::KeyboardAndMouse::SetCapture;
                    use windows::Win32::UI::WindowsAndMessaging::GetCursorPos;

                    let mut pt = windows::Win32::Foundation::POINT::default();
                    if GetCursorPos(&mut pt).is_ok() {
                        use std::sync::atomic::Ordering;
                        ACTIVE_DRAG_TARGET.store(hwnd.0 as isize, Ordering::SeqCst);
                        DRAG_IS_GROUP.store(true, Ordering::SeqCst);

                        // Collect the entire group once at start
                        let group = crate::overlay::result::state::get_window_group(hwnd);
                        let mut snapshot = ACTIVE_DRAG_SNAPSHOT.lock().unwrap();
                        *snapshot = group.into_iter().map(|(h, _)| h.0 as isize).collect();

                        let mut last = LAST_DRAG_POS.lock().unwrap();
                        last.x = pt.x;
                        last.y = pt.y;

                        let mut start = START_DRAG_POS.lock().unwrap();
                        start.x = pt.x;
                        start.y = pt.y;

                        let canvas_val = CANVAS_HWND.load(Ordering::SeqCst);
                        if canvas_val != 0 {
                            let canvas_hwnd = HWND(canvas_val as *mut std::ffi::c_void);
                            let _ = SetCapture(canvas_hwnd);
                            // Hide all buttons immediately
                            update_canvas();
                        }
                    }
                }
            }
            "broom_all_drag_start" => {
                // Initiate mass drag for ALL windows (Middle-click drag)
                unsafe {
                    use windows::Win32::UI::Input::KeyboardAndMouse::SetCapture;
                    use windows::Win32::UI::WindowsAndMessaging::GetCursorPos;

                    let mut pt = windows::Win32::Foundation::POINT::default();
                    if GetCursorPos(&mut pt).is_ok() {
                        use std::sync::atomic::Ordering;
                        ACTIVE_DRAG_TARGET.store(hwnd.0 as isize, Ordering::SeqCst);
                        DRAG_IS_GROUP.store(true, Ordering::SeqCst);

                        // Collect ALL registered markdown windows
                        let windows = MARKDOWN_WINDOWS.lock().unwrap();
                        let mut snapshot = ACTIVE_DRAG_SNAPSHOT.lock().unwrap();
                        *snapshot = windows.keys().cloned().collect();

                        let mut last = LAST_DRAG_POS.lock().unwrap();
                        last.x = pt.x;
                        last.y = pt.y;

                        let mut start = START_DRAG_POS.lock().unwrap();
                        start.x = pt.x;
                        start.y = pt.y;

                        let canvas_val = CANVAS_HWND.load(Ordering::SeqCst);
                        if canvas_val != 0 {
                            let canvas_hwnd = HWND(canvas_val as *mut std::ffi::c_void);
                            let _ = SetCapture(canvas_hwnd);
                            // Hide all buttons immediately
                            update_canvas();
                        }
                    }
                }
            }
            "set_opacity" => {
                if let Some(value) = json.get("value").and_then(|v| v.as_f64()) {
                    let percent = value as u8;
                    let alpha = ((value / 100.0) * 255.0) as u8;

                    // Update state so it persists across button canvas refreshes
                    {
                        let mut states = WINDOW_STATES.lock().unwrap();
                        if let Some(state) = states.get_mut(&(hwnd.0 as isize)) {
                            state.opacity_percent = percent;
                        }
                    }

                    unsafe {
                        use windows::Win32::UI::WindowsAndMessaging::{
                            SetLayeredWindowAttributes, LWA_ALPHA,
                        };
                        let _ = SetLayeredWindowAttributes(
                            hwnd,
                            windows::Win32::Foundation::COLORREF(0),
                            alpha,
                            LWA_ALPHA,
                        );
                    }
                }
            }
            "request_update" => {
                update_canvas();
            }
            "broom_drag" => {
                // Legacy JS-driven drag (unused now but kept for compatibility)
                let scale = get_dpi_scale();
                let dx =
                    (json.get("dx").and_then(|v| v.as_f64()).unwrap_or(0.0) * scale).round() as i32;
                let dy =
                    (json.get("dy").and_then(|v| v.as_f64()).unwrap_or(0.0) * scale).round() as i32;
                crate::overlay::result::trigger_drag_window(hwnd, dx, dy);
            }
            "submit_refine" => {
                let text = json.get("text").and_then(|v| v.as_str()).unwrap_or("");
                crate::overlay::result::trigger_refine_submit(hwnd, text);
            }
            "cancel_refine" => {
                crate::overlay::result::trigger_refine_cancel(hwnd);
            }
            "history_up_refine" => {
                let current = json.get("text").and_then(|v| v.as_str()).unwrap_or("");
                if let Some(text) = crate::overlay::input_history::navigate_history_up(current) {
                    // Send back to JS
                    send_refine_text_update(hwnd, &text, false);
                }
            }
            "history_down_refine" => {
                let current = json.get("text").and_then(|v| v.as_str()).unwrap_or("");
                if let Some(text) = crate::overlay::input_history::navigate_history_down(current) {
                    send_refine_text_update(hwnd, &text, false);
                }
            }
            "mic" => {
                // Trigger transcription preset
                let transcribe_idx = {
                    let app = crate::APP.lock().unwrap();
                    app.config
                        .presets
                        .iter()
                        .position(|p| p.id == "preset_transcribe")
                };

                if let Some(preset_idx) = transcribe_idx {
                    std::thread::spawn(move || {
                        crate::overlay::recording::show_recording_overlay(preset_idx);
                    });
                }
            }
            "request_focus" => unsafe {
                let canvas_val = CANVAS_HWND.load(Ordering::SeqCst);
                if canvas_val != 0 {
                    let canvas_hwnd = HWND(canvas_val as *mut _);
                    let _ = SetForegroundWindow(canvas_hwnd);
                }
            },
            _ => {}
        }
    }
}

/// Send updated window data to the canvas
fn send_windows_update() {
    // Check if theme has changed and inject new CSS if needed
    let is_dark = crate::overlay::is_dark_mode();
    let last_dark = LAST_THEME_IS_DARK.load(Ordering::SeqCst);
    if is_dark != last_dark {
        let new_css = get_canvas_theme_css(is_dark);
        // Escape content safely for JS string
        let content_escaped = new_css.replace('`', "\\`").replace('\\', "\\\\");
        let script = format!(
            "var s = document.getElementById('theme-css'); if(s) s.innerHTML = `{}`;",
            content_escaped
        );
        CANVAS_WEBVIEW.with(|cell| {
            if let Some(webview) = cell.borrow().as_ref() {
                let _ = webview.evaluate_script(&script);
            }
        });
        LAST_THEME_IS_DARK.store(is_dark, Ordering::SeqCst);
    }

    let windows_data = {
        let states = WINDOW_STATES.lock().unwrap();
        let windows = MARKDOWN_WINDOWS.lock().unwrap();

        let mut data = serde_json::Map::new();

        // Check for any active native interaction (Resizing/Moving)
        let any_interacting = states.values().any(|s| {
            matches!(
                s.interaction_mode,
                super::state::InteractionMode::Resizing(_)
                    | super::state::InteractionMode::ResizingGroup(_, _)
                    | super::state::InteractionMode::DraggingWindow
                    | super::state::InteractionMode::DraggingGroup(_)
            )
        });

        // If ANY drag (custom or native) or resize is active, hide ALL buttons
        let dragging_target = ACTIVE_DRAG_TARGET.load(std::sync::atomic::Ordering::SeqCst);
        if dragging_target != 0 || any_interacting {
            // Send empty data -> Hides all
            let json = serde_json::to_string(&data).unwrap_or_default();
            CANVAS_WEBVIEW.with(|cell| {
                if let Some(webview) = cell.borrow().as_ref() {
                    let script = format!("window.updateWindows({});", json);
                    let _ = webview.evaluate_script(&script);
                }
            });
            return;
        }

        for (&hwnd_key, &(x, y, w, h)) in windows.iter() {
            let state = states.get(&hwnd_key);

            let state_obj = serde_json::json!({
                "copySuccess": state.map(|s| s.copy_success).unwrap_or(false),
                "hasUndo": state.map(|s| !s.text_history.is_empty()).unwrap_or(false),
                "hasRedo": state.map(|s| !s.redo_history.is_empty()).unwrap_or(false),
                "navDepth": state.map(|s| s.navigation_depth).unwrap_or(0),
                "maxNavDepth": state.map(|s| s.max_navigation_depth).unwrap_or(0),
                "ttsLoading": state.map(|s| s.tts_loading).unwrap_or(false),
                "ttsSpeaking": state.map(|s| s.tts_request_id != 0 && !s.tts_loading).unwrap_or(false),
                "isMarkdown": state.map(|s| s.is_markdown_mode).unwrap_or(false),
                "isBrowsing": state.map(|s| s.is_browsing).unwrap_or(false),
                "isEditing": state.map(|s| s.is_editing).unwrap_or(false),
                "inputText": state.map(|s| s.input_text.clone()).unwrap_or_default(),
                "opacityPercent": state.map(|s| s.opacity_percent).unwrap_or(100),
            });

            // Scale physical coordinates to logical coordinates for WebView
            let scale = get_dpi_scale();
            let logical_x = (x as f64 / scale) as i32;
            let logical_y = (y as f64 / scale) as i32;
            let logical_w = (w as f64 / scale) as i32;
            let logical_h = (h as f64 / scale) as i32;

            data.insert(
                hwnd_key.to_string(),
                serde_json::json!({
                    "rect": { "x": logical_x, "y": logical_y, "w": logical_w, "h": logical_h },
                    "state": state_obj
                }),
            );
        }

        serde_json::Value::Object(data)
    };

    CANVAS_WEBVIEW.with(|cell| {
        if let Some(webview) = cell.borrow().as_ref() {
            let script = format!("window.updateWindows({});", windows_data);
            let _ = webview.evaluate_script(&script);
        }
    });
}

// Global state for manual Rust-side dragging
static ACTIVE_DRAG_TARGET: std::sync::atomic::AtomicIsize = std::sync::atomic::AtomicIsize::new(0);
static DRAG_IS_GROUP: std::sync::atomic::AtomicBool = std::sync::atomic::AtomicBool::new(false);
static ACTIVE_DRAG_SNAPSHOT: std::sync::Mutex<Vec<isize>> = std::sync::Mutex::new(Vec::new());
static LAST_DRAG_POS: std::sync::Mutex<POINT> = std::sync::Mutex::new(POINT { x: 0, y: 0 });
static START_DRAG_POS: std::sync::Mutex<POINT> = std::sync::Mutex::new(POINT { x: 0, y: 0 });

unsafe extern "system" fn canvas_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_UPDATE_WINDOWS => {
            let _ = SetWindowPos(
                hwnd,
                Some(HWND_TOPMOST),
                0,
                0,
                0,
                0,
                SWP_NOMOVE | SWP_NOSIZE | SWP_NOACTIVATE,
            );
            send_windows_update();
            LRESULT(0)
        }

        WM_APP_SHOW_CANVAS => {
            unsafe {
                use windows::Win32::UI::WindowsAndMessaging::{
                    GetForegroundWindow, IsWindow, SetForegroundWindow,
                };
                // 1. Capture current focus BEFORE showing our window
                let foreground = GetForegroundWindow();

                // 2. Show the window (SW_SHOWNOACTIVATE should prevent focus stealing, but doesn't always work with WebView)
                let _ = ShowWindow(hwnd, SW_SHOWNOACTIVATE);
                let _ = SetWindowPos(
                    hwnd,
                    Some(HWND_TOPMOST),
                    0,
                    0,
                    0,
                    0,
                    SWP_NOMOVE | SWP_NOSIZE | SWP_NOACTIVATE,
                );

                // 3. Show WebView (deferred visibility)
                CANVAS_WEBVIEW.with(|cell| {
                    if let Some(webview) = cell.borrow().as_ref() {
                        let _ = webview.set_visible(true);
                    }
                });

                // 4. Force restore focus if it was stolen
                if !foreground.0.is_null() && IsWindow(Some(foreground)).as_bool() {
                    let _ = SetForegroundWindow(foreground);
                }
            }

            let _ = SetTimer(Some(hwnd), CURSOR_POLL_TIMER_ID, 100, None);
            LRESULT(0)
        }

        WM_APP_HIDE_CANVAS => {
            CANVAS_WEBVIEW.with(|cell| {
                if let Some(webview) = cell.borrow().as_ref() {
                    let _ = webview.set_visible(false);
                }
            });
            let _ = ShowWindow(hwnd, SW_HIDE);
            let _ = KillTimer(Some(hwnd), CURSOR_POLL_TIMER_ID);
            LRESULT(0)
        }

        WM_APP_SEND_REFINE_TEXT => {
            let hwnd_key = wparam.0 as isize;
            let text = {
                let mut updates = PENDING_REFINE_UPDATES.lock().unwrap();
                updates.remove(&hwnd_key)
            };

            if let Some(text) = text {
                let escaped = text
                    .replace('\\', "\\\\")
                    .replace('`', "\\`")
                    .replace("${", "\\${")
                    .replace('\r', "");

                let is_insert = lparam.0 != 0;
                let script = format!(
                    "if(window.setRefineText) window.setRefineText('{}', `{}`, {});",
                    hwnd_key,
                    escaped,
                    if is_insert { "true" } else { "false" }
                );

                CANVAS_WEBVIEW.with(|cell| {
                    if let Some(webview) = cell.borrow().as_ref() {
                        let _ = webview.evaluate_script(&script);
                    }
                });
            }
            LRESULT(0)
        }

        windows::Win32::UI::WindowsAndMessaging::WM_MOUSEACTIVATE => {
            LRESULT(windows::Win32::UI::WindowsAndMessaging::MA_NOACTIVATE as isize)
        }

        windows::Win32::UI::WindowsAndMessaging::WM_MOUSEMOVE => {
            let target_val = ACTIVE_DRAG_TARGET.load(Ordering::SeqCst);
            if target_val != 0 {
                // Get current cursor pos
                let mut pt = POINT::default();
                if GetCursorPos(&mut pt).is_ok() {
                    let mut last = LAST_DRAG_POS.lock().unwrap();
                    let dx = pt.x - last.x;
                    let dy = pt.y - last.y;

                    if dx != 0 || dy != 0 {
                        if DRAG_IS_GROUP.load(Ordering::SeqCst) {
                            let snapshot = ACTIVE_DRAG_SNAPSHOT.lock().unwrap();
                            let mut updates = Vec::with_capacity(snapshot.len());

                            unsafe {
                                use windows::Win32::UI::WindowsAndMessaging::*;
                                if let Ok(mut hdwp) = BeginDeferWindowPos(snapshot.len() as i32) {
                                    for &h_val in snapshot.iter() {
                                        let h = HWND(h_val as *mut std::ffi::c_void);
                                        let mut r = RECT::default();
                                        if GetWindowRect(h, &mut r).is_ok() {
                                            let (nx, ny) = (r.left + dx, r.top + dy);
                                            let (nw, nh) = (r.right - r.left, r.bottom - r.top);

                                            hdwp = DeferWindowPos(
                                                hdwp,
                                                h,
                                                None,
                                                nx,
                                                ny,
                                                0,
                                                0,
                                                SWP_NOSIZE | SWP_NOZORDER | SWP_NOACTIVATE,
                                            )
                                            .unwrap_or(hdwp);
                                            updates.push((h_val, (nx, ny, nw, nh)));
                                        }
                                    }
                                    let _ = EndDeferWindowPos(hdwp);
                                }
                            }
                            update_canvas();

                            // Batch update internal registry without extra GetWindowRect calls or lock flapping
                            if !updates.is_empty() {
                                let mut windows = MARKDOWN_WINDOWS.lock().unwrap();
                                for (key, rect) in updates {
                                    if windows.contains_key(&key) {
                                        windows.insert(key, rect);
                                    }
                                }
                            }
                        } else {
                            let target_hwnd = HWND(target_val as *mut std::ffi::c_void);
                            crate::overlay::result::trigger_drag_window(target_hwnd, dx, dy);
                        }

                        // Update last pos
                        last.x = pt.x;
                        last.y = pt.y;
                    }
                }
                return LRESULT(0);
            }
            DefWindowProcW(hwnd, msg, wparam, lparam)
        }

        windows::Win32::UI::WindowsAndMessaging::WM_LBUTTONUP
        | windows::Win32::UI::WindowsAndMessaging::WM_RBUTTONUP
        | windows::Win32::UI::WindowsAndMessaging::WM_MBUTTONUP => {
            let target_val = ACTIVE_DRAG_TARGET.load(Ordering::SeqCst);
            if target_val != 0 {
                use windows::Win32::UI::Input::KeyboardAndMouse::ReleaseCapture;
                // End drag
                ACTIVE_DRAG_TARGET.store(0, Ordering::SeqCst);
                DRAG_IS_GROUP.store(false, Ordering::SeqCst);
                let _ = ReleaseCapture();
                update_canvas(); // Restore buttons after drag

                // Click vs Drag Check
                let mut pt = POINT::default();
                let _ = GetCursorPos(&mut pt);

                let start = START_DRAG_POS.lock().unwrap();
                let dist_sq = ((pt.x - start.x).pow(2) + (pt.y - start.y).pow(2)) as f64;

                if dist_sq.sqrt() < 5.0 {
                    // Treating as CLICK
                    let is_right_click =
                        msg == windows::Win32::UI::WindowsAndMessaging::WM_RBUTTONUP;
                    let is_middle_click =
                        msg == windows::Win32::UI::WindowsAndMessaging::WM_MBUTTONUP;
                    let target_hwnd = HWND(target_val as *mut std::ffi::c_void);

                    if is_right_click {
                        // Right-click: Close linked windows
                        let group = crate::overlay::result::state::get_window_group(target_hwnd);
                        for (h, _) in group {
                            let _ = PostMessageW(Some(h), WM_CLOSE, WPARAM(0), LPARAM(0));
                        }
                    } else if is_middle_click {
                        // Middle-click: Close all
                        crate::overlay::result::trigger_close_all();
                    } else {
                        // Left-click: Close single
                        let _ = PostMessageW(Some(target_hwnd), WM_CLOSE, WPARAM(0), LPARAM(0));
                    }
                }

                // Force Immediate Cursor Update to JS (so buttons reappear correctly under mouse)
                let scale = get_dpi_scale();
                let logical_x = (pt.x as f64 / scale) as i32;
                let logical_y = (pt.y as f64 / scale) as i32;
                CANVAS_WEBVIEW.with(|cell| {
                    if let Some(webview) = cell.borrow().as_ref() {
                        let script =
                            format!("window.updateCursorPosition({}, {});", logical_x, logical_y);
                        let _ = webview.evaluate_script(&script);
                    }
                });

                // Final update to sync everything (and show buttons again)
                send_windows_update();

                return LRESULT(0);
            }
            DefWindowProcW(hwnd, msg, wparam, lparam)
        }

        WM_TIMER => {
            if wparam.0 == CURSOR_POLL_TIMER_ID {
                // Skip polling if we are dragging (to keep buttons hidden)
                if ACTIVE_DRAG_TARGET.load(Ordering::SeqCst) == 0 {
                    let mut pt = POINT::default();
                    if GetCursorPos(&mut pt).is_ok() {
                        let scale = get_dpi_scale();
                        let logical_x = (pt.x as f64 / scale) as i32;
                        let logical_y = (pt.y as f64 / scale) as i32;

                        CANVAS_WEBVIEW.with(|cell| {
                            if let Some(webview) = cell.borrow().as_ref() {
                                let script = format!(
                                    "window.updateCursorPosition({}, {});",
                                    logical_x, logical_y
                                );
                                let _ = webview.evaluate_script(&script);
                            }
                        });
                    }
                }
            }
            LRESULT(0)
        }

        WM_DISPLAYCHANGE => {
            let screen_w = GetSystemMetrics(SM_CXSCREEN);
            let screen_h = GetSystemMetrics(SM_CYSCREEN);
            let _ = SetWindowPos(
                hwnd,
                None,
                0,
                0,
                screen_w,
                screen_h - 1,
                SWP_NOZORDER | SWP_NOACTIVATE,
            );
            CANVAS_WEBVIEW.with(|cell| {
                if let Some(webview) = cell.borrow().as_ref() {
                    let _ = webview.set_bounds(Rect {
                        position: wry::dpi::Position::Logical(wry::dpi::LogicalPosition::new(
                            0.0, 0.0,
                        )),
                        size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(
                            screen_w as u32,
                            screen_h as u32,
                        )),
                    });
                }
            });
            LRESULT(0)
        }

        WM_CLOSE => {
            let _ = ShowWindow(hwnd, SW_HIDE);
            LRESULT(0)
        }

        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}
</file>

<file path="src/overlay/text_selection.rs">
use crate::APP;
use std::sync::{
    atomic::{AtomicBool, AtomicIsize, Ordering},
    Arc, Mutex, Once,
};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::System::DataExchange::*;
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::System::Memory::*;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;

// Shared wrapper for WebView parent
use crate::overlay::realtime_webview::state::HwndWrapper;

// --- SHARED STATE ---
struct TextSelectionState {
    preset_idx: usize,
    is_selecting: bool,
    is_processing: bool,
    hook_handle: HHOOK,
    webview: Option<wry::WebView>,
}
unsafe impl Send for TextSelectionState {}

static SELECTION_STATE: Mutex<TextSelectionState> = Mutex::new(TextSelectionState {
    preset_idx: 0,
    is_selecting: false,
    is_processing: false,
    hook_handle: HHOOK(std::ptr::null_mut()),
    webview: None,
});

static REGISTER_TAG_CLASS: Once = Once::new();

lazy_static::lazy_static! {
    pub static ref TAG_ABORT_SIGNAL: Arc<AtomicBool> = Arc::new(AtomicBool::new(false));
    pub static ref INITIAL_TEXT_GLOBAL: Mutex<String> = Mutex::new(String::from("Select text..."));
}

thread_local! {
    static SELECTION_WEB_CONTEXT: std::cell::RefCell<Option<wry::WebContext>> = std::cell::RefCell::new(None);
}

// Warmup / Persistence Globals
static TAG_HWND: AtomicIsize = AtomicIsize::new(0);
static IS_WARMING_UP: AtomicBool = AtomicBool::new(false);
static IS_WARMED_UP: AtomicBool = AtomicBool::new(false);

// CONTINUOUS MODE HOTKEY TRACKING
static mut TRIGGER_VK_CODE: u32 = 0;
static mut TRIGGER_MODIFIERS: u32 = 0;
static IS_HOTKEY_HELD: AtomicBool = AtomicBool::new(false);
static CONTINUOUS_ACTIVATED_THIS_SESSION: AtomicBool = AtomicBool::new(false);
static HOLD_DETECTED_THIS_SESSION: AtomicBool = AtomicBool::new(false);

// DEDUPLICATION: Track last processed text to prevent reprocessing same content

// DEDUPLICATION: Timestamp of last instant process to debounce rapid calls
static LAST_INSTANT_PROCESS_TIME: std::sync::atomic::AtomicU64 =
    std::sync::atomic::AtomicU64::new(0);
// DRAG DETECTION: Mouse start position when selection begins
static MOUSE_START_X: std::sync::atomic::AtomicI32 = std::sync::atomic::AtomicI32::new(0);
static MOUSE_START_Y: std::sync::atomic::AtomicI32 = std::sync::atomic::AtomicI32::new(0);
static PENDING_SHOW_ON_WARMUP: AtomicBool = AtomicBool::new(false);

// Messages
const WM_APP_SHOW: u32 = WM_USER + 200;
const WM_APP_HIDE: u32 = WM_USER + 201;

// --- PUBLIC API ---

pub fn is_active() -> bool {
    let hwnd_val = TAG_HWND.load(Ordering::SeqCst);
    if hwnd_val == 0 {
        return false;
    }
    unsafe { IsWindowVisible(HWND(hwnd_val as *mut std::ffi::c_void)).as_bool() }
}

pub fn is_processing() -> bool {
    let state = SELECTION_STATE.lock().unwrap();
    state.is_processing
}

struct ProcessingGuard;

impl Drop for ProcessingGuard {
    fn drop(&mut self) {
        let mut state = SELECTION_STATE.lock().unwrap();
        state.is_processing = false;
    }
}

/// Try to process already-selected text instantly.
pub fn try_instant_process(preset_idx: usize) -> bool {
    // TIME-BASED DEBOUNCE: If we processed via instant process recently, skip
    // This prevents multiple processes when holding hotkey on preselected text
    let now = std::time::SystemTime::now()
        .duration_since(std::time::UNIX_EPOCH)
        .unwrap_or_default()
        .as_millis() as u64;
    let last_time = LAST_INSTANT_PROCESS_TIME.load(Ordering::SeqCst);
    if last_time > 0 && now - last_time < 2000 {
        return false; // Processed within last 2 seconds, skip
    }

    // Set processing flag early to block other threads
    // The guard will reset it to false when this function returns
    let _guard = {
        let mut state = SELECTION_STATE.lock().unwrap();
        if state.is_processing {
            return false;
        }
        state.is_processing = true;
        ProcessingGuard
    };

    // Update timestamp now that we're committed to processing
    LAST_INSTANT_PROCESS_TIME.store(now, Ordering::SeqCst);

    unsafe {
        // Step 1: Save clipboard
        let original_clipboard = get_clipboard_text();

        // Step 2: Clear & Copy
        if OpenClipboard(Some(HWND::default())).is_ok() {
            let _ = EmptyClipboard();
            let _ = CloseClipboard();
        }
        std::thread::sleep(std::time::Duration::from_millis(30));

        let send_input_event = |vk: u16, flags: KEYBD_EVENT_FLAGS| {
            let input = INPUT {
                r#type: INPUT_KEYBOARD,
                Anonymous: INPUT_0 {
                    ki: KEYBDINPUT {
                        wVk: VIRTUAL_KEY(vk),
                        dwFlags: flags,
                        time: 0,
                        dwExtraInfo: 0,
                        wScan: 0,
                    },
                },
            };
            SendInput(&[input], std::mem::size_of::<INPUT>() as i32);
        };

        send_input_event(VK_CONTROL.0, KEYBD_EVENT_FLAGS(0));
        std::thread::sleep(std::time::Duration::from_millis(15));
        send_input_event(0x43, KEYBD_EVENT_FLAGS(0)); // 'C'
        std::thread::sleep(std::time::Duration::from_millis(15));
        send_input_event(0x43, KEYEVENTF_KEYUP);
        std::thread::sleep(std::time::Duration::from_millis(15));
        send_input_event(VK_CONTROL.0, KEYEVENTF_KEYUP);

        // Step 3: Wait & Check
        let mut clipboard_text = String::new();
        for _ in 0..6 {
            std::thread::sleep(std::time::Duration::from_millis(20));
            clipboard_text = get_clipboard_text();
            if !clipboard_text.is_empty() {
                break;
            }
        }

        if clipboard_text.trim().is_empty() {
            if !original_clipboard.is_empty() {
                crate::overlay::utils::copy_to_clipboard(&original_clipboard, HWND::default());
            }
            return false;
        }

        // HIDE BADGE BEFORE PROCESSING (Critical for Master Wheel appearance)
        cancel_selection();

        // CONTINUOUS MODE SUPPORT for instant process
        // Check if user is holding the hotkey for continuous mode
        let mut final_preset_idx = preset_idx;
        if !crate::overlay::continuous_mode::is_active() {
            // Check if hotkey is being held
            let held = crate::overlay::continuous_mode::was_triggered_recently(1500);
            if held {
                let persistent_name = crate::overlay::continuous_mode::get_hotkey_name();
                let latest_name = crate::overlay::continuous_mode::get_latest_hotkey_name();
                crate::log_info!(
                    "[TextSelection] Hotkey Resolution - Persistent: '{}', Latest: '{}'",
                    persistent_name,
                    latest_name
                );

                let mut hotkey_name = persistent_name;
                if hotkey_name.is_empty() {
                    hotkey_name = latest_name;
                }
                if hotkey_name.is_empty() {
                    hotkey_name = "Hotkey".to_string();
                }
                let preset_name = {
                    if let Ok(app) = APP.lock() {
                        app.config
                            .presets
                            .get(preset_idx)
                            .map(|p| p.id.clone())
                            .unwrap_or_default()
                    } else {
                        "Preset".to_string()
                    }
                };

                // Disable continuous mode for Master Preset
                if preset_name != "preset_text_select_master" {
                    crate::overlay::continuous_mode::activate(preset_idx, hotkey_name.clone());
                    crate::overlay::continuous_mode::show_activation_notification(
                        &preset_name,
                        &hotkey_name,
                    );
                }
            }
        }

        // Continuous mode retrigger (immediately, before processing)
        if crate::overlay::continuous_mode::is_active() {
            let current_idx = crate::overlay::continuous_mode::get_preset_idx();
            if current_idx == preset_idx {
                final_preset_idx = current_idx;
                std::thread::spawn(move || {
                    std::thread::sleep(std::time::Duration::from_millis(150));
                    if crate::overlay::continuous_mode::is_active() {
                        let _ = show_text_selection_tag(current_idx);
                    }
                });
            }
        }

        process_selected_text(final_preset_idx, clipboard_text);
        true
    }
}

pub fn cancel_selection() {
    TAG_ABORT_SIGNAL.store(true, Ordering::SeqCst);
    let hwnd_val = TAG_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        unsafe {
            // Just hide it, don't destroy
            let _ = PostMessageW(
                Some(HWND(hwnd_val as *mut std::ffi::c_void)),
                WM_APP_HIDE,
                WPARAM(0),
                LPARAM(0),
            );
        }
    }
}

pub fn warmup() {
    if IS_WARMED_UP.load(Ordering::SeqCst) {
        return;
    }
    if IS_WARMING_UP
        .compare_exchange(false, true, Ordering::SeqCst, Ordering::SeqCst)
        .is_err()
    {
        return;
    }

    std::thread::spawn(|| {
        internal_create_tag_thread();
    });
}

// Positioning constants
pub fn is_warming_up() -> bool {
    IS_WARMING_UP.load(Ordering::SeqCst)
}

const OFFSET_X: i32 = -20;
const OFFSET_Y: i32 = -90;

pub fn show_text_selection_tag(preset_idx: usize) {
    // 1. Ensure Warmed Up / Trigger Warmup
    if !IS_WARMED_UP.load(Ordering::SeqCst) {
        PENDING_SHOW_ON_WARMUP.store(true, Ordering::SeqCst);
        warmup();
        // Fall through - we prepare the state below, and the warmup thread
        // will pick up the need to show once it's ready.
    }

    // 2. Prepare State
    {
        let mut state = SELECTION_STATE.lock().unwrap();
        state.preset_idx = preset_idx;
        state.is_selecting = false;
        state.is_processing = false;
        TAG_ABORT_SIGNAL.store(false, Ordering::SeqCst);

        // Initialize Hotkey Tracking
        // Only reset session flags if NOT already in continuous mode
        // (to prevent multiple notifications on hotkey repeats)
        if !crate::overlay::continuous_mode::is_active() {
            CONTINUOUS_ACTIVATED_THIS_SESSION.store(false, Ordering::SeqCst);
            HOLD_DETECTED_THIS_SESSION.store(false, Ordering::SeqCst);
        }
        if let Some((mods, vk)) = crate::overlay::continuous_mode::get_current_hotkey_info() {
            unsafe {
                TRIGGER_MODIFIERS = mods;
                TRIGGER_VK_CODE = vk;

                // Actually check if it's physically held
                use windows::Win32::UI::Input::KeyboardAndMouse::GetAsyncKeyState;
                if !crate::overlay::continuous_mode::is_active() {
                    let is_physically_held = (GetAsyncKeyState(vk as i32) as u16 & 0x8000) != 0;
                    IS_HOTKEY_HELD.store(is_physically_held, Ordering::SeqCst);
                }
            }
        } else {
            IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
        }
    }

    // 3. Signal Show (Pre-position to prevent jump/lag)
    let hwnd_val = TAG_HWND.load(Ordering::SeqCst);
    if hwnd_val != 0 {
        unsafe {
            let hwnd = HWND(hwnd_val as *mut std::ffi::c_void);

            // Decouple delay: Move window immediately to cursor BEFORE showing
            let mut pt = POINT::default();
            let _ = GetCursorPos(&mut pt);
            let target_x = pt.x + OFFSET_X;
            let target_y = pt.y + OFFSET_Y;

            let _ = MoveWindow(hwnd, target_x, target_y, 200, 120, false);

            let _ = PostMessageW(Some(hwnd), WM_APP_SHOW, WPARAM(0), LPARAM(0));
        }
    }
}

// helper to reset state UI
fn reset_ui_state(initial_text: &str) {
    let state = SELECTION_STATE.lock().unwrap();
    if let Some(wv) = state.webview.as_ref() {
        let reset_js = format!("updateState(false, '{}')", initial_text);
        let _ = wv.evaluate_script(&reset_js);
    }
}

unsafe extern "system" fn tag_wnd_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    let result = std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| match msg {
        WM_APP_SHOW => {
            // Cancel any pending Hide timer to prevent it from hiding us later
            let _ = KillTimer(Some(hwnd), 1);

            // Trigger Fade In Script
            {
                let state = SELECTION_STATE.lock().unwrap();
                if let Some(wv) = state.webview.as_ref() {
                    let _ = wv.evaluate_script("playEntry();");
                }
            }
            let _ = ShowWindow(hwnd, SW_SHOWNOACTIVATE);
            LRESULT(0)
        }
        WM_APP_HIDE => {
            // Trigger Fade Out Script & Delay Hide
            {
                let state = SELECTION_STATE.lock().unwrap();
                if let Some(wv) = state.webview.as_ref() {
                    let _ = wv.evaluate_script("playExit();");
                }
            }
            // 150ms delay for animation
            SetTimer(Some(hwnd), 1, 150, None);
            LRESULT(0)
        }
        WM_TIMER => {
            if wparam.0 == 1 {
                let _ = KillTimer(Some(hwnd), 1);
                // Reset text state internally when truly hidden
                {
                    let initial_text = INITIAL_TEXT_GLOBAL.lock().unwrap();
                    reset_ui_state(&initial_text);
                }
                let _ = ShowWindow(hwnd, SW_HIDE);
            }
            LRESULT(0)
        }
        WM_CLOSE => {
            let _ = KillTimer(Some(hwnd), 1);
            let initial_text = INITIAL_TEXT_GLOBAL.lock().unwrap();
            reset_ui_state(&initial_text);
            let _ = ShowWindow(hwnd, SW_HIDE);
            LRESULT(0)
        }
        WM_DESTROY => {
            PostQuitMessage(0);
            LRESULT(0)
        }
        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }));
    match result {
        Ok(lresult) => lresult,
        Err(_) => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

fn internal_create_tag_thread() {
    unsafe {
        use windows::Win32::System::Com::*;
        let _coinit = CoInitialize(None);

        let instance = GetModuleHandleW(None).unwrap();
        let class_name = w!("SGT_TextTag_Web_Persistent");

        REGISTER_TAG_CLASS.call_once(|| {
            let mut wc = WNDCLASSEXW::default();
            wc.cbSize = std::mem::size_of::<WNDCLASSEXW>() as u32;
            wc.lpfnWndProc = Some(tag_wnd_proc);
            wc.hInstance = instance.into();
            wc.hCursor = LoadCursorW(None, IDC_ARROW).unwrap();
            wc.lpszClassName = class_name;
            wc.style = CS_HREDRAW | CS_VREDRAW;
            let _ = RegisterClassExW(&wc);
        });

        // Create Layered Transparent Window
        let hwnd = CreateWindowExW(
            WS_EX_LAYERED | WS_EX_TOPMOST | WS_EX_TOOLWINDOW | WS_EX_TRANSPARENT | WS_EX_NOACTIVATE,
            class_name,
            w!("SGT Tag"),
            WS_POPUP,
            -1000,
            -1000,
            200,
            120, // Increased height for glow
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        if hwnd.is_invalid() {
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            return;
        }

        // Initialize WebView with dynamic theme support
        let (initial_is_dark, lang) = {
            let app = APP.lock().unwrap();
            (
                app.config.theme_mode == crate::config::ThemeMode::Dark
                    || (app.config.theme_mode == crate::config::ThemeMode::System
                        && crate::gui::utils::is_system_in_dark_mode()),
                app.config.ui_language.clone(),
            )
        };

        let initial_text = match lang.as_str() {
            "vi" => "Bôi đen văn bản...",
            "ko" => "텍스트 선택...",
            _ => "Select text...",
        };
        *INITIAL_TEXT_GLOBAL.lock().unwrap() = initial_text.to_string();
        // Use new get_html with CSS variables and updateTheme function
        let html_content = get_html(initial_text);

        // Consolidate all minor overlays to 'common' to share one browser process and keep RAM at ~80MB
        let shared_data_dir = crate::overlay::get_shared_webview_data_dir(Some("common"));

        // Initialize shared WebContext if needed
        SELECTION_WEB_CONTEXT.with(|ctx| {
            if ctx.borrow().is_none() {
                *ctx.borrow_mut() = Some(wry::WebContext::new(Some(shared_data_dir)));
            }
        });

        // Store HTML in font server and get URL for same-origin font loading
        let page_url =
            crate::overlay::html_components::font_manager::store_html_page(html_content.clone())
                .unwrap_or_else(|| {
                    format!("data:text/html,{}", urlencoding::encode(&html_content))
                });

        let mut final_webview: Option<wry::WebView> = None;

        // Small initial delay to avoid collision with other warming-up modules (TextInput/Badge)
        std::thread::sleep(std::time::Duration::from_millis(150));

        // Retry loop for stability (similar to text_input)
        for _attempt in 1..=3 {
            let res = {
                // LOCK SCOPE: Only one WebView builds at a time to prevent "Not enough quota"
                let _init_lock = crate::overlay::GLOBAL_WEBVIEW_MUTEX.lock().unwrap();

                let build_res = SELECTION_WEB_CONTEXT.with(|ctx| {
                    let mut ctx_ref = ctx.borrow_mut();
                    let builder = if let Some(web_ctx) = ctx_ref.as_mut() {
                        wry::WebViewBuilder::new_with_web_context(web_ctx)
                    } else {
                        wry::WebViewBuilder::new()
                    };

                    builder
                        .with_bounds(wry::Rect {
                            position: wry::dpi::Position::Physical(
                                wry::dpi::PhysicalPosition::new(0, 0),
                            ),
                            size: wry::dpi::Size::Physical(wry::dpi::PhysicalSize::new(200, 120)),
                        })
                        .with_url(&page_url)
                        .with_transparent(true)
                        .build_as_child(&HwndWrapper(hwnd))
                });

                build_res
            };

            match res {
                Ok(wv) => {
                    final_webview = Some(wv);
                    break;
                }
                Err(_e) => {
                    std::thread::sleep(std::time::Duration::from_millis(200));
                }
            }
        }

        if let Some(webview) = final_webview {
            // Set initial theme
            let init_script = format!("updateTheme({});", initial_is_dark);
            let _ = webview.evaluate_script(&init_script);
            SELECTION_STATE.lock().unwrap().webview = Some(webview);
        } else {
            let _ = DestroyWindow(hwnd);
            IS_WARMING_UP.store(false, Ordering::SeqCst);
            let _ = CoUninitialize();
            return;
        }

        TAG_HWND.store(hwnd.0 as isize, Ordering::SeqCst);
        IS_WARMED_UP.store(true, Ordering::SeqCst);
        IS_WARMING_UP.store(false, Ordering::SeqCst);

        // If a show was requested during warmup, the state (preset_idx) is already set
        // Just post the show message to ourselves to pop it up.
        if PENDING_SHOW_ON_WARMUP.swap(false, Ordering::SeqCst) {
            let _ = PostMessageW(Some(hwnd), WM_APP_SHOW, WPARAM(0), LPARAM(0));
        }

        let mut msg = MSG::default();
        let mut visible = false;

        // Theme tracking
        let mut current_is_dark = initial_is_dark;
        let mut last_sent_is_selecting = false;

        loop {
            // Check Quit
            if msg.message == WM_QUIT {
                break;
            }

            if visible {
                // Active Loop (Animation/Update) - Poll messages
                while PeekMessageW(&mut msg, None, 0, 0, PM_REMOVE).as_bool() {
                    if msg.message == WM_QUIT {
                        visible = false;
                        break;
                    }
                    let _ = TranslateMessage(&msg);
                    DispatchMessageW(&msg);
                }
                if msg.message == WM_QUIT {
                    break;
                }

                // --- KEY HELD SYNC (POLLING) ---
                // Continuous Mode Support: Ensure we don't get stuck if KeyUp was missed during warmup.
                if TRIGGER_VK_CODE != 0 {
                    let is_physically_down =
                        (GetAsyncKeyState(TRIGGER_VK_CODE as i32) as u16 & 0x8000) != 0;

                    // If it's physically up, force our state to false.
                    if !is_physically_down && IS_HOTKEY_HELD.load(Ordering::SeqCst) {
                        IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
                    }
                }
            } else {
                // Inactive Loop - Block until message (e.g., WM_APP_SHOW)
                if GetMessageW(&mut msg, None, 0, 0).as_bool() {
                    let _ = TranslateMessage(&msg);
                    DispatchMessageW(&msg);
                } else {
                    break;
                }
            }

            // Check Visibility State (updated by WndProc)
            let is_actually_visible = IsWindowVisible(hwnd).as_bool();

            // On Transition
            if is_actually_visible != visible {
                visible = is_actually_visible;
                // Hook Management
                let mut state = SELECTION_STATE.lock().unwrap();
                if visible {
                    // Install Hook
                    if state.hook_handle.is_invalid() {
                        let hook = SetWindowsHookExW(
                            WH_KEYBOARD_LL,
                            Some(keyboard_hook_proc),
                            Some(GetModuleHandleW(None).unwrap().into()),
                            0,
                        );
                        if let Ok(h) = hook {
                            state.hook_handle = h;
                        }
                    }

                    // NOTE: Physical key sync moved to main polling loop below
                    // Reset Logic
                    last_sent_is_selecting = false;

                    // Sync Theme (Realtime check on show)
                    let new_is_dark = crate::overlay::is_dark_mode();
                    if new_is_dark != current_is_dark {
                        current_is_dark = new_is_dark;
                        if let Some(wv) = state.webview.as_ref() {
                            let _ =
                                wv.evaluate_script(&format!("updateTheme({});", current_is_dark));
                        }
                    }

                    // Reset State in JS
                    if let Some(wv) = state.webview.as_ref() {
                        let reset_js = format!("updateState(false, '{}')", initial_text);
                        let _ = wv.evaluate_script(&reset_js);
                    }
                } else {
                    // Uninstall Hook ONLY if continuous mode is NOT active.
                    // If continuous mode is active, we keep the hook to catch the exit command (ESC or Hotkey)
                    // even while the tag is temporarily hidden/processing.
                    if !crate::overlay::continuous_mode::is_active()
                        && !state.hook_handle.is_invalid()
                    {
                        let _ = UnhookWindowsHookEx(state.hook_handle);
                        state.hook_handle = HHOOK::default();
                    }
                }
            }

            if visible {
                // 1. Check Abort
                if TAG_ABORT_SIGNAL.load(Ordering::SeqCst) {
                    let _ = ShowWindow(hwnd, SW_HIDE);
                    continue;
                }

                // 1.5 Real-time Theme Sync (Check every frame while visible)
                let new_is_dark = crate::overlay::is_dark_mode();
                if new_is_dark != current_is_dark {
                    current_is_dark = new_is_dark;
                    if let Some(wv) = SELECTION_STATE.lock().unwrap().webview.as_ref() {
                        let _ = wv.evaluate_script(&format!("updateTheme({});", current_is_dark));
                    }
                }

                // 2. Logic & Movement
                // 2. Logic & Movement
                let mut pt = POINT::default();
                let _ = GetCursorPos(&mut pt);
                let target_x = pt.x + OFFSET_X;
                let target_y = pt.y + OFFSET_Y;

                // Use MoveWindow for Webview host
                let _ = MoveWindow(hwnd, target_x, target_y, 200, 120, false);

                // EARLY CONTINUOUS MODE TRIGGER
                let cm_active = crate::overlay::continuous_mode::is_active();
                let session_activated = CONTINUOUS_ACTIVATED_THIS_SESSION.load(Ordering::SeqCst);

                if !cm_active && !session_activated {
                    // Latch the hold detection early via heartbeats
                    let heartbeat = crate::overlay::continuous_mode::was_triggered_recently(2000);
                    if heartbeat {
                        HOLD_DETECTED_THIS_SESSION.store(true, Ordering::SeqCst);
                    }

                    if HOLD_DETECTED_THIS_SESSION.load(Ordering::SeqCst) {
                        let mut hotkey_name = crate::overlay::continuous_mode::get_hotkey_name();
                        if hotkey_name.is_empty() {
                            hotkey_name = crate::overlay::continuous_mode::get_latest_hotkey_name();
                        }
                        if hotkey_name.is_empty() {
                            hotkey_name = "Hotkey".to_string();
                        }

                        let p_idx = SELECTION_STATE.lock().unwrap().preset_idx;
                        let p_name = {
                            if let Ok(app) = APP.lock() {
                                app.config
                                    .presets
                                    .get(p_idx)
                                    .map(|p| p.id.clone())
                                    .unwrap_or_default()
                            } else {
                                "Preset".to_string()
                            }
                        };

                        // Disable continuous mode for Master Preset
                        if p_name != "preset_text_select_master" {
                            crate::overlay::continuous_mode::activate(p_idx, hotkey_name.clone());
                            crate::overlay::continuous_mode::show_activation_notification(
                                &p_name,
                                &hotkey_name,
                            );
                            CONTINUOUS_ACTIVATED_THIS_SESSION.store(true, Ordering::SeqCst);
                        }
                    }
                }

                let lbutton_down = (GetAsyncKeyState(VK_LBUTTON.0 as i32) as u16 & 0x8000) != 0;

                let mut should_spawn_thread = false;
                let mut preset_idx_for_thread = 0;

                // Scope for State Lock
                let update_js = {
                    let mut state = SELECTION_STATE.lock().unwrap();

                    if !state.is_selecting && lbutton_down {
                        // Check if mouse is over our own window to avoid triggering selection on UI interaction
                        let mut pt = POINT::default();
                        let _ = GetCursorPos(&mut pt);
                        let hwnd_under_mouse = WindowFromPoint(pt);
                        let mut pid: u32 = 0;
                        GetWindowThreadProcessId(hwnd_under_mouse, Some(&mut pid));
                        let our_pid = std::process::id();

                        if pid != our_pid {
                            state.is_selecting = true;
                            // Record mouse start position for drag detection
                            MOUSE_START_X.store(pt.x, Ordering::SeqCst);
                            MOUSE_START_Y.store(pt.y, Ordering::SeqCst);
                        }
                    } else if state.is_selecting && !lbutton_down && !state.is_processing {
                        // DRAG DETECTION: Only process if mouse moved significantly
                        let mut pt = POINT::default();
                        let _ = GetCursorPos(&mut pt);
                        let start_x = MOUSE_START_X.load(Ordering::SeqCst);
                        let start_y = MOUSE_START_Y.load(Ordering::SeqCst);
                        let dx = (pt.x - start_x).abs();
                        let dy = (pt.y - start_y).abs();
                        let distance = dx + dy; // Manhattan distance

                        if distance >= 10 {
                            // Real drag/selection detected
                            state.is_processing = true;
                            should_spawn_thread = true;
                            preset_idx_for_thread = state.preset_idx;
                        } else {
                            // Just a click, not a selection - reset state
                            state.is_selecting = false;
                        }
                    }

                    if state.is_selecting != last_sent_is_selecting {
                        last_sent_is_selecting = state.is_selecting;
                        let new_text = if state.is_selecting {
                            match lang.as_str() {
                                "vi" => "Thả chuột để xử lý",
                                "ko" => "처리를 위해 마우스를 놓으세요",
                                _ => "Release to process",
                            }
                        } else {
                            initial_text
                        };
                        Some(format!(
                            "updateState({}, '{}')",
                            state.is_selecting, new_text
                        ))
                    } else {
                        None
                    }
                };

                // Update WebView outside lock
                if let Some(js) = update_js {
                    if let Some(webview) = SELECTION_STATE.lock().unwrap().webview.as_ref() {
                        let _ = webview.evaluate_script(&js);
                    }
                }

                // Spawn Worker Thread
                if should_spawn_thread {
                    let hwnd_val = hwnd.0 as usize;
                    std::thread::spawn(move || {
                        let hwnd_copy = HWND(hwnd_val as *mut std::ffi::c_void);

                        if TAG_ABORT_SIGNAL.load(Ordering::Relaxed) {
                            return;
                        }
                        std::thread::sleep(std::time::Duration::from_millis(50));

                        // Clear Clipboard
                        if OpenClipboard(Some(HWND::default())).is_ok() {
                            let _ = EmptyClipboard();
                            let _ = CloseClipboard();
                        }

                        let send_input_event = |vk: u16, flags: KEYBD_EVENT_FLAGS| {
                            let input = INPUT {
                                r#type: INPUT_KEYBOARD,
                                Anonymous: INPUT_0 {
                                    ki: KEYBDINPUT {
                                        wVk: VIRTUAL_KEY(vk),
                                        dwFlags: flags,
                                        time: 0,
                                        dwExtraInfo: 0,
                                        wScan: 0,
                                    },
                                },
                            };
                            SendInput(&[input], std::mem::size_of::<INPUT>() as i32);
                        };

                        // Ctrl + C chain
                        send_input_event(VK_CONTROL.0, KEYBD_EVENT_FLAGS(0));
                        std::thread::sleep(std::time::Duration::from_millis(20));
                        send_input_event(0x43, KEYBD_EVENT_FLAGS(0));
                        std::thread::sleep(std::time::Duration::from_millis(20));
                        send_input_event(0x43, KEYEVENTF_KEYUP);
                        std::thread::sleep(std::time::Duration::from_millis(20));
                        send_input_event(VK_CONTROL.0, KEYEVENTF_KEYUP);

                        let mut clipboard_text = String::new();
                        for _ in 0..10 {
                            if TAG_ABORT_SIGNAL.load(Ordering::Relaxed) {
                                return;
                            }
                            std::thread::sleep(std::time::Duration::from_millis(25));
                            clipboard_text = get_clipboard_text();
                            if !clipboard_text.is_empty() {
                                break;
                            }
                        }

                        if !clipboard_text.trim().is_empty()
                            && !TAG_ABORT_SIGNAL.load(Ordering::Relaxed)
                        {
                            // HIDE FIRST
                            let _ =
                                PostMessageW(Some(hwnd_copy), WM_APP_HIDE, WPARAM(0), LPARAM(0));

                            let mut p_idx = preset_idx_for_thread;

                            // CHECK FOR CONTINUOUS MODE ACTIVATION
                            let cm_active_before = crate::overlay::continuous_mode::is_active();
                            let session_flag =
                                CONTINUOUS_ACTIVATED_THIS_SESSION.load(Ordering::SeqCst);

                            if !cm_active_before && !session_flag {
                                let mut held = if TRIGGER_MODIFIERS == 0 {
                                    IS_HOTKEY_HELD.load(Ordering::SeqCst)
                                } else {
                                    crate::overlay::continuous_mode::are_modifiers_still_held()
                                };

                                if !held {
                                    held = crate::overlay::continuous_mode::was_triggered_recently(
                                        1500,
                                    );
                                }

                                if held {
                                    let mut hotkey_name =
                                        crate::overlay::continuous_mode::get_hotkey_name();

                                    let dbg_latest =
                                        crate::overlay::continuous_mode::get_latest_hotkey_name();
                                    crate::log_info!("[TextSelection] Late Check - Persistent: '{}', Latest: '{}'", hotkey_name, dbg_latest);

                                    if hotkey_name.is_empty() {
                                        hotkey_name = dbg_latest;
                                    }
                                    if hotkey_name.is_empty() {
                                        hotkey_name = "Hotkey".to_string();
                                    }

                                    let preset_name = {
                                        if let Ok(app) = APP.lock() {
                                            app.config
                                                .presets
                                                .get(p_idx)
                                                .map(|p| p.id.clone())
                                                .unwrap_or_default()
                                        } else {
                                            "Preset".to_string()
                                        }
                                    };

                                    let current_active_idx =
                                        crate::overlay::continuous_mode::get_preset_idx();
                                    if current_active_idx != p_idx {
                                        p_idx = current_active_idx;
                                    }
                                    crate::overlay::continuous_mode::activate(
                                        p_idx,
                                        hotkey_name.clone(),
                                    );
                                    crate::overlay::continuous_mode::show_activation_notification(
                                        &preset_name,
                                        &hotkey_name,
                                    );
                                    CONTINUOUS_ACTIVATED_THIS_SESSION.store(true, Ordering::SeqCst);
                                }
                            }

                            // CONTINUOUS MODE RETRIGGER - Immediately after hide, BEFORE processing
                            // This ensures the tag reappears right at mouse release, not after process completes
                            let cm_active = crate::overlay::continuous_mode::is_active();
                            let cm_idx = crate::overlay::continuous_mode::get_preset_idx();
                            if cm_active && cm_idx == p_idx {
                                let retrigger_idx = p_idx;
                                std::thread::spawn(move || {
                                    // Small delay to let the hide animation complete
                                    std::thread::sleep(std::time::Duration::from_millis(150));
                                    if crate::overlay::continuous_mode::is_active() {
                                        let _ = super::show_text_selection_tag(retrigger_idx);
                                    }
                                });
                            }

                            process_selected_text(p_idx, clipboard_text);
                        } else {
                            // Reset state if failed or empty
                            let mut state = SELECTION_STATE.lock().unwrap();
                            state.is_selecting = false;
                            state.is_processing = false;
                        }
                    });
                }

                // 60FPS Cap for polling drag state
                std::thread::sleep(std::time::Duration::from_millis(16));
            }
        }

        // Cleanup
        {
            let mut state = SELECTION_STATE.lock().unwrap();
            state.webview = None;
            if !state.hook_handle.is_invalid() {
                let _ = UnhookWindowsHookEx(state.hook_handle);
                state.hook_handle = HHOOK::default();
            }
        }
    }
}

// Reuse helper functions like get_clipboard_text, process_selected_text
unsafe fn get_clipboard_text() -> String {
    let mut result = String::new();
    if OpenClipboard(Some(HWND::default())).is_ok() {
        if let Ok(h_data) = GetClipboardData(13u32) {
            let h_global: HGLOBAL = std::mem::transmute(h_data);
            let ptr = GlobalLock(h_global);
            if !ptr.is_null() {
                let size = GlobalSize(h_global);
                let wide_slice = std::slice::from_raw_parts(ptr as *const u16, size / 2);
                if let Some(end) = wide_slice.iter().position(|&c| c == 0) {
                    result = String::from_utf16_lossy(&wide_slice[..end]);
                }
            }
            let _ = GlobalUnlock(h_global);
        }
        let _ = CloseClipboard();
    }
    result
}

fn process_selected_text(preset_idx: usize, clipboard_text: String) {
    unsafe {
        let (is_master, _original_mode) = {
            let app = APP.lock().unwrap();
            let p = &app.config.presets[preset_idx];
            (p.is_master, p.text_input_mode.clone())
        };

        let final_preset_idx = if is_master {
            let mut cursor_pos = POINT { x: 0, y: 0 };
            let _ = GetCursorPos(&mut cursor_pos);
            let selected =
                crate::overlay::preset_wheel::show_preset_wheel("text", Some("select"), cursor_pos);
            if let Some(idx) = selected {
                idx
            } else {
                return;
            }
        } else {
            preset_idx
        };

        let (config, mut preset, screen_w, screen_h) = {
            let mut app = APP.lock().unwrap();
            app.config.active_preset_idx = final_preset_idx;
            (
                app.config.clone(),
                app.config.presets[final_preset_idx].clone(),
                GetSystemMetrics(SM_CXSCREEN),
                GetSystemMetrics(SM_CYSCREEN),
            )
        };

        preset.text_input_mode = "select".to_string();

        let center_rect = RECT {
            left: (screen_w - 700) / 2,
            top: (screen_h - 300) / 2,
            right: (screen_w + 700) / 2,
            bottom: (screen_h + 300) / 2,
        };
        let localized_name =
            crate::gui::settings_ui::get_localized_preset_name(&preset.id, &config.ui_language);
        let cancel_hotkey = preset
            .hotkeys
            .first()
            .map(|h| h.name.clone())
            .unwrap_or_default();

        crate::overlay::process::start_text_processing(
            clipboard_text,
            center_rect,
            config,
            preset,
            localized_name,
            cancel_hotkey,
        );
        // NOTE: Continuous retrigger is now handled at mouse release, not here
    }
}

unsafe extern "system" fn keyboard_hook_proc(code: i32, wparam: WPARAM, lparam: LPARAM) -> LRESULT {
    if code == HC_ACTION as i32 {
        let kbd_struct = &*(lparam.0 as *const KBDLLHOOKSTRUCT);
        if wparam.0 == WM_KEYDOWN as usize || wparam.0 == WM_SYSKEYDOWN as usize {
            if kbd_struct.vkCode == VK_ESCAPE.0 as u32 {
                crate::overlay::continuous_mode::deactivate();
                TAG_ABORT_SIGNAL.store(true, Ordering::SeqCst);
                return LRESULT(1);
            }
            if kbd_struct.vkCode == TRIGGER_VK_CODE {
                if !IS_HOTKEY_HELD.load(Ordering::SeqCst) {
                    crate::overlay::continuous_mode::deactivate();
                    TAG_ABORT_SIGNAL.store(true, Ordering::SeqCst);
                    return LRESULT(1);
                }
            }
        } else if wparam.0 == WM_KEYUP as usize || wparam.0 == WM_SYSKEYUP as usize {
            if kbd_struct.vkCode == TRIGGER_VK_CODE {
                IS_HOTKEY_HELD.store(false, Ordering::SeqCst);
            }
        }
    }
    CallNextHookEx(None, code, wparam, lparam)
}

// --- HTML CONTENT ---
fn get_html(initial_text: &str) -> String {
    let font_css = crate::overlay::html_components::font_manager::get_font_css();

    format!(
        r#"<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <style>
        {font_css}
        :root {{
            --bg-color: rgba(255, 255, 255, 0.95);
            --text-color: #202124;
            /* Aurora Gradient - Idle (Blue-Violet-Cyan) */
            --g1: #0033cc;
            --g2: #00ddff;
            --g3: #8844ff;
            /* Aurora Gradient - Active (Red-Gold-Purple DRAMATIC) */
            --a1: #ff0055;
            --a2: #ffdd00;
            --a3: #aa00ff;
            --wave-color: #1a73e8;
        }}
        [data-theme="dark"] {{
            --bg-color: rgba(26, 26, 26, 0.95);
            --text-color: #ffffff;
            /* Aurora Gradient - Idle (Neon Synthwave) */
            --g1: #2bd9fe;
            --g2: #aa22ff;
            --g3: #00fe9b;
            /* Aurora Gradient - Active (Hyper Energy) */
            --a1: #ff00cc;
            --a2: #ccff00;
            --a3: #ff2200;
            --wave-color: #8ab4f8;
        }}

        * {{
            margin: 0;
            padding: 0;
            user-select: none;
            cursor: default;
        }}
        
        body {{
            background: transparent;
            overflow: hidden;
            display: flex;
            align-items: center;
            justify-content: center;
            height: 100vh;
            width: 100vw;
            font-family: 'Google Sans Flex Rounded', 'Google Sans Flex', 'Segoe UI', system-ui, sans-serif;
            font-weight: 500;
        }}
        
        /* Clip the glow to the container shape to prevent "inside out" giant square */
        .badge-container {{
            position: relative;
            padding: 2px; /* Border thickness */
            border-radius: 999px; /* Pill shape */
            background: var(--bg-color); /* Opaque track */
            overflow: hidden; /* CRITICAL FIX: Clips the spinning gradient */
            opacity: 0; /* Default invisible */
            transform: translateY(10px);
            /* Remove default animation, handled by classes */
            box-shadow: 0 4px 12px rgba(0,0,0,0.25);
            transition: box-shadow 0.2s, transform 0.2s;
        }}

        .badge-container.entering {{
            animation: fadeIn 0.15s cubic-bezier(0.2, 0, 0, 1) forwards;
        }}
        
        .badge-container.exiting {{
            animation: fadeOut 0.15s cubic-bezier(0.2, 0, 0, 1) forwards;
        }}

        .badge-glow {{
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: conic-gradient(
                from 0deg, 
                var(--c1), 
                var(--c2), 
                var(--c3), 
                var(--c2), 
                var(--c1)
            );
            animation: spin 4s linear infinite; /* Slower, smoother flow */
            opacity: 1;
            z-index: 0;
            filter: blur(2px); /* Soften the gradient blends */
        }}

        .badge-inner {{
            position: relative;
            background: var(--bg-color); /* Covers the center */
            color: var(--text-color);
            padding: 3px 10px;
            border-radius: 999px; /* Match parent */
            font-size: 12px;
            white-space: nowrap;
            z-index: 1; /* Sit above glow */
            display: flex;
            align-items: center;
            gap: 8px;
            font-stretch: condensed;
            letter-spacing: -0.2px;
            box-shadow: 0 0 4px 1px var(--bg-color); /* Soft edge blending */
        }}

        @keyframes fadeIn {{
            to {{ opacity: 1; transform: translateY(0); }}
        }}

        @keyframes spin {{
            from {{ transform: rotate(0deg); }}
            to {{ transform: rotate(360deg); }}
        }}

        @keyframes waveColor {{
            0% {{
                color: var(--a1);
                font-variation-settings: 'GRAD' 0, 'wght' 500, 'ROND' 100;
                transform: translateY(0px) scale(1);
            }}
            33% {{
                color: var(--a2);
                font-variation-settings: 'GRAD' 200, 'wght' 900, 'ROND' 100;
                transform: translateY(-2px) scale(1.1);
            }}
            66% {{
                color: var(--a3);
                font-variation-settings: 'GRAD' 200, 'wght' 900, 'ROND' 100;
                transform: translateY(-1px) scale(1.1);
            }}
            100% {{
                color: var(--a1);
                font-variation-settings: 'GRAD' 0, 'wght' 500, 'ROND' 100;
                transform: translateY(0px) scale(1);
            }}
        }}

        @keyframes idleWave {{
            0% {{
                color: var(--g1);
                font-variation-settings: 'GRAD' 0, 'wght' 400, 'ROND' 100;
            }}
            50% {{
                color: var(--g2);
                font-variation-settings: 'GRAD' 50, 'wght' 600, 'ROND' 100;
            }}
            100% {{
                color: var(--g1);
                font-variation-settings: 'GRAD' 0, 'wght' 400, 'ROND' 100;
            }}
        }}
        
        @keyframes fadeOut {{
            from {{ opacity: 1; transform: translateY(0); }}
            to {{ opacity: 0; transform: translateY(-10px); }}
        }}

        /* State: Selecting (Active) */
        body.selecting .badge-glow {{
            --c1: var(--a1);
            --c2: var(--a2);
            --c3: var(--a3);
            animation: spin 0.8s linear infinite; /* Faster spin for urgency */
        }}
        
        body.selecting .badge-container {{
            transform: scale(1.05);
            /* Soft orange outer glow */
            box-shadow: 0 0 15px rgba(255, 94, 0, 0.4), 0 4px 12px rgba(0,0,0,0.3);
        }}
        
        /* State: Idle */
        body:not(.selecting) .badge-glow {{
            --c1: var(--g1);
            --c2: var(--g2);
            --c3: var(--g3);
        }}

    </style>
</head>
<body>
    <div class="badge-container">
        <div class="badge-glow"></div>
        <div class="badge-inner">
            <span id="text">{text}</span>
        </div>
    </div>

    <script>
        function playEntry() {{
            const el = document.querySelector('.badge-container');
            if(el) {{
                el.classList.remove('exiting');
                el.classList.add('entering');
            }}
        }}

        function playExit() {{
            const el = document.querySelector('.badge-container');
            if(el) {{
                el.classList.remove('entering');
                el.classList.add('exiting');
            }}
        }}
        
        function updateState(isSelecting, newText) {{
            if (isSelecting) {{
                document.body.classList.add('selecting');
            }} else {{
                document.body.classList.remove('selecting');
            }}
            
            const title = document.getElementById('text');
            if (isSelecting) {{
                // Apply DRAMATIC, SPEEDY, LOOPING Wave Animation
                const chars = newText.split('');
                title.innerHTML = chars.map((char, i) => 
                    `<span style="
                        display: inline-block;
                        animation: waveColor 0.6s linear infinite;
                        animation-delay: ${{i * 0.05}}s;
                    ">${{char === ' ' ? '&nbsp;' : char}}</span>`
                ).join('');
            }} else {{
                // Idle State: Gentle Blue Wave
                const chars = newText.split('');
                title.innerHTML = chars.map((char, i) => 
                    `<span style="
                        display: inline-block;
                        animation: idleWave 3s ease-in-out infinite;
                        animation-delay: ${{i * 0.1}}s;
                    ">${{char === ' ' ? '&nbsp;' : char}}</span>`
                ).join('');
            }}
        }}

        function updateTheme(isDark) {{
            if (isDark) {{
                document.documentElement.setAttribute('data-theme', 'dark');
            }} else {{
                document.documentElement.removeAttribute('data-theme');
            }}
        }}
    </script>
</body>
</html>"#,
        font_css = font_css,
        text = initial_text
    )
}
</file>

<file path="src/gui/locale.rs">
// --- Localization ---
pub struct LocaleText {
    pub history_btn: &'static str,
    pub history_title: &'static str,
    pub max_items_label: &'static str,
    pub history_empty: &'static str,
    pub clear_all_history_btn: &'static str,
    pub view_image_btn: &'static str,
    pub listen_audio_btn: &'static str,
    pub view_text_btn: &'static str, // NEW

    pub prompt_mode_fixed: &'static str,
    pub prompt_mode_dynamic: &'static str,

    pub get_key_link: &'static str,
    pub gemini_api_key_label: &'static str,
    pub gemini_get_key_link: &'static str,
    pub openrouter_api_key_label: &'static str,
    pub openrouter_get_key_link: &'static str,
    pub use_groq_checkbox: &'static str,
    pub use_gemini_checkbox: &'static str,
    pub use_openrouter_checkbox: &'static str,
    pub cerebras_api_key_label: &'static str,
    pub cerebras_get_key_link: &'static str,
    pub use_cerebras_checkbox: &'static str,

    pub global_settings: &'static str,
    pub preset_name_label: &'static str,

    pub search_placeholder: &'static str,

    pub auto_paste_label: &'static str,
    pub auto_paste_newline_label: &'static str,
    pub startup_label: &'static str,
    pub add_hotkey_button: &'static str,
    pub press_keys: &'static str,
    pub cancel_label: &'static str,
    pub reset_defaults_btn: &'static str,

    pub preset_type_label: &'static str,
    pub preset_type_image: &'static str,
    pub preset_type_audio: &'static str,
    pub preset_type_video: &'static str,
    pub preset_type_text: &'static str, // NEW

    pub force_quit: &'static str, // NEW

    pub audio_source_label: &'static str,
    pub audio_src_mic: &'static str,
    pub audio_src_device: &'static str,
    pub hide_recording_ui_label: &'static str,
    pub auto_stop_recording_label: &'static str, // Silence-based auto-stop
    pub hotkeys_section: &'static str,
    pub start_in_tray_label: &'static str,
    pub footer_admin_running: &'static str,
    pub admin_startup_on: &'static str,
    pub admin_startup_success: &'static str,
    pub admin_startup_fail: &'static str,
    pub graphics_mode_label: &'static str,
    pub graphics_mode_standard: &'static str,
    pub graphics_mode_minimal: &'static str,
    pub usage_statistics_title: &'static str,
    pub usage_statistics_tooltip: &'static str,
    pub usage_model_column: &'static str,
    pub usage_remaining_column: &'static str,
    pub usage_check_link: &'static str,

    pub footer_admin_text: &'static str,
    pub footer_version: &'static str,
    pub check_for_updates_btn: &'static str,
    pub current_version_label: &'static str,
    pub checking_github: &'static str,
    pub up_to_date: &'static str,
    pub check_again_btn: &'static str,
    pub new_version_available: &'static str,
    pub release_notes_label: &'static str,
    pub download_update_btn: &'static str,
    pub downloading_update: &'static str,
    pub update_failed: &'static str,
    pub app_folder_writable_hint: &'static str,
    pub retry_btn: &'static str,
    pub update_success: &'static str,
    pub restart_to_use_new_version: &'static str,
    pub restart_app_btn: &'static str,
    // --- NEW TEXT INPUT FIELDS ---
    pub text_input_mode_label: &'static str,
    pub text_mode_select: &'static str,
    pub text_mode_type: &'static str,
    pub continuous_input_label: &'static str, // Checkbox for continuous input mode
    pub command_mode_label: &'static str, // For prompt mode in text/image presets (different from text_input_mode_label)
    pub text_input_title_default: &'static str,
    pub text_input_placeholder: &'static str,
    pub text_input_footer_submit: &'static str,
    pub text_input_footer_newline: &'static str,
    pub text_input_footer_cancel: &'static str,
    pub add_text_preset_btn: &'static str,
    pub add_image_preset_btn: &'static str,
    pub add_audio_preset_btn: &'static str,
    // --- PROCESSING CHAIN UI ---
    pub node_input_prefix: &'static str,
    pub node_input_audio: &'static str,
    pub node_input_image: &'static str,
    pub node_input_text: &'static str,
    pub node_process_title: &'static str,
    pub node_special_default: &'static str,
    pub node_special_image_to_text: &'static str,
    pub node_special_audio_to_text: &'static str,
    pub node_menu_add_normal: &'static str,
    pub node_menu_add_special_generic: &'static str,
    pub node_menu_add_special_image: &'static str,
    pub node_menu_add_special_audio: &'static str,
    pub input_auto_copy_tooltip: &'static str,
    pub input_auto_speak_tooltip: &'static str,

    pub tips_title: &'static str,
    pub tips_list: Vec<&'static str>,
    pub tips_click_hint: &'static str,
    pub restore_preset_btn: &'static str,
    pub restore_preset_tooltip: &'static str,
    // --- COMPOUND SEARCH UI ---
    pub search_doing: &'static str,            // "Doing" / "Đang"
    pub search_searching: &'static str,        // "searching" / "tìm kiếm"
    pub search_query_label: &'static str,      // "Search queries:" / "Truy vấn tìm kiếm:"
    pub search_found_sources: &'static str,    // "FOUND {} SOURCES" / "ĐÃ TÌM THẤY {} NGUỒN"
    pub search_sources_label: &'static str, // "Reference sources (by relevance):" / "Nguồn tham khảo (theo độ liên quan):"
    pub search_no_title: &'static str,      // "(No title)" / "(Không có tiêu đề)"
    pub search_synthesizing: &'static str,  // "SYNTHESIZING INFO..." / "ĐANG TỔNG HỢP THÔNG TIN..."
    pub search_analyzed_sources: &'static str, // "Analyzed {} sources" / "Đã phân tích {} nguồn"
    pub search_processing: &'static str, // "Processing and summarizing results..." / "Đang xử lý và tóm tắt kết quả..."
    // --- MASTER PRESET UI ---
    pub controller_checkbox_label: &'static str, // "Bộ điều khiển" / "Controller" / "컨트롤러"

    // --- GLOBAL SETTINGS UI HEADERS ---
    pub api_keys_header: &'static str,
    pub groq_label: &'static str,
    pub software_update_header: &'static str,
    pub startup_display_header: &'static str,
    // --- MODEL THINKING INDICATOR ---
    pub model_thinking: &'static str,
    // --- REALTIME OVERLAY ---
    pub realtime_listening: &'static str,
    pub realtime_device: &'static str,
    pub realtime_waiting: &'static str,
    pub realtime_translation: &'static str,
    pub realtime_mic: &'static str,
    pub ollama_url_guide: &'static str,
    pub tts_settings_button: &'static str,
    pub tts_settings_title: &'static str,
    pub tts_method_label: &'static str,
    pub tts_method_standard: &'static str,
    pub tts_method_fast: &'static str,
    pub tts_method_edge: &'static str,
    pub tts_google_translate_title: &'static str,
    pub tts_google_translate_desc: &'static str,
    pub tts_edge_title: &'static str,
    pub tts_edge_desc: &'static str,
    pub tts_pitch_label: &'static str,
    pub tts_rate_label: &'static str,
    pub tts_voice_per_language_label: &'static str,
    pub tts_loading_voices: &'static str,
    pub tts_failed_load_voices: &'static str,
    pub tts_retry_label: &'static str,
    pub tts_initializing_voices: &'static str,
    pub tts_add_language_label: &'static str,
    pub tts_reset_to_defaults_label: &'static str,
    pub tts_speed_label: &'static str,
    pub tts_speed_normal: &'static str,
    pub tts_speed_slow: &'static str,
    pub tts_speed_fast: &'static str,
    pub _tts_voice_label: &'static str,
    pub tts_preview_texts: Vec<&'static str>,
    pub tts_male: &'static str,
    pub tts_female: &'static str,
    pub tts_instructions_label: &'static str,
    pub tts_instructions_hint: &'static str,
    pub tts_add_condition: &'static str,
    // Realtime TTS modal
    pub realtime_tts_title: &'static str,
    pub realtime_tts_speed: &'static str,
    pub realtime_tts_auto: &'static str,
    // App selection modal
    pub app_select_title: &'static str,
    pub app_select_hint: &'static str,
    // --- TRAY MENU ---
    pub tray_settings: &'static str,
    pub tray_quit: &'static str,
    pub tray_favorite_bubble: &'static str,
    pub tray_favorite_bubble_disabled: &'static str,
    // --- FAVORITE BUBBLE ---
    pub favorites_empty: &'static str,
    pub favorites_keep_open: &'static str,
    pub recording_subtext: &'static str,
    pub recording_paused: &'static str,
    // --- AUTO COPY BADGE ---
    pub auto_copied_badge: &'static str,
    pub auto_copied_image_badge: &'static str,
    pub live_translate_loading: &'static str,
    pub text_input_loading: &'static str,
    pub recording_loading: &'static str,
    pub markdown_view_loading: &'static str,
    pub preset_wheel_loading: &'static str,
    pub prompt_dj_loading: &'static str,
    pub tray_popup_loading: &'static str,
    pub update_available_notification: &'static str,
    pub cannot_type_no_caret: &'static str,
    // --- DROP OVERLAY ---
    pub drop_overlay_text: &'static str,
    // --- REALTIME EGUI SPECIFIC ---
    pub device_mode_warning: &'static str,
    pub select_app_btn: &'static str,
    pub toggle_translation_tooltip: &'static str,
    pub toggle_transcription_tooltip: &'static str,
    pub font_minus_tooltip: &'static str,
    pub font_plus_tooltip: &'static str,
    pub google_gtx_label: &'static str,
    pub opacity_label: &'static str,
    pub downloaded_successfully: &'static str,
    pub download_recording_tooltip: &'static str,
    // --- HELP ASSISTANT ---
    pub help_assistant_btn: &'static str,
    pub help_assistant_title: &'static str,
    pub help_assistant_question_label: &'static str,
    pub help_assistant_placeholder: &'static str,
    pub help_assistant_ask_btn: &'static str,
    pub help_assistant_loading: &'static str,
    pub help_assistant_answer_label: &'static str,
    pub help_assistant_hint: &'static str,

    // --- PROMPT DJ ---
    pub prompt_dj_btn: &'static str,
    pub prompt_dj_title: &'static str,
    pub screen_record_btn: &'static str,
    pub screen_record_title: &'static str,
    // --- PARAKEET DOWNLOAD MODAL ---
    pub parakeet_downloading_title: &'static str,
    pub parakeet_downloading_message: &'static str,
    pub parakeet_downloading_file: &'static str, // "Downloading {}..."
    pub parakeet_supports_english_only: &'static str,
    // --- OVERLAY BUTTONS TOOLTIPS ---
    pub overlay_copy_tooltip: &'static str,
    pub overlay_undo_tooltip: &'static str,
    pub overlay_redo_tooltip: &'static str,
    pub overlay_edit_tooltip: &'static str,
    pub overlay_refine_placeholder: &'static str, // NEW
    pub overlay_markdown_tooltip: &'static str,
    pub overlay_download_tooltip: &'static str,
    pub overlay_speaker_tooltip: &'static str,
    pub overlay_broom_tooltip: &'static str,
    pub overlay_back_tooltip: &'static str,
    pub overlay_forward_tooltip: &'static str,
    pub overlay_opacity_tooltip: &'static str,
    pub download_feature_btn: &'static str,
    pub download_feature_title: &'static str,
    pub download_delete_deps_btn: &'static str, // "delete yt-dlp (xx MB) and ffmpeg (xx MB)"
    pub download_url_label: &'static str,
    pub download_format_label: &'static str,
    pub download_start_btn: &'static str,
    pub download_open_file_btn: &'static str,
    pub download_open_folder_btn: &'static str,
    pub download_status_starting: &'static str,
    pub download_status_finished: &'static str,
    pub download_status_error: &'static str,
    pub download_deps_missing: &'static str,
    pub download_deps_ytdlp: &'static str,
    pub download_deps_ffmpeg: &'static str,
    pub download_deps_download_btn: &'static str,
    pub download_status_ready: &'static str,
    pub download_status_extracting: &'static str,
    pub download_cancel_btn: &'static str,
    pub download_file_label: &'static str,
    pub download_size_label: &'static str,
    pub download_change_folder_btn: &'static str,
    // Format: "{percent}% of {total} at {speed}, ETA {eta}"
    pub download_progress_info_fmt: &'static str, 
    pub download_advanced_header: &'static str,
    pub download_opt_metadata: &'static str,
    pub download_opt_sponsorblock: &'static str,
    pub download_opt_subtitles: &'static str,
    pub download_opt_playlist: &'static str,
    pub download_opt_cookies: &'static str,
    pub download_scan_ignore_btn: &'static str, // NEW
    pub download_quality_label_text: &'static str, // NEW
    pub download_quality_best: &'static str, // NEW
    pub download_scanning_label: &'static str, // NEW
    pub download_no_cookie_option: &'static str, // NEW
    pub download_show_log_btn: &'static str, // NEW
    pub download_hide_log_btn: &'static str, // NEW
    pub download_subtitle_label: &'static str, // NEW
    pub download_subtitle_auto: &'static str,
    pub download_subs_found_header: &'static str, // NEW
    pub download_subs_none_found: &'static str, // NEW

    // --- DOWNLOADED TOOLS MODAL ---
    pub downloaded_tools_button: &'static str,
    pub downloaded_tools_title: &'static str,
    pub tool_parakeet: &'static str,
    pub tool_ytdlp: &'static str,
    pub tool_ffmpeg: &'static str,
    pub tool_status_installed: &'static str, // "Installed ({})"
    pub tool_status_missing: &'static str,
    pub tool_action_download: &'static str,
    pub tool_action_delete: &'static str,
    pub tool_desc_parakeet: &'static str,
    pub tool_desc_ytdlp: &'static str,
    pub tool_desc_ffmpeg: &'static str,
    pub tool_update_checking: &'static str,
    pub tool_update_latest: &'static str,
    pub tool_update_check_again: &'static str,
    pub tool_update_error: &'static str,
    pub tool_update_retry: &'static str,
    pub tool_update_check_btn: &'static str,
    pub tool_update_available: &'static str,
    // --- CONTINUOUS MODE ---
    pub continuous_mode_activated: &'static str, // "✨ Cấu hình \"{preset}\" sẽ hoạt động liên tục, bấm ESC hay {hotkey} để thoát"
}

impl LocaleText {
    pub fn get(lang_code: &str) -> Self {
        match lang_code {
            "vi" => Self {
                 history_btn: "Lịch sử",
                 history_title: "Thư viện kết quả",
                 max_items_label: "Giới hạn lưu:",
                 history_empty: "Chưa có lịch sử nào.",
                 clear_all_history_btn: "Dọn tất cả", 
                 view_image_btn: "Xem ảnh",
                 listen_audio_btn: "Nghe audio",
                 view_text_btn: "Xem text",

                 prompt_mode_fixed: "Làm theo lệnh sẵn",
                 prompt_mode_dynamic: "Viết lệnh tại chỗ",

                 get_key_link: "Lấy tại console.groq.com",
                 gemini_api_key_label: "Mã API Gemini:",
                 gemini_get_key_link: "Lấy mã tại aistudio.google.com",
                 openrouter_api_key_label: "Mã API OpenRouter:",
                 openrouter_get_key_link: "Lấy mã tại openrouter.ai",
                 use_groq_checkbox: "Groq",
                 use_gemini_checkbox: "Gemini",
                 use_openrouter_checkbox: "OpenRouter",
                 cerebras_api_key_label: "Mã API Cerebras:",
                 cerebras_get_key_link: "Lấy mã tại cloud.cerebras.ai",
                 use_cerebras_checkbox: "Cerebras",

                global_settings: "Cài Đặt Chung",
                preset_name_label: "Tên Cấu Hình:",



                search_placeholder: "Tìm...",

                auto_paste_label: "Tự động dán",
                auto_paste_newline_label: "Tự thêm ký tự xuống dòng sau khi copy",
                startup_label: "Khởi động cùng Windows",
                add_hotkey_button: "+ Thêm Phím",
                press_keys: "Ấn tổ hợp phím...",
                cancel_label: "Hủy",
                reset_defaults_btn: "Khôi phục mặc định",
                force_quit: "Buộc thoát",



                preset_type_label: "Loại hình:",
                preset_type_image: "Hiểu hình ảnh",
                preset_type_audio: "Hiểu âm thanh",
                preset_type_video: "Hiểu video (upcoming)",
                preset_type_text: "Hiểu văn bản", // NEW



                audio_source_label: "Nguồn:",
                audio_src_mic: "Microphone",
                audio_src_device: "Âm thanh máy tính",
                hide_recording_ui_label: "Ẩn giao diện ghi âm",
                auto_stop_recording_label: "Tự động dừng",
                hotkeys_section: "Phím tắt",
                start_in_tray_label: "Khởi động trong tray",
                footer_admin_running: "đang chạy bằng admin",
                admin_startup_on: "Chạy làm Admin khi khởi động",
                admin_startup_success: "Đã bật: Sẽ chạy Admin khi khởi động (Task Scheduler).",
                admin_startup_fail: "Lỗi: Cần chạy App bằng Admin để cài đặt tính năng này.",
                graphics_mode_label: "Đồ hoạ:",
                graphics_mode_standard: "Tiêu chuẩn (Hiệu ứng gradient glow)",
                graphics_mode_minimal: "Tối giản cho máy yếu (Hiệu ứng quét laser)",
                usage_statistics_title: "Thống kê sử dụng",
                usage_statistics_tooltip: "Dùng mô hình ít nhất một lần để hiện chính xác",
                usage_model_column: "Mô hình",
                usage_remaining_column: "Còn lại / Tổng",
                usage_check_link: "Xem lượng dùng ↗",

                footer_admin_text: "chạy bằng admin để dịch game",
                footer_version: "phiên bản",
                check_for_updates_btn: "Kiểm Tra Cập Nhật",
                current_version_label: "Phiên Bản Hiện Tại:",
                checking_github: "Đang kiểm tra GitHub...",
                up_to_date: "Bạn đang dùng phiên bản mới nhất",
                check_again_btn: "Kiểm Tra Lại",
                new_version_available: "Phiên bản mới có sẵn:",
                release_notes_label: "Ghi Chú Phát Hành",
                download_update_btn: "Tải Về & Cập Nhật Ngay",
                downloading_update: "Đang tải về... Ứng dụng sẽ cập nhật tại chỗ.",
                update_failed: "Cập Nhật Thất Bại:",
                app_folder_writable_hint: "Đảm bảo rằng thư mục ứng dụng có thể ghi được.",
                retry_btn: "Thử Lại",
                update_success: "Cập Nhật Thành Công!",
                restart_to_use_new_version: "Khởi động lại để sử dụng phiên bản mới.",
                restart_app_btn: "Khởi Động Lại Ứng Dụng",
                // --- NEW TEXT INPUT FIELDS VI ---
                text_input_mode_label: "Phương thức:",
                text_mode_select: "Hotkey rồi bôi text",
                text_mode_type: "Hotkey rồi gõ",
                continuous_input_label: "Nhập liên tục",
                command_mode_label: "Lệnh:",
                text_input_title_default: "Nhập văn bản cần xử lý:",
                text_input_placeholder: "Nội dung cần xử lý ...",
                text_input_footer_submit: "Enter để Gửi",
                text_input_footer_newline: "Shift+Enter xuống dòng",
                text_input_footer_cancel: "để Hủy",
                add_text_preset_btn: "+ Text",
                add_image_preset_btn: "+ Ảnh",
                add_audio_preset_btn: "+ Âm thanh",
                // --- PROCESSING CHAIN UI VI ---
                node_input_prefix: "Đầu vào:",
                node_input_audio: "Âm thanh",
                node_input_image: "Hình ảnh",
                node_input_text: "Văn bản",
                node_process_title: "Text -> Text",
                node_special_default: "Xử lý đặc biệt",
                node_special_image_to_text: "Ảnh -> Text",
                node_special_audio_to_text: "Audio -> Text",
                node_menu_add_normal: "➕ Thêm node Text -> Text",
                node_menu_add_special_generic: "⭐ Thêm node đặc biệt",
                node_menu_add_special_image: "⭐ Thêm node Ảnh -> Text",
                node_menu_add_special_audio: "⭐ Thêm node Audio -> Text",
                input_auto_copy_tooltip: "Tự động copy (Nguồn)",
                input_auto_speak_tooltip: "Đọc to nguồn",


                tips_title: "Mẹo sử dụng",
                tips_click_hint: "Click vào dòng chữ này để xem danh sách mẹo",
                tips_list: vec![
                    "Nhấp **chuột giữa** một overlay bất kỳ giúp xoá tất cả overlay trên màn hình!",
                    "**Chuột phải** lên một overlay giúp copy nhanh nội dung của overlay đó!",
                    "Khi đang vẽ hộp trên màn hình tối (chưa thả chuột), có thể bấm **ESC** hoặc Phím tắt một lần nữa để hủy.",
                    "Nếu thích ứng dụng **SGT** hãy bấm Star cho Github và chia sẻ cho mọi người biết nha!",
                    "Bạn có biết? Phím tắt có thể gán cho **chuột giữa, chuột 4, chuột 5** nữa nha, không chỉ cho bàn phím.",
                    "Nếu bị **crash** trong lúc hiện overlay thì bạn hãy thử đổi Đồ hoạ sang Tối giản thử xem!",
                    "Bạn không thể đổi tên các Cấu hình có sẵn nhưng **Cấu hình mới** thì đổi được bình thường nha!",
                    "**Thư viện lịch sử** kết quả có cơ chế tự dọn kết quả cũ khi vượt Giới hạn lưu nên bạn khỏi lo nha!",
                    "Trong chuỗi hành động, chỉ **một bước** trong đó được phép bật Tự động copy, hoặc không bước nào.",
                    "Dù **Tự động dán** có được bật, nó cần nó nơi dán text được (con trỏ text nhấp nháy) thì mới dán được.",
                    "Điều khiển **Tự thêm xuống dòng** sau khi copy chỉ xuất hiện khi Tự động copy bật (tại 1 bước nào đó).",
                    "Những tên Cấu hình có nền **xanh lá** nghĩa là nó đã được gán phím tắt để sẵn sàng sử dụng.",
                    "Kéo bằng **chuột trái** chỉ dịch chuyển overlay hiện tại nhưng chuột phải sẽ dịch chuyển hết các overlay cùng nhóm.",
                    "Trên **canvas**: cuộn: zoom, kéo: pan, click đúp: reset view, chuột phải: thêm node. Trên node: kéo: dời, chuột phải: xoá node.",
                    "Cơ chế đặc biệt của **chế độ bôi đen** text: Nếu text đã bôi đen sẵn, bấm phím tắt sẽ xử lý ngay và luôn!",
                    "**Thu âm** có chế độ dừng thông minh nữa đó, nhớ dùng thử nha",
                    "Khi lướt **web** ngay bên trong overlay, chỉ dùng chuột chứ không dùng bàn phím được, thông cảm nha",
                    "Gán phím tắt cho **'Ảnh MASTER'** hoặc **'Bôi MASTER'**,... để gọi vòng tròn chọn (Wheel), giúp truy cập nhiều công cụ chỉ với 1 phím.",
                    "Bấm nút **Chỉnh sửa** không chỉ để sửa text, bạn có thể nhập lệnh để AI viết lại nội dung (VD: 'Dịch sang tiếng Nhật').",
                    "Bạn có thể **kéo thả/dán** file ảnh hoặc file text trực tiếp vào cửa sổ cài đặt để xử lý ngay lập tức!",
                    "Bật **'Bong bóng yêu thích'** (Favorite Bubble) trong menu khay hệ thống để truy cập nhanh các cấu hình mà không cần nhớ phím tắt.",
                    "Trong Cài đặt giọng đọc, hãy thử **tuỳ chọn giọng Xịn** và điều chỉnh giọng vùng miền xem sao!",
                    "Chế độ **'Dịch cabin'** (Thời gian thực) có thể tự động điều chỉnh tốc độ đọc (TTS) để đuổi kịp tốc độ nói của người phát.",
                    "Bấm vào **nút chế độ hiển thị** (bên cạnh biểu tượng con mắt) để chuyển đổi giữa dạng văn bản thô và dạng Markdown/HTML đẹp mắt.",
                    "Các **mô hình** có biểu tượng kính lúp có khả năng truy cập internet để tìm dẫn chứng và thông tin mới nhất.",
                    "Khi **'Tự động copy'** kích hoạt, một thông báo nhỏ màu xanh sẽ hiện ra ở góc dưới màn hình để bạn biết nội dung đã vào Clipboard.",
                    "Không biết cách dùng? Mở **'Hỏi cách dùng SGT'** để trợ lý AI hướng dẫn bạn tận tình nhé!",
                    "Căng thẳng quá thì ghé **'Góc chill chill'** để tạo nhạc nền thư giãn vừa làm vừa chill.",
                    "Cần tải video/audio? **Trình tải đa năng** tích hợp sẵn hỗ trợ YouTube, Facebook và nhiều trang khác, hỗ trợ cả 4K và phụ đề!",
                    "**Giữ chặt Phím tắt** hoặc Cấu hình trong bong bóng để vào **Chế độ Liên tục**, giúp bạn xử lý nhiều vùng hoặc nhiều đoạn văn liên tiếp.",
                    "Bạn có bàn phím MIDI? Cắm vào máy khi mở **Góc chill chill** để điều chỉnh nhạc bằng núm vặn vật lý nhé!",
                     ],
                   restore_preset_btn: "Khôi phục",
                restore_preset_tooltip: "Đặt lại cài đặt về mặc định",
                // --- COMPOUND SEARCH UI VI ---
                search_doing: "Đang thực thi",
                search_searching: "tìm kiếm",
                search_query_label: "📝 Truy vấn tìm kiếm:",
                search_found_sources: "📚 ĐÃ TÌM THẤY {} NGUỒN",
                search_sources_label: "🌐 Nguồn tham khảo (theo độ liên quan):",
                search_no_title: "(Không có tiêu đề)",
                search_synthesizing: "⚡ ĐANG TỔNG HỢP THÔNG TIN...",
                search_analyzed_sources: "📊 Đã phân tích {} nguồn",
                search_processing: "🧠 Đang xử lý và tóm tắt kết quả...",
                // --- MASTER PRESET UI VI ---
                controller_checkbox_label: "Bộ điều khiển",

                // --- GLOBAL SETTINGS UI HEADERS VI ---
                api_keys_header: "🔑 Mã API",
                groq_label: "Mã API Groq:",
                software_update_header: "⬆ Cập Nhật Phần Mềm",
                startup_display_header: "⚙ Khởi Động & Hiển Thị",
                model_thinking: "💭 Đang suy nghĩ...",
                // --- REALTIME OVERLAY VI ---
                realtime_listening: "Đang nghe...",
                realtime_device: "Thiết bị",
                realtime_waiting: "Đang chờ nói...",
                realtime_translation: "Bản dịch",
                realtime_mic: "Micro",
                ollama_url_guide: "Xem hướng dẫn tại ollama.com",
                tts_settings_button: "Cài đặt giọng đọc",
                tts_settings_title: "Thiết lập Giọng Đọc",
                tts_method_label: "Phương pháp Đọc chữ (TTS):",
                tts_method_standard: "Xịn (Gemini Live)",
                tts_method_fast: "Nhanh (Google Translate)",
                tts_method_edge: "Tốt (Edge TTS)",
                tts_google_translate_title: "Google Translate TTS",
                tts_google_translate_desc: "Phương pháp này nhanh hơn và không cần khóa API.",
                tts_edge_title: "Microsoft Edge TTS",
                tts_edge_desc: "Giọng nói chất lượng cao. Miễn phí, không cần khóa API.",
                tts_pitch_label: "Cao độ:",
                tts_rate_label: "Tốc độ:",
                tts_voice_per_language_label: "Giọng theo ngôn ngữ:",
                tts_loading_voices: "Đang tải danh sách giọng...",
                tts_failed_load_voices: "Không thể tải giọng: {}",
                tts_retry_label: "Thử lại",
                tts_initializing_voices: "Đang khởi tạo danh sách giọng...",
                tts_add_language_label: "+ Thêm quy định giọng",
                tts_reset_to_defaults_label: "Khôi phục mặc định",
                tts_speed_label: "Tốc độ đọc:",
                tts_speed_normal: "Bình thường",
                tts_speed_slow: "Chậm",
                tts_speed_fast: "Nhanh",
                _tts_voice_label: "Giọng đọc:",
                tts_preview_texts: vec![
                    "Xin chào, tôi là {}, tôi có thể đọc giúp bạn đoạn văn này.",
                    "Cuộc sống thật đẹp tươi, {} rất vui khi được trò chuyện cùng bạn.",
                    "Hôm nay trời đẹp quá, {} nghĩ chúng ta nên đi dạo một chút.",
                    "Công nghệ giúp cuộc sống trở nên dễ dàng hơn, đúng không nào?",
                    "Hãy luôn giữ nụ cười trên môi nhé, {} chúc bạn một ngày vui vẻ.",
                    "Kiến thức là kho báu mà không ai có thể lấy đi.",
                    "Bạn đang nghe thử giọng đọc của {}, hy vọng bạn sẽ thích.",
                    "{} chúc bạn một ngày làm việc thật hiệu quả và tràn đầy năng lượng.",
                    "Đừng quên uống đủ nước mỗi ngày nhé.",
                    "Cảm ơn bạn đã sử dụng phần mềm Screen Goated Toolbox.",
                ],
                tts_male: "Nam",
                tts_female: "Nữ",
                tts_instructions_label: "Giọng điệu theo ngôn ngữ:",
                tts_instructions_hint: "VD: Đọc giọng miền Tây",
                tts_add_condition: "+ Thêm điều kiện...",
                // Realtime TTS modal
                realtime_tts_title: "Đọc phần Dịch",
                realtime_tts_speed: "Tốc độ",
                realtime_tts_auto: "Tự động",
                // App selection modal
                app_select_title: "Chọn Ứng Dụng",
                app_select_hint: "Chọn ứng dụng cần ghi âm (TTS sẽ được tách riêng)",
                // --- TRAY MENU VI ---
                tray_settings: "⚙️ Cài đặt",
                tray_quit: "Thoát",
                tray_favorite_bubble: "Hiện bong bóng yêu thích",
                tray_favorite_bubble_disabled: "Hiện bong bóng yêu thích (Chưa có mục yêu thích)",
                // --- FAVORITE BUBBLE VI ---
                 favorites_empty: "Vui lòng đưa ít nhất một cấu hình vào ưa thích",
                 favorites_keep_open: "Giữ mở",
                 recording_subtext: "Nhấn ESC/Hotkey để dừng",
                 recording_paused: "Đã tạm dừng",
                 // --- AUTO COPY BADGE VI ---
                 auto_copied_badge: "Đã tự động copy",
                 auto_copied_image_badge: "🖼️ Ảnh đã được sao chép",
                 live_translate_loading: "⏳ Đang khởi động Live Translate...",
                 text_input_loading: "⏳ Đang khởi động nhập văn bản...",
                 recording_loading: "⏳ Đang khởi động ghi âm...",
                 markdown_view_loading: "⏳ Đang khởi động xem kết quả...",
                 preset_wheel_loading: "⏳ Đang khởi động bảng chọn...",
                 prompt_dj_loading: "⏳ Đang khởi động Chill Corner...",
                 tray_popup_loading: "⏳ Đang khởi động menu...",
                 update_available_notification: "🎉 Có bản cập nhật mới!",
                 cannot_type_no_caret: "Dùng tự động dán/ghi nhưng chưa chọn chỗ để ghi!",
                 // --- DROP OVERLAY VI ---
                 drop_overlay_text: "Thả vào đây để xử lý",
                 // --- REALTIME EGUI SPECIFIC VI ---
                 device_mode_warning: "⚠ Đã chọn âm thanh thiết bị nhưng chưa chọn ứng dụng",
                 select_app_btn: "Chọn ứng dụng",
                 toggle_translation_tooltip: "Tắt/Mở dịch",
                 toggle_transcription_tooltip: "Tắt/Mở phụ đề",
                 font_minus_tooltip: "Giảm cỡ chữ",
                 font_plus_tooltip: "Tăng cỡ chữ",
                 google_gtx_label: "Google Dịch",
                 opacity_label: "Độ mờ",
                 downloaded_successfully: "Đã tải về!",
                 download_recording_tooltip: "Tải bản ghi âm",
                 // --- HELP ASSISTANT VI ---
                 help_assistant_btn: "Hỏi cách dùng SGT...",
                 help_assistant_title: "Hỏi về SGT",
                 help_assistant_question_label: "Câu hỏi của bạn:",
                 help_assistant_placeholder: "VD: Làm sao để dịch một vùng trên màn hình?",
                 help_assistant_ask_btn: "Hỏi",
                 help_assistant_loading: "Đang tìm câu trả lời...",
                 help_assistant_answer_label: "Trả lời:",
                 help_assistant_hint: "Nhập câu hỏi về cách sử dụng SGT và nhấn Enter hoặc nút Hỏi",
                  prompt_dj_btn: "Góc chill chill",
                  prompt_dj_title: "PromptDJ - Góc chill chill",
                  screen_record_btn: "Quay màn hình",
                  screen_record_title: "Screen Record - Quay màn hình",
                  // --- PARAKEET DOWNLOAD MODAL VI ---
                  parakeet_downloading_title: "Đang tải mô hình Parakeet (0.6 GB)",
                  parakeet_downloading_message: "Vui lòng đợi...",
                  parakeet_downloading_file: "Đang tải {}...",
                  parakeet_supports_english_only: "(Chỉ hỗ trợ tiếng Anh)",
                  overlay_copy_tooltip: "Sao chép",
                  overlay_undo_tooltip: "Hoàn tác",
                  overlay_redo_tooltip: "Làm lại",
                  overlay_edit_tooltip: "Chỉnh sửa / Viết lại",
                  overlay_refine_placeholder: "Chỉnh sửa kết quả...",
                  overlay_markdown_tooltip: "Bật/Tắt Markdown",
                  overlay_download_tooltip: "Tải về HTML",
                  overlay_speaker_tooltip: "Đọc to (TTS)",
                  overlay_broom_tooltip: "Chổi: Trái - Đóng | Phải - Đóng nhóm | Giữa - Đóng hết | Kéo - Dời | Kéo phải - Dời nhóm | Kéo giữa - Dời hết",
                  overlay_back_tooltip: "Quay lại",
                  overlay_forward_tooltip: "Tiếp theo",
                  overlay_opacity_tooltip: "Độ mờ",
                  
                  download_feature_btn: "Tải video/audio mọi nguồn",
                  download_feature_title: "Tải video/audio mọi nguồn",
                  download_delete_deps_btn: "Xoá yt-dlp ({}) và ffmpeg ({})",
                  download_url_label: "URL:",
                  download_format_label: "Định dạng:",
                  download_start_btn: "TẢI VỀ NGAY",
                  download_open_file_btn: "Mở file",
                  download_open_folder_btn: "Mở thư mục",
                  download_status_starting: "Đang bắt đầu...",
                  download_status_finished: "Đã tải xong!",
                  download_status_error: "Lỗi:",
                  download_deps_missing: "Cần các tool sau (Có thể xoá đi):",
                  download_deps_ytdlp: "yt-dlp:",
                  download_deps_ffmpeg: "ffmpeg:",
                  download_deps_download_btn: "Tải về",
                  download_status_ready: "✅ Sẵn sàng",
                  download_status_extracting: "Đang giải nén...",
                  download_cancel_btn: "Hủy",
                  download_file_label: "Tập tin:",
                  download_size_label: "Kích thước:",
                  download_change_folder_btn: "Thay đổi nơi lưu...",

                  download_progress_info_fmt: "{}% của {}, tốc độ {}, còn {}",
                  download_advanced_header: "Tính năng nâng cao",
                  download_opt_metadata: "Full Metadata (Ảnh bìa, Chapter, Info)",
                  download_opt_sponsorblock: "Lược bỏ quảng cáo, ... (SponsorBlock)",
                  download_opt_subtitles: "Tải phụ đề (Embed/SRT)",
                  download_opt_playlist: "Tải cả danh sách phát (Playlist)",
                  download_opt_cookies: "Lấy Cookies từ trình duyệt (để tải nội dung Premium/Age-gated):",
                  download_scan_ignore_btn: "TẢI VỀ NGAY (mặc kệ quét tìm chất lượng)",
                  download_quality_label_text: "Chất lượng:",
                  download_quality_best: "Tốt nhất",
                  download_scanning_label: "(Đang quét...)",
                  download_no_cookie_option: "Không dùng cookie",
                  download_show_log_btn: "Hiện nhật ký lỗi",
                  download_hide_log_btn: "Ẩn nhật ký lỗi",
                  download_subtitle_label: "Phụ đề:",
                  download_subtitle_auto: "Tự động",
                  download_subs_found_header: "NN đã tìm thấy",
                  download_subs_none_found: "Không tìm thấy phụ đề",
                  
                  downloaded_tools_button: "Công cụ đã tải",
                  downloaded_tools_title: "Quản lý công cụ đã tải",
                  tool_parakeet: "Mô hình Parakeet Realtime",
                  tool_ytdlp: "Công cụ yt-dlp",
                  tool_ffmpeg: "Công cụ ffmpeg",
                  tool_status_installed: "Đã tải ({})",
                  tool_status_missing: "Chưa tải",
                  tool_action_download: "Tải về",
                  tool_action_delete: "Xoá",
                  tool_desc_parakeet: "Dùng trong tính năng Dịch cabin và là mô hình \"Stream offline\" trong node Audio->Text",
                  tool_desc_ytdlp: "Dùng trong tính năng Tải media",
                   tool_desc_ffmpeg: "Dùng trong tính năng Tải media",
                   tool_update_checking: "Đang kiểm tra...",
                   tool_update_latest: "Đã là mới nhất",
                   tool_update_check_again: "Kiểm tra lại",
                   tool_update_error: "Lỗi",
                   tool_update_retry: "Thử lại",
                   tool_update_check_btn: "Kiểm tra cập nhật",
                   tool_update_available: "Cập nhật ({})",
                   continuous_mode_activated: "✨ Cấu hình \"{preset}\" sẽ hoạt động liên tục, bấm ESC hay {hotkey} để thoát",
                   },
            "ko" => Self {
                 history_btn: "히스토리",
                 history_title: "결과 라이브러리",
                 max_items_label: "저장 한도:",
                 history_empty: "기록이 없습니다.",
                 clear_all_history_btn: "모두 삭제",
                 view_image_btn: "이미지 보기",
                 listen_audio_btn: "오디오 듣기",
                 view_text_btn: "텍스트 보기",

                 prompt_mode_fixed: "사전 정의된 프롬프트",
                 prompt_mode_dynamic: "즉석에서 작성",

                get_key_link: "console.groq.com에서 API 키 받기",
                gemini_api_key_label: "Gemini API 키:",
                gemini_get_key_link: "aistudio.google.com에서 API 키 받기",
                openrouter_api_key_label: "OpenRouter API 키:",
                openrouter_get_key_link: "openrouter.ai에서 API 키 받기",
                use_groq_checkbox: "Groq",
                use_gemini_checkbox: "Gemini",
                use_openrouter_checkbox: "OpenRouter",
                cerebras_api_key_label: "Cerebras API 키:",
                cerebras_get_key_link: "cloud.cerebras.ai에서 API 키 받기",
                use_cerebras_checkbox: "Cerebras",

                global_settings: "전역 설정",
                preset_name_label: "프리셋 이름:",



                search_placeholder: "검색...",

                auto_paste_label: "자동 붙여넣기",
                auto_paste_newline_label: "복사 후 자동 줄바꿈 추가",
                startup_label: "Windows 시작 시 실행",
                add_hotkey_button: "+ 키 추가",
                press_keys: "조합 키 누르기...",
                cancel_label: "취소",
                reset_defaults_btn: "기본값으로 재설정",
                force_quit: "강제 종료",



                preset_type_label: "유형:",
                preset_type_image: "이미지 이해",
                preset_type_audio: "오디오 이해",
                preset_type_video: "비디오 이해 (upcoming)",
                preset_type_text: "텍스트 이해", // NEW



                audio_source_label: "오디오 소스:",
                audio_src_mic: "마이크",
                audio_src_device: "컴퓨터 오디오",
                hide_recording_ui_label: "녹음 UI 숨기기",
                auto_stop_recording_label: "자동 중지",
                hotkeys_section: "단축키",
                start_in_tray_label: "트레이로 시작",
                footer_admin_running: "관리자 권한으로 실행 중",
                admin_startup_on: "시작 시 관리자로 실행",
                admin_startup_success: "활성화됨: 시작 시 관리자 권한으로 실행됩니다 (작업 스케줄러).",
                admin_startup_fail: "오류: 이 설정은 관리자 권한으로 실행해야 변경 가능합니다.",
                graphics_mode_label: "그래픽:",
                graphics_mode_standard: "표준 (그래디언트 글로우 효과)",
                graphics_mode_minimal: "최소 (약한 컴퓨터용, 레이저 스캔 효과)",
                usage_statistics_title: "사용 통계",
                usage_statistics_tooltip: "정확한 데이터를 보려면 모델을 최소 한 번 사용하세요",
                usage_model_column: "모델",
                usage_remaining_column: "남은 / 전체",
                usage_check_link: "사용량 확인 ↗",

                footer_admin_text: "게임을 번역하려면 관리자로 실행하세요",
                footer_version: "버전",
                check_for_updates_btn: "업데이트 확인",
                current_version_label: "현재 버전:",
                checking_github: "GitHub를 확인 중...",
                up_to_date: "최신 버전을 사용 중입니다",
                check_again_btn: "다시 확인",
                new_version_available: "새 버전을 사용할 수 있습니다:",
                release_notes_label: "릴리스 노트",
                download_update_btn: "지금 다운로드 & 업데이트",
                downloading_update: "다운로드 중... 앱이 제자리에서 업데이트됩니다.",
                update_failed: "업데이트 실패:",
                app_folder_writable_hint: "앱 폴더에 쓰기 권한이 있는지 확인하세요.",
                retry_btn: "다시 시도",
                update_success: "업데이트 성공!",
                restart_to_use_new_version: "새 버전을 사용하려면 다시 시작하세요.",
                restart_app_btn: "앱 다시 시작",
                // --- NEW TEXT INPUT FIELDS KO ---
                text_input_mode_label: "작동 방식:",
                text_mode_select: "단축키 후 텍스트 선택",
                text_mode_type: "단축키 후 입력",
                continuous_input_label: "연속 입력",
                command_mode_label: "명령:",
                text_input_title_default: "처리할 텍스트 입력:",
                text_input_placeholder: "처리할 내용 ...",
                text_input_footer_submit: "Enter: 제출",
                text_input_footer_newline: "Shift+Enter: 줄바꿈",
                text_input_footer_cancel: "취소",
                add_text_preset_btn: "+ 텍스트",
                add_image_preset_btn: "+ 이미지",
                add_audio_preset_btn: "+ 오디오",
                // --- PROCESSING CHAIN UI KO ---
                node_input_prefix: "입력:",
                node_input_audio: "오디오",
                node_input_image: "이미지",
                node_input_text: "텍스트",
                node_process_title: "텍스트 -> 텍스트",
                node_special_default: "특별 처리",
                node_special_image_to_text: "이미지 -> 텍스트",
                node_special_audio_to_text: "오디오 -> 텍스트",
                node_menu_add_normal: "➕ 텍스트 -> 텍스트 노드 추가",
                node_menu_add_special_generic: "⭐ 특별 노드 추가",
                node_menu_add_special_image: "⭐ 이미지 -> 텍스트 노드 추가",
                node_menu_add_special_audio: "⭐ 오디오 -> 텍스트 노드 추가",
                input_auto_copy_tooltip: "자동 복사 (소스)",
                input_auto_speak_tooltip: "소스 읽기",


                tips_title: "사용 팁",
                tips_click_hint: "이 텍스트를 클릭하여 팁 목록 보기",
                tips_list: vec![
                    "오버레이를 **마우스 가운데 버튼(휠)**으로 클릭하면 모든 오버레이가 닫힙니다!",
                    "오버레이를 **마우스 오른쪽 버튼**으로 클릭하면 내용이 빠르게 복사됩니다!",
                    "화면이 어두워진 상태(캡처 중)에서 **ESC**나 단축키를 다시 누르면 취소됩니다.",
                    "**SGT** 앱이 마음에 드신다면 Github에서 Star를 눌러주시고 공유해주세요!",
                    "알고 계셨나요? **단축키**는 키보드뿐만 아니라 마우스 휠, 버튼 4, 5에도 지정 가능합니다!",
                    "오버레이 표시 중 렉이 걸린다면 **그래픽 설정**을 '최소'로 변경해보세요!",
                    "기본 프리셋 이름은 변경할 수 없지만, **새로 만든 프리셋**은 변경 가능합니다!",
                    "**히스토리**는 저장 한도를 초과하면 오래된 항목부터 자동으로 삭제됩니다.",
                    "작업 체인에서는 **한 단계만** 자동 복사를 활성화할 수 있으며, 또는 어떤 단계도 활성화할 수 없습니다.",
                    "자동 붙여넣기가 활성화되어 있어도 **텍스트 입력 위치(깜박이는 커서)**가 있어야만 작동합니다.",
                    "자동 줄바꿈 추가 컨트롤은 **자동 복사**가 활성화되어 있을 때(한 단계 이상에서)만 나타납니다.",
                    "녹색 배경의 **프리셋 이름**은 단축키가 이미 할당되어 사용할 준비가 된 것을 의미합니다.",
                    "왼쪽 마우스로 드래그하면 **현재 오버레이**만 이동하지만, 오른쪽 마우스로 드래그하면 같은 그룹의 모든 오버레이가 이동합니다.",
                    "캔버스에서: 스크롤: 확대/축소, 드래그: 이동, 더블 클릭: 보기 초기화, 오른쪽 클릭: 노드 추가. **노드**에서: 드래그: 이동, 오른쪽 클릭: 노드 삭제.",
                    "텍스트 선택 모드의 특별한 기능: 이미 **텍스트가 선택**되어 있으면 단축키를 누르면 즉시 처리됩니다!",
                    "**오디오 녹음**에는 스마트 중지 모드도 있으니 꼭 써보세요!",
                    "오버레이 내에서 **웹**을 탐색할 때는 마우스만 사용하세요 - 키보드는 작동하지 않습니다, 양해 부탁드립니다!",
                    "'**이미지 MASTER**' 또는 '**선택 MASTER**'에 단축키를 지정하면 휠 선택기가 열려 여러 도구에 한 번에 액세스할 수 있습니다!",
                    "편집 버튼을 클릭하여 **텍스트를 수정**할 뿐만 아니라, AI에게 콘텐츠를 다시 작성하도록 명령을 입력할 수 있습니다(예: '일본어로 번역').",
                    "이미지 파일이나 **텍스트 파일**을 설정 창으로 직접 드래그하여 놓거나 붙여넣어 즉시 처리할 수 있습니다!",
                    "시스템 트레이 메뉴에서 **즐겨찾기 버블**을 활성화하여 단축키를 기억하지 않고도 구성에 빠르게 액세스할 수 있습니다.",
                    "음성 설정에서 **표준 음성 옵션**을 시도하고 지역 억양을 조정하여 최적의 설정을 찾아보세요!",
                    "**실시간 번역** 모드는 읽기 속도(TTS)를 자동으로 조정하여 말하는 사람의 속도에 맞출 수 있습니다.",
                    "디스플레이 모드 **버튼**(눈 아이콘 옆)을 클릭하여 일반 텍스트와 아름답게 포맷된 Markdown/HTML 보기 사이를 전환합니다.",
                    "돋보기 아이콘이 있는 **모델**은 인터넷에 액세스하여 인용문과 최신 정보를 찾을 수 있습니다.",
                    "자동 복사가 활성화되면 **화면 하단**에 작은 녹색 알림이 나타나 콘텐츠가 클립보드에 복사되었음을 확인할 수 있습니다.",
                    "사용 방법을 모르신다면? **'SGT 사용법 물어보기'**를 열어서 AI 어시스턴트에게 친절한 안내를 받으세요!",
                    "스트레스를 받을 땐 **'힐링 공간'**에 가서 편안한 배경음악을 만들어 업무 중에 힐링하세요.",
                    "비디오/오디오 다운로드가 필요하신가요? 내장된 **만능 다운로더**는 YouTube, Facebook 등 다양한 사이트의 4K 및 자막을 지원합니다!",
                    "**단축키** 또는 버블의 프리셋을 **길게 누르면** **연속 모드**로 진입하여, 여러 영역이나 텍스트를 연속으로 처리할 수 있습니다.",
                    "MIDI 키보드가 있나요? **힐링 공간**을 열 때 연결하면 물리 노브로 음악을 조절할 수 있습니다!",
                     ],
                   restore_preset_btn: "복원",
                   restore_preset_tooltip: "기본 설정으로 초기화",
                   // --- COMPOUND SEARCH UI KO ---
                   search_doing: "진행 중:",
                   search_searching: "검색",
                   search_query_label: "📝 검색 쿼리:",
                   search_found_sources: "📚 {} 소스 발견",
                   search_sources_label: "🌐 참고 소스 (관련도순):",
                   search_no_title: "(제목 없음)",
                   search_synthesizing: "⚡ 정보 종합 중...",
                   search_analyzed_sources: "📊 {} 소스 분석 완료",
                   search_processing: "🧠 결과 처리 및 요약 중...",
                   // --- MASTER PRESET UI KO ---
                   controller_checkbox_label: "컨트롤러",

                   // --- GLOBAL SETTINGS UI HEADERS KO ---
                   api_keys_header: "🔑 API 키",
                   groq_label: "Groq API 키:",
                   software_update_header: "⬆ 소프트웨어 업데이트",
                   startup_display_header: "⚙ 시작 및 표시",
                   model_thinking: "💭 생각 중...",
                // --- REALTIME OVERLAY KO ---
                realtime_listening: "듣고 있는 중...",
                realtime_device: "장치 오디오",
                realtime_waiting: "말하기 대기 중...",
                realtime_translation: "번역",
                realtime_mic: "마이크",
                ollama_url_guide: "올라마 설명서 보기",
                tts_settings_button: "TTS 설정",
                tts_settings_title: "TTS 설정",
                tts_method_label: "TTS 방식:",
                tts_method_standard: "표준 (Gemini Live)",
                tts_method_fast: "빠름 (Google Translate)",
                tts_method_edge: "좋음 (Edge TTS)",
                tts_google_translate_title: "Google Translate TTS",
                tts_google_translate_desc: "이 방식은 더 빠르며 API 키가 필요하지 않습니다.",
                tts_edge_title: "Microsoft Edge TTS",
                tts_edge_desc: "고품질 신경망 음성. 무료이며 API 키가 필요하지 않습니다.",
                tts_pitch_label: "피치:",
                tts_rate_label: "속도:",
                tts_voice_per_language_label: "언어별 음성:",
                tts_loading_voices: "음성 목록을 불러오는 중...",
                tts_failed_load_voices: "음성 로드 실패: {}",
                tts_retry_label: "다시 시도",
                tts_initializing_voices: "음성 목록을 초기화 중...",
                tts_add_language_label: "+ 음성 설정 추가",
                tts_reset_to_defaults_label: "기본값으로 재설정",
                tts_speed_label: "읽기 속도:",
                tts_speed_normal: "보통",
                tts_speed_slow: "느림",
                tts_speed_fast: "빠름",
                _tts_voice_label: "목소리:",
                tts_preview_texts: vec![
                    "안녕하세요, 제 이름은 {}입니다. 만나서 반갑습니다.",
                    "오늘 날씨가 정말 좋네요, {}와 함께 산책 어떠세요?",
                    "무엇을 도와드릴까요? 언제든 {}에게 말씀해주세요.",
                    "{}가 행복한 하루 보내시길 바랍니다.",
                    "이것은 음성 합성 테스트 문장입니다. {}의 목소리는 어떤가요?",
                    "한국어 발음이 자연스럽게 들리나요?",
                    "꿈을 향해 꾸준히 나아가세요, {}가 응원할게요.",
                    "건강이 가장 중요하니 챙기세요.",
                    "잠시 휴식을 취하는 것도 좋은 방법입니다.",
                    "Screen Goated Toolbox를 사용해주셔서 감사합니다.",
                ],
                 tts_male: "남성",
                 tts_female: "여성",
                 tts_instructions_label: "언어별 말투:",
                 tts_instructions_hint: "예: 사투리로 말해",
                 tts_add_condition: "+ 조건 추가...",
                // Realtime TTS modal
                realtime_tts_title: "번역 읽기",
                realtime_tts_speed: "속도",
                realtime_tts_auto: "자동",
                // App selection modal
                app_select_title: "앱 선택",
                app_select_hint: "녹음할 앱을 선택하세요 (TTS는 분리됨)",
                // --- TRAY MENU KO ---
                tray_settings: "⚙️ 설정",
                tray_quit: "종료",
                tray_favorite_bubble: "즐겨찾기 버블 표시",
                tray_favorite_bubble_disabled: "즐겨찾기 버블 표시 (즐겨찾기 없음)",
                // --- FAVORITE BUBBLE KO ---
                 favorites_empty: "즐겨찾기에 최소한 하나의 프리셋을 추가해주세요",
                 favorites_keep_open: "열린 상태 유지",
                 recording_subtext: "ESC/Hotkey를 눌러 중지",
                 recording_paused: "일시 중지됨",
                 // --- AUTO COPY BADGE KO ---
                 auto_copied_badge: "자동으로 복사됨",
                 auto_copied_image_badge: "🖼️ 이미지가 복사됨",
                 live_translate_loading: "⏳ 실시간 번역 로딩 중...",
                 text_input_loading: "⏳ 텍스트 입력 로딩 중...",
                 recording_loading: "⏳ 녹음 로딩 중...",
                 markdown_view_loading: "⏳ 결과 보기 로딩 중...",
                 preset_wheel_loading: "⏳ 선택 휠 로딩 중...",
                 prompt_dj_loading: "⏳ Chill Corner 로딩 중...",
                 tray_popup_loading: "⏳ 메뉴 로딩 중...",
                 update_available_notification: "🎉 새 업데이트 이용 가능!",
                 cannot_type_no_caret: "자동 붙여넣기/쓰기가 활성화되었지만 텍스트 입력이 선택되지 않았습니다!",
                 // --- DROP OVERLAY KO ---
                 drop_overlay_text: "여기에 드롭하여 처리",
                 // --- REALTIME EGUI SPECIFIC KO ---
                 device_mode_warning: "⚠ 장치 오디오가 선택되었지만 앱이 선택되지 않았습니다",
                 select_app_btn: "앱 선택",
                 toggle_translation_tooltip: "번역 켜기/끄기",
                 toggle_transcription_tooltip: "자막 켜기/끄기",
                 font_minus_tooltip: "글꼴 축소",
                 font_plus_tooltip: "글꼴 확대",
                 google_gtx_label: "Google 번역",
                 opacity_label: "불투명도",
                 downloaded_successfully: "다운로드 완료!",
                 download_recording_tooltip: "녹음 다운로드",
                 
                 download_feature_btn: "모든 소스에서 비디오/오디오 다운로드",
                 download_feature_title: "모든 소스에서 비디오/오디오 다운로드",
                 download_delete_deps_btn: "yt-dlp ({}) 및 ffmpeg ({}) 삭제",
                 download_url_label: "URL:",
                 download_format_label: "형식:",
                 download_start_btn: "다운로드 시작",
                 download_open_file_btn: "파일 열기",
                 download_open_folder_btn: "폴더 열기",
                 download_status_starting: "시작 중...",
                 download_status_finished: "다운로드 완료!",
                 download_status_error: "오류:",
                 download_deps_missing: "필수 도구 (삭제 가능):",
                 download_deps_ytdlp: "yt-dlp:",
                 download_deps_ffmpeg: "ffmpeg:",
                 download_deps_download_btn: "다운로드",
                 download_status_ready: "✅ 준비됨",
                 download_status_extracting: "압축 해제 중...",
                 download_cancel_btn: "취소",
                 download_file_label: "파일:",
                 download_size_label: "크기:",
                 download_change_folder_btn: "폴더 변경...",
                  download_progress_info_fmt: "{}% / {}, 속도 {}, 남은 시간 {}",
                  download_advanced_header: "고급 기능",
                  download_opt_metadata: "메타데이터 포함 (썸네일, 챕터, 정보)",
                  download_opt_sponsorblock: "SponsorBlock (광고/후원 자동 건너뛰기)",
                  download_opt_subtitles: "자막 다운로드 (Embed/SRT)",
                  download_opt_playlist: "재생 목록 다운로드 (Playlist)",
                  download_opt_cookies: "브라우저 쿠키 사용 (연령 제한/프리미엄 콘텐츠):",
                  download_scan_ignore_btn: "지금 다운로드 (화질 검색 무시)",
                  download_quality_label_text: "화질:",
                  download_quality_best: "최고 화질",
                  download_scanning_label: "(스캔 중...)",
                  download_no_cookie_option: "쿠키 사용 안 함",
                  download_show_log_btn: "오류 로그 보기",
                  download_hide_log_btn: "오류 로그 숨기기",

                  downloaded_tools_button: "다운로드된 도구",
                  downloaded_tools_title: "다운로드된 도구 관리",
                  tool_parakeet: "Parakeet 실시간 모델",
                  tool_ytdlp: "yt-dlp 도구",
                  tool_ffmpeg: "ffmpeg 도구",
                  tool_status_installed: "설치됨 ({})",
                  tool_status_missing: "설치되지 않음",
                  tool_action_download: "다운로드",
                  tool_action_delete: "삭제",
                  tool_desc_parakeet: "캐빈 번역 기능 및 Audio->Text 노드의 \"Stream offline\" 모델로 사용됩니다",
                  tool_desc_ytdlp: "미디어 다운로드 기능에서 사용됨",
                   tool_desc_ffmpeg: "미디어 다운로드 기능에서 사용됨",
                   tool_update_checking: "확인 중...",
                   tool_update_latest: "최신 버전",
                   tool_update_check_again: "다시 확인",
                   tool_update_error: "오류",
                   tool_update_retry: "재시도",
                   tool_update_check_btn: "업데이트 확인",
                   tool_update_available: "업데이트 ({})",
// --- HELP ASSISTANT KO ---
                 help_assistant_btn: "SGT 사용법 물어보기...",
                 help_assistant_title: "SGT에 대해 물어보기",
                 help_assistant_question_label: "질문:",
                 help_assistant_placeholder: "예: 화면 영역을 번역하려면 어떻게 하나요?",
                 help_assistant_ask_btn: "질문",
                 help_assistant_loading: "답변을 찾는 중...",
                 help_assistant_answer_label: "답변:",
                 help_assistant_hint: "SGT 사용법에 대한 질문을 입력하고 Enter 또는 질문 버튼을 누르세요",
                  prompt_dj_btn: "힐링 공간",
                  prompt_dj_title: "PromptDJ - 힐링 공간",
                  screen_record_btn: "화면 녹화",
                  screen_record_title: "Screen Record - 화면 녹화",
                  // --- PARAKEET DOWNLOAD MODAL KO ---
                  parakeet_downloading_title: "Parakeet 모델 다운로드 중 (0.6 GB)",
                  parakeet_downloading_message: "잠시만 기다려주세요...",
                  parakeet_downloading_file: "{} 다운로드 중...",
                   parakeet_supports_english_only: "(영어만 지원됨)",
                   overlay_copy_tooltip: "복사",
                   overlay_undo_tooltip: "실행 취소",
                   overlay_redo_tooltip: "다시 실행",
                   overlay_edit_tooltip: "편집 / 다듬기",
                   overlay_refine_placeholder: "결과 수정...", // NEW
                   overlay_markdown_tooltip: "마크다운 토글",
                   overlay_download_tooltip: "HTML 저장",
                   overlay_speaker_tooltip: "텍스트 읽기 (TTS)",
                   overlay_broom_tooltip: "빗자루: 왼쪽 - 닫기 | 오른쪽 - 그룹 닫기 | 가운데 - 모두 닫기 | 드래그 - 이동 | 오른쪽 드래그 - 그룹 이동 | 가운데 드래그 - 모두 이동",
                   overlay_back_tooltip: "뒤로",
                   overlay_forward_tooltip: "앞으로",
                   overlay_opacity_tooltip: "불투명도",
                   download_subtitle_label: "자막:",
                   download_subtitle_auto: "자동",
                   download_subs_found_header: "찾은 언어",
                   download_subs_none_found: "자막을 찾을 수 없습니다",
                   continuous_mode_activated: "✨ 프리셋 \"{preset}\"이(가) 연속 모드로 실행됩니다. ESC 또는 {hotkey}를 눌러 종료",
                  },
                _ => Self {
                 history_btn: "History",
                 history_title: "Result Library",
                 max_items_label: "Max Items:",
                 history_empty: "No history yet.",
                 clear_all_history_btn: "Clear All",
                 view_image_btn: "View Image",
                 listen_audio_btn: "Listen Audio",
                 view_text_btn: "View Text",

                 prompt_mode_fixed: "Predefined Prompt",
                 prompt_mode_dynamic: "Write on the spot",

                get_key_link: "Get API Key at console.groq.com",
                gemini_api_key_label: "Gemini API Key:",
                gemini_get_key_link: "Get API Key at aistudio.google.com",
                openrouter_api_key_label: "OpenRouter API Key:",
                openrouter_get_key_link: "Get API Key at openrouter.ai",
                use_groq_checkbox: "Groq",
                use_gemini_checkbox: "Gemini",
                use_openrouter_checkbox: "OpenRouter",
                cerebras_api_key_label: "Cerebras API Key:",
                cerebras_get_key_link: "Get API Key at cloud.cerebras.ai",
                 use_cerebras_checkbox: "Cerebras",
                global_settings: "Global Settings",
                 preset_name_label: "Preset Name:",



                search_placeholder: "Search...",

                auto_paste_label: "Auto-paste",
                auto_paste_newline_label: "Auto add newline after copy",
                startup_label: "Run at Windows Startup",
                add_hotkey_button: "+ Add Key",
                press_keys: "Press combination...",
                cancel_label: "Cancel",
                reset_defaults_btn: "Reset to Defaults",
                force_quit: "Force Quit",



                preset_type_label: "Type:",
                preset_type_image: "Image Understanding",
                preset_type_audio: "Audio Understanding",
                preset_type_video: "Video Understanding (upcoming)",
                preset_type_text: "Text Understanding", // NEW



                audio_source_label: "Audio Source:",
                audio_src_mic: "Microphone",
                audio_src_device: "Device Audio",
                hide_recording_ui_label: "Hide Recording UI",
                auto_stop_recording_label: "Auto-stop",
                hotkeys_section: "Hotkeys",
                start_in_tray_label: "Start in tray",
                footer_admin_running: "running as admin",
                admin_startup_on: "Run as Administrator on startup",
                admin_startup_success: "Enabled: Will run as Admin on startup (Task Scheduler).",
                admin_startup_fail: "Error: Must run App as Admin to set this.",
                graphics_mode_label: "Graphics:",
                graphics_mode_standard: "Standard (Gradient glow effect)",
                graphics_mode_minimal: "Minimal for weak PC (Laser scan effect)",
                usage_statistics_title: "Usage Statistics",
                usage_statistics_tooltip: "Use a model at least once for accurate data",
                usage_model_column: "Model",
                usage_remaining_column: "Remaining / Total",
                usage_check_link: "Check Usage ↗",

                footer_admin_text: "Run with admin to translate games",
                footer_version: "Version",
                check_for_updates_btn: "Check for Updates",
                current_version_label: "Current Version:",
                checking_github: "Checking GitHub...",
                up_to_date: "You are up to date",
                check_again_btn: "Check Again",
                new_version_available: "New version available:",
                release_notes_label: "Release Notes",
                download_update_btn: "Download & Update Now",
                downloading_update: "Downloading... The app will update in-place.",
                update_failed: "Update Failed:",
                app_folder_writable_hint: "Make sure the app folder is writable.",
                retry_btn: "Retry",
                update_success: "Update Success!",
                restart_to_use_new_version: "Restart to use the new version.",
                restart_app_btn: "Restart App",
                // --- NEW TEXT INPUT FIELDS EN ---
                text_input_mode_label: "Mode:",
                text_mode_select: "Hotkey then Select Text",
                text_mode_type: "Hotkey then Type",
                continuous_input_label: "Continuous Input",
                command_mode_label: "Command:",
                text_input_title_default: "Enter text to process:",
                text_input_placeholder: "Content to process...",
                text_input_footer_submit: "Enter to Submit",
                text_input_footer_newline: "Shift+Enter for New Line",
                text_input_footer_cancel: "to Cancel",
                add_text_preset_btn: "+ Text",
                add_image_preset_btn: "+ Image",
                add_audio_preset_btn: "+ Audio",
                // --- PROCESSING CHAIN UI EN ---
                node_input_prefix: "Input:",
                node_input_audio: "Audio",
                node_input_image: "Image",
                node_input_text: "Text",
                node_process_title: "Text -> Text",
                node_special_default: "Special Node",
                node_special_image_to_text: "Image -> Text",
                node_special_audio_to_text: "Audio -> Text",
                node_menu_add_normal: "➕ Add Text -> Text Node",
                node_menu_add_special_generic: "⭐ Add Special Node",
                node_menu_add_special_image: "⭐ Add Image -> Text Node",
                node_menu_add_special_audio: "⭐ Add Audio -> Text Node",
                input_auto_copy_tooltip: "Auto-copy (Source)",
                input_auto_speak_tooltip: "Speak Source",


                tips_title: "Usage Tips",
                tips_click_hint: "Click text to view tip list",
                tips_list: vec![
                    "**Middle-click** any overlay window to instantly close ALL overlays!",
                    "**Right-click** an overlay to quickly copy its text content!",
                    "While drawing the box (dimmed screen), press **ESC** or Hotkey again to cancel.",
                    "If you like **SGT**, please give us a Star on Github and share it!",
                    "Did you know? **Hotkeys** can be assigned to Middle Mouse, Button 4, and 5!",
                    "If the overlay **crashes/lags**, try switching Graphics Mode to 'Minimal'!",
                    "You cannot rename default presets, but **custom presets** can be renamed freely!",
                    "The **History library** automatically cleans up old items when the limit is reached.",
                    "In the action chain, only **one step** can have Auto copy enabled, or no steps at all.",
                    "Even if **Auto-paste** is enabled, it requires a text cursor (blinking) at the paste location to work.",
                    "The **Auto add newline** control only appears when Auto copy is enabled (on at least one step).",
                    "Preset names with a **green/lime background** indicate they have a hotkey assigned and are ready to use.",
                    "Left-click drag moves only the **current overlay**, but right-click drag moves all overlays in the same group.",
                    "On **canvas**: scroll: zoom, drag: pan, double-click: reset view, right-click: add node. On node: drag: move, right-click: delete.",
                    "Text-select mode special feature: If **text is already highlighted**, pressing the hotkey will process it instantly!",
                    "**Audio recording** also has a smart stop mode, remember to try it!",
                    "When browsing the **web** directly in the overlay, use only the mouse - keyboard input won't work, sorry!",
                    "Assign a hotkey to **'Image MASTER'** or **'Selection MASTER'** to open the Wheel selector, giving you quick access to multiple tools with just one key!",
                    "Click the **Edit button** not only to fix text, but you can also type commands for AI to rewrite your content (e.g., 'Translate to Japanese').",
                    "You can **drag and drop** or paste image files or text files directly into the settings window for instant processing!",
                    "Enable the **Favorite Bubble** in the system tray menu to quickly access your configurations without needing to remember hotkeys.",
                    "In Voice Settings, try the **Standard voice** option and adjust the regional accent to see what works best for you!",
                    "The **Realtime Translation** mode can automatically adjust the reading speed (TTS) to keep up with the speaker's pace.",
                    "Click the **display mode button** (next to the eye icon) to switch between plain text and beautifully formatted Markdown/HTML views.",
                    "Models with a **magnifying glass icon** can access the internet to find citations and the latest information.",
                    "When **Auto-copy** is activated, a small green notification will appear at the bottom of your screen to confirm your content has been copied to the clipboard.",
                    "Not sure how to use SGT? Open **'Ask how to use SGT...'** and let the AI assistant guide you through it!",
                    "Feeling stressed? Visit the **'Chill Corner'** to create a relaxing background music experience while you work.",
                    "Need to download video/audio? The built-in **Universal Downloader** supports YouTube, Facebook, and more, including 4K and subtitles!",
                    "**Hold down the Hotkey** or the Preset in the bubble to enter **Continuous Mode**, allowing you to process multiple regions or texts in succession.",
                    "Got a MIDI keyboard? Plug it in when opening **Chill Corner** to adjust the music using physical knobs!",
                     ],
                   restore_preset_btn: "Restore",
                   restore_preset_tooltip: "Reset preset to default settings",
                   // --- COMPOUND SEARCH UI EN ---
                   search_doing: "Running",
                   search_searching: "searching",
                   search_query_label: "📝 Search queries:",
                   search_found_sources: "📚 FOUND {} SOURCES",
                   search_sources_label: "🌐 Reference sources (by relevance):",
                   search_no_title: "(No title)",
                   search_synthesizing: "⚡ SYNTHESIZING INFO...",
                   search_analyzed_sources: "📊 Analyzed {} sources",
                   search_processing: "🧠 Processing and summarizing results...",
                   // --- MASTER PRESET UI EN ---
                   controller_checkbox_label: "Controller",

                   // --- GLOBAL SETTINGS UI HEADERS EN ---
                   api_keys_header: "🔑 API Keys",
                   groq_label: "Groq API Key:",
                   software_update_header: "⬆ Software Update",
                   startup_display_header: "⚙ Startup & Display",
                   model_thinking: "💭 Thinking...",
                // --- REALTIME OVERLAY EN ---
                realtime_listening: "Listening...",
                realtime_device: "Device",
                realtime_waiting: "Waiting for speech...",
                realtime_translation: "Translation",
                realtime_mic: "Mic",
                ollama_url_guide: "View guide at ollama.com",
                tts_settings_button: "Voice Settings",
                tts_settings_title: "TTS Settings",
                tts_method_label: "TTS Method:",
                tts_method_standard: "Standard (Gemini Live)",
                tts_method_fast: "Fast (Google Translate)",
                tts_method_edge: "Edge TTS",
                tts_google_translate_title: "Google Translate TTS",
                tts_google_translate_desc: "This method is faster and doesn't require an API key.",
                tts_edge_title: "Microsoft Edge TTS",
                tts_edge_desc: "High-quality neural voices. Free, no API key required.",
                tts_pitch_label: "Pitch:",
                tts_rate_label: "Rate:",
                tts_voice_per_language_label: "Voice per Language:",
                tts_loading_voices: "Loading voice list...",
                tts_failed_load_voices: "Failed to load voices: {}",
                tts_retry_label: "Retry",
                tts_initializing_voices: "Initializing voice list...",
                tts_add_language_label: "+ Add Voice Config",
                tts_reset_to_defaults_label: "Reset to Defaults",
                tts_speed_label: "Reading Speed:",
                tts_speed_normal: "Normal",
                tts_speed_slow: "Slow",
                tts_speed_fast: "Fast",
                _tts_voice_label: "Voice:",
                tts_preview_texts: vec![
                    "Hello, I am {}, ready to read this text for you.",
                    "The quick brown fox jumps over the lazy dog.",
                    "Today is a beautiful day, {} hopes you learn something new.",
                    "Technology is rapidly changing the world we live in.",
                    "I hope you are having a wonderful day, from {}.",
                    "This is a demonstration of the synthetic voice capabilities of {}.",
                    "Remember to take breaks and rest your eyes.",
                    "Success is the sum of small efforts repeated day in and day out.",
                    "Stay curious and never stop exploring with {}.",
                    "Thank you for using Screen Goated Toolbox.",
                ],
                tts_male: "Male",
                tts_female: "Female",
                tts_instructions_label: "Per-language Accent:",
                tts_instructions_hint: "e.g. Use a Southern accent",
                tts_add_condition: "+ Add condition...",
                // Realtime TTS modal
                realtime_tts_title: "Read translation",
                realtime_tts_speed: "Speed",
                realtime_tts_auto: "AUTO",
                // App selection modal
                app_select_title: "Select App to Capture",
                app_select_hint: "Choose the app whose audio you want to transcribe (TTS isolated)",
                // --- TRAY MENU EN ---
                tray_settings: "⚙️ Settings",
                tray_quit: "Quit",
                tray_favorite_bubble: "Show favorite bubble",
                tray_favorite_bubble_disabled: "Show favorite bubble (No favorites set yet)",
                // --- FAVORITE BUBBLE EN ---
                 favorites_empty: "Please add at least one configuration to favorites",
                 favorites_keep_open: "Keep Open",
                 recording_subtext: "Press ESC/Hotkey to stop",
                 recording_paused: "Paused",
                 // --- AUTO COPY BADGE EN ---
                 auto_copied_badge: "Auto-copied",
                 auto_copied_image_badge: "🖼️ Image copied",
                 live_translate_loading: "⏳ Loading Live Translate...",
                 text_input_loading: "⏳ Loading text input...",
                 recording_loading: "⏳ Loading recording...",
                 markdown_view_loading: "⏳ Loading result viewer...",
                 preset_wheel_loading: "⏳ Loading preset selector...",
                 prompt_dj_loading: "⏳ Loading Chill Corner...",
                 tray_popup_loading: "⏳ Loading menu...",
                 update_available_notification: "🎉 New update available!",
                 cannot_type_no_caret: "Auto paste/write active but no text input selected!",
                 // --- DROP OVERLAY EN ---
                 drop_overlay_text: "Drop here to process",
                 // --- REALTIME EGUI SPECIFIC EN ---
                 device_mode_warning: "⚠ Device audio selected but no app chosen",
                 select_app_btn: "Select App",
                 toggle_translation_tooltip: "Toggle Translation",
                 toggle_transcription_tooltip: "Toggle Transcription",
                 font_minus_tooltip: "Font -",
                 font_plus_tooltip: "Font +",
                 google_gtx_label: "Google Translate",
                 opacity_label: "Opacity",
                 downloaded_successfully: "Downloaded!",
                 download_recording_tooltip: "Download Recording",
                 // --- HELP ASSISTANT EN ---
                 help_assistant_btn: "Ask how to use SGT...",
                 help_assistant_title: "Ask about SGT",
                 help_assistant_question_label: "Your question:",
                 help_assistant_placeholder: "E.g., How do I translate a region on screen?",
                 help_assistant_ask_btn: "Ask",
                 help_assistant_loading: "Finding answer...",
                 help_assistant_answer_label: "Answer:",
                 help_assistant_hint: "Enter a question about using SGT and press Enter or click Ask",
                  prompt_dj_btn: "Chill Corner",
                  prompt_dj_title: "PromptDJ - Chill Corner",
                  screen_record_btn: "Screen Record",
                  screen_record_title: "Screen Record",
                  // --- PARAKEET DOWNLOAD MODAL EN ---
                  parakeet_downloading_title: "Downloading Parakeet (0.6 GB)",
                  parakeet_downloading_message: "Please wait...",
                  parakeet_downloading_file: "Downloading {}...",
                   parakeet_supports_english_only: "(Only supports English)",
                   overlay_copy_tooltip: "Copy",
                   overlay_undo_tooltip: "Undo",
                   overlay_redo_tooltip: "Redo",
                   overlay_edit_tooltip: "Edit / Refine",
                   overlay_refine_placeholder: "Refine result...",
                   overlay_markdown_tooltip: "Toggle Markdown",
                   overlay_download_tooltip: "Save HTML",
                   overlay_speaker_tooltip: "Speak (TTS)",
                   overlay_broom_tooltip: "Broom: Left - Close | Right - Close Group | Middle - Close All | Drag - Move | Right-Drag - Move Group | Middle-Drag - Move All",
                   overlay_back_tooltip: "Back",
                   overlay_forward_tooltip: "Forward",
                   overlay_opacity_tooltip: "Opacity",
                   
                   download_feature_btn: "Download Video/Audio from Anywhere",
                   download_feature_title: "Download Video/Audio from Anywhere",
                   download_delete_deps_btn: "Delete yt-dlp ({}) and ffmpeg ({})",
                   download_url_label: "URL:",
                   download_format_label: "Format:",
                   download_start_btn: "START DOWNLOAD",
                   download_open_file_btn: "Open File",
                   download_open_folder_btn: "Open Folder",
                   download_status_starting: "Starting...",
                   download_status_finished: "Download Finished!",
                   download_status_error: "Error:",
                   download_deps_missing: "Requires external tools (Can be deleted later):",
                   download_deps_ytdlp: "yt-dlp:",
                   download_deps_ffmpeg: "ffmpeg:",
                   download_deps_download_btn: "Download",
                   download_status_ready: "✅ Ready",
                   download_status_extracting: "Extracting...",
                   download_cancel_btn: "Cancel",
                   download_file_label: "File:",
                   download_size_label: "Size:",
                   download_change_folder_btn: "Change Folder...",

                   download_progress_info_fmt: "{}% of {}, at {}, ETA {}",
                   download_advanced_header: "Advanced Features",
                   download_opt_metadata: "Full Metadata (Thumbnail, Chapters, Info)",
                   download_opt_sponsorblock: "SponsorBlock (Remove sponsors/intros)",
                   download_opt_subtitles: "Download Subtitles (Embed/SRT)",
                   download_opt_playlist: "Process Playlist",
                   download_opt_cookies: "Use Browser Cookies (For Premium/Age-gated):",
                   download_scan_ignore_btn: "DOWNLOAD NOW (Ignore Quality Scan)",
                   download_quality_label_text: "Quality:",
                   download_quality_best: "Best",
                   download_scanning_label: "(Scanning...)",
                   download_no_cookie_option: "No cookies used",
                   download_show_log_btn: "Show Error Log",
                   download_hide_log_btn: "Hide Error Log",
                    download_subtitle_label: "Subtitles:",
                    download_subtitle_auto: "Auto",
                    download_subs_found_header: "Languages found",
                    download_subs_none_found: "No subtitles found",

                   downloaded_tools_button: "Downloaded Tools",
                   downloaded_tools_title: "Downloaded Tools Manager",
                   tool_parakeet: "Parakeet Realtime Model",
                   tool_ytdlp: "yt-dlp Tool",
                   tool_ffmpeg: "ffmpeg Tool",
                   tool_status_installed: "Installed ({})",
                   tool_status_missing: "Not installed",
                   tool_action_download: "Download",
                   tool_action_delete: "Delete",
                   tool_desc_parakeet: "Used in Cabin Translation and as the \"Stream offline\" model in Audio->Text node",
                   tool_desc_ytdlp: "Used in Media Download feature",
                   tool_desc_ffmpeg: "Used in Media Download feature",
                   tool_update_checking: "Checking...",
                   tool_update_latest: "Latest",
                   tool_update_check_again: "Check Again",
                   tool_update_error: "Error",
                   tool_update_retry: "Retry",
                   tool_update_check_btn: "Check Update",
                   tool_update_available: "Update ({})",
                   continuous_mode_activated: "✨ Preset \"{preset}\" will run continuously. Press ESC or {hotkey} to exit",
                  },
                }
    }
}
</file>

<file path="src/main.rs">
#![cfg_attr(not(debug_assertions), windows_subsystem = "windows")]

mod api;
mod assets;
mod config;
mod debug_log;
pub mod gui;
mod history;
mod icon_gen;
mod model_config;
mod overlay;
mod registry_integration;
mod updater;
pub mod win_types;

use config::{load_config, Config, ThemeMode};
use gui::locale::LocaleText;
use history::HistoryManager;
use lazy_static::lazy_static;
use std::collections::HashMap;
use std::panic;
use std::sync::{Arc, Mutex};
use tray_icon::menu::{CheckMenuItem, Menu, MenuItem};
use windows::core::*;
use windows::Win32::Foundation::*;
use windows::Win32::Graphics::Gdi::*;
use windows::Win32::System::Com::CoInitialize;
use windows::Win32::System::LibraryLoader::*;
use windows::Win32::System::Threading::*;
use windows::Win32::UI::Input::KeyboardAndMouse::*;
use windows::Win32::UI::WindowsAndMessaging::*;

// Window dimensions - Increased to accommodate two-column sidebar and longer text labels
pub const WINDOW_WIDTH: f32 = 1230.0;
pub const WINDOW_HEIGHT: f32 = 650.0;

// Modifier Constants for Hook
const MOD_ALT: u32 = 0x0001;
const MOD_CONTROL: u32 = 0x0002;
const MOD_SHIFT: u32 = 0x0004;
const MOD_WIN: u32 = 0x0008;

// Wrappers for thread-safe types now imported from win_types
use crate::win_types::{SendHandle, SendHhook, SendHwnd};

// Global event for inter-process restore signaling (manual-reset event)
lazy_static! {
    pub static ref RESTORE_EVENT: Option<SendHandle> = unsafe {
        CreateEventW(None, true, false, w!("Global\\ScreenGoatedToolboxRestoreEvent")).ok().map(SendHandle)
    };
    // Global handle for the listener window (for the mouse hook to post messages to)
    static ref LISTENER_HWND: Mutex<SendHwnd> = Mutex::new(SendHwnd::default());
    // Global handle for the mouse hook
    static ref MOUSE_HOOK: Mutex<SendHhook> = Mutex::new(SendHhook::default());
}

// 1. Define a wrapper for the GDI Handle to ensure we clean it up
pub struct GdiCapture {
    pub hbitmap: HBITMAP,
    pub width: i32,
    pub height: i32,
}

// Make it safe to send between threads (Handles are process-global in Windows GDI)
unsafe impl Send for GdiCapture {}
unsafe impl Sync for GdiCapture {}

impl Drop for GdiCapture {
    fn drop(&mut self) {
        unsafe {
            if !self.hbitmap.is_invalid() {
                let _ = DeleteObject(self.hbitmap.into());
            }
        }
    }
}

pub struct AppState {
    pub config: Config,
    pub screenshot_handle: Option<GdiCapture>,
    pub hotkeys_updated: bool,
    pub registered_hotkey_ids: Vec<i32>, // Track IDs of currently registered hotkeys
    // New: Track API usage limits (Key: Model Full Name, Value: "Remaining / Total")
    pub model_usage_stats: HashMap<String, String>,
    pub history: Arc<HistoryManager>,         // NEW
    pub last_active_window: Option<SendHwnd>, // NEW: Store window handle for auto-paste focus restoration
}

lazy_static! {
    pub static ref APP: Arc<Mutex<AppState>> = Arc::new(Mutex::new({
        let config = load_config();
        let history = Arc::new(HistoryManager::new(config.max_history_items));
        AppState {
            config,
            screenshot_handle: None,
            hotkeys_updated: false,
            registered_hotkey_ids: Vec::new(),
            model_usage_stats: HashMap::new(),
            history,
            last_active_window: None, // NEW
        }
    }));
}

/// Enable dark mode for Win32 native menus (context menus, tray menus)
/// This uses the undocumented SetPreferredAppMode API from uxtheme.dll
fn enable_dark_mode_for_app() {
    use windows::core::w;
    use windows::Win32::System::LibraryLoader::{GetProcAddress, LoadLibraryW};

    // PreferredAppMode enum values
    const ALLOW_DARK: u32 = 1; // AllowDark mode

    unsafe {
        // Load uxtheme.dll
        if let Ok(uxtheme) = LoadLibraryW(w!("uxtheme.dll")) {
            // SetPreferredAppMode is at ordinal 135 (undocumented)
            // MAKEINTRESOURCEA(135) is just the number 135 cast to PCSTR
            let ordinal = 135u16;
            let ordinal_ptr = ordinal as usize as *const u8;
            let proc_name = windows::core::PCSTR::from_raw(ordinal_ptr);

            if let Some(set_preferred_app_mode) = GetProcAddress(uxtheme, proc_name) {
                // Cast to function pointer: fn(u32) -> u32
                let func: extern "system" fn(u32) -> u32 =
                    std::mem::transmute(set_preferred_app_mode);
                func(ALLOW_DARK);
            }
        }
    }
}

/// Cleanup temporary files left by the application (e.g. restart scripts, partial downloads)
fn cleanup_temporary_files() {
    // 1. Clean up restart scripts in %TEMP%
    let temp_dir = std::env::temp_dir();
    if let Ok(entries) = std::fs::read_dir(&temp_dir) {
        for entry in entries.flatten() {
            let name = entry.file_name();
            let name_str = name.to_string_lossy();
            if name_str.starts_with("sgt_restart_") && name_str.ends_with(".bat") {
                let _ = std::fs::remove_file(entry.path());
            }
        }
    }

    // 2. Clean up partial downloads in the app's bin directory
    let bin_dir = dirs::data_local_dir()
        .unwrap_or_else(|| std::path::PathBuf::from("."))
        .join("screen-goated-toolbox")
        .join("bin");

    if bin_dir.exists() {
        if let Ok(entries) = std::fs::read_dir(&bin_dir) {
            for entry in entries.flatten() {
                let path = entry.path();
                if path.extension().map_or(false, |ext| ext == "tmp") {
                    let _ = std::fs::remove_file(&path);
                }
            }
        }
    }

    // 3. Clean up any update-related files in current directory
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(exe_dir) = exe_path.parent() {
            let temp_download = exe_dir.join("temp_download");
            if temp_download.exists() {
                let _ = std::fs::remove_file(temp_download);
            }
        }
    }
}

mod unpack_dlls;

fn main() -> eframe::Result<()> {
    crate::log_info!("========================================");
    crate::log_info!(
        "Screen Goated Toolbox v{} STARTUP",
        env!("CARGO_PKG_VERSION")
    );
    crate::log_info!("========================================");

    // --- UNPACK DLLS ---
    // Extract embedded CRT and DirectML DLLs so the app is truly portable
    unpack_dlls::unpack_dlls();

    // --- CLEANUP TEMP FILES ---
    // Remove leftover restart scripts or partial downloads
    cleanup_temporary_files();

    // --- ENSURE CONTEXT MENU ENTRY ---
    crate::log_info!("Ensuring context menu entry...");
    registry_integration::ensure_context_menu_entry();
    crate::log_info!("Context menu entry ensured.");

    // --- INIT COM ---
    // Essential for Tray Icon and Shell interactions, especially in Admin/Task Scheduler context.
    unsafe {
        let _ = CoInitialize(None);
        // Force Per-Monitor V2 DPI Awareness for correct screen metrics and sharp visuals
        if let Ok(hidpi) = LoadLibraryW(w!("user32.dll")) {
            if let Some(set_context) = GetProcAddress(
                hidpi,
                PCSTR::from_raw("SetProcessDpiAwarenessContext\0".as_ptr()),
            ) {
                let func: extern "system" fn(isize) -> BOOL = std::mem::transmute(set_context);
                // -4 is DPI_AWARENESS_CONTEXT_PER_MONITOR_AWARE_V2
                let _ = func(-4);
            }
        }
    }

    // --- ENABLE DARK MODE FOR NATIVE MENUS ---
    // Uses undocumented Windows API to make context menus respect system dark theme
    enable_dark_mode_for_app();

    // --- APPLY PENDING UPDATE ---
    if let Ok(exe_path) = std::env::current_exe() {
        if let Some(exe_dir) = exe_path.parent() {
            let staging_path = exe_dir.join("update_pending.exe");
            let backup_path = exe_path.with_extension("exe.old");

            // If there's a pending update, apply it
            if staging_path.exists() {
                // Backup current exe
                let _ = std::fs::copy(&exe_path, &backup_path);
                // Replace with staged exe
                if std::fs::rename(&staging_path, &exe_path).is_ok() {
                    // Success - cleanup temp file
                    let _ = std::fs::remove_file("temp_download");
                }
            }

            // --- CLEANUP OLD EXE FILES ---
            let current_exe_name = exe_path.file_name().and_then(|n| n.to_str()).unwrap_or("");
            if let Ok(entries) = std::fs::read_dir(exe_dir) {
                for entry in entries.filter_map(|e| e.ok()) {
                    let file_name = entry.file_name();
                    let name_str = file_name.to_string_lossy();

                    // Delete old ScreenGoatedToolbox_v*.exe files (keep only current)
                    if (name_str.starts_with("ScreenGoatedToolbox_v") && name_str.ends_with(".exe"))
                        && name_str.as_ref() != current_exe_name
                    {
                        let _ = std::fs::remove_file(entry.path());
                    }

                    // Delete .old backup files
                    if name_str.ends_with(".exe.old") {
                        let _ = std::fs::remove_file(entry.path());
                    }
                }
            }
        }
    }

    // --- CRASH HANDLER START ---
    panic::set_hook(Box::new(|panic_info| {
        // 1. Format the error message
        let location = if let Some(location) = panic_info.location() {
            format!("File: {}\nLine: {}", location.file(), location.line())
        } else {
            "Unknown location".to_string()
        };

        let payload = if let Some(s) = panic_info.payload().downcast_ref::<&str>() {
            s.to_string()
        } else if let Some(s) = panic_info.payload().downcast_ref::<String>() {
            s.clone()
        } else {
            "Unknown panic payload".to_string()
        };

        let error_msg = format!(
            "CRASH DETECTED!\n\nError: {}\n\nLocation:\n{}",
            payload, location
        );

        // Show a Windows Message Box so the user knows it crashed
        let wide_msg: Vec<u16> = error_msg.encode_utf16().chain(std::iter::once(0)).collect();
        let wide_title: Vec<u16> = "SGT Crash Report"
            .encode_utf16()
            .chain(std::iter::once(0))
            .collect();

        unsafe {
            MessageBoxW(
                None,
                PCWSTR(wide_msg.as_ptr()),
                PCWSTR(wide_title.as_ptr()),
                MB_ICONERROR | MB_OK,
            );
        }
    }));
    // --- CRASH HANDLER END ---

    // Ensure the named event exists (for first instance, for second instance to signal)
    let _ = RESTORE_EVENT.as_ref();

    // Keep the handle alive for the duration of the program
    let _single_instance_mutex = unsafe {
        let instance = CreateMutexW(
            None,
            true,
            w!("Global\\ScreenGoatedToolboxSingleInstanceMutex"),
        );
        if let Ok(handle) = instance {
            if GetLastError() == ERROR_ALREADY_EXISTS {
                // Another instance is running - pass arguments via temp file and signal it
                let args: Vec<String> = std::env::args().collect();
                for arg in args.iter().skip(1) {
                    if arg.starts_with("--") {
                        continue;
                    }
                    let path = std::path::PathBuf::from(arg);
                    if path.exists() && path.is_file() {
                        let temp_file = std::env::temp_dir().join("sgt_pending_file.txt");
                        if let Ok(mut f) = std::fs::File::create(temp_file) {
                            use std::io::Write;
                            let _ = write!(f, "{}", path.to_string_lossy());
                        }
                        break;
                    }
                }

                if let Some(event) = RESTORE_EVENT.as_ref() {
                    let _ = SetEvent(event.0);
                }
                let _ = CloseHandle(handle);
                // Exit successfully after signaling
                return Ok(());
            }
            Some(handle)
        } else {
            None
        }
    };

    std::thread::spawn(|| {
        run_hotkey_listener();
    });

    // Initialize TTS for instant speech synthesis
    api::tts::init_tts();

    // Initialize Gemini Live LLM connection pool
    api::gemini_live::init_gemini_live();

    // --- CHECK FOR RESTARTED FLAG AND FILE ARGUMENTS ---
    let args: Vec<String> = std::env::args().collect();
    let mut pending_file_path: Option<std::path::PathBuf> = None;

    if args.iter().any(|arg| arg == "--restarted") {
        std::thread::spawn(|| {
            // Wait for app and overlays to settle before showing notification
            std::thread::sleep(std::time::Duration::from_millis(2500));
            overlay::auto_copy_badge::show_update_notification(
                "Đã khởi động lại app để khôi phục hoàn toàn",
            );
        });
    }

    // Check for potential file path in arguments (drag-and-drop or context menu)
    for arg in args.iter().skip(1) {
        // Skip flags
        if arg.starts_with("--") {
            continue;
        }
        let path = std::path::PathBuf::from(arg);
        if path.exists() && path.is_file() {
            crate::log_info!("Check arguments: Found valid file path: {:?}", path);
            pending_file_path = Some(path);
            break; // Handle only one file for now
        } else {
            crate::log_info!("Check arguments: Invalid path or not a file: {:?}", arg);
        }
    }

    // --- CLEAR WEBVIEW DATA IF SCHEDULED (before any WebViews are created) ---
    {
        let mut config = APP.lock().unwrap();
        if config.config.clear_webview_on_startup {
            // Clear WebView data - should succeed since no WebViews exist yet
            overlay::clear_webview_permissions();
            // Reset the flag
            config.config.clear_webview_on_startup = false;
            // Save immediately
            config::save_config(&config.config);
        }
    }

    // Offload warmups to a sequenced thread to prevent splash screen lag
    std::thread::spawn(|| {
        // 0. Warmup fonts first (download/cache for instant display)
        // This runs in background and should complete before first WebView loads
        overlay::html_components::font_manager::warmup_fonts();

        // Helper: Wait for tray popup to close before proceeding
        // This prevents WebView2 focus stealing from closing the popup
        let wait_for_popup_close = || {
            while overlay::tray_popup::is_popup_open() {
                std::thread::sleep(std::time::Duration::from_millis(100));
            }
        };

        // 1. Start warmups immediately so they are DONE before the splash appears.
        // This ensures the tray popup and bubble are high-priority and ready.
        std::thread::sleep(std::time::Duration::from_millis(100));

        // 1. Warmup tray popup (with is_warmup=true to avoid focus stealing)
        wait_for_popup_close();
        overlay::tray_popup::warmup_tray_popup();

        // 1.5 Warmup preset wheel (persistent hidden window)
        overlay::preset_wheel::warmup();

        // 2. Wait for splash screen / main box to appear and settle
        std::thread::sleep(std::time::Duration::from_millis(3000));

        // 3. Warmup text input window first (more likely to be used quickly)
        wait_for_popup_close();
        overlay::text_input::warmup();

        // 3.5 Warmup auto copy badge
        wait_for_popup_close();
        overlay::auto_copy_badge::warmup();

        // 3.75 Warmup text selection tag (native GDI)
        wait_for_popup_close();
        overlay::text_selection::warmup();

        // 7. Wait before realtime warmup (Wait duration preserved for safety)
        std::thread::sleep(std::time::Duration::from_millis(5000));

        // 9. Warmup Recording Overlay
        wait_for_popup_close();
        overlay::recording::warmup_recording_overlay();
    });

    // 1. Load config early to get theme setting and language for tray i18n
    let initial_config = APP.lock().unwrap().config.clone();

    // --- TRAY MENU SETUP (with i18n) ---
    let tray_locale = LocaleText::get(&initial_config.ui_language);
    let tray_menu = Menu::new();

    // Favorite bubble toggle - check if any presets are favorited
    let has_favorites = initial_config.presets.iter().any(|p| p.is_favorite);
    let favorite_bubble_text = if has_favorites {
        tray_locale.tray_favorite_bubble
    } else {
        tray_locale.tray_favorite_bubble_disabled
    };
    let tray_favorite_bubble_item = CheckMenuItem::with_id(
        "1003",
        favorite_bubble_text,
        has_favorites, // enabled only if has favorites
        initial_config.show_favorite_bubble && has_favorites,
        None,
    );

    let tray_settings_item = MenuItem::with_id("1002", tray_locale.tray_settings, true, None);
    let tray_quit_item = MenuItem::with_id("1001", tray_locale.tray_quit, true, None);
    let _ = tray_menu.append(&tray_favorite_bubble_item);
    let _ = tray_menu.append(&tray_settings_item);
    let _ = tray_menu.append(&tray_quit_item);

    // --- WINDOW SETUP ---
    let mut viewport_builder = eframe::egui::ViewportBuilder::default()
        .with_inner_size([WINDOW_WIDTH, WINDOW_HEIGHT])
        .with_resizable(true)
        .with_visible(false) // Start invisible
        .with_transparent(true)
        .with_decorations(false); // Enable custom title bar by disabling native decorations

    // 2. Detect System Theme
    let system_dark = gui::utils::is_system_in_dark_mode();

    // 3. Resolve Initial Theme
    let effective_dark = match initial_config.theme_mode {
        ThemeMode::Dark => true,
        ThemeMode::Light => false,
        ThemeMode::System => system_dark,
    };

    // 4. Use Effective Theme for initial icon
    let icon_data = crate::icon_gen::get_window_icon(effective_dark);
    viewport_builder = viewport_builder.with_icon(std::sync::Arc::new(icon_data));

    let options = eframe::NativeOptions {
        viewport: viewport_builder,
        ..Default::default()
    };

    eframe::run_native(
        "Screen Goated Toolbox (SGT by nganlinh4)",
        options,
        Box::new(move |cc| {
            gui::configure_fonts(&cc.egui_ctx);

            // Store global context for background threads
            *gui::GUI_CONTEXT.lock().unwrap() = Some(cc.egui_ctx.clone());

            // 5. Set Initial Visuals Explicitly
            if effective_dark {
                cc.egui_ctx.set_visuals(eframe::egui::Visuals::dark());
            } else {
                cc.egui_ctx.set_visuals(eframe::egui::Visuals::light());
            }

            // 6. Set Native Icon
            gui::utils::update_window_icon_native(effective_dark);

            Ok(Box::new(gui::SettingsApp::new(
                initial_config,
                APP.clone(),
                tray_menu,
                tray_settings_item,
                tray_quit_item,
                tray_favorite_bubble_item,
                cc.egui_ctx.clone(),
                pending_file_path,
            )))
        }),
    )
}

pub fn register_all_hotkeys(hwnd: HWND) {
    let mut app = APP.lock().unwrap();
    let presets = &app.config.presets;

    let mut registered_ids = Vec::new();
    for (p_idx, preset) in presets.iter().enumerate() {
        for (h_idx, hotkey) in preset.hotkeys.iter().enumerate() {
            // ID encoding: 1000 * preset_idx + hotkey_idx + 1

            // Skip Mouse Buttons for RegisterHotKey (handled via hook)
            if [0x04, 0x05, 0x06].contains(&hotkey.code) {
                continue;
            }

            let id = (p_idx as i32 * 1000) + (h_idx as i32) + 1;
            unsafe {
                let _ = RegisterHotKey(
                    Some(hwnd),
                    id,
                    HOT_KEY_MODIFIERS(hotkey.modifiers),
                    hotkey.code,
                );
            }
            registered_ids.push(id);
        }
    }
    app.registered_hotkey_ids = registered_ids;

    // Register Global Screen Record Hotkeys (IDs: 9900-9999)
    for (idx, sr_hotkey) in app.config.screen_record_hotkeys.iter().enumerate() {
        if idx >= 100 {
            break;
        } // Max 100 SR hotkeys
        let id = 9900 + idx as i32;
        unsafe {
            let _ = RegisterHotKey(
                Some(hwnd),
                id,
                HOT_KEY_MODIFIERS(sr_hotkey.modifiers),
                sr_hotkey.code,
            );
        }
    }
}

pub fn unregister_all_hotkeys(hwnd: HWND) {
    let app = APP.lock().unwrap();
    for &id in &app.registered_hotkey_ids {
        unsafe {
            let _ = UnregisterHotKey(Some(hwnd), id);
        }
    }
    // Unregister Global SR Hotkeys
    for idx in 0..100 {
        unsafe {
            let _ = UnregisterHotKey(Some(hwnd), 9900 + idx);
        }
    }
}

// Low-Level Mouse Hook Procedure
unsafe extern "system" fn mouse_hook_proc(code: i32, wparam: WPARAM, lparam: LPARAM) -> LRESULT {
    if code >= 0 {
        let msg = wparam.0 as u32;
        let vk_code = match msg {
            WM_LBUTTONDOWN | WM_RBUTTONDOWN | WM_MBUTTONDOWN => {
                crate::overlay::screen_record::engine::IS_MOUSE_CLICKED
                    .store(true, std::sync::atomic::Ordering::SeqCst);
                if msg == WM_MBUTTONDOWN {
                    Some(0x04)
                } else {
                    None
                }
            }
            WM_LBUTTONUP | WM_RBUTTONUP | WM_MBUTTONUP => {
                // crate::log_info!("Mouse UP"); // Verify hook activity
                crate::overlay::screen_record::engine::IS_MOUSE_CLICKED
                    .store(false, std::sync::atomic::Ordering::SeqCst);
                None
            }
            WM_XBUTTONDOWN => {
                crate::overlay::screen_record::engine::IS_MOUSE_CLICKED
                    .store(true, std::sync::atomic::Ordering::SeqCst);
                let info = *(lparam.0 as *const MSLLHOOKSTRUCT);
                let xbutton = (info.mouseData >> 16) & 0xFFFF;
                if xbutton == 1 {
                    Some(0x05)
                }
                // VK_XBUTTON1
                else if xbutton == 2 {
                    Some(0x06)
                }
                // VK_XBUTTON2
                else {
                    None
                }
            }
            WM_XBUTTONUP => {
                crate::overlay::screen_record::engine::IS_MOUSE_CLICKED
                    .store(false, std::sync::atomic::Ordering::SeqCst);
                None
            }
            _ => None,
        };

        if let Some(vk) = vk_code {
            // Check modifiers using GetAsyncKeyState for real-time state
            let mut mods = 0;
            if (GetAsyncKeyState(VK_MENU.0 as i32) as u16 & 0x8000) != 0 {
                mods |= MOD_ALT;
            }
            if (GetAsyncKeyState(VK_CONTROL.0 as i32) as u16 & 0x8000) != 0 {
                mods |= MOD_CONTROL;
            }
            if (GetAsyncKeyState(VK_SHIFT.0 as i32) as u16 & 0x8000) != 0 {
                mods |= MOD_SHIFT;
            }
            if (GetAsyncKeyState(VK_LWIN.0 as i32) as u16 & 0x8000) != 0
                || (GetAsyncKeyState(VK_RWIN.0 as i32) as u16 & 0x8000) != 0
            {
                mods |= MOD_WIN;
            }

            // Check config for a match
            let mut found_id = None;
            if let Ok(app) = APP.lock() {
                for (p_idx, preset) in app.config.presets.iter().enumerate() {
                    for (h_idx, hotkey) in preset.hotkeys.iter().enumerate() {
                        if hotkey.code == vk && hotkey.modifiers == mods {
                            // Synthesize ID same as register_all_hotkeys
                            found_id = Some((p_idx as i32 * 1000) + (h_idx as i32) + 1);
                            break;
                        }
                    }
                    if found_id.is_some() {
                        break;
                    }
                }

                // Check Global Screen Record Hotkeys
                if found_id.is_none() {
                    for (idx, sr_hk) in app.config.screen_record_hotkeys.iter().enumerate() {
                        if sr_hk.code == vk && sr_hk.modifiers == mods {
                            found_id = Some(9900 + idx as i32);
                            break;
                        }
                    }
                }
            }

            if let Some(id) = found_id {
                if let Ok(hwnd_target) = LISTENER_HWND.lock() {
                    if !hwnd_target.0.is_invalid() {
                        // Post WM_HOTKEY to the listener window logic
                        let _ = PostMessageW(
                            Some(hwnd_target.0),
                            WM_HOTKEY,
                            WPARAM(id as usize),
                            LPARAM(0),
                        );
                        return LRESULT(1); // Consume/Block input
                    }
                }
            }
        }
    }
    CallNextHookEx(None, code, wparam, lparam)
}

const WM_RELOAD_HOTKEYS: u32 = WM_USER + 101;
const WM_APP_PROCESS_PENDING_FILE: u32 = WM_USER + 102;
const WM_UNREGISTER_HOTKEYS: u32 = WM_USER + 103;
const WM_REGISTER_HOTKEYS: u32 = WM_USER + 104;

fn run_hotkey_listener() {
    unsafe {
        // Error handling: GetModuleHandleW should not fail, but handle it
        let instance = match GetModuleHandleW(None) {
            Ok(h) => h,
            Err(_) => {
                eprintln!("Error: Failed to get module handle for hotkey listener");
                return;
            }
        };

        let class_name = w!("HotkeyListenerClass");

        let wc = WNDCLASSW {
            lpfnWndProc: Some(hotkey_proc),
            hInstance: instance.into(),
            lpszClassName: class_name,
            ..Default::default()
        };

        // RegisterClassW can fail if class already exists, which is okay
        let _ = RegisterClassW(&wc);

        let hwnd = CreateWindowExW(
            WINDOW_EX_STYLE::default(),
            class_name,
            w!("Listener"),
            WS_OVERLAPPEDWINDOW,
            0,
            0,
            0,
            0,
            None,
            None,
            Some(instance.into()),
            None,
        )
        .unwrap_or_default();

        // Error handling: hwnd is invalid if creation failed
        if hwnd.is_invalid() {
            eprintln!("Error: Failed to create hotkey listener window");
            return;
        }

        // Store HWND for the hook
        if let Ok(mut guard) = LISTENER_HWND.lock() {
            *guard = SendHwnd(hwnd);
        }

        // Spawn thread to wait for RESTORE_EVENT
        let listener_hwnd_val = hwnd.0 as isize;
        std::thread::spawn(move || {
            if let Some(event) = RESTORE_EVENT.as_ref() {
                loop {
                    // Wait indefinitely for signal
                    if WaitForSingleObject(event.0, INFINITE) == WAIT_OBJECT_0 {
                        // Signal received! Post message to main thread/listener window
                        let _ = PostMessageW(
                            Some(HWND(listener_hwnd_val as *mut _)),
                            WM_APP_PROCESS_PENDING_FILE,
                            WPARAM(0),
                            LPARAM(0),
                        );
                        // Reset event to wait for next signal
                        let _ = ResetEvent(event.0);
                    }
                }
            }
        });

        // Install Mouse Hook
        if let Ok(hhook) =
            SetWindowsHookExW(WH_MOUSE_LL, Some(mouse_hook_proc), Some(instance.into()), 0)
        {
            println!("DEBUG: Mouse hook installed successfully");
            if let Ok(mut hook_guard) = MOUSE_HOOK.lock() {
                *hook_guard = SendHhook(hhook);
            }
        } else {
            eprintln!("Warning: Failed to install low-level mouse hook");
        }

        register_all_hotkeys(hwnd);

        let mut msg = MSG::default();
        loop {
            if GetMessageW(&mut msg, None, 0, 0).as_bool() {
                if msg.message == WM_RELOAD_HOTKEYS {
                    unregister_all_hotkeys(hwnd);
                    register_all_hotkeys(hwnd);

                    if let Ok(mut app) = APP.lock() {
                        app.hotkeys_updated = false;
                    }
                } else if msg.message == WM_UNREGISTER_HOTKEYS {
                    unregister_all_hotkeys(hwnd);
                } else if msg.message == WM_REGISTER_HOTKEYS {
                    register_all_hotkeys(hwnd);
                } else {
                    let _ = TranslateMessage(&msg);
                    DispatchMessageW(&msg);
                }
            }
        }
    }
}

unsafe extern "system" fn hotkey_proc(
    hwnd: HWND,
    msg: u32,
    wparam: WPARAM,
    lparam: LPARAM,
) -> LRESULT {
    match msg {
        WM_APP_PROCESS_PENDING_FILE => {
            // Read temp file
            let temp_file = std::env::temp_dir().join("sgt_pending_file.txt");
            if temp_file.exists() {
                if let Ok(content) = std::fs::read_to_string(&temp_file) {
                    let path = std::path::PathBuf::from(content.trim());
                    if path.exists() {
                        crate::log_info!("HOTKEY LISTENER: Processing pending file: {:?}", path);
                        // Spawn a thread to avoid blocking the hotkey listener (hook) thread
                        let path_clone = path.clone();
                        std::thread::spawn(move || {
                            crate::gui::app::input_handler::process_file_path(&path_clone);
                        });
                    }
                }
                // Cleanup
                let _ = std::fs::remove_file(temp_file);
            }
            LRESULT(0)
        }
        WM_HOTKEY => {
            let id = wparam.0 as i32;
            if id >= 9900 && id <= 9999 {
                // Toggle Screen Recording
                crate::overlay::screen_record::toggle_recording();
                return LRESULT(0);
            }
            if id > 0 {
                // debounce logic
                static mut LAST_HOTKEY_TIMESTAMP: Option<std::time::Instant> = None;

                let now = std::time::Instant::now();
                let is_repeat = unsafe {
                    if let Some(t) = LAST_HOTKEY_TIMESTAMP {
                        // 150ms debounce
                        if now.duration_since(t).as_millis() < 150 {
                            true
                        } else {
                            LAST_HOTKEY_TIMESTAMP = Some(now);
                            false
                        }
                    } else {
                        LAST_HOTKEY_TIMESTAMP = Some(now);
                        false
                    }
                };

                // Valid Hotkey Received - Update Heartbeat
                if !is_repeat {
                    overlay::continuous_mode::reset_heartbeat();
                }
                overlay::continuous_mode::update_last_trigger_time();

                if is_repeat {
                    return LRESULT(0);
                }

                // Check if continuous mode is active or pending
                let mut just_activated_continuous = false;
                if overlay::continuous_mode::is_active() {
                    // Continuous mode is ACTIVE.
                    // Ignore ALL hotkey presses - let the keyboard hooks handle exit (ESC or hotkey tap).
                    // This prevents deactivation during text processing when tag is hidden.
                    return LRESULT(0);
                } else if overlay::continuous_mode::is_pending_start() {
                    // Scenario 2. Continuous Mode is PENDING (e.g. from Bubble).
                    // We must NOT cancel. We promote to ACTIVE and let the logic proceed to trigger the preset.
                    let current = overlay::continuous_mode::get_preset_idx();
                    let hotkey = overlay::continuous_mode::get_hotkey_name();
                    overlay::continuous_mode::activate(current, hotkey);
                    just_activated_continuous = true;
                    // Do NOT return. Proceed to trigger logic below.
                }

                // CRITICAL: If preset wheel is active, dismiss it and return early
                // This allows pressing the hotkey again to dismiss the wheel
                if overlay::preset_wheel::is_wheel_active() {
                    overlay::preset_wheel::dismiss_wheel();
                    return LRESULT(0);
                }

                let preset_idx = ((id - 1) / 1000) as usize;

                // Determine context and fetch hotkey name
                let (preset_type, text_mode, is_audio_stopping, hotkey_name) = {
                    if let Ok(app) = APP.lock() {
                        if preset_idx < app.config.presets.len() {
                            let p = &app.config.presets[preset_idx];
                            let p_type = p.preset_type.clone();
                            let t_mode = p.text_input_mode.clone();
                            let stopping =
                                p_type == "audio" && overlay::is_recording_overlay_active();

                            // Find the specific hotkey name that triggered this
                            let hk_idx = ((id - 1) % 1000) as usize;
                            let hk_name = if hk_idx < p.hotkeys.len() {
                                // Store hotkey info for continuous mode detection
                                let hk = &p.hotkeys[hk_idx];
                                if overlay::continuous_mode::supports_continuous_mode(&p_type) {
                                    crate::log_info!("[Hotkey] Setting current hotkey for hold detection: mods={}, code={}, name='{}'", hk.modifiers, hk.code, hk.name);
                                    overlay::continuous_mode::set_current_hotkey(
                                        hk.modifiers,
                                        hk.code,
                                    );
                                    overlay::continuous_mode::set_latest_hotkey_name(
                                        hk.name.clone(),
                                    );
                                }
                                hk.name.clone()
                            } else {
                                String::new()
                            };

                            (p_type, t_mode, stopping, hk_name)
                        } else {
                            (
                                "image".to_string(),
                                "select".to_string(),
                                false,
                                String::new(),
                            )
                        }
                    } else {
                        (
                            "image".to_string(),
                            "select".to_string(),
                            false,
                            String::new(),
                        )
                    }
                };

                // FIX: Only capture target window if we are NOT stopping an audio recording.
                if !is_audio_stopping {
                    let target_window = crate::overlay::utils::get_target_window_for_paste();

                    if let Ok(mut app) = APP.lock() {
                        app.last_active_window = target_window.map(crate::win_types::SendHwnd);
                    }
                }

                if preset_type == "audio" {
                    // Check for realtime mode
                    let is_realtime = {
                        if let Ok(app) = APP.lock() {
                            if preset_idx < app.config.presets.len() {
                                app.config.presets[preset_idx].audio_processing_mode == "realtime"
                            } else {
                                false
                            }
                        } else {
                            false
                        }
                    };

                    if is_realtime {
                        // Realtime mode - toggle realtime overlay
                        // Check if minimal or webview is active
                        let is_minimal_active = overlay::realtime_egui::MINIMAL_ACTIVE
                            .load(std::sync::atomic::Ordering::SeqCst);
                        let is_webview_active = overlay::is_realtime_overlay_active();

                        if is_webview_active {
                            // WebView active - stop it (toggle off)
                            overlay::stop_realtime_overlay();
                        } else if is_minimal_active {
                            // Minimal egui active - do NOT allow hotkey to close (user must use window X)
                            // This prevents buggy behavior
                        } else {
                            // Nothing active - Start
                            std::thread::spawn(move || {
                                overlay::show_realtime_overlay(preset_idx);
                            });
                        }
                    } else {
                        // Record-then-process mode
                        if overlay::is_recording_overlay_active() {
                            overlay::stop_recording_and_submit();
                        } else {
                            std::thread::spawn(move || {
                                overlay::show_recording_overlay(preset_idx);
                            });
                        }
                    }
                } else if preset_type == "text" {
                    // NEW TEXT LOGIC
                    if text_mode == "select" {
                        // Toggle Logic for Selection
                        if overlay::text_selection::is_active()
                            || overlay::text_selection::is_warming_up()
                        {
                            // Ignore repeat hotkeys to allow "hold to activate" or during warmup
                            overlay::continuous_mode::update_last_trigger_time();
                            return LRESULT(0);
                        } else if overlay::continuous_mode::is_active()
                            && !just_activated_continuous
                        {
                            // Continuous mode is active - the worker thread's retrigger handles showing the tag
                            // Just ignore hotkey repeats to prevent duplicate notifications
                            overlay::continuous_mode::update_last_trigger_time();
                            return LRESULT(0);
                        } else {
                            // NEW: Try instant processing if text is already selected
                            // Prevent duplicate processing if already running
                            if overlay::text_selection::is_processing() {
                                return LRESULT(0);
                            }

                            std::thread::spawn(move || {
                                // 1. Show Badge IMMEDIATELY (Decoupled)
                                overlay::show_text_selection_tag(preset_idx);

                                // 2. Try processing in background
                                let success =
                                    overlay::text_selection::try_instant_process(preset_idx);

                                if success {
                                    // If we successfully processed text, we don't need the badge anymore.
                                    overlay::text_selection::cancel_selection();
                                }
                            });
                        }
                    } else {
                        // Type Mode - Toggle Logic for Input Window
                        if overlay::text_input::is_active() {
                            overlay::text_input::cancel_input();
                        } else {
                            if let Ok(app) = APP.lock() {
                                let config = app.config.clone();
                                let preset = config.presets[preset_idx].clone();
                                let screen_w = GetSystemMetrics(SM_CXSCREEN);
                                let screen_h = GetSystemMetrics(SM_CYSCREEN);
                                let center_rect = RECT {
                                    left: (screen_w - 700) / 2,
                                    top: (screen_h - 300) / 2,
                                    right: (screen_w + 700) / 2,
                                    bottom: (screen_h + 300) / 2,
                                };

                                // Get localized preset name for display
                                let localized_name = gui::settings_ui::get_localized_preset_name(
                                    &preset.id,
                                    &config.ui_language,
                                );

                                let hotkey_name_clone = hotkey_name.clone();
                                std::thread::spawn(move || {
                                    overlay::process::start_text_processing(
                                        String::new(),
                                        center_rect,
                                        config,
                                        preset,
                                        localized_name,
                                        hotkey_name_clone,
                                    );
                                });
                            }
                        }
                    }
                } else {
                    // Image Mode
                    // STRICT Debounce/Blocking for "Hold to Activate"
                    if overlay::is_busy() || overlay::is_selection_overlay_active() {
                        // User is still holding/pressing the key
                        overlay::continuous_mode::update_last_trigger_time();
                        return LRESULT(0);
                    }

                    // Set BUSY flag immediately on Main Thread to block repeats
                    overlay::set_is_busy(true);

                    let app_clone = APP.clone();
                    let mut p_idx = preset_idx;
                    std::thread::spawn(move || {
                        loop {
                            // 1. Capture Logic
                            match capture_screen_fast() {
                                Ok(capture) => {
                                    if let Ok(mut app) = app_clone.lock() {
                                        app.screenshot_handle = Some(capture);
                                    } else {
                                        break;
                                    }

                                    // 2. Show Overlay (BLOCKING)
                                    overlay::show_selection_overlay(p_idx);
                                }
                                Err(e) => {
                                    eprintln!("Capture Error: {}", e);
                                    break;
                                }
                            }

                            // 3. Check for exit or update preset
                            if !overlay::continuous_mode::is_active() {
                                break;
                            }

                            // Update p_idx in case it changed (e.g. from Master Preset wheel selection)
                            let current_active_idx = overlay::continuous_mode::get_preset_idx();
                            if current_active_idx != p_idx {
                                p_idx = current_active_idx;
                            }

                            // Small delay before retriggering to prevent tight looping
                            std::thread::sleep(std::time::Duration::from_millis(200));
                        }
                        // Ensure flag is cleared on exit
                        overlay::set_is_busy(false);
                    });
                }
            }
            LRESULT(0)
        }

        _ => DefWindowProcW(hwnd, msg, wparam, lparam),
    }
}

fn capture_screen_fast() -> anyhow::Result<GdiCapture> {
    unsafe {
        let x = GetSystemMetrics(SM_XVIRTUALSCREEN);
        let y = GetSystemMetrics(SM_YVIRTUALSCREEN);
        let width = GetSystemMetrics(SM_CXVIRTUALSCREEN);
        let height = GetSystemMetrics(SM_CYVIRTUALSCREEN);

        // Validate dimensions
        if width <= 0 || height <= 0 {
            return Err(anyhow::anyhow!(
                "GDI Error: Invalid screen dimensions ({} x {})",
                width,
                height
            ));
        }

        let hdc_screen = GetDC(None);
        if hdc_screen.is_invalid() {
            return Err(anyhow::anyhow!(
                "GDI Error: Failed to get screen device context"
            ));
        }

        let hdc_mem = CreateCompatibleDC(Some(hdc_screen));
        if hdc_mem.is_invalid() {
            let _ = ReleaseDC(None, hdc_screen);
            return Err(anyhow::anyhow!(
                "GDI Error: Failed to create compatible device context"
            ));
        }

        let hbitmap = CreateCompatibleBitmap(hdc_screen, width, height);

        if hbitmap.is_invalid() {
            let _ = DeleteDC(hdc_mem);
            let _ = ReleaseDC(None, hdc_screen);
            return Err(anyhow::anyhow!(
                "GDI Error: Failed to create compatible bitmap."
            ));
        }

        SelectObject(hdc_mem, hbitmap.into());

        // This is the only "heavy" part, but it's purely GPU/GDI memory move. Very fast.
        BitBlt(
            hdc_mem,
            0,
            0,
            width,
            height,
            Some(hdc_screen),
            x,
            y,
            SRCCOPY,
        )?;

        // Cleanup DCs, but KEEP the HBITMAP
        let _ = DeleteDC(hdc_mem);
        ReleaseDC(None, hdc_screen);

        Ok(GdiCapture {
            hbitmap,
            width,
            height,
        })
    }
}
</file>

</files>
